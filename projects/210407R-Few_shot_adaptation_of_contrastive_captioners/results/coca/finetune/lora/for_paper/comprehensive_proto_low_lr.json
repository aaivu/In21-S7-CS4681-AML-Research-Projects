{
  "exp_000_1shot_prototypical_augFalse_low_lr": {
    "config": {
      "n_shot": 1,
      "loss_type": "prototypical",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        4.671597719192505,
        4.492617845535278,
        4.3682050704956055,
        4.252080202102661,
        4.129472255706787,
        4.020467638969421,
        3.8864877223968506,
        3.766304850578308,
        3.662579894065857,
        3.5329350233078003,
        3.4430642127990723,
        3.312000036239624,
        3.211687207221985,
        3.1025125980377197,
        3.0137287378311157,
        2.9078917503356934,
        2.8045341968536377,
        2.7144615650177,
        2.6172618865966797,
        2.5343401432037354,
        2.449075937271118,
        2.3605023622512817,
        2.277497887611389,
        2.209913969039917,
        2.1386775970458984,
        2.055251955986023,
        1.989294171333313
      ],
      "val_accuracy": [
        2.0,
        8.0,
        19.0,
        41.0,
        61.0,
        75.0,
        87.0,
        93.0,
        98.0,
        99.0,
        99.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        5e-05,
        4.9980725906018074e-05,
        4.99229333433282e-05,
        4.982671142387316e-05,
        4.9692208514878444e-05,
        4.951963201008076e-05,
        4.9309248009941914e-05,
        4.906138091134118e-05,
        4.877641290737884e-05,
        4.8454783398062106e-05,
        4.809698831278217e-05,
        4.770357934562703e-05,
        4.727516310470919e-05,
        4.681240017681993e-05,
        4.6316004108852305e-05,
        4.5786740307563636e-05,
        4.522542485937369e-05,
        4.463292327201862e-05,
        4.401014914000078e-05,
        4.3358062735892145e-05,
        4.267766952966369e-05,
        4.197001863832355e-05,
        4.1236201208254596e-05,
        4.0477348732745845e-05,
        3.969463130731182e-05,
        3.888925582549005e-05,
        3.806246411789872e-05
      ],
      "train_accuracy": [
        1.0,
        2.0,
        9.0,
        22.0,
        42.0,
        64.0,
        78.0,
        88.0,
        95.0,
        98.0,
        99.0,
        99.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 69.0,
      "mean_per_class_accuracy": 69.0,
      "total_samples": 2000,
      "correct_predictions": 1380
    },
    "training_time": 137.97228741645813,
    "best_epoch": 26
  },
  "exp_001_5shot_prototypical_augFalse_low_lr": {
    "config": {
      "n_shot": 5,
      "loss_type": "prototypical",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        5.195732951164246,
        4.663749396800995,
        4.416430503129959,
        3.840302735567093,
        3.605028808116913,
        3.6488768458366394,
        3.620838910341263,
        2.7186752259731293,
        2.7855130434036255,
        2.455946236848831,
        2.39064159989357,
        2.0375736504793167,
        1.8837629854679108,
        1.7677634060382843,
        1.7797141522169113,
        1.7222244888544083,
        1.9493710696697235,
        1.5998429507017136,
        1.329960785806179,
        1.6963046938180923,
        1.5395015180110931,
        1.3583847656846046,
        1.2079065814614296,
        1.4711825400590897,
        1.2065560668706894,
        1.2406592443585396,
        1.2478550896048546,
        1.280911035835743,
        0.9308299645781517,
        1.4234259128570557,
        1.040871500968933,
        1.5217781886458397,
        1.072829581797123,
        1.0458823889493942,
        1.0837192088365555,
        0.9312984049320221,
        0.8984159231185913,
        1.2186426669359207,
        0.8931420519948006
      ],
      "val_accuracy": [
        20.599999999999998,
        58.199999999999996,
        79.80000000000001,
        90.4,
        93.8,
        97.0,
        97.8,
        98.2,
        98.8,
        99.0,
        98.8,
        99.4,
        99.6,
        99.6,
        99.6,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        5e-05,
        4.9980725906018074e-05,
        4.99229333433282e-05,
        4.982671142387316e-05,
        4.9692208514878444e-05,
        4.951963201008076e-05,
        4.9309248009941914e-05,
        4.906138091134118e-05,
        4.877641290737884e-05,
        4.8454783398062106e-05,
        4.809698831278217e-05,
        4.770357934562703e-05,
        4.727516310470919e-05,
        4.681240017681993e-05,
        4.6316004108852305e-05,
        4.5786740307563636e-05,
        4.522542485937369e-05,
        4.463292327201862e-05,
        4.401014914000078e-05,
        4.3358062735892145e-05,
        4.267766952966369e-05,
        4.197001863832355e-05,
        4.1236201208254596e-05,
        4.0477348732745845e-05,
        3.969463130731182e-05,
        3.888925582549005e-05,
        3.806246411789872e-05,
        3.7215531037423875e-05,
        3.6349762493488664e-05,
        3.5466493438435696e-05,
        3.4567085809127236e-05,
        3.3652926426937317e-05,
        3.272542485937368e-05,
        3.178601124662685e-05,
        3.083613409639763e-05,
        2.98772580504032e-05,
        2.8910861626005766e-05,
        2.7938434936445935e-05,
        2.6961477393196116e-05
      ],
      "train_accuracy": [
        5.4,
        35.199999999999996,
        68.4,
        84.6,
        91.4,
        94.0,
        96.8,
        97.8,
        98.2,
        98.8,
        99.0,
        98.8,
        99.6,
        99.6,
        99.6,
        99.6,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 89.8,
      "mean_per_class_accuracy": 89.8,
      "total_samples": 2000,
      "correct_predictions": 1796
    },
    "training_time": 726.3128044605255,
    "best_epoch": 38
  },
  "exp_002_10shot_prototypical_augFalse_low_lr": {
    "config": {
      "n_shot": 10,
      "loss_type": "prototypical",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        4.442054718732834,
        3.8746192306280136,
        3.356078401207924,
        2.88750159740448,
        2.471965476870537,
        2.1103027313947678,
        1.8097547888755798,
        1.559749811887741,
        1.3672748059034348,
        1.2084418684244156,
        1.0931497775018215,
        0.9968869388103485,
        0.9220874793827534,
        0.8656554520130157,
        0.8182172849774361,
        0.7794329971075058,
        0.7473669312894344,
        0.7173120677471161,
        0.6950134299695492,
        0.677508257329464,
        0.655874989926815,
        0.6425185166299343,
        0.630354356020689,
        0.6164617575705051,
        0.6064420901238918,
        0.5943006351590157,
        0.5872338265180588,
        0.5842780470848083,
        0.5758857019245625,
        0.5713777393102646,
        0.56576157361269,
        0.5602082163095474,
        0.5598659329116344,
        0.5548685379326344,
        0.550694614648819,
        0.5463924556970596,
        0.5480853691697121,
        0.5419631823897362,
        0.5390108227729797,
        0.536961805075407
      ],
      "val_accuracy": [
        44.2,
        80.5,
        92.80000000000001,
        94.0,
        96.39999999999999,
        96.6,
        97.6,
        98.6,
        98.7,
        98.7,
        98.9,
        99.2,
        98.9,
        99.3,
        99.4,
        99.5,
        99.6,
        99.6,
        99.6,
        99.7,
        99.7,
        99.7,
        99.8,
        99.8,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9
      ],
      "learning_rates": [
        5e-05,
        4.9980725906018074e-05,
        4.99229333433282e-05,
        4.982671142387316e-05,
        4.9692208514878444e-05,
        4.951963201008076e-05,
        4.9309248009941914e-05,
        4.906138091134118e-05,
        4.877641290737884e-05,
        4.8454783398062106e-05,
        4.809698831278217e-05,
        4.770357934562703e-05,
        4.727516310470919e-05,
        4.681240017681993e-05,
        4.6316004108852305e-05,
        4.5786740307563636e-05,
        4.522542485937369e-05,
        4.463292327201862e-05,
        4.401014914000078e-05,
        4.3358062735892145e-05,
        4.267766952966369e-05,
        4.197001863832355e-05,
        4.1236201208254596e-05,
        4.0477348732745845e-05,
        3.969463130731182e-05,
        3.888925582549005e-05,
        3.806246411789872e-05,
        3.7215531037423875e-05,
        3.6349762493488664e-05,
        3.5466493438435696e-05,
        3.4567085809127236e-05,
        3.3652926426937317e-05,
        3.272542485937368e-05,
        3.178601124662685e-05,
        3.083613409639763e-05,
        2.98772580504032e-05,
        2.8910861626005766e-05,
        2.7938434936445935e-05,
        2.6961477393196116e-05,
        2.5981495393976706e-05
      ],
      "train_accuracy": [
        9.700000000000001,
        62.1,
        86.9,
        92.5,
        94.69999999999999,
        96.2,
        97.0,
        97.8,
        98.3,
        98.7,
        98.6,
        99.0,
        98.8,
        98.9,
        99.3,
        99.4,
        99.4,
        99.5,
        99.6,
        99.7,
        99.7,
        99.7,
        99.7,
        99.7,
        99.8,
        99.8,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9
      ]
    },
    "final_metrics": {
      "overall_accuracy": 92.25,
      "mean_per_class_accuracy": 92.25,
      "total_samples": 2000,
      "correct_predictions": 1845
    },
    "training_time": 1404.8106253147125,
    "best_epoch": 39
  },
  "exp_003_20shot_prototypical_augFalse_low_lr": {
    "config": {
      "n_shot": 20,
      "loss_type": "prototypical",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [],
      "val_accuracy": [],
      "learning_rates": [],
      "train_accuracy": []
    },
    "final_metrics": {},
    "training_time": 0,
    "best_epoch": 0,
    "error": "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 64.12 MiB is free. Process 3025 has 14.68 GiB memory in use. Of the allocated memory 14.34 GiB is allocated by PyTorch, and 207.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
  }
}