{
  "exp_000_20shot_contrastive_augFalse_default": {
    "config": {
      "n_shot": 20,
      "loss_type": "contrastive",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 0.0001,
        "weight_decay": 0.01,
        "batch_size": 32,
        "num_epochs": 100,
        "label_smoothing": 0.1,
        "temperature": 0.1,
        "patience": 20
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        3.3119137570971535,
        1.1368340518739488,
        0.9295633539320931,
        0.8606915067112635,
        0.8532812623750596,
        0.8492471963640243,
        0.8274406241992164,
        0.8251479722204662,
        0.8211403082287501,
        0.8186336424615648,
        0.8205999902316502,
        0.8236743334739928,
        0.8217915816912575,
        0.8180199000570509,
        0.8201685727588715,
        0.8087726330000257,
        0.8055152495702108,
        0.8122471230370658,
        0.8030839429961311,
        0.8092036578390334,
        0.8060929756315928,
        0.8103480320128184,
        0.8155096050292726,
        0.8060879253205799,
        0.811304593843127,
        0.8075523679218595,
        0.8061539294227721
      ],
      "val_accuracy": [
        92.35,
        98.0,
        99.05000000000001,
        99.75,
        99.6,
        99.95,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        0.0001,
        9.997532801828658e-05,
        9.990133642141359e-05,
        9.977809823015401e-05,
        9.960573506572391e-05,
        9.93844170297569e-05,
        9.911436253643445e-05,
        9.879583809693738e-05,
        9.842915805643157e-05,
        9.801468428384717e-05,
        9.75528258147577e-05,
        9.70440384477113e-05,
        9.64888242944126e-05,
        9.588773128419907e-05,
        9.5241352623301e-05,
        9.455032620941843e-05,
        9.381533400219321e-05,
        9.303710135019722e-05,
        9.22163962751008e-05,
        9.135402871372814e-05,
        9.045084971874742e-05,
        8.950775061878456e-05,
        8.852566213878951e-05,
        8.750555348152303e-05,
        8.644843137107063e-05,
        8.535533905932742e-05,
        8.422735529643448e-05
      ],
      "train_accuracy": [
        59.25,
        94.65,
        97.65,
        99.5,
        99.2,
        99.65,
        99.95,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        99.9,
        99.95,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 93.10000000000001,
      "mean_per_class_accuracy": 93.1,
      "total_samples": 2000,
      "correct_predictions": 1862
    },
    "training_time": 5823.7971930503845,
    "best_epoch": 26
  },
  "exp_001_20shot_contrastive_augFalse_low_lr": {
    "config": {
      "n_shot": 20,
      "loss_type": "contrastive",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [],
      "val_accuracy": [],
      "learning_rates": [],
      "train_accuracy": []
    },
    "final_metrics": {},
    "training_time": 0,
    "best_epoch": 0,
    "error": "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 149.12 MiB is free. Process 4819 has 15.74 GiB memory in use. Of the allocated memory 15.03 GiB is allocated by PyTorch, and 418.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
  },
  "exp_002_20shot_prototypical_augFalse_default": {
    "config": {
      "n_shot": 20,
      "loss_type": "prototypical",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 0.0001,
        "weight_decay": 0.01,
        "batch_size": 32,
        "num_epochs": 100,
        "label_smoothing": 0.1,
        "temperature": 0.1,
        "patience": 20
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        3.03461944489252,
        1.0377157084525577,
        0.8678377440997532,
        0.8273794736180987,
        0.8073152511838882,
        0.7995462237842499,
        0.7948026799020314,
        0.7921381677900042,
        0.7902388005029588,
        0.7887024018499587,
        0.7874808226312909,
        0.786430297389863,
        0.7855635588131253,
        0.784787532829103,
        0.7841340398031568,
        0.7835485783834306,
        0.7830437279882885,
        0.782595778268481,
        0.7821968481654212,
        0.7818395902240087,
        0.7815289904200842,
        0.7812284609628102,
        0.7809807885260809,
        0.7807471638634091,
        0.7805339495340983,
        0.780357281366984
      ],
      "val_accuracy": [
        94.85,
        98.2,
        99.5,
        99.7,
        99.95,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        0.0001,
        9.997532801828658e-05,
        9.990133642141359e-05,
        9.977809823015401e-05,
        9.960573506572391e-05,
        9.93844170297569e-05,
        9.911436253643445e-05,
        9.879583809693738e-05,
        9.842915805643157e-05,
        9.801468428384717e-05,
        9.75528258147577e-05,
        9.70440384477113e-05,
        9.64888242944126e-05,
        9.588773128419907e-05,
        9.5241352623301e-05,
        9.455032620941843e-05,
        9.381533400219321e-05,
        9.303710135019722e-05,
        9.22163962751008e-05,
        9.135402871372814e-05,
        9.045084971874742e-05,
        8.950775061878456e-05,
        8.852566213878951e-05,
        8.750555348152303e-05,
        8.644843137107063e-05,
        8.535533905932742e-05
      ],
      "train_accuracy": [
        62.4,
        94.5,
        98.1,
        99.5,
        99.85000000000001,
        99.95,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 92.60000000000001,
      "mean_per_class_accuracy": 92.6,
      "total_samples": 2000,
      "correct_predictions": 1852
    },
    "training_time": 5629.969670534134,
    "best_epoch": 25
  },
  "exp_003_20shot_prototypical_augFalse_low_lr": {
    "config": {
      "n_shot": 20,
      "loss_type": "prototypical",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [],
      "val_accuracy": [],
      "learning_rates": [],
      "train_accuracy": []
    },
    "final_metrics": {},
    "training_time": 0,
    "best_epoch": 0,
    "error": "CUDA out of memory. Tried to allocate 258.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 151.12 MiB is free. Process 4819 has 15.74 GiB memory in use. Of the allocated memory 15.03 GiB is allocated by PyTorch, and 415.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
  }
}