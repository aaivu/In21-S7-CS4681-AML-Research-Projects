{
  "exp_000_1shot_cross_entropy_augFalse_low_lr": {
    "config": {
      "n_shot": 1,
      "loss_type": "cross_entropy",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        4.683238983154297,
        4.522928237915039,
        4.396049976348877,
        4.273234605789185,
        4.148881196975708,
        4.014265656471252,
        3.9086936712265015,
        3.7951468229293823,
        3.6748956441879272,
        3.558730721473694,
        3.4512622356414795,
        3.3424630165100098,
        3.2290422916412354,
        3.1349445581436157,
        3.0260424613952637,
        2.920921802520752,
        2.8255831003189087,
        2.729949474334717,
        2.6417360305786133,
        2.546674132347107,
        2.4587074518203735,
        2.3745415210723877,
        2.292858123779297,
        2.2190903425216675,
        2.143970251083374,
        2.0834996700286865,
        2.012920379638672
      ],
      "val_accuracy": [
        2.0,
        6.0,
        22.0,
        34.0,
        59.0,
        67.0,
        84.0,
        94.0,
        98.0,
        98.0,
        99.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        5e-05,
        4.9980725906018074e-05,
        4.99229333433282e-05,
        4.982671142387316e-05,
        4.9692208514878444e-05,
        4.951963201008076e-05,
        4.9309248009941914e-05,
        4.906138091134118e-05,
        4.877641290737884e-05,
        4.8454783398062106e-05,
        4.809698831278217e-05,
        4.770357934562703e-05,
        4.727516310470919e-05,
        4.681240017681993e-05,
        4.6316004108852305e-05,
        4.5786740307563636e-05,
        4.522542485937369e-05,
        4.463292327201862e-05,
        4.401014914000078e-05,
        4.3358062735892145e-05,
        4.267766952966369e-05,
        4.197001863832355e-05,
        4.1236201208254596e-05,
        4.0477348732745845e-05,
        3.969463130731182e-05,
        3.888925582549005e-05,
        3.806246411789872e-05
      ],
      "train_accuracy": [
        0.0,
        2.0,
        7.000000000000001,
        24.0,
        36.0,
        61.0,
        68.0,
        85.0,
        94.0,
        98.0,
        98.0,
        99.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 67.95,
      "mean_per_class_accuracy": 67.95,
      "total_samples": 2000,
      "correct_predictions": 1359
    },
    "training_time": 134.95999932289124,
    "best_epoch": 26
  },
  "exp_001_1shot_contrastive_augFalse_low_lr": {
    "config": {
      "n_shot": 1,
      "loss_type": "contrastive",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        4.615189790725708,
        4.473649501800537,
        4.342350006103516,
        4.215058088302612,
        4.092543125152588,
        3.981229782104492,
        3.859281539916992,
        3.7447205781936646,
        3.63629686832428,
        3.51241934299469,
        3.4138333797454834,
        3.305895447731018,
        3.1928188800811768,
        3.081325650215149,
        2.983437418937683,
        2.889980435371399,
        2.781654953956604,
        2.6924588680267334,
        2.6082887649536133,
        2.507863402366638,
        2.430081844329834,
        2.3421016931533813,
        2.2658286094665527,
        2.181440234184265,
        2.1112653017044067,
        2.0464223623275757,
        1.9626028537750244
      ],
      "val_accuracy": [
        3.0,
        12.0,
        23.0,
        40.0,
        55.00000000000001,
        71.0,
        86.0,
        91.0,
        94.0,
        98.0,
        99.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        5e-05,
        4.9980725906018074e-05,
        4.99229333433282e-05,
        4.982671142387316e-05,
        4.9692208514878444e-05,
        4.951963201008076e-05,
        4.9309248009941914e-05,
        4.906138091134118e-05,
        4.877641290737884e-05,
        4.8454783398062106e-05,
        4.809698831278217e-05,
        4.770357934562703e-05,
        4.727516310470919e-05,
        4.681240017681993e-05,
        4.6316004108852305e-05,
        4.5786740307563636e-05,
        4.522542485937369e-05,
        4.463292327201862e-05,
        4.401014914000078e-05,
        4.3358062735892145e-05,
        4.267766952966369e-05,
        4.197001863832355e-05,
        4.1236201208254596e-05,
        4.0477348732745845e-05,
        3.969463130731182e-05,
        3.888925582549005e-05,
        3.806246411789872e-05
      ],
      "train_accuracy": [
        1.0,
        3.0,
        12.0,
        25.0,
        42.0,
        56.99999999999999,
        75.0,
        87.0,
        91.0,
        94.0,
        98.0,
        99.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 67.45,
      "mean_per_class_accuracy": 67.45,
      "total_samples": 2000,
      "correct_predictions": 1349
    },
    "training_time": 140.51121950149536,
    "best_epoch": 26
  },
  "exp_002_5shot_cross_entropy_augFalse_low_lr": {
    "config": {
      "n_shot": 5,
      "loss_type": "cross_entropy",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        4.542520999908447,
        4.204347848892212,
        3.9004047214984894,
        3.611313909292221,
        3.3307704627513885,
        3.0659099519252777,
        2.813886970281601,
        2.5744984447956085,
        2.352719157934189,
        2.1497246623039246,
        1.9603579640388489,
        1.7922595143318176,
        1.6410161256790161,
        1.505996286869049,
        1.389726683497429,
        1.287183552980423,
        1.199816271662712,
        1.119875431060791,
        1.0549538433551788,
        0.9962712451815605,
        0.9456596076488495,
        0.9005639031529427,
        0.8613790348172188,
        0.828429102897644,
        0.7969374284148216,
        0.7707898914813995,
        0.74875707924366,
        0.727485217154026,
        0.7092571929097176,
        0.692639485001564,
        0.6776806116104126,
        0.664341002702713,
        0.6514137014746666,
        0.6412455663084984,
        0.6319157108664513,
        0.6229982823133469
      ],
      "val_accuracy": [
        19.0,
        55.00000000000001,
        80.60000000000001,
        89.0,
        92.80000000000001,
        94.8,
        97.39999999999999,
        98.0,
        98.4,
        98.8,
        99.6,
        99.6,
        99.4,
        99.6,
        99.6,
        99.8,
        99.6,
        99.6,
        99.6,
        99.8,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        5e-05,
        4.9980725906018074e-05,
        4.99229333433282e-05,
        4.982671142387316e-05,
        4.9692208514878444e-05,
        4.951963201008076e-05,
        4.9309248009941914e-05,
        4.906138091134118e-05,
        4.877641290737884e-05,
        4.8454783398062106e-05,
        4.809698831278217e-05,
        4.770357934562703e-05,
        4.727516310470919e-05,
        4.681240017681993e-05,
        4.6316004108852305e-05,
        4.5786740307563636e-05,
        4.522542485937369e-05,
        4.463292327201862e-05,
        4.401014914000078e-05,
        4.3358062735892145e-05,
        4.267766952966369e-05,
        4.197001863832355e-05,
        4.1236201208254596e-05,
        4.0477348732745845e-05,
        3.969463130731182e-05,
        3.888925582549005e-05,
        3.806246411789872e-05,
        3.7215531037423875e-05,
        3.6349762493488664e-05,
        3.5466493438435696e-05,
        3.4567085809127236e-05,
        3.3652926426937317e-05,
        3.272542485937368e-05,
        3.178601124662685e-05,
        3.083613409639763e-05,
        2.98772580504032e-05
      ],
      "train_accuracy": [
        2.4,
        30.599999999999998,
        67.2,
        83.39999999999999,
        90.2,
        94.0,
        95.0,
        97.39999999999999,
        98.2,
        98.2,
        99.0,
        99.6,
        99.4,
        99.6,
        99.6,
        99.6,
        99.6,
        99.6,
        99.6,
        99.6,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 89.75,
      "mean_per_class_accuracy": 89.75,
      "total_samples": 2000,
      "correct_predictions": 1795
    },
    "training_time": 633.1180922985077,
    "best_epoch": 35
  },
  "exp_003_5shot_contrastive_augFalse_low_lr": {
    "config": {
      "n_shot": 5,
      "loss_type": "contrastive",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        4.958405673503876,
        4.65853214263916,
        4.336481690406799,
        3.999598413705826,
        3.701078772544861,
        3.415001720190048,
        3.2638162970542908,
        2.972444713115692,
        2.7494507133960724,
        2.4968091547489166,
        2.3782816231250763,
        2.110887959599495,
        2.0635419487953186,
        1.900035411119461,
        1.830422967672348,
        1.6774461269378662,
        1.5574719458818436,
        1.583448588848114,
        1.381986990571022,
        1.3388173580169678,
        1.3670151680707932,
        1.341081589460373,
        1.2223519086837769,
        1.2455113530158997,
        1.217087410390377,
        1.243506282567978,
        1.178538739681244,
        1.100918360054493,
        1.1082917600870132,
        1.063244678080082,
        1.0172134190797806,
        1.0518291518092155,
        1.0309960693120956,
        1.0416154488921165,
        0.9706739261746407,
        1.0543840825557709,
        0.9421856701374054,
        0.9810063391923904,
        1.0061817467212677,
        0.9521833658218384
      ],
      "val_accuracy": [
        15.8,
        48.0,
        75.2,
        88.2,
        93.0,
        96.0,
        96.8,
        97.6,
        97.6,
        98.2,
        99.0,
        99.0,
        99.2,
        99.2,
        99.4,
        99.4,
        99.4,
        99.4,
        99.6,
        99.6,
        99.6,
        99.6,
        99.8,
        99.8,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        5e-05,
        4.9980725906018074e-05,
        4.99229333433282e-05,
        4.982671142387316e-05,
        4.9692208514878444e-05,
        4.951963201008076e-05,
        4.9309248009941914e-05,
        4.906138091134118e-05,
        4.877641290737884e-05,
        4.8454783398062106e-05,
        4.809698831278217e-05,
        4.770357934562703e-05,
        4.727516310470919e-05,
        4.681240017681993e-05,
        4.6316004108852305e-05,
        4.5786740307563636e-05,
        4.522542485937369e-05,
        4.463292327201862e-05,
        4.401014914000078e-05,
        4.3358062735892145e-05,
        4.267766952966369e-05,
        4.197001863832355e-05,
        4.1236201208254596e-05,
        4.0477348732745845e-05,
        3.969463130731182e-05,
        3.888925582549005e-05,
        3.806246411789872e-05,
        3.7215531037423875e-05,
        3.6349762493488664e-05,
        3.5466493438435696e-05,
        3.4567085809127236e-05,
        3.3652926426937317e-05,
        3.272542485937368e-05,
        3.178601124662685e-05,
        3.083613409639763e-05,
        2.98772580504032e-05,
        2.8910861626005766e-05,
        2.7938434936445935e-05,
        2.6961477393196116e-05,
        2.5981495393976706e-05
      ],
      "train_accuracy": [
        3.5999999999999996,
        26.200000000000003,
        59.0,
        80.80000000000001,
        90.0,
        94.39999999999999,
        96.2,
        97.0,
        97.39999999999999,
        97.6,
        98.4,
        98.8,
        99.0,
        99.2,
        99.2,
        99.4,
        99.4,
        99.4,
        99.4,
        99.6,
        99.6,
        99.6,
        99.6,
        99.8,
        99.8,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 89.95,
      "mean_per_class_accuracy": 89.95,
      "total_samples": 2000,
      "correct_predictions": 1799
    },
    "training_time": 706.5709474086761,
    "best_epoch": 39
  },
  "exp_004_10shot_cross_entropy_augFalse_low_lr": {
    "config": {
      "n_shot": 10,
      "loss_type": "cross_entropy",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        4.42879393696785,
        3.852029502391815,
        3.337951138615608,
        2.8692217618227005,
        2.4462406933307648,
        2.0858672335743904,
        1.783752016723156,
        1.5375745221972466,
        1.3402939811348915,
        1.1897555738687515,
        1.067609328776598,
        0.978398934006691,
        0.9036909937858582,
        0.8453766517341137,
        0.7964148111641407,
        0.7583297900855541,
        0.727248553186655,
        0.6991963163018227,
        0.67527299746871,
        0.6550744138658047,
        0.637709841132164,
        0.6239249855279922,
        0.6114255078136921,
        0.6003392897546291,
        0.5893785208463669,
        0.5805719159543514,
        0.5721593797206879,
        0.5660184770822525,
        0.5603059232234955,
        0.5536805763840675,
        0.5495827384293079,
        0.5451616160571575,
        0.5403771474957466,
        0.5376798138022423,
        0.533427506685257,
        0.5302843749523163,
        0.5266623683273792,
        0.5240939520299435,
        0.5223283339291811,
        0.5202561728656292,
        0.5177464857697487,
        0.5157003812491894,
        0.5140490718185902,
        0.5121408030390739,
        0.5110359154641628,
        0.509405305609107,
        0.5083736348897219,
        0.50699308142066,
        0.5063911583274603,
        0.5054516494274139,
        0.5047345794737339,
        0.5041466485708952,
        0.5026079751551151,
        0.5024823881685734,
        0.5016097854822874,
        0.5007911715656519,
        0.5000361688435078
      ],
      "val_accuracy": [
        44.1,
        82.1,
        90.3,
        95.1,
        96.0,
        97.0,
        97.89999999999999,
        98.1,
        98.4,
        98.6,
        98.5,
        98.7,
        98.8,
        99.2,
        99.3,
        99.4,
        99.5,
        99.4,
        99.5,
        99.6,
        99.6,
        99.6,
        99.7,
        99.8,
        99.7,
        99.8,
        99.8,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        5e-05,
        4.9980725906018074e-05,
        4.99229333433282e-05,
        4.982671142387316e-05,
        4.9692208514878444e-05,
        4.951963201008076e-05,
        4.9309248009941914e-05,
        4.906138091134118e-05,
        4.877641290737884e-05,
        4.8454783398062106e-05,
        4.809698831278217e-05,
        4.770357934562703e-05,
        4.727516310470919e-05,
        4.681240017681993e-05,
        4.6316004108852305e-05,
        4.5786740307563636e-05,
        4.522542485937369e-05,
        4.463292327201862e-05,
        4.401014914000078e-05,
        4.3358062735892145e-05,
        4.267766952966369e-05,
        4.197001863832355e-05,
        4.1236201208254596e-05,
        4.0477348732745845e-05,
        3.969463130731182e-05,
        3.888925582549005e-05,
        3.806246411789872e-05,
        3.7215531037423875e-05,
        3.6349762493488664e-05,
        3.5466493438435696e-05,
        3.4567085809127236e-05,
        3.3652926426937317e-05,
        3.272542485937368e-05,
        3.178601124662685e-05,
        3.083613409639763e-05,
        2.98772580504032e-05,
        2.8910861626005766e-05,
        2.7938434936445935e-05,
        2.6961477393196116e-05,
        2.5981495393976706e-05,
        2.499999999999999e-05,
        2.4018504606023283e-05,
        2.3038522606803873e-05,
        2.2061565063554058e-05,
        2.108913837399423e-05,
        2.012274194959679e-05,
        1.9163865903602363e-05,
        1.8213988753373136e-05,
        1.7274575140626315e-05,
        1.634707357306268e-05,
        1.5432914190872757e-05,
        1.4533506561564306e-05,
        1.3650237506511333e-05,
        1.2784468962576126e-05,
        1.1937535882101281e-05,
        1.1110744174509945e-05,
        1.0305368692688176e-05
      ],
      "train_accuracy": [
        9.1,
        64.60000000000001,
        85.39999999999999,
        92.9,
        95.39999999999999,
        96.3,
        97.3,
        98.1,
        98.3,
        98.5,
        98.5,
        98.5,
        98.6,
        98.9,
        99.2,
        99.3,
        99.3,
        99.4,
        99.4,
        99.5,
        99.6,
        99.6,
        99.6,
        99.7,
        99.7,
        99.7,
        99.8,
        99.8,
        99.8,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 92.05,
      "mean_per_class_accuracy": 92.05,
      "total_samples": 2000,
      "correct_predictions": 1841
    },
    "training_time": 1871.0730829238892,
    "best_epoch": 56
  },
  "exp_005_10shot_contrastive_augFalse_low_lr": {
    "config": {
      "n_shot": 10,
      "loss_type": "contrastive",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [
        4.8664442002773285,
        4.2854339480400085,
        3.7686464339494705,
        3.343497559428215,
        2.9376315474510193,
        2.5161629617214203,
        2.2799293398857117,
        1.9810123145580292,
        1.8003715202212334,
        1.5951898097991943,
        1.4666007831692696,
        1.3777768835425377,
        1.355352632701397,
        1.310310184955597,
        1.2324701771140099,
        1.2186168730258942,
        1.159987710416317,
        1.161767266690731,
        1.0962598286569118,
        1.1479769684374332,
        1.0752558633685112,
        1.0625205636024475,
        1.1064776331186295,
        1.0500785820186138,
        1.0298441164195538,
        1.006243720650673,
        1.054307397454977,
        0.9477704800665379,
        1.004226490855217,
        0.9747757241129875,
        1.0243307836353779,
        1.0110163316130638,
        1.010099597275257,
        0.981758002191782,
        1.006836675107479,
        1.0055322088301182,
        0.9728263765573502,
        0.9582035653293133,
        0.8959198296070099,
        1.0067771784961224,
        0.9111464396119118,
        0.9970553740859032,
        0.9636976756155491,
        0.9647522456943989,
        0.9158436208963394,
        0.9782602824270725,
        1.0179560966789722,
        0.9113532342016697,
        0.9049890600144863,
        0.8969699367880821,
        0.8846100978553295,
        0.9719628319144249,
        0.8999874405562878,
        0.9168614335358143,
        0.8860626704990864,
        0.8977354541420937,
        0.9195834249258041
      ],
      "val_accuracy": [
        39.800000000000004,
        80.9,
        90.2,
        94.19999999999999,
        96.3,
        96.7,
        97.39999999999999,
        98.0,
        98.1,
        98.6,
        98.7,
        98.9,
        99.2,
        99.1,
        99.2,
        99.2,
        99.6,
        99.5,
        99.5,
        99.5,
        99.7,
        99.6,
        99.7,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ],
      "learning_rates": [
        5e-05,
        4.9980725906018074e-05,
        4.99229333433282e-05,
        4.982671142387316e-05,
        4.9692208514878444e-05,
        4.951963201008076e-05,
        4.9309248009941914e-05,
        4.906138091134118e-05,
        4.877641290737884e-05,
        4.8454783398062106e-05,
        4.809698831278217e-05,
        4.770357934562703e-05,
        4.727516310470919e-05,
        4.681240017681993e-05,
        4.6316004108852305e-05,
        4.5786740307563636e-05,
        4.522542485937369e-05,
        4.463292327201862e-05,
        4.401014914000078e-05,
        4.3358062735892145e-05,
        4.267766952966369e-05,
        4.197001863832355e-05,
        4.1236201208254596e-05,
        4.0477348732745845e-05,
        3.969463130731182e-05,
        3.888925582549005e-05,
        3.806246411789872e-05,
        3.7215531037423875e-05,
        3.6349762493488664e-05,
        3.5466493438435696e-05,
        3.4567085809127236e-05,
        3.3652926426937317e-05,
        3.272542485937368e-05,
        3.178601124662685e-05,
        3.083613409639763e-05,
        2.98772580504032e-05,
        2.8910861626005766e-05,
        2.7938434936445935e-05,
        2.6961477393196116e-05,
        2.5981495393976706e-05,
        2.499999999999999e-05,
        2.4018504606023283e-05,
        2.3038522606803873e-05,
        2.2061565063554058e-05,
        2.108913837399423e-05,
        2.012274194959679e-05,
        1.9163865903602363e-05,
        1.8213988753373136e-05,
        1.7274575140626315e-05,
        1.634707357306268e-05,
        1.5432914190872757e-05,
        1.4533506561564306e-05,
        1.3650237506511333e-05,
        1.2784468962576126e-05,
        1.1937535882101281e-05,
        1.1110744174509945e-05,
        1.0305368692688176e-05
      ],
      "train_accuracy": [
        8.9,
        60.4,
        85.0,
        91.7,
        94.69999999999999,
        96.2,
        96.8,
        97.5,
        97.89999999999999,
        98.3,
        98.4,
        98.6,
        99.0,
        98.8,
        99.0,
        99.2,
        99.4,
        99.5,
        99.5,
        99.4,
        99.4,
        99.6,
        99.6,
        99.7,
        99.8,
        99.8,
        99.8,
        99.8,
        99.8,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        99.9,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0,
        100.0
      ]
    },
    "final_metrics": {
      "overall_accuracy": 92.15,
      "mean_per_class_accuracy": 92.15,
      "total_samples": 2000,
      "correct_predictions": 1843
    },
    "training_time": 1872.5090155601501,
    "best_epoch": 56
  },
  "exp_006_20shot_cross_entropy_augFalse_low_lr": {
    "config": {
      "n_shot": 20,
      "loss_type": "cross_entropy",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [],
      "val_accuracy": [],
      "learning_rates": [],
      "train_accuracy": []
    },
    "final_metrics": {},
    "training_time": 0,
    "best_epoch": 0,
    "error": "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 64.12 MiB is free. Process 4460 has 14.68 GiB memory in use. Of the allocated memory 14.34 GiB is allocated by PyTorch, and 207.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
  },
  "exp_007_20shot_contrastive_augFalse_low_lr": {
    "config": {
      "n_shot": 20,
      "loss_type": "contrastive",
      "use_augmentation": false,
      "hyperparams": {
        "learning_rate": 5e-05,
        "weight_decay": 0.001,
        "batch_size": 64,
        "num_epochs": 80,
        "label_smoothing": 0.05,
        "temperature": 0.05,
        "patience": 15
      },
      "model": "coca_ViT-L-14",
      "pretrained": "mscoco_finetuned_laion2B-s13B-b90k"
    },
    "epoch_history": {
      "train_loss": [],
      "val_accuracy": [],
      "learning_rates": [],
      "train_accuracy": []
    },
    "final_metrics": {},
    "training_time": 0,
    "best_epoch": 0,
    "error": "CUDA out of memory. Tried to allocate 130.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 64.12 MiB is free. Process 4460 has 14.68 GiB memory in use. Of the allocated memory 14.34 GiB is allocated by PyTorch, and 207.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
  }
}

====================================================================================================
EXPERIMENT SUMMARY
====================================================================================================
Config                                                       Epochs   Best Val Acc Test Acc   Time (s)  
----------------------------------------------------------------------------------------------------
exp_000_20shot_cross_entropy_augFalse_low_lr                 23       100.00       91.50      3171.0    
====================================================================================================
Successful experiments: 1/1