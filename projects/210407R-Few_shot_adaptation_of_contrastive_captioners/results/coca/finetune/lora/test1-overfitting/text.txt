learning_rate=1e-4 (cosine decay on),
weight_decay=0.01,
num_epochs=100 (with early stopping),
label_smoothing=0.1,
optimizer= adamW,
loss=crossentropy,
batch_size: int = 32,
warmup_epochs: int = 10,

shots=2,10,else
r=4,8,16
lora_alpha=16,32,64

20shot_cross_entropy_augTrue        94.25        94.25 


