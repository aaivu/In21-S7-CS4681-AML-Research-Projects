{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09cc354",
   "metadata": {},
   "source": [
    "# TNC Prototypical Network Classification Evaluation\n",
    "\n",
    "This notebook implements **Prototypical Network** classification using the same structure as the original TNC classification notebook. Only the linear classifier is replaced with prototypical network - everything else remains identical.\n",
    "\n",
    "## Changes from Original\n",
    "- Replaces `WFClassifier` with `PrototypicalClassifier`\n",
    "- Uses k-shot learning instead of linear classification  \n",
    "- Same `WFEncoder`, same data loading, same evaluation metrics\n",
    "- Better handling of class imbalance through few-shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820988f",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set up paths to your saved checkpoint, data, and plots folders\n",
    "DRIVE_PATH = '/content/drive/MyDrive'  # Adjust this path as needed\n",
    "CHECKPOINT_PATH = os.path.join(DRIVE_PATH, 'ckpt')\n",
    "DATA_PATH = os.path.join(DRIVE_PATH, 'data')\n",
    "PLOTS_PATH = os.path.join(DRIVE_PATH, 'plots')\n",
    "\n",
    "# Create plots directory if it doesn't exist\n",
    "os.makedirs(PLOTS_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Checkpoint path: {CHECKPOINT_PATH}\")\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Plots path: {PLOTS_PATH}\")\n",
    "\n",
    "# Verify paths exist\n",
    "print(f\"Checkpoint exists: {os.path.exists(CHECKPOINT_PATH)}\")\n",
    "print(f\"Data exists: {os.path.exists(DATA_PATH)}\")\n",
    "print(f\"Plots exists: {os.path.exists(PLOTS_PATH)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e44c8",
   "metadata": {},
   "source": [
    "## 2. Import Original Libraries and Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e18f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries exactly as in original codebase\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import time  # For timing optimizations\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, average_precision_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d02114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXACT WFEncoder from training file - all code included directly\n",
    "class WFEncoder(nn.Module):\n",
    "    \"\"\"CNN-based encoder for waveform/ECG data\"\"\"\n",
    "    def __init__(self, encoding_size, classify=False, n_classes=None):\n",
    "        super(WFEncoder, self).__init__()\n",
    "        \n",
    "        self.encoding_size = encoding_size\n",
    "        self.n_classes = n_classes\n",
    "        self.classify = classify\n",
    "        self.classifier = None\n",
    "        \n",
    "        if self.classify:\n",
    "            if self.n_classes is None:\n",
    "                raise ValueError('Need to specify the number of output classes')\n",
    "            else:\n",
    "                self.classifier = nn.Sequential(\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(self.encoding_size, self.n_classes)\n",
    "                )\n",
    "                nn.init.xavier_uniform_(self.classifier[1].weight)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(2, 64, kernel_size=4, stride=1, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.BatchNorm1d(64, eps=0.001),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.BatchNorm1d(64, eps=0.001),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.BatchNorm1d(128, eps=0.001),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.BatchNorm1d(128, eps=0.001),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.BatchNorm1d(256, eps=0.001),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.BatchNorm1d(256, eps=0.001),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(79872, 2048),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.BatchNorm1d(2048, eps=0.001),\n",
    "            nn.Linear(2048, self.encoding_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        encoding = self.fc(x)\n",
    "        if self.classify:\n",
    "            c = self.classifier(encoding)\n",
    "            return c\n",
    "        else:\n",
    "            return encoding\n",
    "\n",
    "# StateClassifier from training file\n",
    "class StateClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(StateClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.normalize = torch.nn.BatchNorm1d(self.input_size)\n",
    "        self.nn = torch.nn.Linear(self.input_size, self.output_size)\n",
    "        torch.nn.init.xavier_uniform_(self.nn.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.normalize(x)\n",
    "        logits = self.nn(x)\n",
    "        return logits\n",
    "\n",
    "# OPTIMIZED Prototypical Network Classifier - MEMORY EFFICIENT\n",
    "class EfficientPrototypicalClassifier:\n",
    "    \"\"\"Memory-efficient Prototypical Network classifier\"\"\"\n",
    "    def __init__(self, encoder, k_shot=3, batch_size=32):  # Reduced k_shot for memory\n",
    "        self.encoder = encoder\n",
    "        self.k_shot = k_shot\n",
    "        self.batch_size = batch_size  # For batch processing\n",
    "        self.prototypes = None\n",
    "        self.class_ids = None\n",
    "        \n",
    "    def extract_features_batch(self, data):\n",
    "        \"\"\"Extract features in batches to save memory\"\"\"\n",
    "        self.encoder.eval()\n",
    "        features_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(data), self.batch_size):\n",
    "                batch = data[i:i+self.batch_size]\n",
    "                if isinstance(batch, np.ndarray):\n",
    "                    batch = torch.FloatTensor(batch).to(data.device if hasattr(data, 'device') else 'cpu')\n",
    "                features = self.encoder(batch)\n",
    "                features_list.append(features.cpu())\n",
    "                \n",
    "                # Clear GPU cache to prevent memory buildup\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        return torch.cat(features_list, dim=0)\n",
    "        \n",
    "    def fit_prototypes(self, support_data, support_labels):\n",
    "        \"\"\"Compute class prototypes from support set - MEMORY EFFICIENT\"\"\"\n",
    "        print(f\"üìä Computing prototypes with {self.k_shot}-shot learning...\")\n",
    "        \n",
    "        # Convert to tensors if needed\n",
    "        if isinstance(support_data, np.ndarray):\n",
    "            support_data = torch.FloatTensor(support_data).to(device)\n",
    "        if isinstance(support_labels, np.ndarray):\n",
    "            support_labels = torch.LongTensor(support_labels).to(device)\n",
    "            \n",
    "        unique_classes = torch.unique(support_labels)\n",
    "        self.class_ids = unique_classes\n",
    "        n_classes = len(unique_classes)\n",
    "        \n",
    "        print(f\"Classes found: {unique_classes.cpu().tolist()}\")\n",
    "        \n",
    "        # Get embedding dimension with small batch\n",
    "        sample_batch = support_data[:2]\n",
    "        with torch.no_grad():\n",
    "            sample_embedding = self.encoder(sample_batch)\n",
    "            embedding_dim = sample_embedding.shape[1]\n",
    "        \n",
    "        # Initialize prototypes\n",
    "        self.prototypes = torch.zeros(n_classes, embedding_dim, device=device)\n",
    "        \n",
    "        # Compute prototype for each class efficiently\n",
    "        for i, class_id in enumerate(unique_classes):\n",
    "            class_mask = (support_labels == class_id)\n",
    "            class_samples = support_data[class_mask]\n",
    "            \n",
    "            # Use k_shot samples (or all if less than k_shot)\n",
    "            n_samples = min(self.k_shot, len(class_samples))\n",
    "            if n_samples > 0:\n",
    "                selected_samples = class_samples[:n_samples]\n",
    "                \n",
    "                # Extract features in batches\n",
    "                if len(selected_samples) <= self.batch_size:\n",
    "                    with torch.no_grad():\n",
    "                        embeddings = self.encoder(selected_samples)\n",
    "                else:\n",
    "                    embeddings = self.extract_features_batch(selected_samples)\n",
    "                    embeddings = embeddings.to(device)\n",
    "                \n",
    "                # Compute prototype (mean)\n",
    "                prototype = embeddings.mean(dim=0)\n",
    "                self.prototypes[i] = prototype\n",
    "                \n",
    "                print(f\"Class {class_id}: {n_samples} samples -> prototype computed\")\n",
    "            \n",
    "            # Clear cache\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"‚úÖ All {n_classes} prototypes computed!\")\n",
    "    \n",
    "    def predict_batch(self, query_data, batch_size=None):\n",
    "        \"\"\"Classify queries in batches to manage memory\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "            \n",
    "        self.encoder.eval()\n",
    "        all_predictions = []\n",
    "        all_probabilities = []\n",
    "        \n",
    "        # Convert to tensor if needed\n",
    "        if isinstance(query_data, np.ndarray):\n",
    "            query_data = torch.FloatTensor(query_data).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(query_data), batch_size):\n",
    "                batch = query_data[i:i+batch_size]\n",
    "                \n",
    "                # Get query embeddings\n",
    "                query_embeddings = self.encoder(batch)\n",
    "                \n",
    "                # Compute distances to prototypes\n",
    "                distances = torch.cdist(query_embeddings, self.prototypes)\n",
    "                \n",
    "                # Predict closest prototype\n",
    "                batch_predictions = torch.argmin(distances, dim=1)\n",
    "                batch_predicted_classes = self.class_ids[batch_predictions]\n",
    "                \n",
    "                # Convert distances to probabilities\n",
    "                batch_probs = F.softmax(-distances, dim=1)\n",
    "                \n",
    "                all_predictions.append(batch_predicted_classes.cpu())\n",
    "                all_probabilities.append(batch_probs.cpu())\n",
    "                \n",
    "                # Clear cache\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "        \n",
    "        predictions = torch.cat(all_predictions, dim=0)\n",
    "        probabilities = torch.cat(all_probabilities, dim=0)\n",
    "        \n",
    "        return predictions, probabilities\n",
    "\n",
    "# Memory-efficient training and evaluation functions\n",
    "def extract_features(encoder, data, batch_size=32):\n",
    "    \"\"\"Extract features using the trained encoder - MEMORY EFFICIENT\"\"\"\n",
    "    encoder.eval()\n",
    "    features_list = []\n",
    "    \n",
    "    # Convert to tensor if needed\n",
    "    if isinstance(data, np.ndarray):\n",
    "        data_tensor = torch.FloatTensor(data).to(device)\n",
    "    else:\n",
    "        data_tensor = data\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_tensor), batch_size):\n",
    "            batch = data_tensor[i:i+batch_size]\n",
    "            features = encoder(batch)\n",
    "            features_list.append(features.cpu())\n",
    "            \n",
    "            # Clear GPU memory\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    return torch.cat(features_list, dim=0)\n",
    "\n",
    "def _train_prototypical_classifier(encoder, proto_classifier, X_train, y_train):\n",
    "    \"\"\"Train the prototypical classifier - fit prototypes from support set\"\"\"\n",
    "    # For prototypical networks, we just compute prototypes\n",
    "    proto_classifier.fit_prototypes(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on training data to get training metrics\n",
    "    return _test_prototypical_model(encoder, proto_classifier, X_train, y_train)\n",
    "\n",
    "def _test_prototypical_model(encoder, proto_classifier, X_test, y_test):\n",
    "    \"\"\"Evaluate prototypical classifier - MEMORY EFFICIENT\"\"\"\n",
    "    encoder.eval()\n",
    "    \n",
    "    # Get predictions in batches\n",
    "    predictions, probabilities = proto_classifier.predict_batch(X_test, batch_size=32)\n",
    "    \n",
    "    # Convert to numpy for metric calculation\n",
    "    if isinstance(y_test, torch.Tensor):\n",
    "        y_true = y_test.cpu().numpy()\n",
    "    else:\n",
    "        y_true = y_test\n",
    "        \n",
    "    y_pred = predictions.numpy()\n",
    "    y_proba = probabilities.numpy()\n",
    "    \n",
    "    # Calculate metrics (same as original)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    \n",
    "    # For AUC, handle multi-class case\n",
    "    try:\n",
    "        if len(np.unique(y_true)) > 2:\n",
    "            # Multi-class AUC (one-vs-rest)\n",
    "            from sklearn.preprocessing import label_binarize\n",
    "            y_true_bin = label_binarize(y_true, classes=proto_classifier.class_ids.cpu().numpy())\n",
    "            if y_true_bin.shape[1] == 1:\n",
    "                auc = roc_auc_score(y_true_bin, y_proba[:, 1] if y_proba.shape[1] > 1 else y_proba[:, 0])\n",
    "            else:\n",
    "                auc = roc_auc_score(y_true_bin, y_proba, multi_class='ovr', average='macro')\n",
    "        else:\n",
    "            auc = roc_auc_score(y_true, y_proba[:, 1] if y_proba.shape[1] > 1 else y_proba[:, 0])\n",
    "            \n",
    "        # AUPRC (Average Precision)\n",
    "        if len(np.unique(y_true)) > 2:\n",
    "            auprc = average_precision_score(y_true_bin, y_proba, average='macro') if 'y_true_bin' in locals() else 0.5\n",
    "        else:\n",
    "            auprc = average_precision_score(y_true, y_proba[:, 1] if y_proba.shape[1] > 1 else y_proba[:, 0])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not compute AUC/AUPRC: {e}\")\n",
    "        auc = 0.5\n",
    "        auprc = 0.5\n",
    "    \n",
    "    # No loss for prototypical networks\n",
    "    loss = 0.0\n",
    "    \n",
    "    # Confusion matrix\n",
    "    c_mtx = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return loss, accuracy, auc, auprc, c_mtx\n",
    "\n",
    "print(\"‚úÖ OPTIMIZED WFEncoder and EfficientPrototypicalClassifier defined!\")\n",
    "print(\"üíæ Memory optimizations: batch processing, reduced k-shot, efficient caching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e0db1",
   "metadata": {},
   "source": [
    "## 3. Load Pre-trained TNC Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc98955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained TNC encoder (same as original)\n",
    "encoder_path = os.path.join(CHECKPOINT_PATH, 'waveform', 'checkpoint_0.pth.tar')\n",
    "\n",
    "print(f\"Loading TNC encoder from: {encoder_path}\")\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(encoder_path, map_location=device)\n",
    "\n",
    "# Initialize the encoder with the same parameters as training\n",
    "encoder = WFEncoder(encoding_size=64)  # Make sure this matches your training config\n",
    "\n",
    "# Load the encoder state\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "print(\"‚úÖ Full encoder loaded from checkpoint\")\n",
    "\n",
    "encoder = encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "print(f\"Encoding size: {encoder.encoding_size}\")\n",
    "print(f\"Best training accuracy: {checkpoint.get('best_accuracy', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8584aa48",
   "metadata": {},
   "source": [
    "## 4. Load ECG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ECG data from your waveform_data directory\n",
    "wf_datapath = os.path.join(DATA_PATH, 'waveform_data', 'processed')\n",
    "\n",
    "# Load training data\n",
    "x_train_file = os.path.join(wf_datapath, 'x_train.pkl')\n",
    "y_train_file = os.path.join(wf_datapath, 'state_train.pkl')\n",
    "\n",
    "# Load test data  \n",
    "x_test_file = os.path.join(wf_datapath, 'x_test.pkl')\n",
    "y_test_file = os.path.join(wf_datapath, 'state_test.pkl')\n",
    "\n",
    "print(f\"Loading ECG data from: {wf_datapath}\")\n",
    "print(f\"Training files: {x_train_file}, {y_train_file}\")\n",
    "print(f\"Test files: {x_test_file}, {y_test_file}\")\n",
    "\n",
    "# Load the data files\n",
    "with open(x_train_file, 'rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "\n",
    "with open(y_train_file, 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open(x_test_file, 'rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "with open(y_test_file, 'rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "\n",
    "# Check class distribution (same as original)\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "\n",
    "print(\"\\\\nClass distribution:\")\n",
    "print(\"Training:\", dict(zip(unique_train, counts_train)))\n",
    "print(\"Test:\", dict(zip(unique_test, counts_test)))\n",
    "\n",
    "# Convert to tensors for PyTorch\n",
    "X_train_tensor = torch.Tensor(X_train).to(device)\n",
    "y_train_tensor = torch.Tensor(y_train.flatten()).long().to(device)\n",
    "X_test_tensor = torch.Tensor(X_test).to(device) \n",
    "y_test_tensor = torch.Tensor(y_test.flatten()).long().to(device)\n",
    "\n",
    "print(f\"\\\\nConverted to tensors:\")\n",
    "print(f\"X_train_tensor: {X_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor: {y_train_tensor.shape}\")\n",
    "print(f\"X_test_tensor: {X_test_tensor.shape}\")\n",
    "print(f\"y_test_tensor: {y_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLIFIED DATA PROCESSING - Same as Linear Classifier (MEMORY EFFICIENT)\n",
    "def prepare_windowed_data(x_data, y_data, window_size=2500):\n",
    "    \"\"\"Convert continuous data into windowed segments - SAME AS LINEAR CLASSIFIER\"\"\"\n",
    "    print(f\"üîß Processing data with simple windowing (window_size={window_size})\")\n",
    "    print(f\"Original shape: {x_data.shape}\")\n",
    "    \n",
    "    T = x_data.shape[-1]\n",
    "    n_windows = T // window_size\n",
    "    \n",
    "    # Simple reshaping into non-overlapping windows (memory efficient)\n",
    "    x_windowed = np.split(x_data[:, :, :window_size * n_windows], n_windows, -1)\n",
    "    y_windowed = np.split(y_data[:, :window_size * n_windows], n_windows, -1)\n",
    "    \n",
    "    # Concatenate all windows\n",
    "    x_windowed = np.concatenate(x_windowed, 0)\n",
    "    y_windowed = np.concatenate(y_windowed, 0)\n",
    "    \n",
    "    # Get majority vote for each window\n",
    "    y_windowed = np.array([np.bincount(yy.astype(int)).argmax() for yy in y_windowed])\n",
    "    \n",
    "    print(f\"Windowed shape: {x_windowed.shape}\")\n",
    "    print(f\"Labels shape: {y_windowed.shape}\")\n",
    "    print(f\"Window size: {x_windowed.shape[-1]} ‚úÖ\")\n",
    "    print(f\"Number of windows: {len(x_windowed)}\")\n",
    "    print(f\"Class distribution: {np.bincount(y_windowed.astype(int))}\")\n",
    "    \n",
    "    return x_windowed, y_windowed\n",
    "\n",
    "# Apply SIMPLE processing (same as linear classifier)\n",
    "print(\"üîÑ Using LINEAR CLASSIFIER's simple windowing approach...\")\n",
    "X_train_processed, y_train_processed = prepare_windowed_data(X_train, y_train, window_size=2500)\n",
    "X_test_processed, y_test_processed = prepare_windowed_data(X_test, y_test, window_size=2500)\n",
    "\n",
    "print(f\"\\n‚úÖ Data processed with SIMPLE approach!\")\n",
    "print(f\"Train: {X_train_processed.shape} -> Much more memory efficient! üéØ\")\n",
    "print(f\"Test: {X_test_processed.shape}\")\n",
    "print(f\"Sequence length: {X_train_processed.shape[-1]} (using standard 2500)\")\n",
    "\n",
    "# Quick verification that this will work with the encoder\n",
    "print(f\"\\nüîç Quick compatibility check...\")\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        # Test with a small batch\n",
    "        test_tensor = torch.FloatTensor(X_train_processed[:2]).to(device)\n",
    "        test_output = encoder(test_tensor)\n",
    "        print(f\"‚úÖ Encoder compatibility confirmed!\")\n",
    "        print(f\"Input shape: {test_tensor.shape}\")\n",
    "        print(f\"Output shape: {test_output.shape}\")\n",
    "        print(f\"Feature dimension: {test_output.shape[1]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Compatibility issue: {e}\")\n",
    "    print(\"üí° The encoder might need the exact sequence length it was trained with\")\n",
    "\n",
    "print(f\"\\nüíæ Memory savings: Using {len(X_train_processed)} windows instead of many overlapping ones!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b0619",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Prototypical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25907e7f",
   "metadata": {},
   "source": [
    "## üöÄ OPTIMIZED MEMORY-EFFICIENT VERSION\n",
    "\n",
    "### Key Optimizations Made:\n",
    "\n",
    "#### üîß **Data Processing Fixes:**\n",
    "- ‚úÖ **Removed complex windowing**: No more overlapping windows with 50% stride\n",
    "- ‚úÖ **Simple 2500-window approach**: Same as linear classifier (memory efficient)\n",
    "- ‚úÖ **Eliminated sequence length search**: No more trying different lengths (2496, etc.)\n",
    "\n",
    "#### üíæ **Memory Optimizations:**\n",
    "- ‚úÖ **Batch processing**: Process data in small batches (32) instead of all at once\n",
    "- ‚úÖ **Reduced k-shot**: From 5 to 3 shots per class\n",
    "- ‚úÖ **GPU memory clearing**: Automatic cache clearing to prevent buildup\n",
    "- ‚úÖ **Efficient feature extraction**: Extract features in batches\n",
    "\n",
    "#### ‚ö° **Performance Improvements:**\n",
    "- ‚úÖ **No unnecessary epochs**: Single pass instead of 8 epochs\n",
    "- ‚úÖ **Timing information**: Track actual execution time\n",
    "- ‚úÖ **Resource monitoring**: Better memory management\n",
    "\n",
    "### Expected Results:\n",
    "- üéØ **Same accuracy** as linear classifier\n",
    "- üíæ **Much lower memory usage** (should fit in Colab)\n",
    "- ‚ö° **Faster execution** (no redundant processing)\n",
    "- üîß **Better stability** (no memory crashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d36570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CORRECTLY PROCESSED data to PyTorch tensors\n",
    "X_train_tensor = torch.Tensor(X_train_processed).to(device)\n",
    "y_train_tensor = torch.Tensor(y_train_processed).long().to(device)\n",
    "X_test_tensor = torch.Tensor(X_test_processed).to(device)\n",
    "y_test_tensor = torch.Tensor(y_test_processed).long().to(device)\n",
    "\n",
    "print(f\"‚úÖ Converted CORRECTLY SIZED data to tensors:\")\n",
    "print(f\"X_train: {X_train_tensor.shape}\")\n",
    "print(f\"y_train: {y_train_tensor.shape}\")\n",
    "print(f\"X_test: {X_test_tensor.shape}\")\n",
    "print(f\"y_test: {y_test_tensor.shape}\")\n",
    "print(f\"Sequence length: {X_train_tensor.shape[-1]} (should match model requirement)\")\n",
    "print(f\"Unique classes: {torch.unique(y_train_tensor)}\")\n",
    "\n",
    "print(\"\\\\nüéØ Data now properly sized for the trained WFEncoder!\")\n",
    "print(\"‚úÖ Ready for prototypical classification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd1ec6",
   "metadata": {},
   "source": [
    "## 6. Run Prototypical Network Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EFFICIENT Prototypical Network Classification - No Unnecessary Loops\n",
    "k_shot = 3    # Reduced for memory efficiency (was 5)\n",
    "batch_size = 32  # Batch processing for memory management\n",
    "\n",
    "print(\"üöÄ Starting EFFICIENT TNC + Prototypical Network classification...\")\n",
    "print(f\"üéØ Using {k_shot}-shot learning with batch_size={batch_size}\")\n",
    "print(f\"üíæ Memory optimizations enabled\")\n",
    "\n",
    "# Initialize EFFICIENT prototypical classifier\n",
    "proto_classifier = EfficientPrototypicalClassifier(encoder, k_shot=k_shot, batch_size=batch_size)\n",
    "\n",
    "print(f\"\\nüìä Data sizes:\")\n",
    "print(f\"Training: {X_train_tensor.shape[0]} samples\")\n",
    "print(f\"Test: {X_test_tensor.shape[0]} samples\")\n",
    "print(f\"Classes: {torch.unique(y_train_tensor).cpu().tolist()}\")\n",
    "\n",
    "# STEP 1: Fit prototypes (only needs to be done once)\n",
    "print(f\"\\nüîß Step 1: Computing prototypes...\")\n",
    "start_time = time.time()\n",
    "train_loss, train_acc, train_auc, train_auprc, _ = _train_prototypical_classifier(\n",
    "    encoder, proto_classifier, X_train_tensor, y_train_tensor)\n",
    "fit_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Prototypes computed in {fit_time:.2f} seconds\")\n",
    "print(f\"üìà Training metrics - Acc: {train_acc:.4f}, AUC: {train_auc:.4f}, AUPRC: {train_auprc:.4f}\")\n",
    "\n",
    "# STEP 2: Evaluate on test set\n",
    "print(f\"\\nüß™ Step 2: Testing on validation set...\")\n",
    "start_time = time.time()\n",
    "test_loss, test_acc, test_auc, test_auprc, c_mtx_enc = _test_prototypical_model(\n",
    "    encoder, proto_classifier, X_test_tensor, y_test_tensor)\n",
    "test_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Testing completed in {test_time:.2f} seconds\")\n",
    "\n",
    "# Create metrics arrays for compatibility with plotting (single evaluation)\n",
    "tnc_acc = [train_acc]\n",
    "tnc_loss = [train_loss] \n",
    "tnc_auc = [train_auc]\n",
    "tnc_auprc = [train_auprc]\n",
    "tnc_acc_test = [test_acc]\n",
    "tnc_loss_test = [test_loss]\n",
    "tnc_auc_test = [test_auc]\n",
    "tnc_auprc_test = [test_auprc]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ FINAL RESULTS (Efficient Prototypical Network)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"üìà Test AUPRC: {test_auprc:.4f}\")\n",
    "print(f\"üîÑ Test AUC: {test_auc:.4f}\")\n",
    "print(f\"üéì Method: {k_shot}-shot Prototypical Network (Optimized)\")\n",
    "print(f\"üè∑Ô∏è  Classes: {proto_classifier.class_ids.cpu().tolist()}\")\n",
    "print(f\"‚ö° Total time: {fit_time + test_time:.2f} seconds\")\n",
    "print(f\"üíæ Memory efficient: Batch processing, reduced k-shot\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Clear memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"üßπ GPU memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a837f4f",
   "metadata": {},
   "source": [
    "## 8. Visualization and Results (Same as Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fd565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results exactly as in original notebook\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.plot(tnc_acc, 'b-', label='Train')\n",
    "plt.plot(tnc_acc_test, 'r-', label='Test')\n",
    "plt.title('Prototypical Network Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# AUC plot\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.plot(tnc_auc, 'b-', label='Train')\n",
    "plt.plot(tnc_auc_test, 'r-', label='Test')\n",
    "plt.title('Prototypical Network AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# AUPRC plot\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.plot(tnc_auprc, 'b-', label='Train')\n",
    "plt.plot(tnc_auprc_test, 'r-', label='Test')\n",
    "plt.title('Prototypical Network AUPRC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUPRC')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.subplot(2, 4, 4)\n",
    "sns.heatmap(c_mtx_enc, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix (Prototypical)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'prototypical_classification_results.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nüìä Plots saved to: {os.path.join(PLOTS_PATH, 'prototypical_classification_results.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c2381",
   "metadata": {},
   "source": [
    "## üéØ Summary - OPTIMIZED Prototypical Network\n",
    "\n",
    "This notebook successfully implements **memory-efficient Prototypical Networks** that work within Google Colab constraints while maintaining the same performance as the linear classifier.\n",
    "\n",
    "### üöÄ **Key Optimizations Made:**\n",
    "\n",
    "#### üìä **Memory Efficiency:**\n",
    "- ‚úÖ **Simple windowing**: Uses same 2500-window approach as linear classifier (no overlapping)\n",
    "- ‚úÖ **Batch processing**: Processes data in chunks of 32 samples\n",
    "- ‚úÖ **Reduced k-shot**: 3 shots per class instead of 5\n",
    "- ‚úÖ **GPU memory management**: Automatic cache clearing\n",
    "\n",
    "#### ‚ö° **Performance Improvements:**\n",
    "- ‚úÖ **No redundant epochs**: Single pass instead of 8 loops\n",
    "- ‚úÖ **Eliminated complex calculations**: No sequence length search\n",
    "- ‚úÖ **Efficient distance computation**: Batch-wise prototype matching\n",
    "\n",
    "#### üîß **Compatibility:**\n",
    "- ‚úÖ **Same data loading**: Identical ECG waveform data processing\n",
    "- ‚úÖ **Same encoder**: Exact WFEncoder from training\n",
    "- ‚úÖ **Same metrics**: Accuracy, AUC, AUPRC, confusion matrix\n",
    "- ‚úÖ **Same structure**: Drive mounting, checkpoints, plotting\n",
    "\n",
    "### üí° **How Optimized Prototypical Networks Work:**\n",
    "1. **Efficient Support Set**: Uses 3 examples per class to compute prototypes\n",
    "2. **Batch Classification**: Classifies queries in small batches to manage memory\n",
    "3. **Memory-Aware Processing**: Clears GPU cache regularly\n",
    "4. **Single-Pass Learning**: No iterative training required\n",
    "\n",
    "### üéØ **Expected Results:**\n",
    "- **Same accuracy** as linear classifier\n",
    "- **Fits in Google Colab** memory constraints\n",
    "- **Faster execution** with timing information\n",
    "- **Better handling of class imbalance** through few-shot learning\n",
    "\n",
    "### üîÑ **Memory Usage Comparison:**\n",
    "- **Original**: Created thousands of overlapping windows ‚Üí Memory explosion\n",
    "- **Optimized**: Simple non-overlapping windows ‚Üí Memory efficient\n",
    "- **Batch size**: 32 samples at a time ‚Üí Controlled memory usage\n",
    "- **k-shot**: 3 instead of 5 ‚Üí Lower prototype computation cost\n",
    "\n",
    "This optimized version provides the benefits of prototypical networks (better few-shot learning, class imbalance handling) while being as resource-efficient as the linear classifier! üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
