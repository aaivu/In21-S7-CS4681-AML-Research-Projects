# Methodology: AI Evaluation: Reasoning Evaluation

**Student:** 210574A  
**Research Area:** AI Evaluation: Reasoning Evaluation  
**Date:** 2025-09-01

## 1. Overview

The methodology focuses on enhancing financial sentiment analysis using FinBERT by addressing class imbalance issues through data augmentation with Large Language Models (LLMs) like GPT-5. The goal is to integrate synthetic data generated by LLMs into the training set to improve the model's robustness, accuracy, and generalization. This methodology involves a combination of data augmentation, model fine-tuning, and rigorous evaluation to assess improvements in sentiment classification.

## 2. Research Design

This research employs an experimental design with a quantitative approach to evaluate the impact of synthetic data on the performance of FinBERT. The research will involve the following phases:

1. Data augmentation using GPT-5 for generating paraphrased sentences.
2. Fine-tuning FinBERT on the augmented dataset.
3. Performance evaluation on various sentiment classes to assess improvements in accuracy, F1-score, and reduction of misclassification errors.

The study will also include a comparative analysis between the baseline model (trained on the original dataset) and the augmented model (trained on the combined dataset of original and synthetic data).

## 3. Data Collection

### 3.1 Data Sources

- **Financial PhraseBank dataset**: A publicly available dataset of financial news headlines with labeled sentiment classes (positive, negative, and neutral).
- **GPT-5 API**: Used for generating synthetic data through paraphrasing of underrepresented sentiment classes.

### 3.2 Data Description

The Financial PhraseBank dataset consists of financial news headlines and sentences that are labeled with three sentiment classes: positive, negative, and neutral. The dataset includes 1,629 samples for training, 182 for validation, and 453 for testing. The class distribution is heavily imbalanced, with the neutral class being the dominant class.

### 3.3 Data Preprocessing

The preprocessing steps will include:

- Text normalization (e.g., removing punctuation, lowercasing).
- Tokenization using FinBERTâ€™s tokenizer.
- Handling class imbalance by augmenting the positive and negative sentiment classes using GPT-5.
- Data splitting into training, validation, and test sets, ensuring a fair representation of all sentiment classes.

## 4. Model Architecture

The proposed model utilizes **FinBERT**, a domain-specific BERT-based model fine-tuned for financial sentiment analysis. FinBERT is pre-trained on a large financial corpus and has shown superior performance over general-purpose models. For this research, the architecture will include:

- **Input Layer**: Tokenized financial news text.
- **Transformer Layers**: 12 layers, 768 hidden dimensions, pre-trained on financial text.
- **Classification Head**: A softmax layer for predicting sentiment classes (positive, negative, and neutral).

The model will be fine-tuned using both the original and augmented datasets to improve its ability to classify financial sentiments accurately.

## 5. Experimental Setup

### 5.1 Evaluation Metrics

The following evaluation metrics will be used:

- **Accuracy**: The proportion of correctly classified instances.
- **Precision**: The ability of the model to correctly identify positive and negative classes.
- **Recall**: The ability of the model to correctly identify all instances of each class.
- **F1-score**: The harmonic mean of precision and recall, especially important for imbalanced datasets.
- **Confusion Matrix**: To visualize misclassifications and class-specific errors.

### 5.2 Baseline Models

The baseline model will be **FinBERT**, fine-tuned only on the original Financial PhraseBank dataset. Performance will be compared with the **augmented FinBERT model**, which is fine-tuned on the combined dataset (original + synthetic data).

### 5.3 Hardware/Software Requirements

- **Hardware**: A machine with GPU capabilities (e.g., NVIDIA Tesla V100 or A100) for model training.
- **Software**:
  - Python (v3.8+)
  - Libraries: PyTorch, Hugging Face Transformers, scikit-learn
  - GPT-5 API access
  - Jupyter Notebooks for experimentation and results visualization

## 6. Implementation Plan

| Phase   | Tasks                             | Duration | Deliverables        |
| ------- | --------------------------------- | -------- | ------------------- |
| Phase 1 | Data preprocessing                | 2 weeks  | Clean dataset       |
| Phase 2 | Model implementation              | 3 weeks  | Working model       |
| Phase 3 | Data augmentation and fine-tuning | 3 weeks  | Augmented model     |
| Phase 4 | Experiments and evaluation        | 2 weeks  | Performance metrics |
| Phase 5 | Analysis and writing              | 1 week   | Final report        |

## 7. Risk Analysis

- **Risk 1**: **Class Imbalance** - Despite augmentation, the model may still struggle with certain minority classes.
  - **Mitigation**: Apply advanced sampling techniques (e.g., oversampling) and further augment the minority classes.
- **Risk 2**: **Overfitting** - Fine-tuning the model on augmented data may lead to overfitting.
  - **Mitigation**: Use regularization techniques, early stopping, and cross-validation.
- **Risk 3**: **Computational Cost** - The use of GPT-5 and fine-tuning large models may be computationally expensive.
  - **Mitigation**: Monitor resource usage and consider using cloud-based solutions for scaling.

## 8. Expected Outcomes

- **Improved Accuracy**: The augmented model is expected to show a significant increase in classification accuracy, particularly for underrepresented sentiment classes (positive and negative).
- **Increased Generalization**: The integration of synthetic data should enhance the model's ability to generalize to unseen financial texts.
- **Enhanced Model Robustness**: The model will be more resilient to noise in the dataset, as demonstrated by reduced misclassification errors.
