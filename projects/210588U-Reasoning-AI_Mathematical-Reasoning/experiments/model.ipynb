{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Install Dependencies\n",
    "!pip install -q datasets transformers accelerate evaluate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# @title 2. Imports and Device Check\n",
    "import torch, os, re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, T5ForConditionalGeneration,\n",
    "    DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    ")\n",
    "\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. Configuration\n",
    "dataset_name = \"lighteval/MATH-Hard\"     # or \"hendrycks/competition_math\"\n",
    "model_name = \"google/byt5-base\"\n",
    "output_dir = \"./byt5_math_proof_output\"\n",
    "\n",
    "num_train_epochs = 10\n",
    "per_device_train_batch_size = 4\n",
    "per_device_eval_batch_size = 4\n",
    "num_think_tokens = 1      # adds <think> tokens for reasoning\n",
    "max_input_length = 512\n",
    "max_target_length = 512\n",
    "self_consistency_k = 0    # >0 enables majority-vote inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['problem', 'level', 'type', 'solution'],\n",
      "    num_rows: 1152\n",
      "})\n",
      "Dataset({\n",
      "    features: ['problem', 'level', 'type', 'solution'],\n",
      "    num_rows: 13\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# @title 4. Load Dataset\n",
    "def load_math_dataset(name, split=\"train\", max_examples=None):\n",
    "    ds = load_dataset(name, split=split)\n",
    "    if max_examples:\n",
    "        ds = ds.select(range(max_examples))\n",
    "    print(ds)\n",
    "    return ds\n",
    "\n",
    "train_dataset = load_math_dataset(dataset_name, split=\"train[:50%]\")\n",
    "test_dataset  = load_math_dataset(dataset_name, split=\"test[:1%]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Preprocessing Functions\n",
    "def build_input(problem):\n",
    "    return (\n",
    "        \"Solve this problem step by step. \"\n",
    "        \"Show reasoning clearly and put the final answer inside \\\\boxed{...}.\\n\\n\"\n",
    "        f\"Problem: {problem}\\n\\nSolution:\"\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess_examples(examples, tokenizer, max_input_length, max_target_length, num_think_tokens=0):\n",
    "    inputs  = [build_input(p) for p in examples[\"problem\"]]\n",
    "\n",
    "    examples[\"solution\"] = [s.replace(\"\\\\\\\\boxed\", \"\\\\boxed\") for s in examples[\"solution\"]]\n",
    "    targets = examples[\"solution\"]  # full LaTeX solution with \\boxed{...}\n",
    "\n",
    "\n",
    "    if num_think_tokens > 0:\n",
    "        prefix = \"<think>\" * num_think_tokens\n",
    "        targets = [prefix + t for t in targets]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=max_input_length, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets, max_length=max_target_length, truncation=True, padding=\"max_length\"\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "# @title 6. Load Tokenizer & Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "if num_think_tokens > 0 and \"<think>\" not in tokenizer.get_vocab():\n",
    "    tokenizer.add_tokens([\"<think>\"])\n",
    "    model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9483b11edf344114bb03a8f8ddb1015c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4007: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# @title 7. Tokenize Datasets\n",
    "def preprocess_fn(batch):\n",
    "    return preprocess_examples(batch, tokenizer, max_input_length, max_target_length, num_think_tokens)\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocess_fn, batched=True, remove_columns=train_dataset.column_names)\n",
    "tokenized_test  = test_dataset.map(preprocess_fn,  batched=True, remove_columns=test_dataset.column_names)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 8. Evaluation Metrics\n",
    "def extract_boxed_answer(text: str):\n",
    "    # matches \\boxed{ ... } (raw string in HF JSON often has '\\\\boxed{')\n",
    "    m = re.findall(r\"\\\\boxed\\{([^}]*)\\}\", text)\n",
    "    return m[-1].strip() if m else None\n",
    "\n",
    "def final_answer_accuracy(preds, refs):\n",
    "    total, hits = 0, 0\n",
    "    for p, r in zip(preds, refs):\n",
    "        p_box, r_box = extract_boxed_answer(p), extract_boxed_answer(r)\n",
    "        # Count only if reference actually has a boxed answer\n",
    "        # (MATH should, but this guards weird cases)\n",
    "        if r_box is None:\n",
    "            continue\n",
    "        total += 1\n",
    "        if p_box is not None and p_box == r_box:\n",
    "            hits += 1\n",
    "    return {\"final_answer_acc\": (hits / total) if total else 0.0}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    if isinstance(preds, tuple): preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    acc = final_answer_accuracy(decoded_preds, decoded_labels)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipython-input-3891800150.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "# @title 9. Training Arguments & Trainer\n",
    "args_1 = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=Path(output_dir) / \"logs\",\n",
    "    logging_steps=100,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    # evaluation_strategy=  # ← removed for compatibility\n",
    "    # If you want periodic saving/logging by steps instead of epochs, you can add:\n",
    "    # save_steps=500,\n",
    "    # logging_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "# ================================================================================\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=6e-4,           # T5/ByT5 like a higher LR than BERT\n",
    "    warmup_ratio=0.05,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16, # effective batch 32\n",
    "    dataloader_num_workers=2,\n",
    "\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=512,\n",
    "\n",
    "    logging_dir=Path(output_dir) / \"logs\",\n",
    "    logging_steps=100,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_total_limit=2,\n",
    "    bf16=torch.cuda.is_available(),   # or fp16=True if no bf16\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='678' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [678/720 2:52:45 < 10:44, 0.07 it/s, Epoch 9.40/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.211400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.803700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.612400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.559600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.526700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title 10. Train & Evaluate\n",
    "train = True\n",
    "evaluate = True\n",
    "\n",
    "if train:\n",
    "    print(\"🚀 Starting fine-tuning...\")\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "if evaluate:\n",
    "    print(\"📈 Evaluating...\")\n",
    "    results = trainer.evaluate()\n",
    "    print(\"Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 11. Self-Consistency Evaluation\n",
    "if self_consistency_k > 0:\n",
    "    from collections import Counter\n",
    "    print(f\"Running self-consistency with k={self_consistency_k}\")\n",
    "    model.eval()\n",
    "    preds, refs = [], []\n",
    "    for ex in test_dataset:\n",
    "        q, ref = ex[\"problem\"], ex[\"solution\"]\n",
    "        input_ids = tokenizer(q, return_tensors=\"pt\").input_ids\n",
    "        candidates = []\n",
    "        for _ in range(self_consistency_k):\n",
    "            out = model.generate(input_ids, do_sample=True, top_p=0.9, max_length=max_target_length)\n",
    "            text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "            candidates.append(text)\n",
    "        preds.append(Counter(candidates).most_common(1)[0][0])\n",
    "        refs.append(ref)\n",
    "    acc = final_answer_accuracy(preds, refs)\n",
    "    print(\"Self-consistency final-answer Acc:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 12. Quick Inference\n",
    "# Inference (device-safe)\n",
    "# --- generation config ---\n",
    "gen_kwargs = dict(\n",
    "    max_new_tokens=512,\n",
    "    num_beams=4,                # or do_sample=True, top_p=0.9 for self-consistency\n",
    "    length_penalty=0.8,         # discourage overly long rambles\n",
    "    no_repeat_ngram_size=3,\n",
    ")\n",
    "\n",
    "# --- inference ---\n",
    "question = \"Compute the derivative of x^3 + 2x^2 + 5x + 7.\"\n",
    "inp = build_input(question)  # <-- use your build_input() if you added it\n",
    "inputs = tokenizer(inp, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(**inputs, **gen_kwargs)\n",
    "\n",
    "print(tokenizer.decode(output_ids[0], skip_special_tokens=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[0].keys())\n",
    "print(train_dataset[0][\"problem\"])\n",
    "print(train_dataset[0][\"solution\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
