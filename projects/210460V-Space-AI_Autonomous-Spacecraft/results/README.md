# Validation and Results

Both the baseline ART and Physics-Aware ART were evaluated on identical validation datasets  
(*N = 10,000*, *T = 100*, *Dâ‚“ = 6*, *Dáµ¤ = 3*).  
Table 1 summarizes the average quantitative results obtained.

| **Model** | **ğ“›â‚œâ‚’â‚œâ‚â‚—** | **ğ“›â‚›â‚œâ‚â‚œâ‚‘** | **ğ“›â‚câ‚œáµ¢â‚’â‚™** | **physics_res** | **MSE@10** | **MSE@50** | **Feas. Ratio** |
|:-----------|:------------:|:------------:|:------------:|:----------------:|:-----------:|:-----------:|:----------------:|
| Baseline ART | 6.941Ã—10â»Â¹ | 4.257Ã—10â»Â³ | 6.899Ã—10â»Â¹ | 2.626Ã—10â»Â¹ | 7.973Ã—10Â² | 5.169Ã—10Â³ | 0.0 |
| **Physics-Aware ART** | **6.887Ã—10â»Â¹** | **3.570Ã—10â»âµ** | **6.886Ã—10â»Â¹** | **2.531Ã—10â»Â¹** | 9.070Ã—10Â² | **5.089Ã—10Â³** | 0.0 |

**Table 1.** Comparison of baseline ART and Physics-Aware ART on validation dataset.  
Lower is better for all metrics.

---

The results show that the physics-aware enhancement yields:

- a **99% reduction** in one-step state prediction error (ğ“›â‚›â‚œâ‚â‚œâ‚‘),  
- a **3.6% decrease** in physics residuals, indicating improved adherence to orbital dynamics,  
- a marginally lower overall validation loss (ğ“›â‚œâ‚’â‚œâ‚â‚—), and  
- improved medium-horizon stability (MSE@50).

The control prediction loss (ğ“›â‚câ‚œáµ¢â‚’â‚™) shows a slight improvement of approximately **0.77%**, indicating that the physics-aware regularization not only preserves but marginally enhances the modelâ€™s ability to imitate optimal control actions.  

However, both models still exhibit numerical divergence at long horizons (MSE@100) and a zero feasibility ratio.  
This degradation in long-term convergence is likely attributed to the absence of Sequential Convex Programming (SCP) refinement during data generation and training, where only the optimally solved convex trajectories were utilized without iterative feasibility correction.

---

### Interpretation

These results confirm that incorporating physics-informed regularization improves local dynamic consistency and mid-horizon rollout stability without compromising policy imitation performance.  
The approach effectively biases the Transformer toward physically valid transitions, bridging the gap between pure data-driven learning and physically grounded trajectory generation.
