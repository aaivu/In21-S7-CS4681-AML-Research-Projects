{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID-CodeFormer: Training Notebook\n",
    "\n",
    "This notebook provides a complete workflow to train **ID-CodeFormer**, an enhanced version of CodeFormer with improved identity preservation. This is achieved by integrating an ArcFace-based identity loss into the training pipeline, as described in the project's research papers.\n",
    "\n",
    "### Workflow Overview:\n",
    "1.  **Setup Environment**: Clones the repository and installs all necessary dependencies.\n",
    "2.  **Mount Google Drive**: Connects to your Google Drive to access the training dataset.\n",
    "3.  **Download Pre-trained Models**: Fetches the required weights for CodeFormer, VQGAN, facelib, and the ArcFace model.\n",
    "4.  **Apply Code Modifications**: Programmatically modifies the codebase to add the identity loss functionality.\n",
    "5.  **Configure Training**: Creates the YAML configuration file for the training run, pointing to the dataset in your Google Drive.\n",
    "6.  **Start Training**: Launches the training process.\n",
    "\n",
    "**Before you begin**: Make sure your Colab runtime is set to **GPU** (`Runtime > Change runtime type`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, we clone the CodeFormer repository and install the required Python packages. This step also builds the custom CUDA extensions needed by the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the CodeFormer repository from GitHub\n",
    "!git clone https://github.com/SanjanaChamindu/CodeFormer.git\n",
    "%cd CodeFormer\n",
    "\n",
    "# Install the dependencies listed in requirements.txt\n",
    "# Note: This might take a few minutes.\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Set up the basicsr library, which includes custom CUDA ops\n",
    "!python basicsr/setup.py develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive\n",
    "\n",
    "Now, we'll mount your Google Drive. This allows the notebook to access the FFHQ dataset that you have stored there. You will be prompted to authorize this access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Pre-trained Models\n",
    "\n",
    "We need several pre-trained models to start training. This includes the base CodeFormer and VQGAN weights, models for face detection/parsing (facelib), and the ArcFace model for our new identity loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the official CodeFormer pre-trained models for training\n",
    "!python scripts/download_pretrained_models.py CodeFormer_train\n",
    "\n",
    "# Download the facelib helper models\n",
    "!python scripts/download_pretrained_models.py facelib\n",
    "\n",
    "# Download the pre-trained ArcFace model for the identity loss\n",
    "# It will be saved into the 'weights/facelib' directory\n",
    "!wget -P ./weights/facelib https://github.com/deepinsight/insightface/raw/master/model_zoo/arcface_torch/ms1mv3_arcface_r100_fp16.zip\n",
    "!unzip -o -d ./weights/facelib ./weights/facelib/ms1mv3_arcface_r100_fp16.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start Training\n",
    "\n",
    "Now we can finally start training our ID-CodeFormer model. The training progress will be printed below, and checkpoints will be saved periodically to the `experiments/ID_CodeFormer_Exp1` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python basicsr/train.py -opt options/train_id_codeformer.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference with the Trained Model (Optional)\n",
    "\n",
    "Once training is complete, you can use this section to test your new model. Make sure to update the `--input_path` to your test images and `--model_path` to the path of your saved checkpoint (e.g., `experiments/ID_CodeFormer_Exp1/models/net_g_latest.pth`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder for test images\n",
    "!mkdir -p inputs/my_test_images\n",
    "\n",
    "# Note: You should upload your own test images to the 'inputs/my_test_images' folder\n",
    "\n",
    "# Run inference with a specific checkpoint\n",
    "# Make sure to replace 'net_g_latest.pth' with the checkpoint you want to test\n",
    "# Note: The inference script does not have a --model_path argument by default, you would need to modify it or place your trained model in the expected path 'weights/CodeFormer/codeformer.pth'\n",
    "!python inference_codeformer.py \\\n",
    "    --input_path inputs/my_test_images \\\n",
    "    -w 0.7 \\\n",
    "    --bg_upsampler realesrgan \\\n",
    "    --face_upsample"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Training_ID-CodeFormer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
