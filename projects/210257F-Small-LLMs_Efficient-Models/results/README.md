# ğŸ“Š Results Directory â€” EdgeMIN Project

This folder contains the **evaluation outputs, trained model artifacts, and performance summaries** generated throughout the EdgeMIN model compression pipeline.

EdgeMIN is a three-stage systematic compression framework combining **relational knowledge distillation**, **structured pruning**, and **post-training quantization** to make Transformer models efficient for **edge device deployment**.

---

## ğŸ“ Directory Overview

```bash
EdgeMIN_Project/
â”‚
â”œâ”€â”€ distilled_student/              # Stage 1 output: Distilled MiniLMv2 student model
â”œâ”€â”€ figures/                        # Visual results and plots (e.g., size vs. accuracy, latency comparisons)
â”œâ”€â”€ models/                         # Final trained and compressed model weights
â”œâ”€â”€ results/                        # (You are here) â€” all evaluation metrics and outputs
â”œâ”€â”€ tmp_pruning_finetune/           # Intermediate checkpoints during pruning fine-tuning
â”œâ”€â”€ tmp_qat_training/               # Temporary artifacts from quantization-aware training
â”‚
â”œâ”€â”€ accuracy_results.csv            # Accuracy metrics for all models across compression stages
â”œâ”€â”€ baseline_results.csv            # Baseline (teacher model) evaluation before compression
â”œâ”€â”€ evaluation_results.csv          # Combined accuracy, latency, FLOPs, and model size results
â”œâ”€â”€ evaluation_results.xlsx          # Excel version of full evaluation metrics for easy analysis
â”œâ”€â”€ evaluation_summary.txt          # Summary of compression performance and key observations
â”œâ”€â”€ quantized_model.pth             # Final quantized and pruned EdgeMIN model (INT8 weights)
â””â”€â”€ throughput_results.csv          # CPU throughput and latency measurements (samples/sec)
```

## ğŸ”— Access Trained Models

All trained and compressed models are also available in the following shared Google Drive folder:

ğŸ‘‰ **[Access Trained Models on Google Drive](https://drive.google.com/drive/u/0/folders/1EabMrsx7YFVIBq4K9B4Z6sIbHRfwhSxs)**

This includes:
- Distilled student model checkpoints  
- Pruned and fine-tuned models  
- Quantized INT8 deployment models  
- Evaluation results and logs  
