{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13196451,"sourceType":"datasetVersion","datasetId":8363024}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers==4.50","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import PegasusXConfig, PegasusXForConditionalGeneration, pipeline, AutoTokenizer\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = PegasusXConfig(max_position_embeddings = 512, activation_function=\"silu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fine Tuning","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nds_path=\"/kaggle/input/cnndailymail/train.parquet\"\nds = load_dataset('parquet', data_files=ds_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-x-base\")\n\n# Define the preprocessing function\ndef preprocess_function(examples):\n    # Tokenize the reports (input)\n    model_inputs = tokenizer(\n        examples['article'],\n        max_length=128,\n        truncation=True,\n    )\n\n    # Tokenize the summaries (labels)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples['highlights'],\n            max_length=128,\n            truncation=True,\n        )\n\n    # Add the labels to the model inputs\n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs\n\n# Apply the preprocessing function to the entire dataset\n#tokenized_dataset = combined_dataset.map(preprocess_function, batched=True)\ntokenized_dataset = ds.map(preprocess_function, batched=True)\ntrain_dataset_split = tokenized_dataset['train']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import PegasusXForConditionalGeneration, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n\n# Load the model\nmodel = PegasusXForConditionalGeneration.from_pretrained(\"google/pegasus-x-base\",config=config, ignore_mismatched_sizes=True).to(device)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",            # The output directory\n    per_device_train_batch_size=1,     # Batch size for training\n    num_train_epochs=3,                # Number of training epochs\n    logging_dir='./logs',              # Directory for logs\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    report_to=\"tensorboard\" # Recommended for more advanced visualization\n)\n\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset_split = train_dataset_split.select(range(16000))\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset_split,\n    tokenizer=tokenizer,\n    data_collator=data_collator\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Start fine-tuning!\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir -p results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -r results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming 'trainer' is your Hugging Face Trainer object\noutput_dir = \"/kaggle/working/silu\"\ntrainer.save_model(output_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n# model_ckpt = \"/kaggle/working/silu/\"\n# tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n# model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n\n# pipe = pipeline('summarization', model = model_ckpt)\n# pipe_out = pipe(test_text)\n# print(pipe_out)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}