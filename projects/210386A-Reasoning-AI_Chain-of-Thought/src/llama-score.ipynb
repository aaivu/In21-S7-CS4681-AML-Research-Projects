{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==============================================================================\n# CELL 0: Install/Upgrade Required Packages\n# ==============================================================================\n# Run this first, then restart kernel\n\"\"\"\n!pip uninstall -y transformers accelerate trl peft -y\n!pip install transformers==4.36.2 --no-cache-dir\n!pip install accelerate==0.25.0 --no-cache-dir\n!pip install peft==0.7.1 --no-cache-dir\n!pip install trl==0.7.4 --no-cache-dir\n!pip install bitsandbytes==0.41.3 --no-cache-dir\n!pip install datasets==2.10.2 --no-cache-dir\n\"\"\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n# RUN THIS CELL FIRST - Install/Upgrade BitsAndBytes\n# ==============================================================================\nimport subprocess\nimport sys\n\nprint(\"=\"*80)\nprint(\"INSTALLING/UPGRADING BITSANDBYTES\")\nprint(\"=\"*80)\n\n# Method 1: Try standard upgrade\ntry:\n    print(\"\\n1. Upgrading bitsandbytes to latest version...\")\n    result = subprocess.run(\n        [sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"bitsandbytes\"],\n        capture_output=True,\n        text=True\n    )\n    print(result.stdout)\n    if result.returncode == 0:\n        print(\"Successfully upgraded bitsandbytes\")\n    else:\n        print(\"Upgrade had some issues, trying alternative method...\")\n        raise Exception(\"Standard install failed\")\nexcept Exception as e:\n    # Method 2: Try with specific version\n    print(\"Trying to install specific version (0.41.0)...\")\n    try:\n        subprocess.check_call(\n            [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"bitsandbytes==0.41.0\"],\n            stdout=subprocess.PIPE\n        )\n        print(\"Installed bitsandbytes 0.41.0\")\n    except:\n        print(\"Could not install specific version\")\n\n# Verify installation\nprint(\"\\n3. Verifying installation...\")\ntry:\n    import bitsandbytes as bnb\n    print(f\"✓ bitsandbytes version: {bnb.__version__}\")\n    print(\"✓ Import successful!\")\nexcept Exception as e:\n    print(f\"✗ Import failed: {e}\")\n    print(\"\\n⚠ IMPORTANT: If bitsandbytes still doesn't work:\")\n    print(\"   - Set USE_QUANTIZATION = False in the config\")\n    print(\"   - The code will automatically fall back to FP16\")\n    print(\"   - You'll need more GPU memory but it will work\")\n\n# Also upgrade related packages\nprint(\"\\n4. Upgrading related packages...\")\ntry:\n    subprocess.check_call(\n        [sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"-q\", \"accelerate\", \"transformers\"],\n    )\n    print(\"Upgraded accelerate and transformers\")\nexcept:\n    print(\"Could not upgrade all packages\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"INSTALLATION COMPLETE \")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T06:10:47.725356Z","iopub.execute_input":"2025-10-07T06:10:47.725715Z","iopub.status.idle":"2025-10-07T06:10:55.113239Z","shell.execute_reply.started":"2025-10-07T06:10:47.725679Z","shell.execute_reply":"2025-10-07T06:10:55.112454Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nINSTALLING/UPGRADING BITSANDBYTES\n================================================================================\n\n1. Upgrading bitsandbytes to latest version...\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.48.1)\nRequirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n\nSuccessfully upgraded bitsandbytes\n\n3. Verifying installation...\n✓ bitsandbytes version: 0.48.1\n✓ Import successful!\n\n4. Upgrading related packages...\nUpgraded accelerate and transformers\n\n================================================================================\nINSTALLATION COMPLETE \n================================================================================\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n\n# ==============================================================================\n# CELL 1: Imports and Configuration\n# ==============================================================================\nimport os\nimport torch\nimport torch.nn.functional as F\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForCausalLM, \n    BitsAndBytesConfig,\n)\nfrom peft import (\n    LoraConfig, \n    get_peft_model, \n    prepare_model_for_kbit_training,\n    PeftModel\n)\n# Note: We'll implement a simplified PPO instead of using trl's PPOTrainer to avoid import issues\nfrom datasets import Dataset\nfrom kaggle_secrets import UserSecretsClient\nimport numpy as np\nfrom typing import List, Dict, Tuple\nimport re\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\n\n# Get HF token\nhf = UserSecretsClient()\nHF_TOKEN = hf.get_secret(\"HF_TOKEN\")\n\n# Configuration\nREPO = \"O1-OPEN/OpenO1-LLama-8B-v0.1\"\n# SUBFOLDER = \"checkpoint-1000\"\nUSE_SUBFOLDER = False\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nMAX_LENGTH = 512\nMAX_NEW_TOKENS = 256\n\n# Training hyperparameters\nSTAGE1_EPOCHS = 3\nSTAGE1_BATCH_SIZE = 2\nSTAGE1_GRAD_ACCUM = 8\nSTAGE1_LR = 2e-4\nKL_COEF = 0.1  # KL penalty coefficient\n\nSTAGE2_STEPS = 1000\nSTAGE2_BATCH_SIZE = 2\nSTAGE2_LR = 1e-5\nCORRECTION_BONUS = 1.0  # Bonus when second attempt > first\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nprint(f\"Using device: {DEVICE}\")\nprint(f\"Available GPUs: {torch.cuda.device_count()}\")\n\n# ==============================================================================\n# CELL 2: Load Tokenizer and Models (4-bit Quantization)\n# ==============================================================================\nprint(\"Loading tokenizer...\")\nif USE_SUBFOLDER:\n    tokenizer = AutoTokenizer.from_pretrained(\n        REPO, \n        subfolder=SUBFOLDER,\n        trust_remote_code=True,\n        token=HF_TOKEN\n    )\nelse:\n    tokenizer = AutoTokenizer.from_pretrained(\n        REPO,\n        trust_remote_code=True,\n        token=HF_TOKEN\n    )\n\n# Set pad token\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.pad_token_id = tokenizer.eos_token_id\n\nprint(\"Setting up 4-bit quantization...\")\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)\n\nprint(\"Loading base model (this may take several minutes)...\")\nmodel_kwargs = {\n    \"quantization_config\": bnb_config,\n    \"device_map\": \"auto\",  # Spreads across both T4s\n    \"trust_remote_code\": True,\n    \"token\": HF_TOKEN,\n}\nif USE_SUBFOLDER:\n    model_kwargs[\"subfolder\"] = SUBFOLDER\n\nbase_model = AutoModelForCausalLM.from_pretrained(REPO, **model_kwargs)\nbase_model.config.use_cache = False  # Required for gradient checkpointing\n\nprint(\"Loading reference model (frozen)...\")\nref_model = AutoModelForCausalLM.from_pretrained(REPO, **model_kwargs)\nref_model.eval()\nfor p in ref_model.parameters():\n    p.requires_grad = False\n\nprint(f\"Base model device map: {base_model.hf_device_map}\")\n\n# ==============================================================================\n# CELL 3: Prepare Model with LoRA\n# ==============================================================================\nprint(\"Preparing model for k-bit training...\")\nbase_model = prepare_model_for_kbit_training(base_model)\n\n# LoRA configuration\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Qwen modules\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nprint(\"Attaching LoRA adapters...\")\nmodel = get_peft_model(base_model, lora_config)\nmodel.print_trainable_parameters()\n\n# ==============================================================================\n# CELL 4: Prepare Dataset (Example Format)\n# ==============================================================================\n# Your dataset should have: problem, first_attempt, second_attempt, correctness\n# Format: {\"problem\": \"...\", \"first_attempt\": \"...\", \"second_attempt\": \"...\", \"answer\": \"...\", \"is_correct_1\": bool, \"is_correct_2\": bool}\ndef create_sample_dataset():\n    \"\"\"Create a small sample dataset for testing\"\"\"\n    samples = [\n        {\n            \"problem\": \"What is 25 + 17?\",\n            \"first_attempt\": \"Let me calculate: 25 + 17 = 41\",\n            \"second_attempt\": \"Let me recalculate: 25 + 17 = 42\",\n            \"answer\": \"42\",\n            \"is_correct_1\": False,\n            \"is_correct_2\": True\n        },\n        {\n            \"problem\": \"Solve: 3x + 5 = 14\",\n            \"first_attempt\": \"3x = 14 - 5 = 9, so x = 4\",\n            \"second_attempt\": \"3x = 14 - 5 = 9, so x = 3\",\n            \"answer\": \"3\",\n            \"is_correct_1\": False,\n            \"is_correct_2\": True\n        },\n        {\n            \"problem\": \"What is 15 * 8?\",\n            \"first_attempt\": \"15 * 8 = 110\",\n            \"second_attempt\": \"Let me recalculate: 15 * 8 = 120\",\n            \"answer\": \"120\",\n            \"is_correct_1\": False,\n            \"is_correct_2\": True\n        },\n        {\n            \"problem\": \"If y - 7 = 12, what is y?\",\n            \"first_attempt\": \"y = 12 + 7 = 20\",\n            \"second_attempt\": \"y = 12 + 7 = 19\",\n            \"answer\": \"19\",\n            \"is_correct_1\": False,\n            \"is_correct_2\": True\n        },\n    ] * 25  # Repeat to create larger dataset\n    return Dataset.from_list(samples)\n\n# def create_sample_dataset():\n#     \"\"\"Create a small sample dataset for testing\"\"\"\n#     samples = [\n#         {\n#             \"problem\": \"What is 25 + 17?\",\n#             \"first_attempt\": \"Let me calculate: 25 + 17 = 41\",\n#             \"second_attempt\": \"Let me recalculate: 25 + 17 = 42\",\n#             \"answer\": \"42\",\n#             \"is_correct_1\": False,\n#             \"is_correct_2\": True\n#         },\n#         {\n#             \"problem\": \"Solve: 3x + 5 = 14\",\n#             \"first_attempt\": \"3x = 14 - 5 = 9, so x = 4\",\n#             \"second_attempt\": \"3x = 14 - 5 = 9, so x = 3\",\n#             \"answer\": \"3\",\n#             \"is_correct_1\": False,\n#             \"is_correct_2\": True\n#         },\n#         # Add more examples...\n#     ]\n#     return Dataset.from_list(samples)\n\n# Load your actual dataset here\nprint(\"Creating/loading dataset...\")\ntrain_dataset = create_sample_dataset()\nprint(f\"Dataset size: {len(train_dataset)}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T06:11:02.524292Z","iopub.execute_input":"2025-10-07T06:11:02.524944Z","iopub.status.idle":"2025-10-07T06:13:20.763324Z","shell.execute_reply.started":"2025-10-07T06:11:02.524918Z","shell.execute_reply":"2025-10-07T06:13:20.762503Z"}},"outputs":[{"name":"stderr","text":"2025-10-07 06:11:06.331570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759817466.360451     344 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759817466.369321     344 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nAvailable GPUs: 2\nLoading tokenizer...\nSetting up 4-bit quantization...\nLoading base model (this may take several minutes)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d9e5a45e6ab47fc902e0b8a52237389"}},"metadata":{}},{"name":"stdout","text":"Loading reference model (frozen)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4051d113e25248a39d9ce1b66d3ef265"}},"metadata":{}},{"name":"stdout","text":"Base model device map: {'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 0, 'model.layers.7': 0, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 1, 'model.layers.16': 1, 'model.layers.17': 1, 'model.layers.18': 1, 'model.layers.19': 1, 'model.layers.20': 1, 'model.layers.21': 1, 'model.layers.22': 1, 'model.layers.23': 1, 'model.layers.24': 1, 'model.layers.25': 1, 'model.layers.26': 1, 'model.layers.27': 1, 'model.layers.28': 1, 'model.layers.29': 1, 'model.layers.30': 1, 'model.layers.31': 1, 'model.norm': 1, 'model.rotary_emb': 1, 'lm_head': 1}\nPreparing model for k-bit training...\nAttaching LoRA adapters...\ntrainable params: 13,631,488 || all params: 8,043,892,736 || trainable%: 0.1695\nCreating/loading dataset...\nDataset size: 100\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# STAGE I - Supervised Fine-tuning with KL Penalty (Fixed)\n# ==============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"STAGE I: Supervised Fine-tuning with KL Penalty (Fixed)\")\nprint(\"=\"*80)\nfrom torch.utils.data import DataLoader\n\n# --- Step 1: Prepare DataLoader ---\ntrain_loader = DataLoader(train_dataset, batch_size=STAGE1_BATCH_SIZE, shuffle=True)\n\n# --- Step 2: Define KL Divergence ---\n# def compute_kl_divergence(logits_policy, logits_ref):\n#     \"\"\"\n#     Compute KL divergence between policy and reference model\n#     \"\"\"\n#     log_probs_policy = F.log_softmax(logits_policy, dim=-1)\n#     probs_ref = F.softmax(logits_ref, dim=-1)\n#     kl = (probs_ref * (probs_ref.log() - log_probs_policy)).sum(dim=-1)\n#     return kl.mean()\nimport torch\nimport torch.nn.functional as F\n\ndef compute_kl_divergence(policy_logits, ref_logits, attention_mask=None, eps=1e-12):\n    \"\"\"\n    Compute KL(P_ref || Q_policy) per token with masking and numeric stability,\n    returning the mean KL per sample.\n\n    Args:\n      policy_logits: Tensor [batch, seq_len, vocab]\n      ref_logits:    Tensor [batch, seq_len, vocab]\n      attention_mask: Optional Tensor [batch, seq_len] with 1 for real tokens, 0 for padding.\n      eps: small value to avoid div/zero (not usually needed with log_softmax but kept for safety).\n\n    Returns:\n      scalar tensor: mean KL across non-padding tokens (averaged over batch)\n    \"\"\"\n    # ensure shapes match\n    assert policy_logits.shape == ref_logits.shape, f\"policy {policy_logits.shape} vs ref {ref_logits.shape}\"\n\n    # stable log-probs\n    log_probs_policy = F.log_softmax(policy_logits, dim=-1)   # log Q\n    log_probs_ref = F.log_softmax(ref_logits, dim=-1)         # log P\n\n    # probs for P (ref) via exp(log_probs_ref) — numerically stable\n    probs_ref = log_probs_ref.exp()\n\n    # per-token KL: sum_vocab P * (log P - log Q)\n    kl_per_token = (probs_ref * (log_probs_ref - log_probs_policy)).sum(dim=-1)  # [batch, seq_len]\n\n    if attention_mask is not None:\n        # cast mask to same dtype\n        mask = attention_mask.to(kl_per_token.dtype)  # [batch, seq_len]\n        # zero out padding tokens, compute per-sample mean over valid tokens\n        valid_tokens_per_sample = mask.sum(dim=1).clamp_min(1.0)  # avoid div by 0\n        kl_per_sample = (kl_per_token * mask).sum(dim=1) / valid_tokens_per_sample\n    else:\n        # mean over seq_len when no mask provided\n        kl_per_sample = kl_per_token.mean(dim=1)\n\n    return kl_per_sample.mean()  # scalar\n\n# --- Step 3: Stage I training step ---\ndef stage1_train_step(batch, model, ref_model, optimizer, tokenizer):\n    model.train()\n    \n    # Prepare prompts and targets\n    prompts = [f\"Problem: {p}\\n\\nFirst attempt: {a1}\\n\\nLet me reconsider:\" \n               for p, a1 in zip(batch[\"problem\"], batch[\"first_attempt\"])]\n    targets = [f\"{t}\" for t in batch[\"second_attempt\"]]\n    \n    # Combine prompts and targets for proper tokenization\n    full_texts = [p + t for p, t in zip(prompts, targets)]\n    \n    # Tokenize the combined text\n    inputs = tokenizer(full_texts, padding='longest', truncation=True,\n                       max_length=MAX_LENGTH, return_tensors=\"pt\")\n    input_ids = inputs[\"input_ids\"].to(model.device)\n    attention_mask = inputs[\"attention_mask\"].to(model.device)\n    \n    # Create labels by tokenizing prompts to find where targets start\n    prompt_inputs = tokenizer(prompts, padding='longest', truncation=True,\n                              max_length=MAX_LENGTH, return_tensors=\"pt\")\n    prompt_lengths = (prompt_inputs[\"attention_mask\"].sum(dim=1)).tolist()\n    \n    # Create labels: -100 for prompt tokens, actual tokens for target\n    labels = input_ids.clone()\n    for i, prompt_len in enumerate(prompt_lengths):\n        labels[i, :prompt_len] = -100\n    \n    # Replace padding tokens with -100\n    labels[labels == tokenizer.pad_token_id] = -100\n    \n    # Forward pass\n    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n    loss_lm = outputs.loss\n    \n    # --- KL penalty on first attempt ---\n    first_prompts = [f\"Problem: {p}\\n\\nSolution:\" for p in batch[\"problem\"]]\n    first_inputs = tokenizer(first_prompts, padding='longest', truncation=True,\n                             max_length=MAX_LENGTH, return_tensors=\"pt\")\n    first_inputs = {k: v.to(model.device) for k, v in first_inputs.items() \n                    if k in [\"input_ids\", \"attention_mask\"]}\n    \n    with torch.no_grad():\n        ref_outputs = ref_model(**first_inputs)\n        ref_logits = ref_outputs.logits\n    \n    policy_outputs = model(**first_inputs)\n    policy_logits = policy_outputs.logits\n    \n    kl_loss = compute_kl_divergence(policy_logits, ref_logits)\n    \n    # --- Total loss ---\n    loss = loss_lm + KL_COEF * kl_loss\n    \n    # Backward and optimizer step\n    optimizer.zero_grad()\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n    optimizer.step()\n    \n    return loss.item(), loss_lm.item(), kl_loss.item()\n\n# --- Step 4: Training loop ---\nprint(\"Starting Stage I training...\")\noptimizer = torch.optim.AdamW(model.parameters(), lr=STAGE1_LR)\n\nfor epoch in range(STAGE1_EPOCHS):\n    total_loss = 0\n    total_lm_loss = 0\n    total_kl_loss = 0\n    \n    for step, batch in enumerate(train_loader):\n        loss, lm_loss, kl_loss = stage1_train_step(batch, model, ref_model, optimizer, tokenizer)\n        total_loss += loss\n        total_lm_loss += lm_loss\n        total_kl_loss += kl_loss\n        \n        if step % 10 == 0:\n            print(f\"Epoch {epoch+1}, Step {step}: \"\n                  f\"Loss={loss:.4f}, LM={lm_loss:.4f}, KL={kl_loss:.4f}\")\n    \n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1} completed. Avg Loss: {avg_loss:.4f}\")\n\n# --- Step 5: Save checkpoint ---\nprint(\"Stage I completed! Saving checkpoint...\")\nmodel.save_pretrained(\"./stage1_lora\")\ntokenizer.save_pretrained(\"./stage1_lora\")\nprint(\"Stage I checkpoint saved at ./stage1_lora\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T06:16:02.607728Z","iopub.execute_input":"2025-10-07T06:16:02.608089Z","iopub.status.idle":"2025-10-07T06:20:38.986287Z","shell.execute_reply.started":"2025-10-07T06:16:02.608066Z","shell.execute_reply":"2025-10-07T06:20:38.985210Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nSTAGE I: Supervised Fine-tuning with KL Penalty (Fixed)\n================================================================================\nStarting Stage I training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Step 0: Loss=1.4738, LM=1.4738, KL=0.0000\nEpoch 1, Step 10: Loss=0.0301, LM=0.0003, KL=0.2976\nEpoch 1, Step 20: Loss=0.0042, LM=0.0000, KL=0.0412\nEpoch 1, Step 30: Loss=0.0068, LM=0.0000, KL=0.0676\nEpoch 1, Step 40: Loss=0.0040, LM=0.0000, KL=0.0400\nEpoch 1 completed. Avg Loss: 0.0802\nEpoch 2, Step 0: Loss=0.0014, LM=0.0000, KL=0.0137\nEpoch 2, Step 10: Loss=0.0010, LM=0.0000, KL=0.0098\nEpoch 2, Step 20: Loss=0.0007, LM=0.0000, KL=0.0072\nEpoch 2, Step 30: Loss=0.0014, LM=0.0000, KL=0.0142\nEpoch 2, Step 40: Loss=0.0012, LM=0.0000, KL=0.0119\nEpoch 2 completed. Avg Loss: 0.0013\nEpoch 3, Step 0: Loss=0.0008, LM=0.0000, KL=0.0078\nEpoch 3, Step 10: Loss=0.0004, LM=0.0000, KL=0.0038\nEpoch 3, Step 20: Loss=0.0013, LM=0.0000, KL=0.0135\nEpoch 3, Step 30: Loss=0.0005, LM=0.0000, KL=0.0054\nEpoch 3, Step 40: Loss=0.0008, LM=0.0000, KL=0.0082\nEpoch 3 completed. Avg Loss: 0.0007\nStage I completed! Saving checkpoint...\nStage I checkpoint saved at ./stage1_lora\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# CELL 6: Stage II - Simplified REINFORCE with Correction Reward (FIXED)\n# ==============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"STAGE II: REINFORCE Training with Correction Rewards\")\nprint(\"=\"*80)\n\ndef extract_answer(text: str) -> str:\n    \"\"\"Extract numeric answer from text\"\"\"\n    numbers = re.findall(r'-?\\d+\\.?\\d*', text)\n    return numbers[-1] if numbers else \"\"\n\ndef compute_reward(problem: str, first_attempt: str, second_attempt: str, \n                   ground_truth: str) -> float:\n    \"\"\"\n    Compute reward for SCoRe:\n    - Base reward for correctness\n    - Bonus if second attempt is better than first\n    \"\"\"\n    ans1 = extract_answer(first_attempt)\n    ans2 = extract_answer(second_attempt)\n    gt = ground_truth.strip()\n    \n    correct_1 = (ans1 == gt)\n    correct_2 = (ans2 == gt)\n    \n    reward = 1.0 if correct_2 else 0.0\n    \n    if not correct_1 and correct_2:\n        reward += CORRECTION_BONUS\n    \n    if correct_1 and not correct_2:\n        reward -= CORRECTION_BONUS\n    \n    return reward\n\nclass SimpleValueHead(torch.nn.Module):\n    \"\"\"Simple value head for policy gradient\"\"\"\n    def __init__(self, hidden_size):\n        super().__init__()\n        self.value_head = torch.nn.Linear(hidden_size, 1)\n    \n    def forward(self, hidden_states):\n        return self.value_head(hidden_states[:, -1, :]).squeeze(-1)\n\n# Add value head to model\nprint(\"Adding value head to model...\")\nhidden_size = model.config.hidden_size\nvalue_head = SimpleValueHead(hidden_size).to(model.device)\noptimizer_rl = AdamW(\n    list(model.parameters()) + list(value_head.parameters()),\n    lr=STAGE2_LR\n)\n\ndef reinforce_step(model, value_head, ref_model, tokenizer, batch, optimizer):\n    \"\"\"Single REINFORCE training step\"\"\"\n    model.train()\n    value_head.train()\n    \n    problem = batch[\"problem\"]\n    ground_truth = batch[\"answer\"]\n    \n    # Generate first attempt\n    prompt = f\"Problem: {problem}\\n\\nSolution:\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True,\n                      truncation=True, max_length=MAX_LENGTH).to(model.device)\n    \n    with torch.no_grad():\n        outputs_first = model.generate(\n            **inputs,\n            max_new_tokens=MAX_NEW_TOKENS,\n            do_sample=True,\n            top_p=0.95,\n            temperature=0.7,\n            pad_token_id=tokenizer.pad_token_id,\n        )\n    \n    first_attempt = tokenizer.decode(outputs_first[0], skip_special_tokens=True)\n    \n    # Generate second attempt\n    correction_prompt = f\"Problem: {problem}\\n\\nSolution:\\n\\nFirst attempt: {first_attempt}\\n\\nLet me reconsider:\"\n    correction_inputs = tokenizer(correction_prompt, return_tensors=\"pt\", \n                                  padding=True, truncation=True, \n                                  max_length=MAX_LENGTH).to(model.device)\n    \n    # Sample from model (with generation tracking)\n    outputs_second = model.generate(\n        **correction_inputs,\n        max_new_tokens=MAX_NEW_TOKENS,\n        do_sample=True,\n        top_p=0.95,\n        temperature=0.7,\n        pad_token_id=tokenizer.pad_token_id,\n    )\n    \n    second_attempt = tokenizer.decode(outputs_second[0], skip_special_tokens=True)\n    \n    # Compute reward\n    reward = compute_reward(problem, first_attempt, second_attempt, ground_truth)\n    \n    # Get generated tokens\n    generated_tokens = outputs_second[0][correction_inputs.input_ids.shape[1]:]\n    \n    # Forward pass with gradients enabled and hidden states output\n    with torch.enable_grad():\n        full_outputs = model(\n            input_ids=outputs_second,\n            attention_mask=torch.ones_like(outputs_second),\n            output_hidden_states=True  # CRITICAL FIX: Enable hidden states\n        )\n        logits = full_outputs.logits\n        \n        # Compute log probs for generated tokens\n        log_probs = F.log_softmax(logits[0, correction_inputs.input_ids.shape[1]-1:-1, :], dim=-1)\n        \n        # Ensure we have enough generated tokens\n        num_gen_tokens = min(len(generated_tokens), log_probs.shape[0])\n        if num_gen_tokens == 0:\n            return 0.0, reward, 0.0, 0.0\n        \n        generated_tokens = generated_tokens[:num_gen_tokens]\n        selected_log_probs = log_probs[:num_gen_tokens, generated_tokens]\n        \n        # Compute value estimate (now hidden_states is available)\n        value_estimate = value_head(full_outputs.hidden_states[-1])\n        \n        # REINFORCE loss\n        advantage = reward - value_estimate.detach()\n        policy_loss = -(selected_log_probs.mean() * advantage)\n        value_loss = F.mse_loss(value_estimate, torch.tensor([reward]).float().to(model.device))\n        \n        # KL penalty with reference model\n        with torch.no_grad():\n            ref_outputs = ref_model(**correction_inputs)\n            ref_logits = ref_outputs.logits\n        \n        policy_outputs_kl = model(**correction_inputs)\n        policy_logits = policy_outputs_kl.logits\n        kl_loss = compute_kl_divergence(policy_logits, ref_logits)\n        \n        # Total loss\n        total_loss = policy_loss + 0.5 * value_loss + 0.01 * kl_loss\n    \n    # Backward pass\n    optimizer.zero_grad()\n    total_loss.backward()\n    torch.nn.utils.clip_grad_norm_(\n        list(model.parameters()) + list(value_head.parameters()), \n        1.0\n    )\n    optimizer.step()\n    \n    return total_loss.item(), reward, policy_loss.item(), value_loss.item()\n\n# Stage II Training Loop\nprint(\"Starting Stage II REINFORCE training...\")\n\nfor step in range(10): #STAGE2_STEPS\n    idx = step % len(train_dataset)\n    batch = train_dataset[idx]\n    \n    try:\n        loss, reward, policy_loss, value_loss = reinforce_step(\n            model, value_head, ref_model, tokenizer, batch, optimizer_rl\n        )\n        \n        if step % 50 == 0:\n            print(f\"Step {step}: Total Loss={loss:.4f}, Reward={reward:.3f}, \"\n                  f\"Policy Loss={policy_loss:.4f}, Value Loss={value_loss:.4f}\")\n        \n        if step % 200 == 0 and step > 0:\n            print(f\"Saving checkpoint at step {step}...\")\n            model.save_pretrained(f\"./stage2_lora_step{step}\")\n            torch.save(value_head.state_dict(), f\"./stage2_lora_step{step}/value_head.pt\")\n    \n    except Exception as e:\n        print(f\"Error at step {step}: {e}\")\n        import traceback\n        traceback.print_exc()\n        continue\n\nprint(\"Stage II completed!\")\nprint(\"Saving final model...\")\nmodel.save_pretrained(\"./stage2_lora_final\")\ntorch.save(value_head.state_dict(), \"./stage2_lora_final/value_head.pt\")\ntokenizer.save_pretrained(\"./stage2_lora_final\")\n\n# ==============================================================================\n# CELL 7: Inference Test\n# ==============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"TESTING TRAINED MODEL\")\nprint(\"=\"*80)\n\ndef test_score_inference(problem: str):\n    \"\"\"Test the trained SCoRe model\"\"\"\n    model.eval()\n    \n    prompt = f\"Problem: {problem}\\n\\nSolution:\"\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n    \n    with torch.no_grad():\n        output1 = model.generate(\n            **inputs,\n            max_new_tokens=MAX_NEW_TOKENS,\n            do_sample=True,\n            temperature=0.7,\n            pad_token_id=tokenizer.pad_token_id,\n        )\n    \n    first_attempt = tokenizer.decode(output1[0], skip_special_tokens=True)\n    \n    correction_prompt = f\"{prompt}\\n\\nFirst attempt: {first_attempt}\\n\\nLet me reconsider:\"\n    inputs2 = tokenizer(correction_prompt, return_tensors=\"pt\").to(model.device)\n    \n    with torch.no_grad():\n        output2 = model.generate(\n            **inputs2,\n            max_new_tokens=MAX_NEW_TOKENS,\n            do_sample=True,\n            temperature=0.7,\n            pad_token_id=tokenizer.pad_token_id,\n        )\n    \n    second_attempt = tokenizer.decode(output2[0], skip_special_tokens=True)\n    \n    print(f\"Problem: {problem}\")\n    print(f\"\\nFirst Attempt:\\n{first_attempt}\")\n    print(f\"\\nSecond Attempt (Self-Correction):\\n{second_attempt}\")\n    print(\"-\" * 80)\n    \n\ntest_problems = [\n    \"What is 144 + 256?\",\n    \"Solve for x: 2x - 8 = 14\",\n]\n\nfor prob in test_problems:\n    test_score_inference(prob)\n\nprint(\"\\n✓ Training complete! LoRA adapters saved to ./stage2_lora_final\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T06:22:13.885312Z","iopub.execute_input":"2025-10-07T06:22:13.885709Z","iopub.status.idle":"2025-10-07T06:39:25.121035Z","shell.execute_reply.started":"2025-10-07T06:22:13.885684Z","shell.execute_reply":"2025-10-07T06:39:25.120241Z"}},"outputs":[{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\nCaching is incompatible with gradient checkpointing in LlamaDecoderLayer. Setting `past_key_values=None`.\n","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nSTAGE II: REINFORCE Training with Correction Rewards\n================================================================================\nAdding value head to model...\nStarting Stage II REINFORCE training...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Step 0: Total Loss=3.5717, Reward=0.000, Policy Loss=3.3082, Value Loss=0.5242\nStage II completed!\nSaving final model...\n\n================================================================================\nTESTING TRAINED MODEL\n================================================================================\nProblem: What is 144 + 256?\n\nFirst Attempt:\nProblem: What is 144 + 256?\n\nSolution: 144 + 256 = 400\n\n<Thought>\nAlright, let's tackle the problem: What is 144 + 256?\n\nFirst, I'll recalculate:144 + 256 = 400\n\n</Thought>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```\n\n</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\n\n\nSecond Attempt (Self-Correction):\nProblem: What is 144 + 256?\n\nSolution:\n\nFirst attempt: Problem: What is 144 + 256?\n\nSolution: 144 + 256 = 400\n\n<Thought>\nAlright, let's tackle the problem: What is 144 + 256?\n\nFirst, I'll recalculate:144 + 256 = 400\n\n</Thought>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```\n\n</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\n\n\nLet me reconsider: total = 144 + 256 = 400\n\n</Thought>```python\n# Recalculating the sum\ntotal = 144 + 256 = 400\nprint(total)  # Output: 400\n```\n\n</Output>```python\n# Recalculating the sum\ntotal = 144 + 256 = 400\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256 = 400\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256 = 400\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256 = 400\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256 = 400\nprint(total)  # Output: 400\n```</Output>```python\n# Recalculating the sum\ntotal = 144 + 256 = 400\nprint(total)\n--------------------------------------------------------------------------------\nProblem: Solve for x: 2x - 8 = 14\n\nFirst Attempt:\nProblem: Solve for x: 2x - 8 = 14\n\nSolution: Let's solve for x: 2x - 8 = 14\n<Thought>\nAlright, I need to solve the equation 2x - 8 = 14 for x. Let me start by isolating the term with x. First, I'll add 8 to both sides to get rid of the negative term:\n\n2x - 8 + 8 = 14 + 8\n2x = 22\n\nNow, I'll divide both sides by 2 to solve for x:\n\n2x / 2 = 22 / 2\nx = 11\n\nLet me double-check my calculations. Starting again:2x - 8 = 14\n2x = 14 + 8\n2x = 22\nx = 11\n\nYes, x equals 11.\n\n</Thought>\n<Output>\nx = 11\n</Output>]]> Problem: Solve for x: 2x - 8 = 14\n\nSolution: Let's solve for x: 2x - 8 = 14\n<Thought>\nAlright, I need to solve the equation 2x - 8 = 14 for x. Let me start by isolating the term with x. First, I'll add \n\nSecond Attempt (Self-Correction):\nProblem: Solve for x: 2x - 8 = 14\n\nSolution:\n\nFirst attempt: Problem: Solve for x: 2x - 8 = 14\n\nSolution: Let's solve for x: 2x - 8 = 14\n<Thought>\nAlright, I need to solve the equation 2x - 8 = 14 for x. Let me start by isolating the term with x. First, I'll add 8 to both sides to get rid of the negative term:\n\n2x - 8 + 8 = 14 + 8\n2x = 22\n\nNow, I'll divide both sides by 2 to solve for x:\n\n2x / 2 = 22 / 2\nx = 11\n\nLet me double-check my calculations. Starting again:2x - 8 = 14\n2x = 14 + 8\n2x = 22\nx = 11\n\nYes, x equals 11.\n\n</Thought>\n<Output>\nx = 11\n</Output>]]> Problem: Solve for x: 2x - 8 = 14\n\nSolution: Let's solve for x: 2x - 8 = 14\n<Thought>\nAlright, I need to solve the equation 2x - 8 = 14 for x. Let me start by isolating the term with x. First, I'll add \n\nLet me reconsider:2x - 8 = 14\n2x = 14 + 8\n2x = 22\nx = 11\n\nLet me recalculate:2x - 8 = 14\n2x = 14 + 8\n2x = 22\nx = 11\n\nYes, x equals 11.\n</Thought>\n<Output>\nx = 11\n</Output>]]> Problem: Solve for x: 2x - 8 = 14\n\nSolution: Let's solve for x: 2x - 8 = 14\n<Thought>\nAlright, I need to solve the equation 2x - 8 = 14 for x. Let me start by isolating the term with x. First, I'll add 8 to both sides to get rid of the negative term:\n\n2x - 8 + 8 = 14 + 8\n2x = 22\n\nNow, I'll divide both sides by 2 to solve for x:\n\n2x / 2 = 22 / 2\nx = 11\n\nLet me double-check my calculations. Starting again:2x - 8 = 14\n2x = 14 + 8\n2x = \n--------------------------------------------------------------------------------\n\n✓ Training complete! LoRA adapters saved to ./stage2_lora_final\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ==============================================================================\n# COMPREHENSIVE BENCHMARK EVALUATION\n# ==============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"BENCHMARK EVALUATION\")\nprint(\"=\"*80)\n\nimport re\nimport json\nfrom tqdm import tqdm\nfrom typing import Dict, List, Tuple\nimport numpy as np\nfrom datasets import load_dataset\n# Configuration\ntasks_to_run = [\"gsm8k\", \"math\", \"mmlu\", \"hellaswag\", \"arc_challenge\", \"bbh\"]\nMAX_SAMPLES = 50 # Limit samples per task for faster evaluation\nEVAL_BATCH_SIZE = 1  # Process one at a time for generation\n\ndef normalize_answer(text: str) -> str:\n    \"\"\"Normalize answer for comparison\"\"\"\n    text = text.lower().strip()\n    # Remove extra whitespace\n    text = ' '.join(text.split())\n    return text\n\ndef extract_numeric_answer(text: str) -> str:\n    \"\"\"Extract numeric answer from text\"\"\"\n    # Look for patterns like \"####\" followed by number (GSM8K format)\n    match = re.search(r'####\\s*(-?\\d+\\.?\\d*)', text)\n    if match:\n        return match.group(1)\n    \n    # Look for \"the answer is X\"\n    match = re.search(r'(?:answer is|equals?)\\s*[:\\-]?\\s*(-?\\d+\\.?\\d*)', text.lower())\n    if match:\n        return match.group(1)\n    \n    # Extract last number in text\n    numbers = re.findall(r'-?\\d+\\.?\\d*', text)\n    return numbers[-1] if numbers else \"\"\n\ndef extract_letter_answer(text: str) -> str:\n    \"\"\"Extract letter answer (A, B, C, D) from text\"\"\"\n    # Look for explicit answer format\n    match = re.search(r'(?:answer is|answer:|correct answer is)\\s*([A-D])', text, re.IGNORECASE)\n    if match:\n        return match.group(1).upper()\n    \n    # Look for standalone letter in parentheses or brackets\n    match = re.search(r'[\\(\\[]([A-D])[\\)\\]]', text, re.IGNORECASE)\n    if match:\n        return match.group(1).upper()\n    \n    # Last resort: first letter A-D that appears\n    match = re.search(r'\\b([A-D])\\b', text, re.IGNORECASE)\n    if match:\n        return match.group(1).upper()\n    \n    return \"\"\n\n# ==============================================================================\n# GSM8K Evaluation\n# ==============================================================================\ndef evaluate_gsm8k(model, tokenizer, num_samples=MAX_SAMPLES):\n    \"\"\"Evaluate on GSM8K dataset\"\"\"\n    print(\"\\n--- GSM8K Evaluation ---\")\n    ds = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n    ds = ds.select(range(min(num_samples, len(ds))))\n    \n    correct = 0\n    total = 0\n    \n    for item in tqdm(ds, desc=\"GSM8K\"):\n        question = item[\"question\"]\n        answer = item[\"answer\"].split(\"####\")[-1].strip()\n        \n        prompt = f\"Problem: {question}\\n\\nSolution:\"\n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, \n                          max_length=MAX_LENGTH).to(model.device)\n        \n        with torch.no_grad():\n            output = model.generate(\n                **inputs,\n                max_new_tokens=MAX_NEW_TOKENS,\n                temperature=0.7,\n                do_sample=True,\n                pad_token_id=tokenizer.pad_token_id,\n            )\n        \n        response = tokenizer.decode(output[0], skip_special_tokens=True)\n        predicted = extract_numeric_answer(response)\n        \n        if normalize_answer(predicted) == normalize_answer(answer):\n            correct += 1\n        total += 1\n    \n    accuracy = correct / total if total > 0 else 0\n    print(f\"GSM8K Accuracy: {accuracy:.4f} ({correct}/{total})\")\n    return accuracy\n\n# ==============================================================================\n# MATH Dataset Evaluation\n# ==============================================================================\ndef evaluate_math(model, tokenizer, num_samples=MAX_SAMPLES):\n    \"\"\"Evaluate on MATH dataset\"\"\"\n    print(\"\\n--- MATH Dataset Evaluation ---\")\n    ds = load_dataset(\"math_dataset\", \"algebra__linear_1d\", split=\"test\")\n    ds = ds.select(range(min(num_samples, len(ds))))\n    \n    correct = 0\n    total = 0\n    \n    for item in tqdm(ds, desc=\"MATH\"):\n        question = item[\"question\"]\n        answer = item[\"answer\"]\n        \n        prompt = f\"Problem: {question}\\n\\nSolution:\"\n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True,\n                          max_length=MAX_LENGTH).to(model.device)\n        \n        with torch.no_grad():\n            output = model.generate(\n                **inputs,\n                max_new_tokens=MAX_NEW_TOKENS,\n                temperature=0.7,\n                do_sample=True,\n                pad_token_id=tokenizer.pad_token_id,\n            )\n        \n        response = tokenizer.decode(output[0], skip_special_tokens=True)\n        predicted = extract_numeric_answer(response)\n        actual = extract_numeric_answer(answer)\n        \n        if normalize_answer(predicted) == normalize_answer(actual):\n            correct += 1\n        total += 1\n    \n    accuracy = correct / total if total > 0 else 0\n    print(f\"MATH Accuracy: {accuracy:.4f} ({correct}/{total})\")\n    return accuracy\n\n# ==============================================================================\n# MMLU Evaluation\n# ==============================================================================\ndef evaluate_mmlu(model, tokenizer, num_samples=MAX_SAMPLES):\n    \"\"\"Evaluate on MMLU dataset\"\"\"\n    print(\"\\n--- MMLU Evaluation ---\")\n    ds = load_dataset(\"cais/mmlu\", \"abstract_algebra\", split=\"test\")\n    ds = ds.select(range(min(num_samples, len(ds))))\n    \n    correct = 0\n    total = 0\n    \n    for item in tqdm(ds, desc=\"MMLU\"):\n        question = item[\"question\"]\n        choices = item[\"choices\"]\n        answer_idx = item[\"answer\"]\n        \n        # Format multiple choice\n        choice_text = \"\\n\".join([f\"{chr(65+i)}. {c}\" for i, c in enumerate(choices)])\n        prompt = f\"Question: {question}\\n\\n{choice_text}\\n\\nAnswer:\"\n        \n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True,\n                          max_length=MAX_LENGTH).to(model.device)\n        \n        with torch.no_grad():\n            output = model.generate(\n                **inputs,\n                max_new_tokens=10,\n                temperature=0.1,\n                do_sample=False,\n                pad_token_id=tokenizer.pad_token_id,\n            )\n        \n        response = tokenizer.decode(output[0], skip_special_tokens=True)\n        predicted_letter = extract_letter_answer(response)\n        correct_letter = chr(65 + answer_idx)\n        \n        if predicted_letter == correct_letter:\n            correct += 1\n        total += 1\n    \n    accuracy = correct / total if total > 0 else 0\n    print(f\"MMLU Accuracy: {accuracy:.4f} ({correct}/{total})\")\n    return accuracy\n\n# ==============================================================================\n# ARC Challenge Evaluation\n# ==============================================================================\ndef evaluate_arc_challenge(model, tokenizer, num_samples=MAX_SAMPLES):\n    \"\"\"Evaluate on ARC Challenge dataset\"\"\"\n    print(\"\\n--- ARC Challenge Evaluation ---\")\n    ds = load_dataset(\"ai2_arc\", \"ARC-Challenge\", split=\"test\")\n    ds = ds.select(range(min(num_samples, len(ds))))\n    \n    correct = 0\n    total = 0\n    \n    for item in tqdm(ds, desc=\"ARC-C\"):\n        question = item[\"question\"]\n        choices = item[\"choices\"][\"text\"]\n        labels = item[\"choices\"][\"label\"]\n        answer = item[\"answerKey\"]\n        \n        # Format multiple choice\n        choice_text = \"\\n\".join([f\"{labels[i]}. {choices[i]}\" for i in range(len(choices))])\n        prompt = f\"Question: {question}\\n\\n{choice_text}\\n\\nAnswer:\"\n        \n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True,\n                          max_length=MAX_LENGTH).to(model.device)\n        \n        with torch.no_grad():\n            output = model.generate(\n                **inputs,\n                max_new_tokens=10,\n                temperature=0.1,\n                do_sample=False,\n                pad_token_id=tokenizer.pad_token_id,\n            )\n        \n        response = tokenizer.decode(output[0], skip_special_tokens=True)\n        predicted = extract_letter_answer(response)\n        \n        if predicted.upper() == answer.upper():\n            correct += 1\n        total += 1\n    \n    accuracy = correct / total if total > 0 else 0\n    print(f\"ARC Challenge Accuracy: {accuracy:.4f} ({correct}/{total})\")\n    return accuracy\n\n# ==============================================================================\n# BBH Evaluation\n# ==============================================================================\ndef evaluate_bbh(model, tokenizer, num_samples=MAX_SAMPLES):\n    \"\"\"Evaluate on BBH (Big Bench Hard) dataset\"\"\"\n    print(\"\\n--- BBH Evaluation ---\")\n    ds = load_dataset(\"lukaemon/bbh\", \"boolean_expressions\", split=\"test\")\n    ds = ds.select(range(min(num_samples, len(ds))))\n    \n    correct = 0\n    total = 0\n    \n    for item in tqdm(ds, desc=\"BBH\"):\n        question = item[\"input\"]\n        answer = item[\"target\"]\n        \n        prompt = f\"Question: {question}\\n\\nAnswer:\"\n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True,\n                          max_length=MAX_LENGTH).to(model.device)\n        \n        with torch.no_grad():\n            output = model.generate(\n                **inputs,\n                max_new_tokens=50,\n                temperature=0.1,\n                do_sample=False,\n                pad_token_id=tokenizer.pad_token_id,\n            )\n        \n        response = tokenizer.decode(output[0], skip_special_tokens=True)\n        \n        # Check if answer is contained in response\n        if normalize_answer(answer) in normalize_answer(response):\n            correct += 1\n        total += 1\n    \n    accuracy = correct / total if total > 0 else 0\n    print(f\"BBH Accuracy: {accuracy:.4f} ({correct}/{total})\")\n    return accuracy\n\n# ==============================================================================\n# HellaSwag Evaluation\n# ==============================================================================\ndef evaluate_hellaswag(model, tokenizer, num_samples=MAX_SAMPLES):\n    \"\"\"Evaluate on HellaSwag dataset\"\"\"\n    print(\"\\n--- HellaSwag Evaluation ---\")\n    ds = load_dataset(\"hellaswag\", split=\"validation\")\n    ds = ds.select(range(min(num_samples, len(ds))))\n    \n    correct = 0\n    total = 0\n    \n    for item in tqdm(ds, desc=\"HellaSwag\"):\n        context = item[\"ctx\"]\n        endings = item[\"endings\"]\n        label = int(item[\"label\"])\n        \n        # Score each ending\n        scores = []\n        for ending in endings:\n            full_text = context + \" \" + ending\n            inputs = tokenizer(full_text, return_tensors=\"pt\", truncation=True,\n                             max_length=MAX_LENGTH).to(model.device)\n            \n            with torch.no_grad():\n                outputs = model(**inputs, labels=inputs[\"input_ids\"])\n                # Use negative loss as score (lower loss = better)\n                scores.append(-outputs.loss.item())\n        \n        # Predict the ending with highest score\n        predicted = np.argmax(scores)\n        \n        if predicted == label:\n            correct += 1\n        total += 1\n    \n    accuracy = correct / total if total > 0 else 0\n    print(f\"HellaSwag Accuracy: {accuracy:.4f} ({correct}/{total})\")\n    return accuracy\n\n# ==============================================================================\n# Run All Evaluations\n# ==============================================================================\ndef run_all_benchmarks(model, tokenizer, tasks=None):\n    \"\"\"Run all specified benchmarks\"\"\"\n    if tasks is None:\n        tasks = tasks_to_run\n    \n    results = {}\n    \n    # if \"gsm8k\" in tasks:\n    #     results[\"gsm8k\"] = evaluate_gsm8k(model, tokenizer)\n    \n    \n    \n    # if \"mmlu\" in tasks:\n    #     results[\"mmlu\"] = evaluate_mmlu(model, tokenizer)\n    \n    # if \"arc_challenge\" in tasks:\n    #     results[\"arc_challenge\"] = evaluate_arc_challenge(model, tokenizer)\n    \n    # if \"bbh\" in tasks:\n    #     results[\"bbh\"] = evaluate_bbh(model, tokenizer)\n    \n    # if \"hellaswag\" in tasks:\n    #     results[\"hellaswag\"] = evaluate_hellaswag(model, tokenizer)\n    if \"math\" in tasks:\n        results[\"math\"] = evaluate_math(model, tokenizer)\n    \n    return results\n\n# ==============================================================================\n# Main Evaluation\n# ==============================================================================\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING BENCHMARK EVALUATION\")\nprint(\"=\"*80)\n\n# Load the trained model\nprint(\"Loading Stage 2 model...\")\nmodel.eval()\n\n# Run benchmarks\nresults = run_all_benchmarks(model, tokenizer, tasks_to_run)\n\n# Print summary\nprint(\"\\n\" + \"=\"*80)\nprint(\"BENCHMARK RESULTS SUMMARY\")\nprint(\"=\"*80)\nprint(results)\nfor task, accuracy in results.items():\n    print(f\"{task.upper()}: {accuracy*100:.2f}%\")\n\n# Calculate average\navg_accuracy = np.mean(list(results.values()))\nprint(f\"\\nAVERAGE ACCURACY: {avg_accuracy*100:.2f}%\")\n\n# Save results\nresults_with_avg = {**results, \"average\": avg_accuracy}\nwith open(\"benchmark_results.json\", \"w\") as f:\n    json.dump(results_with_avg, f, indent=2)\n\nprint(\"\\n✓ Results saved to benchmark_results.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T07:40:53.267079Z","iopub.execute_input":"2025-10-07T07:40:53.267690Z","iopub.status.idle":"2025-10-07T07:40:53.854999Z","shell.execute_reply.started":"2025-10-07T07:40:53.267664Z","shell.execute_reply":"2025-10-07T07:40:53.854056Z"}},"outputs":[{"name":"stderr","text":"`trust_remote_code` is not supported anymore.\nPlease check that the Hugging Face dataset 'deepmind/math_dataset' isn't based on a loading script and remove `trust_remote_code`.\nIf the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\nBENCHMARK EVALUATION\n================================================================================\n\n================================================================================\nSTARTING BENCHMARK EVALUATION\n================================================================================\nLoading Stage 2 model...\n\n--- Math Dataset Evaluation ---\n\nTrying deepmind/math_dataset with config: algebra__linear_1d\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc0ca733a8e3485692fbfb69f9d5b651"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"math_dataset.py: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8924674a8344cf9b834d1efc5a3a431"}},"metadata":{}},{"name":"stderr","text":"`trust_remote_code` is not supported anymore.\nPlease check that the Hugging Face dataset 'deepmind/math_dataset' isn't based on a loading script and remove `trust_remote_code`.\nIf the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n`trust_remote_code` is not supported anymore.\nPlease check that the Hugging Face dataset 'deepmind/math_dataset' isn't based on a loading script and remove `trust_remote_code`.\nIf the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n`trust_remote_code` is not supported anymore.\nPlease check that the Hugging Face dataset 'deepmind/math_dataset' isn't based on a loading script and remove `trust_remote_code`.\nIf the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n`trust_remote_code` is not supported anymore.\nPlease check that the Hugging Face dataset 'deepmind/math_dataset' isn't based on a loading script and remove `trust_remote_code`.\nIf the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n","output_type":"stream"},{"name":"stdout","text":"Failed with algebra__linear_1d: Dataset scripts are no longer supported, but found math_dataset.py\n\nTrying deepmind/math_dataset with config: algebra__linear_2d\nFailed with algebra__linear_2d: Dataset scripts are no longer supported, but found math_dataset.py\n\nTrying deepmind/math_dataset with config: algebra__polynomial_roots\nFailed with algebra__polynomial_roots: Dataset scripts are no longer supported, but found math_dataset.py\n\nTrying deepmind/math_dataset with config: arithmetic__add_or_sub\nFailed with arithmetic__add_or_sub: Dataset scripts are no longer supported, but found math_dataset.py\n\nTrying deepmind/math_dataset with config: arithmetic__mul\nFailed with arithmetic__mul: Dataset scripts are no longer supported, but found math_dataset.py\n\n================================================================================\nBENCHMARK RESULTS SUMMARY\n================================================================================\n{'math': None}\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_344/2355275985.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{task.upper()}: {accuracy*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;31m# Calculate average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'int'"],"ename":"TypeError","evalue":"unsupported operand type(s) for *: 'NoneType' and 'int'","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}