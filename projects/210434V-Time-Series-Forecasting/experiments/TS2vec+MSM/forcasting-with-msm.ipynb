{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2255675,"sourceType":"datasetVersion","datasetId":1357279},{"sourceId":4371501,"sourceType":"datasetVersion","datasetId":2569834},{"sourceId":7084494,"sourceType":"datasetVersion","datasetId":4081618}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:20:56.419425Z","iopub.execute_input":"2025-09-22T16:20:56.419741Z","iopub.status.idle":"2025-09-22T16:21:00.791903Z","shell.execute_reply.started":"2025-09-22T16:20:56.419723Z","shell.execute_reply":"2025-09-22T16:21:00.791309Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ettsmall/ETTh2.csv\n/kaggle/input/ettsmall/ETTm2.csv\n/kaggle/input/ettsmall/ETTm1.csv\n/kaggle/input/ettsmall/ETTh1.csv\n/kaggle/input/ucr-archives/data/UCR/NATOPS/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/NATOPS/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/NATOPS/y.npy\n/kaggle/input/ucr-archives/data/UCR/NATOPS/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/NATOPS/X.npy\n/kaggle/input/ucr-archives/data/UCR/NATOPS/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EOGHorizontalSignal/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/EOGHorizontalSignal/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EOGHorizontalSignal/y.npy\n/kaggle/input/ucr-archives/data/UCR/EOGHorizontalSignal/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/EOGHorizontalSignal/X.npy\n/kaggle/input/ucr-archives/data/UCR/EOGHorizontalSignal/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/BeetleFly/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/BeetleFly/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/BeetleFly/y.npy\n/kaggle/input/ucr-archives/data/UCR/BeetleFly/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/BeetleFly/X.npy\n/kaggle/input/ucr-archives/data/UCR/BeetleFly/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/HouseTwenty/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/HouseTwenty/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/HouseTwenty/y.npy\n/kaggle/input/ucr-archives/data/UCR/HouseTwenty/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/HouseTwenty/X.npy\n/kaggle/input/ucr-archives/data/UCR/HouseTwenty/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineCorrect/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineCorrect/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineCorrect/y.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineCorrect/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineCorrect/X.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineCorrect/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ECG5000/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ECG5000/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ECG5000/y.npy\n/kaggle/input/ucr-archives/data/UCR/ECG5000/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ECG5000/X.npy\n/kaggle/input/ucr-archives/data/UCR/ECG5000/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesRegularTrain/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesRegularTrain/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesRegularTrain/y.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesRegularTrain/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesRegularTrain/X.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesRegularTrain/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandMovementCh2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandMovementCh2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandMovementCh2/y.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandMovementCh2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandMovementCh2/X.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandMovementCh2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CharacterTrajectories/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/CharacterTrajectories/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CharacterTrajectories/y.npy\n/kaggle/input/ucr-archives/data/UCR/CharacterTrajectories/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/CharacterTrajectories/X.npy\n/kaggle/input/ucr-archives/data/UCR/CharacterTrajectories/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/BirdChicken/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/BirdChicken/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/BirdChicken/y.npy\n/kaggle/input/ucr-archives/data/UCR/BirdChicken/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/BirdChicken/X.npy\n/kaggle/input/ucr-archives/data/UCR/BirdChicken/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/WordSynonyms/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/WordSynonyms/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/WordSynonyms/y.npy\n/kaggle/input/ucr-archives/data/UCR/WordSynonyms/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/WordSynonyms/X.npy\n/kaggle/input/ucr-archives/data/UCR/WordSynonyms/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Haptics/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Haptics/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Haptics/y.npy\n/kaggle/input/ucr-archives/data/UCR/Haptics/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Haptics/X.npy\n/kaggle/input/ucr-archives/data/UCR/Haptics/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ2/y.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ2/X.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FordA/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FordA/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FordA/y.npy\n/kaggle/input/ucr-archives/data/UCR/FordA/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FordA/X.npy\n/kaggle/input/ucr-archives/data/UCR/FordA/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DuckDuckGeese/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/DuckDuckGeese/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DuckDuckGeese/y.npy\n/kaggle/input/ucr-archives/data/UCR/DuckDuckGeese/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/DuckDuckGeese/X.npy\n/kaggle/input/ucr-archives/data/UCR/DuckDuckGeese/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/JapaneseVowels/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/JapaneseVowels/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/JapaneseVowels/y.npy\n/kaggle/input/ucr-archives/data/UCR/JapaneseVowels/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/JapaneseVowels/X.npy\n/kaggle/input/ucr-archives/data/UCR/JapaneseVowels/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface2/y.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface2/X.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ShapesAll/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ShapesAll/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ShapesAll/y.npy\n/kaggle/input/ucr-archives/data/UCR/ShapesAll/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ShapesAll/X.npy\n/kaggle/input/ucr-archives/data/UCR/ShapesAll/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Earthquakes/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Earthquakes/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Earthquakes/y.npy\n/kaggle/input/ucr-archives/data/UCR/Earthquakes/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Earthquakes/X.npy\n/kaggle/input/ucr-archives/data/UCR/Earthquakes/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MotorImagery/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/MotorImagery/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MotorImagery/y.npy\n/kaggle/input/ucr-archives/data/UCR/MotorImagery/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/MotorImagery/X.npy\n/kaggle/input/ucr-archives/data/UCR/MotorImagery/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CinCECGTorso/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/CinCECGTorso/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CinCECGTorso/y.npy\n/kaggle/input/ucr-archives/data/UCR/CinCECGTorso/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/CinCECGTorso/X.npy\n/kaggle/input/ucr-archives/data/UCR/CinCECGTorso/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PhalangesOutlinesCorrect/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PhalangesOutlinesCorrect/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PhalangesOutlinesCorrect/y.npy\n/kaggle/input/ucr-archives/data/UCR/PhalangesOutlinesCorrect/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PhalangesOutlinesCorrect/X.npy\n/kaggle/input/ucr-archives/data/UCR/PhalangesOutlinesCorrect/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface1/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface1/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface1/y.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface1/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface1/X.npy\n/kaggle/input/ucr-archives/data/UCR/SonyAIBORobotSurface1/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineCorrect/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineCorrect/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineCorrect/y.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineCorrect/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineCorrect/X.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineCorrect/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CBF/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/CBF/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CBF/y.npy\n/kaggle/input/ucr-archives/data/UCR/CBF/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/CBF/X.npy\n/kaggle/input/ucr-archives/data/UCR/CBF/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerSmallTrain/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerSmallTrain/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerSmallTrain/y.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerSmallTrain/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerSmallTrain/X.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerSmallTrain/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD3/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD3/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD3/y.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD3/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD3/X.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD3/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax2/y.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax2/X.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PenDigits/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PenDigits/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PenDigits/y.npy\n/kaggle/input/ucr-archives/data/UCR/PenDigits/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PenDigits/X.npy\n/kaggle/input/ucr-archives/data/UCR/PenDigits/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGRegularTrain/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGRegularTrain/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGRegularTrain/y.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGRegularTrain/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGRegularTrain/X.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGRegularTrain/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointMaleVersusFemale/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointMaleVersusFemale/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointMaleVersusFemale/y.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointMaleVersusFemale/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointMaleVersusFemale/X.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointMaleVersusFemale/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Trace/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Trace/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Trace/y.npy\n/kaggle/input/ucr-archives/data/UCR/Trace/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Trace/X.npy\n/kaggle/input/ucr-archives/data/UCR/Trace/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointAgeSpan/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointAgeSpan/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointAgeSpan/y.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointAgeSpan/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointAgeSpan/X.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointAgeSpan/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation2/y.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation2/X.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/TwoLeadECG/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/TwoLeadECG/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/TwoLeadECG/y.npy\n/kaggle/input/ucr-archives/data/UCR/TwoLeadECG/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/TwoLeadECG/X.npy\n/kaggle/input/ucr-archives/data/UCR/TwoLeadECG/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ArticularyWordRecognition/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ArticularyWordRecognition/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ArticularyWordRecognition/y.npy\n/kaggle/input/ucr-archives/data/UCR/ArticularyWordRecognition/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ArticularyWordRecognition/X.npy\n/kaggle/input/ucr-archives/data/UCR/ArticularyWordRecognition/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Phoneme/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Phoneme/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Phoneme/y.npy\n/kaggle/input/ucr-archives/data/UCR/Phoneme/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Phoneme/X.npy\n/kaggle/input/ucr-archives/data/UCR/Phoneme/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PEMS-SF/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PEMS-SF/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PEMS-SF/y.npy\n/kaggle/input/ucr-archives/data/UCR/PEMS-SF/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PEMS-SF/X.npy\n/kaggle/input/ucr-archives/data/UCR/PEMS-SF/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxTW/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxTW/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxTW/y.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxTW/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxTW/X.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxTW/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PigArtPressure/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PigArtPressure/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PigArtPressure/y.npy\n/kaggle/input/ucr-archives/data/UCR/PigArtPressure/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PigArtPressure/X.npy\n/kaggle/input/ucr-archives/data/UCR/PigArtPressure/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SwedishLeaf/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SwedishLeaf/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SwedishLeaf/y.npy\n/kaggle/input/ucr-archives/data/UCR/SwedishLeaf/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SwedishLeaf/X.npy\n/kaggle/input/ucr-archives/data/UCR/SwedishLeaf/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FaceFour/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FaceFour/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FaceFour/y.npy\n/kaggle/input/ucr-archives/data/UCR/FaceFour/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FaceFour/X.npy\n/kaggle/input/ucr-archives/data/UCR/FaceFour/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/RefrigerationDevices/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/RefrigerationDevices/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/RefrigerationDevices/y.npy\n/kaggle/input/ucr-archives/data/UCR/RefrigerationDevices/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/RefrigerationDevices/X.npy\n/kaggle/input/ucr-archives/data/UCR/RefrigerationDevices/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/LargeKitchenAppliances/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/LargeKitchenAppliances/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/LargeKitchenAppliances/y.npy\n/kaggle/input/ucr-archives/data/UCR/LargeKitchenAppliances/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/LargeKitchenAppliances/X.npy\n/kaggle/input/ucr-archives/data/UCR/LargeKitchenAppliances/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/OliveOil/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/OliveOil/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/OliveOil/y.npy\n/kaggle/input/ucr-archives/data/UCR/OliveOil/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/OliveOil/X.npy\n/kaggle/input/ucr-archives/data/UCR/OliveOil/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/StarLightCurves/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/StarLightCurves/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/StarLightCurves/y.npy\n/kaggle/input/ucr-archives/data/UCR/StarLightCurves/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/StarLightCurves/X.npy\n/kaggle/input/ucr-archives/data/UCR/StarLightCurves/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Heartbeat/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Heartbeat/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Heartbeat/y.npy\n/kaggle/input/ucr-archives/data/UCR/Heartbeat/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Heartbeat/X.npy\n/kaggle/input/ucr-archives/data/UCR/Heartbeat/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/StandWalkJump/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/StandWalkJump/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/StandWalkJump/y.npy\n/kaggle/input/ucr-archives/data/UCR/StandWalkJump/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/StandWalkJump/X.npy\n/kaggle/input/ucr-archives/data/UCR/StandWalkJump/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EigenWorms/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/EigenWorms/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EigenWorms/y.npy\n/kaggle/input/ucr-archives/data/UCR/EigenWorms/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/EigenWorms/X.npy\n/kaggle/input/ucr-archives/data/UCR/EigenWorms/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD2/y.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD2/X.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Coffee/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Coffee/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Coffee/y.npy\n/kaggle/input/ucr-archives/data/UCR/Coffee/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Coffee/X.npy\n/kaggle/input/ucr-archives/data/UCR/Coffee/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolConcentration/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolConcentration/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolConcentration/y.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolConcentration/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolConcentration/X.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolConcentration/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Beef/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Beef/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Beef/y.npy\n/kaggle/input/ucr-archives/data/UCR/Beef/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Beef/X.npy\n/kaggle/input/ucr-archives/data/UCR/Beef/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GunPoint/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/GunPoint/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GunPoint/y.npy\n/kaggle/input/ucr-archives/data/UCR/GunPoint/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/GunPoint/X.npy\n/kaggle/input/ucr-archives/data/UCR/GunPoint/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerRegularTrain/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerRegularTrain/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerRegularTrain/y.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerRegularTrain/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerRegularTrain/X.npy\n/kaggle/input/ucr-archives/data/UCR/FreezerRegularTrain/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Rock/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Rock/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Rock/y.npy\n/kaggle/input/ucr-archives/data/UCR/Rock/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Rock/X.npy\n/kaggle/input/ucr-archives/data/UCR/Rock/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MedicalImages/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/MedicalImages/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MedicalImages/y.npy\n/kaggle/input/ucr-archives/data/UCR/MedicalImages/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/MedicalImages/X.npy\n/kaggle/input/ucr-archives/data/UCR/MedicalImages/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Car/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Car/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Car/y.npy\n/kaggle/input/ucr-archives/data/UCR/Car/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Car/X.npy\n/kaggle/input/ucr-archives/data/UCR/Car/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryAll/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryAll/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryAll/y.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryAll/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryAll/X.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryAll/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning7/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning7/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning7/y.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning7/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning7/X.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning7/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Strawberry/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Strawberry/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Strawberry/y.npy\n/kaggle/input/ucr-archives/data/UCR/Strawberry/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Strawberry/X.npy\n/kaggle/input/ucr-archives/data/UCR/Strawberry/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/BasicMotions/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/BasicMotions/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/BasicMotions/y.npy\n/kaggle/input/ucr-archives/data/UCR/BasicMotions/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/BasicMotions/X.npy\n/kaggle/input/ucr-archives/data/UCR/BasicMotions/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Libras/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Libras/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Libras/y.npy\n/kaggle/input/ucr-archives/data/UCR/Libras/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Libras/X.npy\n/kaggle/input/ucr-archives/data/UCR/Libras/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ShapeletSim/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ShapeletSim/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ShapeletSim/y.npy\n/kaggle/input/ucr-archives/data/UCR/ShapeletSim/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ShapeletSim/X.npy\n/kaggle/input/ucr-archives/data/UCR/ShapeletSim/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DiatomSizeReduction/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/DiatomSizeReduction/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DiatomSizeReduction/y.npy\n/kaggle/input/ucr-archives/data/UCR/DiatomSizeReduction/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/DiatomSizeReduction/X.npy\n/kaggle/input/ucr-archives/data/UCR/DiatomSizeReduction/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopWeekend/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopWeekend/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopWeekend/y.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopWeekend/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopWeekend/X.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopWeekend/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ChlorineConcentration/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ChlorineConcentration/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ChlorineConcentration/y.npy\n/kaggle/input/ucr-archives/data/UCR/ChlorineConcentration/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ChlorineConcentration/X.npy\n/kaggle/input/ucr-archives/data/UCR/ChlorineConcentration/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ItalyPowerDemand/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ItalyPowerDemand/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ItalyPowerDemand/y.npy\n/kaggle/input/ucr-archives/data/UCR/ItalyPowerDemand/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ItalyPowerDemand/X.npy\n/kaggle/input/ucr-archives/data/UCR/ItalyPowerDemand/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Handwriting/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Handwriting/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Handwriting/y.npy\n/kaggle/input/ucr-archives/data/UCR/Handwriting/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Handwriting/X.npy\n/kaggle/input/ucr-archives/data/UCR/Handwriting/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ElectricDevices/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ElectricDevices/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ElectricDevices/y.npy\n/kaggle/input/ucr-archives/data/UCR/ElectricDevices/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ElectricDevices/X.npy\n/kaggle/input/ucr-archives/data/UCR/ElectricDevices/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/OSULeaf/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/OSULeaf/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/OSULeaf/y.npy\n/kaggle/input/ucr-archives/data/UCR/OSULeaf/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/OSULeaf/X.npy\n/kaggle/input/ucr-archives/data/UCR/OSULeaf/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ1/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ1/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ1/y.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ1/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ1/X.npy\n/kaggle/input/ucr-archives/data/UCR/GesturePebbleZ1/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ScreenType/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ScreenType/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ScreenType/y.npy\n/kaggle/input/ucr-archives/data/UCR/ScreenType/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ScreenType/X.npy\n/kaggle/input/ucr-archives/data/UCR/ScreenType/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopDay/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopDay/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopDay/y.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopDay/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopDay/X.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopDay/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/InsectWingbeatSound/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/InsectWingbeatSound/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/InsectWingbeatSound/y.npy\n/kaggle/input/ucr-archives/data/UCR/InsectWingbeatSound/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/InsectWingbeatSound/X.npy\n/kaggle/input/ucr-archives/data/UCR/InsectWingbeatSound/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteX/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteX/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteX/y.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteX/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteX/X.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteX/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxTW/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxTW/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxTW/y.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxTW/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxTW/X.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxTW/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Computers/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Computers/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Computers/y.npy\n/kaggle/input/ucr-archives/data/UCR/Computers/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Computers/X.npy\n/kaggle/input/ucr-archives/data/UCR/Computers/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FaceAll/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FaceAll/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FaceAll/y.npy\n/kaggle/input/ucr-archives/data/UCR/FaceAll/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FaceAll/X.npy\n/kaggle/input/ucr-archives/data/UCR/FaceAll/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/BME/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/BME/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/BME/y.npy\n/kaggle/input/ucr-archives/data/UCR/BME/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/BME/X.npy\n/kaggle/input/ucr-archives/data/UCR/BME/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesSmallTrain/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesSmallTrain/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesSmallTrain/y.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesSmallTrain/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesSmallTrain/X.npy\n/kaggle/input/ucr-archives/data/UCR/MixedShapesSmallTrain/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/AtrialFibrillation/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/AtrialFibrillation/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/AtrialFibrillation/y.npy\n/kaggle/input/ucr-archives/data/UCR/AtrialFibrillation/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/AtrialFibrillation/X.npy\n/kaggle/input/ucr-archives/data/UCR/AtrialFibrillation/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FingerMovements/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FingerMovements/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FingerMovements/y.npy\n/kaggle/input/ucr-archives/data/UCR/FingerMovements/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FingerMovements/X.npy\n/kaggle/input/ucr-archives/data/UCR/FingerMovements/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Wafer/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Wafer/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Wafer/y.npy\n/kaggle/input/ucr-archives/data/UCR/Wafer/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Wafer/X.npy\n/kaggle/input/ucr-archives/data/UCR/Wafer/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning2/y.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning2/X.npy\n/kaggle/input/ucr-archives/data/UCR/Lightning2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointOldVersusYoung/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointOldVersusYoung/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointOldVersusYoung/y.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointOldVersusYoung/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointOldVersusYoung/X.npy\n/kaggle/input/ucr-archives/data/UCR/GunPointOldVersusYoung/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/InlineSkate/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/InlineSkate/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/InlineSkate/y.npy\n/kaggle/input/ucr-archives/data/UCR/InlineSkate/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/InlineSkate/X.npy\n/kaggle/input/ucr-archives/data/UCR/InlineSkate/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ECG200/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ECG200/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ECG200/y.npy\n/kaggle/input/ucr-archives/data/UCR/ECG200/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ECG200/X.npy\n/kaggle/input/ucr-archives/data/UCR/ECG200/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PhonemeSpectra/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PhonemeSpectra/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PhonemeSpectra/y.npy\n/kaggle/input/ucr-archives/data/UCR/PhonemeSpectra/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PhonemeSpectra/X.npy\n/kaggle/input/ucr-archives/data/UCR/PhonemeSpectra/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolLevel/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolLevel/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolLevel/y.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolLevel/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolLevel/X.npy\n/kaggle/input/ucr-archives/data/UCR/EthanolLevel/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP2/y.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP2/X.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PickupGestureWiimoteZ/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PickupGestureWiimoteZ/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PickupGestureWiimoteZ/y.npy\n/kaggle/input/ucr-archives/data/UCR/PickupGestureWiimoteZ/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PickupGestureWiimoteZ/X.npy\n/kaggle/input/ucr-archives/data/UCR/PickupGestureWiimoteZ/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Meat/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Meat/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Meat/y.npy\n/kaggle/input/ucr-archives/data/UCR/Meat/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Meat/X.npy\n/kaggle/input/ucr-archives/data/UCR/Meat/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FordB/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FordB/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FordB/y.npy\n/kaggle/input/ucr-archives/data/UCR/FordB/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FordB/X.npy\n/kaggle/input/ucr-archives/data/UCR/FordB/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FiftyWords/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FiftyWords/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FiftyWords/y.npy\n/kaggle/input/ucr-archives/data/UCR/FiftyWords/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FiftyWords/X.npy\n/kaggle/input/ucr-archives/data/UCR/FiftyWords/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PowerCons/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PowerCons/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PowerCons/y.npy\n/kaggle/input/ucr-archives/data/UCR/PowerCons/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PowerCons/X.npy\n/kaggle/input/ucr-archives/data/UCR/PowerCons/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/TwoPatterns/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/TwoPatterns/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/TwoPatterns/y.npy\n/kaggle/input/ucr-archives/data/UCR/TwoPatterns/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/TwoPatterns/X.npy\n/kaggle/input/ucr-archives/data/UCR/TwoPatterns/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ArrowHead/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ArrowHead/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ArrowHead/y.npy\n/kaggle/input/ucr-archives/data/UCR/ArrowHead/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ArrowHead/X.npy\n/kaggle/input/ucr-archives/data/UCR/ArrowHead/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FacesUCR/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FacesUCR/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FacesUCR/y.npy\n/kaggle/input/ucr-archives/data/UCR/FacesUCR/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FacesUCR/X.npy\n/kaggle/input/ucr-archives/data/UCR/FacesUCR/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PigAirwayPressure/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PigAirwayPressure/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PigAirwayPressure/y.npy\n/kaggle/input/ucr-archives/data/UCR/PigAirwayPressure/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PigAirwayPressure/X.npy\n/kaggle/input/ucr-archives/data/UCR/PigAirwayPressure/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Fish/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Fish/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Fish/y.npy\n/kaggle/input/ucr-archives/data/UCR/Fish/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Fish/X.npy\n/kaggle/input/ucr-archives/data/UCR/Fish/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandGenderCh2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandGenderCh2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandGenderCh2/y.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandGenderCh2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandGenderCh2/X.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandGenderCh2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PLAID/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PLAID/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PLAID/y.npy\n/kaggle/input/ucr-archives/data/UCR/PLAID/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PLAID/X.npy\n/kaggle/input/ucr-archives/data/UCR/PLAID/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineAgeGroup/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineAgeGroup/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineAgeGroup/y.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineAgeGroup/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineAgeGroup/X.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineAgeGroup/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Yoga/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Yoga/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Yoga/y.npy\n/kaggle/input/ucr-archives/data/UCR/Yoga/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Yoga/X.npy\n/kaggle/input/ucr-archives/data/UCR/Yoga/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation1/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation1/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation1/y.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation1/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation1/X.npy\n/kaggle/input/ucr-archives/data/UCR/ToeSegmentation1/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CricketZ/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/CricketZ/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CricketZ/y.npy\n/kaggle/input/ucr-archives/data/UCR/CricketZ/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/CricketZ/X.npy\n/kaggle/input/ucr-archives/data/UCR/CricketZ/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP1/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP1/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP1/y.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP1/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP1/X.npy\n/kaggle/input/ucr-archives/data/UCR/SelfRegulationSCP1/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryZ/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryZ/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryZ/y.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryZ/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryZ/X.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryZ/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SmallKitchenAppliances/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SmallKitchenAppliances/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SmallKitchenAppliances/y.npy\n/kaggle/input/ucr-archives/data/UCR/SmallKitchenAppliances/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SmallKitchenAppliances/X.npy\n/kaggle/input/ucr-archives/data/UCR/SmallKitchenAppliances/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxTW/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxTW/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxTW/y.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxTW/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxTW/X.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxTW/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/HandMovementDirection/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/HandMovementDirection/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/HandMovementDirection/y.npy\n/kaggle/input/ucr-archives/data/UCR/HandMovementDirection/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/HandMovementDirection/X.npy\n/kaggle/input/ucr-archives/data/UCR/HandMovementDirection/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibrary/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibrary/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibrary/y.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibrary/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibrary/X.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibrary/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGSmallTrain/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGSmallTrain/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGSmallTrain/y.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGSmallTrain/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGSmallTrain/X.npy\n/kaggle/input/ucr-archives/data/UCR/InsectEPGSmallTrain/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Fungi/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Fungi/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Fungi/y.npy\n/kaggle/input/ucr-archives/data/UCR/Fungi/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Fungi/X.npy\n/kaggle/input/ucr-archives/data/UCR/Fungi/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Mallat/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Mallat/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Mallat/y.npy\n/kaggle/input/ucr-archives/data/UCR/Mallat/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Mallat/X.npy\n/kaggle/input/ucr-archives/data/UCR/Mallat/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Herring/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Herring/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Herring/y.npy\n/kaggle/input/ucr-archives/data/UCR/Herring/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Herring/X.npy\n/kaggle/input/ucr-archives/data/UCR/Herring/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Plane/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Plane/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Plane/y.npy\n/kaggle/input/ucr-archives/data/UCR/Plane/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Plane/X.npy\n/kaggle/input/ucr-archives/data/UCR/Plane/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Chinatown/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Chinatown/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Chinatown/y.npy\n/kaggle/input/ucr-archives/data/UCR/Chinatown/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Chinatown/X.npy\n/kaggle/input/ucr-archives/data/UCR/Chinatown/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Ham/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Ham/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Ham/y.npy\n/kaggle/input/ucr-archives/data/UCR/Ham/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Ham/X.npy\n/kaggle/input/ucr-archives/data/UCR/Ham/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryX/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryX/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryX/y.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryX/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryX/X.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryX/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ACSF1/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ACSF1/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ACSF1/y.npy\n/kaggle/input/ucr-archives/data/UCR/ACSF1/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ACSF1/X.npy\n/kaggle/input/ucr-archives/data/UCR/ACSF1/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FaceDetection/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/FaceDetection/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/FaceDetection/y.npy\n/kaggle/input/ucr-archives/data/UCR/FaceDetection/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/FaceDetection/X.npy\n/kaggle/input/ucr-archives/data/UCR/FaceDetection/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CricketX/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/CricketX/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CricketX/y.npy\n/kaggle/input/ucr-archives/data/UCR/CricketX/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/CricketX/X.npy\n/kaggle/input/ucr-archives/data/UCR/CricketX/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EOGVerticalSignal/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/EOGVerticalSignal/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/EOGVerticalSignal/y.npy\n/kaggle/input/ucr-archives/data/UCR/EOGVerticalSignal/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/EOGVerticalSignal/X.npy\n/kaggle/input/ucr-archives/data/UCR/EOGVerticalSignal/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CricketY/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/CricketY/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/CricketY/y.npy\n/kaggle/input/ucr-archives/data/UCR/CricketY/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/CricketY/X.npy\n/kaggle/input/ucr-archives/data/UCR/CricketY/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax1/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax1/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax1/y.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax1/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax1/X.npy\n/kaggle/input/ucr-archives/data/UCR/NonInvasiveFetalECGThorax1/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Cricket/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Cricket/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Cricket/y.npy\n/kaggle/input/ucr-archives/data/UCR/Cricket/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Cricket/X.npy\n/kaggle/input/ucr-archives/data/UCR/Cricket/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SpokenArabicDigits/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SpokenArabicDigits/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SpokenArabicDigits/y.npy\n/kaggle/input/ucr-archives/data/UCR/SpokenArabicDigits/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SpokenArabicDigits/X.npy\n/kaggle/input/ucr-archives/data/UCR/SpokenArabicDigits/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/LSST/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/LSST/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/LSST/y.npy\n/kaggle/input/ucr-archives/data/UCR/LSST/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/LSST/X.npy\n/kaggle/input/ucr-archives/data/UCR/LSST/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MoteStrain/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/MoteStrain/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MoteStrain/y.npy\n/kaggle/input/ucr-archives/data/UCR/MoteStrain/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/MoteStrain/X.npy\n/kaggle/input/ucr-archives/data/UCR/MoteStrain/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandSubjectCh2/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandSubjectCh2/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandSubjectCh2/y.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandSubjectCh2/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandSubjectCh2/X.npy\n/kaggle/input/ucr-archives/data/UCR/SemgHandSubjectCh2/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineCorrect/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineCorrect/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineCorrect/y.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineCorrect/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineCorrect/X.npy\n/kaggle/input/ucr-archives/data/UCR/DistalPhalanxOutlineCorrect/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Wine/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Wine/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Wine/y.npy\n/kaggle/input/ucr-archives/data/UCR/Wine/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Wine/X.npy\n/kaggle/input/ucr-archives/data/UCR/Wine/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MelbournePedestrian/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/MelbournePedestrian/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MelbournePedestrian/y.npy\n/kaggle/input/ucr-archives/data/UCR/MelbournePedestrian/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/MelbournePedestrian/X.npy\n/kaggle/input/ucr-archives/data/UCR/MelbournePedestrian/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteY/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteY/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteY/y.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteY/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteY/X.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteY/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SyntheticControl/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SyntheticControl/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SyntheticControl/y.npy\n/kaggle/input/ucr-archives/data/UCR/SyntheticControl/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SyntheticControl/X.npy\n/kaggle/input/ucr-archives/data/UCR/SyntheticControl/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryY/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryY/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryY/y.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryY/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryY/X.npy\n/kaggle/input/ucr-archives/data/UCR/UWaveGestureLibraryY/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/RacketSports/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/RacketSports/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/RacketSports/y.npy\n/kaggle/input/ucr-archives/data/UCR/RacketSports/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/RacketSports/X.npy\n/kaggle/input/ucr-archives/data/UCR/RacketSports/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Crop/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Crop/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Crop/y.npy\n/kaggle/input/ucr-archives/data/UCR/Crop/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Crop/X.npy\n/kaggle/input/ucr-archives/data/UCR/Crop/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PigCVP/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/PigCVP/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/PigCVP/y.npy\n/kaggle/input/ucr-archives/data/UCR/PigCVP/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/PigCVP/X.npy\n/kaggle/input/ucr-archives/data/UCR/PigCVP/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineAgeGroup/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineAgeGroup/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineAgeGroup/y.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineAgeGroup/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineAgeGroup/X.npy\n/kaggle/input/ucr-archives/data/UCR/ProximalPhalanxOutlineAgeGroup/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteZ/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteZ/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteZ/y.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteZ/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteZ/X.npy\n/kaggle/input/ucr-archives/data/UCR/AllGestureWiimoteZ/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ECGFiveDays/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ECGFiveDays/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ECGFiveDays/y.npy\n/kaggle/input/ucr-archives/data/UCR/ECGFiveDays/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ECGFiveDays/X.npy\n/kaggle/input/ucr-archives/data/UCR/ECGFiveDays/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UMD/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/UMD/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/UMD/y.npy\n/kaggle/input/ucr-archives/data/UCR/UMD/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/UMD/X.npy\n/kaggle/input/ucr-archives/data/UCR/UMD/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopGame/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopGame/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopGame/y.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopGame/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopGame/X.npy\n/kaggle/input/ucr-archives/data/UCR/DodgerLoopGame/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SmoothSubspace/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/SmoothSubspace/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/SmoothSubspace/y.npy\n/kaggle/input/ucr-archives/data/UCR/SmoothSubspace/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/SmoothSubspace/X.npy\n/kaggle/input/ucr-archives/data/UCR/SmoothSubspace/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Epilepsy/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Epilepsy/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Epilepsy/y.npy\n/kaggle/input/ucr-archives/data/UCR/Epilepsy/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Epilepsy/X.npy\n/kaggle/input/ucr-archives/data/UCR/Epilepsy/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/WormsTwoClass/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/WormsTwoClass/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/WormsTwoClass/y.npy\n/kaggle/input/ucr-archives/data/UCR/WormsTwoClass/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/WormsTwoClass/X.npy\n/kaggle/input/ucr-archives/data/UCR/WormsTwoClass/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Adiac/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Adiac/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Adiac/y.npy\n/kaggle/input/ucr-archives/data/UCR/Adiac/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Adiac/X.npy\n/kaggle/input/ucr-archives/data/UCR/Adiac/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/HandOutlines/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/HandOutlines/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/HandOutlines/y.npy\n/kaggle/input/ucr-archives/data/UCR/HandOutlines/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/HandOutlines/X.npy\n/kaggle/input/ucr-archives/data/UCR/HandOutlines/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Worms/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Worms/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Worms/y.npy\n/kaggle/input/ucr-archives/data/UCR/Worms/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Worms/X.npy\n/kaggle/input/ucr-archives/data/UCR/Worms/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD1/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD1/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD1/y.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD1/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD1/X.npy\n/kaggle/input/ucr-archives/data/UCR/GestureMidAirD1/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Symbols/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/Symbols/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/Symbols/y.npy\n/kaggle/input/ucr-archives/data/UCR/Symbols/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/Symbols/X.npy\n/kaggle/input/ucr-archives/data/UCR/Symbols/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineAgeGroup/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineAgeGroup/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineAgeGroup/y.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineAgeGroup/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineAgeGroup/X.npy\n/kaggle/input/ucr-archives/data/UCR/MiddlePhalanxOutlineAgeGroup/y_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ShakeGestureWiimoteZ/y_train.npy\n/kaggle/input/ucr-archives/data/UCR/ShakeGestureWiimoteZ/X_valid.npy\n/kaggle/input/ucr-archives/data/UCR/ShakeGestureWiimoteZ/y.npy\n/kaggle/input/ucr-archives/data/UCR/ShakeGestureWiimoteZ/X_train.npy\n/kaggle/input/ucr-archives/data/UCR/ShakeGestureWiimoteZ/X.npy\n/kaggle/input/ucr-archives/data/UCR/ShakeGestureWiimoteZ/y_valid.npy\n/kaggle/input/massive-yahoo-finance-dataset/stock_details_5_years.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/Niroshan2001/ts2vec.git\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:21:00.793230Z","iopub.execute_input":"2025-09-22T16:21:00.793724Z","iopub.status.idle":"2025-09-22T16:21:01.918531Z","shell.execute_reply.started":"2025-09-22T16:21:00.793705Z","shell.execute_reply":"2025-09-22T16:21:01.917597Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'ts2vec'...\nremote: Enumerating objects: 313, done.\u001b[K\nremote: Counting objects: 100% (102/102), done.\u001b[K\nremote: Compressing objects: 100% (64/64), done.\u001b[K\nremote: Total 313 (delta 54), reused 69 (delta 38), pack-reused 211 (from 2)\u001b[K\nReceiving objects: 100% (313/313), 133.26 KiB | 2.61 MiB/s, done.\nResolving deltas: 100% (165/165), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%cd ts2vec\n!git fetch origin\n!git checkout anomaly\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:21:01.919671Z","iopub.execute_input":"2025-09-22T16:21:01.920000Z","iopub.status.idle":"2025-09-22T16:21:02.395191Z","shell.execute_reply.started":"2025-09-22T16:21:01.919975Z","shell.execute_reply":"2025-09-22T16:21:02.394251Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ts2vec\nBranch 'anomaly' set up to track remote branch 'anomaly' from 'origin'.\nSwitched to a new branch 'anomaly'\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#!pip install -r requirements.txt\n!pip install bottleneck\n!pip install statsmodels\n!pip install scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:21:02.396363Z","iopub.execute_input":"2025-09-22T16:21:02.396658Z","iopub.status.idle":"2025-09-22T16:21:14.095518Z","shell.execute_reply.started":"2025-09-22T16:21:02.396625Z","shell.execute_reply":"2025-09-22T16:21:14.094781Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bottleneck in /usr/local/lib/python3.11/dist-packages (1.4.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bottleneck) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bottleneck) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bottleneck) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bottleneck) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bottleneck) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bottleneck) (2024.2.0)\nRequirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\nRequirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.26.4)\nRequirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.15.3)\nRequirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.3)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.22.3->statsmodels) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.22.3->statsmodels) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.22.3->statsmodels) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.22.3->statsmodels) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.22.3->statsmodels) (2024.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import os\n\n# # Paths\n# base_path = \"/kaggle/input/ucr-archives/data/UCR\"  # root folder containing all datasets\n# out_root = \"datasets/UCR\"  # output folder for converted datasets\n# os.makedirs(out_root, exist_ok=True)\n\n# # List all datasets in UCR folder\n# datasets = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n# print(\"Datasets found:\", datasets)\n\n# for dataset in datasets:\n#     print(f\"Processing dataset: {dataset}\")\n#     dataset_path = os.path.join(base_path, dataset)\n#     out_path = os.path.join(out_root, dataset)\n#     os.makedirs(out_path, exist_ok=True)\n    \n#     # Load npy files\n#     X_train = np.load(os.path.join(dataset_path, \"X_train.npy\"))\n#     y_train = np.load(os.path.join(dataset_path, \"y_train.npy\"))\n#     X_valid = np.load(os.path.join(dataset_path, \"X_valid.npy\"))\n#     y_valid = np.load(os.path.join(dataset_path, \"y_valid.npy\"))\n    \n#     # Flatten each time series into 1D (handles multi-channel if present)\n#     X_train_flat = X_train.reshape(X_train.shape[0], -1)\n#     X_valid_flat = X_valid.reshape(X_valid.shape[0], -1)\n    \n#     # Build DataFrames: first column = label, rest = features\n#     train_df = pd.DataFrame(np.hstack([y_train.reshape(-1, 1), X_train_flat]))\n#     test_df  = pd.DataFrame(np.hstack([y_valid.reshape(-1, 1), X_valid_flat]))\n    \n#     # Save in UCR .tsv format\n#     train_df.to_csv(os.path.join(out_path, f\"{dataset}_TRAIN.tsv\"), sep=\"\\t\", header=False, index=False)\n#     test_df.to_csv(os.path.join(out_path, f\"{dataset}_TEST.tsv\"), sep=\"\\t\", header=False, index=False)\n    \n#     print(f\"{dataset} converted successfully!\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:21:14.096464Z","iopub.execute_input":"2025-09-22T16:21:14.096696Z","iopub.status.idle":"2025-09-22T16:21:14.100958Z","shell.execute_reply.started":"2025-09-22T16:21:14.096661Z","shell.execute_reply":"2025-09-22T16:21:14.100359Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#!python train.py Beef UCR --loader UCR --batch-size 8 --repr-dims 320 --max-threads 8 --seed 42 --eval\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:21:14.101633Z","iopub.execute_input":"2025-09-22T16:21:14.101883Z","iopub.status.idle":"2025-09-22T16:21:14.126292Z","shell.execute_reply.started":"2025-09-22T16:21:14.101860Z","shell.execute_reply":"2025-09-22T16:21:14.125600Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nimport shutil\n\n# Kaggle path to your CSV\nsource_path = \"/kaggle/input/ettsmall/ETTh1.csv\"  # adjust if needed\n\n# Destination path expected by ts2vec\ndest_folder = \"datasets\"\nos.makedirs(dest_folder, exist_ok=True)\ndest_path = os.path.join(dest_folder, \"ETTh1.csv\")\n\n# Copy the CSV\nshutil.copyfile(source_path, dest_path)\nprint(f\"Copied {source_path} -> {dest_path}\")\n\n# Kaggle path to your CSV\nsource_path = \"/kaggle/input/ettsmall/ETTh2.csv\"  # adjust if needed\n\n# Destination path expected by ts2vec\ndest_folder = \"datasets\"\nos.makedirs(dest_folder, exist_ok=True)\ndest_path = os.path.join(dest_folder, \"ETTh2.csv\")\n\n# Copy the CSV\nshutil.copyfile(source_path, dest_path)\nprint(f\"Copied {source_path} -> {dest_path}\")\n\n# Kaggle path to your CSV\nsource_path = \"/kaggle/input/ettsmall/ETTm1.csv\"  # adjust if needed\n\n# Destination path expected by ts2vec\ndest_folder = \"datasets\"\nos.makedirs(dest_folder, exist_ok=True)\ndest_path = os.path.join(dest_folder, \"ETTm1.csv\")\n\n# Copy the CSV\nshutil.copyfile(source_path, dest_path)\nprint(f\"Copied {source_path} -> {dest_path}\")\n\n\n# Kaggle path to your CSV\nsource_path = \"/kaggle/input/ettsmall/ETTm2.csv\"  # adjust if needed\n\n# Destination path expected by ts2vec\ndest_folder = \"datasets\"\nos.makedirs(dest_folder, exist_ok=True)\ndest_path = os.path.join(dest_folder, \"ETTm2.csv\")\n\n# Copy the CSV\nshutil.copyfile(source_path, dest_path)\nprint(f\"Copied {source_path} -> {dest_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:21:14.128191Z","iopub.execute_input":"2025-09-22T16:21:14.128442Z","iopub.status.idle":"2025-09-22T16:21:14.522835Z","shell.execute_reply.started":"2025-09-22T16:21:14.128425Z","shell.execute_reply":"2025-09-22T16:21:14.522203Z"}},"outputs":[{"name":"stdout","text":"Copied /kaggle/input/ettsmall/ETTh1.csv -> datasets/ETTh1.csv\nCopied /kaggle/input/ettsmall/ETTh2.csv -> datasets/ETTh2.csv\nCopied /kaggle/input/ettsmall/ETTm1.csv -> datasets/ETTm1.csv\nCopied /kaggle/input/ettsmall/ETTm2.csv -> datasets/ETTm2.csv\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Multivariate - Conservative MSM\n!python train_msm.py ETTh1 forecast_multivar_msm_conservative --loader forecast_csv --repr-dims 320 --max-threads 8 --seed 42 --eval --msm-weight 0.1 --msm-mask-rate 0.2 --msm-decoder-depth 3\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:21:14.523577Z","iopub.execute_input":"2025-09-22T16:21:14.523860Z","iopub.status.idle":"2025-09-22T16:25:06.923986Z","shell.execute_reply.started":"2025-09-22T16:21:14.523818Z","shell.execute_reply":"2025-09-22T16:25:06.923060Z"}},"outputs":[{"name":"stdout","text":"Dataset: ETTh1\nArguments: Namespace(dataset='ETTh1', run_name='forecast_multivar_msm_conservative', loader='forecast_csv', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0, msm_weight=0.1, msm_mask_rate=0.2, msm_decoder_depth=3, dynamic_lambda=False)\nLoading data... done\nTraining...\nEpoch #0: loss=6.528228 (contrastive=7.140549, msm=1.017344, =0.100)\nEpoch #1: loss=6.462072 (contrastive=7.067138, msm=1.016486, =0.100)\nEpoch #2: loss=4.011843 (contrastive=4.344891, msm=1.014412, =0.100)\nEpoch #3: loss=3.257289 (contrastive=3.507648, msm=1.004053, =0.100)\nEpoch #4: loss=3.020071 (contrastive=3.243612, msm=1.008205, =0.100)\nEpoch #5: loss=2.821392 (contrastive=3.023437, msm=1.002986, =0.100)\nEpoch #6: loss=2.861639 (contrastive=3.064966, msm=1.031698, =0.100)\nEpoch #7: loss=2.460152 (contrastive=2.623623, msm=0.988917, =0.100)\nEpoch #8: loss=2.051391 (contrastive=2.168801, msm=0.994701, =0.100)\nEpoch #9: loss=2.144095 (contrastive=2.273001, msm=0.983943, =0.100)\nEpoch #10: loss=2.060524 (contrastive=2.180680, msm=0.979115, =0.100)\nEpoch #11: loss=1.896022 (contrastive=1.997407, msm=0.983556, =0.100)\nEpoch #12: loss=2.095481 (contrastive=2.219383, msm=0.980362, =0.100)\nEpoch #13: loss=1.962372 (contrastive=2.072796, msm=0.968560, =0.100)\nEpoch #14: loss=2.008277 (contrastive=2.124809, msm=0.959487, =0.100)\nEpoch #15: loss=1.849241 (contrastive=1.948377, msm=0.957018, =0.100)\nEpoch #16: loss=2.049775 (contrastive=2.171731, msm=0.952173, =0.100)\nEpoch #17: loss=1.853490 (contrastive=1.952922, msm=0.958608, =0.100)\nEpoch #18: loss=1.771009 (contrastive=1.863396, msm=0.939528, =0.100)\nEpoch #19: loss=1.785490 (contrastive=1.881797, msm=0.918726, =0.100)\nEpoch #20: loss=1.795779 (contrastive=1.894526, msm=0.907054, =0.100)\nEpoch #21: loss=1.795919 (contrastive=1.895153, msm=0.902817, =0.100)\nEpoch #22: loss=1.629883 (contrastive=1.714728, msm=0.866276, =0.100)\nEpoch #23: loss=1.694770 (contrastive=1.788329, msm=0.852747, =0.100)\nEpoch #24: loss=1.734408 (contrastive=1.833389, msm=0.843585, =0.100)\nEpoch #25: loss=1.602975 (contrastive=1.688324, msm=0.834831, =0.100)\nEpoch #26: loss=1.576531 (contrastive=1.663710, msm=0.791917, =0.100)\nEpoch #27: loss=1.528078 (contrastive=1.609470, msm=0.795547, =0.100)\nEpoch #28: loss=1.553261 (contrastive=1.640601, msm=0.767206, =0.100)\nEpoch #29: loss=1.634985 (contrastive=1.734357, msm=0.740633, =0.100)\nEpoch #30: loss=1.655780 (contrastive=1.759707, msm=0.720441, =0.100)\nEpoch #31: loss=1.648605 (contrastive=1.752432, msm=0.714163, =0.100)\nEpoch #32: loss=1.461812 (contrastive=1.546713, msm=0.697708, =0.100)\nEpoch #33: loss=1.632569 (contrastive=1.738110, msm=0.682700, =0.100)\nEpoch #34: loss=1.523674 (contrastive=1.620430, msm=0.652864, =0.100)\nEpoch #35: loss=1.486575 (contrastive=1.578803, msm=0.656522, =0.100)\nEpoch #36: loss=1.311670 (contrastive=1.386712, msm=0.636291, =0.100)\nEpoch #37: loss=1.327603 (contrastive=1.406226, msm=0.619994, =0.100)\nEpoch #38: loss=1.508768 (contrastive=1.608109, msm=0.614707, =0.100)\nEpoch #39: loss=1.336864 (contrastive=1.418056, msm=0.606131, =0.100)\nEpoch #40: loss=1.513916 (contrastive=1.616406, msm=0.591507, =0.100)\nEpoch #41: loss=1.274617 (contrastive=1.352243, msm=0.575985, =0.100)\nEpoch #42: loss=1.368271 (contrastive=1.457069, msm=0.569094, =0.100)\nEpoch #43: loss=1.332801 (contrastive=1.419415, msm=0.553271, =0.100)\nEpoch #44: loss=1.251419 (contrastive=1.329306, msm=0.550443, =0.100)\nEpoch #45: loss=1.517583 (contrastive=1.626947, msm=0.533305, =0.100)\nEpoch #46: loss=1.446886 (contrastive=1.548601, msm=0.531456, =0.100)\nEpoch #47: loss=1.262356 (contrastive=1.343791, msm=0.529441, =0.100)\nEpoch #48: loss=1.239362 (contrastive=1.319632, msm=0.516936, =0.100)\nEpoch #49: loss=1.297914 (contrastive=1.385148, msm=0.512803, =0.100)\nEpoch #50: loss=1.206785 (contrastive=1.285781, msm=0.495821, =0.100)\nEpoch #51: loss=1.238243 (contrastive=1.322056, msm=0.483930, =0.100)\nEpoch #52: loss=1.158810 (contrastive=1.234625, msm=0.476474, =0.100)\nEpoch #53: loss=1.245854 (contrastive=1.331737, msm=0.472903, =0.100)\nEpoch #54: loss=1.189375 (contrastive=1.271137, msm=0.453513, =0.100)\nEpoch #55: loss=1.171655 (contrastive=1.250742, msm=0.459875, =0.100)\nEpoch #56: loss=1.235479 (contrastive=1.322654, msm=0.450910, =0.100)\nEpoch #57: loss=1.094486 (contrastive=1.167441, msm=0.437898, =0.100)\nEpoch #58: loss=0.999447 (contrastive=1.062754, msm=0.429684, =0.100)\nEpoch #59: loss=1.086718 (contrastive=1.160594, msm=0.421843, =0.100)\nEpoch #60: loss=1.168205 (contrastive=1.250826, msm=0.424612, =0.100)\nEpoch #61: loss=1.056554 (contrastive=1.127567, msm=0.417433, =0.100)\nEpoch #62: loss=1.008902 (contrastive=1.075247, msm=0.411799, =0.100)\nEpoch #63: loss=0.926791 (contrastive=0.984373, msm=0.408559, =0.100)\nEpoch #64: loss=0.986957 (contrastive=1.050804, msm=0.412331, =0.100)\nEpoch #65: loss=1.014154 (contrastive=1.081803, msm=0.405313, =0.100)\nEpoch #66: loss=1.269910 (contrastive=1.367049, msm=0.395661, =0.100)\nEpoch #67: loss=0.965680 (contrastive=1.028954, msm=0.396212, =0.100)\nEpoch #68: loss=0.968292 (contrastive=1.033022, msm=0.385731, =0.100)\nEpoch #69: loss=0.983504 (contrastive=1.049955, msm=0.385450, =0.100)\nEpoch #70: loss=0.973866 (contrastive=1.039618, msm=0.382107, =0.100)\nEpoch #71: loss=0.836739 (contrastive=0.888035, msm=0.375074, =0.100)\nEpoch #72: loss=0.922859 (contrastive=0.984317, msm=0.369732, =0.100)\nEpoch #73: loss=0.869119 (contrastive=0.923909, msm=0.376010, =0.100)\nEpoch #74: loss=0.917354 (contrastive=0.977274, msm=0.378067, =0.100)\nEpoch #75: loss=0.817789 (contrastive=0.867356, msm=0.371683, =0.100)\nEpoch #76: loss=1.196191 (contrastive=1.287954, msm=0.370323, =0.100)\nEpoch #77: loss=0.822783 (contrastive=0.873945, msm=0.362322, =0.100)\nEpoch #78: loss=0.796001 (contrastive=0.843260, msm=0.370674, =0.100)\nEpoch #79: loss=0.857049 (contrastive=0.912752, msm=0.355714, =0.100)\nEpoch #80: loss=0.958389 (contrastive=1.025614, msm=0.353369, =0.100)\nEpoch #81: loss=0.741937 (contrastive=0.786054, msm=0.344883, =0.100)\nEpoch #82: loss=0.899412 (contrastive=0.960871, msm=0.346290, =0.100)\nEpoch #83: loss=0.933553 (contrastive=0.998022, msm=0.353329, =0.100)\nEpoch #84: loss=0.715722 (contrastive=0.757772, msm=0.337266, =0.100)\nEpoch #85: loss=0.884165 (contrastive=0.944899, msm=0.337558, =0.100)\nEpoch #86: loss=0.732155 (contrastive=0.776198, msm=0.335762, =0.100)\nEpoch #87: loss=0.791837 (contrastive=0.842697, msm=0.334100, =0.100)\nEpoch #88: loss=0.659168 (contrastive=0.695706, msm=0.330330, =0.100)\nEpoch #89: loss=1.169830 (contrastive=1.262186, msm=0.338627, =0.100)\nEpoch #90: loss=0.642125 (contrastive=0.675930, msm=0.337876, =0.100)\nEpoch #91: loss=0.790100 (contrastive=0.841646, msm=0.326188, =0.100)\nEpoch #92: loss=0.928890 (contrastive=0.995885, msm=0.325936, =0.100)\nEpoch #93: loss=0.851964 (contrastive=0.910797, msm=0.322464, =0.100)\nEpoch #94: loss=0.625667 (contrastive=0.658735, msm=0.328049, =0.100)\nEpoch #95: loss=0.709833 (contrastive=0.752452, msm=0.326262, =0.100)\nEpoch #96: loss=0.732487 (contrastive=0.777561, msm=0.326826, =0.100)\nEpoch #97: loss=0.896991 (contrastive=0.961249, msm=0.318672, =0.100)\nEpoch #98: loss=0.574071 (contrastive=0.601929, msm=0.323350, =0.100)\nEpoch #99: loss=0.964805 (contrastive=1.037220, msm=0.313073, =0.100)\nEpoch #100: loss=0.659308 (contrastive=0.697761, msm=0.313224, =0.100)\nEpoch #101: loss=0.653874 (contrastive=0.690633, msm=0.323047, =0.100)\nEpoch #102: loss=0.687875 (contrastive=0.729009, msm=0.317670, =0.100)\nEpoch #103: loss=0.892047 (contrastive=0.955148, msm=0.324131, =0.100)\nEpoch #104: loss=0.722583 (contrastive=0.768518, msm=0.309171, =0.100)\nEpoch #105: loss=0.660233 (contrastive=0.699295, msm=0.308674, =0.100)\nEpoch #106: loss=0.687620 (contrastive=0.729008, msm=0.315121, =0.100)\nEpoch #107: loss=0.654078 (contrastive=0.692647, msm=0.306961, =0.100)\nEpoch #108: loss=0.737950 (contrastive=0.785855, msm=0.306806, =0.100)\nEpoch #109: loss=0.927333 (contrastive=0.996368, msm=0.306012, =0.100)\nEpoch #110: loss=0.626629 (contrastive=0.661773, msm=0.310327, =0.100)\nEpoch #111: loss=1.568208 (contrastive=1.709267, msm=0.298675, =0.100)\nEpoch #112: loss=0.607186 (contrastive=0.640897, msm=0.303785, =0.100)\nEpoch #113: loss=0.639312 (contrastive=0.676618, msm=0.303556, =0.100)\nEpoch #114: loss=0.923172 (contrastive=0.993213, msm=0.292803, =0.100)\nEpoch #115: loss=0.709692 (contrastive=0.754240, msm=0.308761, =0.100)\nEpoch #116: loss=0.679353 (contrastive=0.721498, msm=0.300048, =0.100)\nEpoch #117: loss=0.696556 (contrastive=0.742792, msm=0.280434, =0.100)\nEpoch #118: loss=0.641215 (contrastive=0.679608, msm=0.295684, =0.100)\nEpoch #119: loss=0.728171 (contrastive=0.776299, msm=0.295021, =0.100)\nEpoch #120: loss=0.568472 (contrastive=0.598564, msm=0.297644, =0.100)\nEpoch #121: loss=0.535325 (contrastive=0.562490, msm=0.290842, =0.100)\nEpoch #122: loss=0.806712 (contrastive=0.863796, msm=0.292948, =0.100)\nEpoch #123: loss=0.541005 (contrastive=0.568849, msm=0.290414, =0.100)\nEpoch #124: loss=0.572398 (contrastive=0.604692, msm=0.281748, =0.100)\nEpoch #125: loss=0.540688 (contrastive=0.569352, msm=0.282717, =0.100)\nEpoch #126: loss=0.697670 (contrastive=0.744195, msm=0.278954, =0.100)\nEpoch #127: loss=0.671642 (contrastive=0.715096, msm=0.280559, =0.100)\nEpoch #128: loss=1.498039 (contrastive=1.634304, msm=0.271650, =0.100)\nEpoch #129: loss=0.487939 (contrastive=0.510792, msm=0.282260, =0.100)\nEpoch #130: loss=0.550529 (contrastive=0.580619, msm=0.279717, =0.100)\nEpoch #131: loss=0.611409 (contrastive=0.648678, msm=0.275995, =0.100)\nEpoch #132: loss=0.765556 (contrastive=0.819333, msm=0.281558, =0.100)\nEpoch #133: loss=0.562788 (contrastive=0.593819, msm=0.283509, =0.100)\nEpoch #134: loss=0.550470 (contrastive=0.581205, msm=0.273848, =0.100)\nEpoch #135: loss=0.569142 (contrastive=0.601386, msm=0.278941, =0.100)\nEpoch #136: loss=0.508487 (contrastive=0.534525, msm=0.274141, =0.100)\nEpoch #137: loss=0.488389 (contrastive=0.512365, msm=0.272605, =0.100)\nEpoch #138: loss=0.523919 (contrastive=0.552239, msm=0.269036, =0.100)\nEpoch #139: loss=0.456132 (contrastive=0.477292, msm=0.265686, =0.100)\nEpoch #140: loss=0.701374 (contrastive=0.748444, msm=0.277741, =0.100)\nEpoch #141: loss=0.995584 (contrastive=1.075690, msm=0.274630, =0.100)\nEpoch #142: loss=0.454892 (contrastive=0.475177, msm=0.272328, =0.100)\nEpoch #143: loss=0.458907 (contrastive=0.480763, msm=0.262199, =0.100)\nEpoch #144: loss=0.829182 (contrastive=0.892694, msm=0.257576, =0.100)\nEpoch #145: loss=0.510656 (contrastive=0.537653, msm=0.267681, =0.100)\nEpoch #146: loss=0.408053 (contrastive=0.424447, msm=0.260506, =0.100)\nEpoch #147: loss=0.408536 (contrastive=0.424728, msm=0.262808, =0.100)\nEpoch #148: loss=0.678212 (contrastive=0.724161, msm=0.264675, =0.100)\nEpoch #149: loss=0.690426 (contrastive=0.737952, msm=0.262688, =0.100)\nEpoch #150: loss=0.458970 (contrastive=0.481941, msm=0.252225, =0.100)\nEpoch #151: loss=0.377464 (contrastive=0.391118, msm=0.254579, =0.100)\nEpoch #152: loss=0.548075 (contrastive=0.579507, msm=0.265188, =0.100)\nEpoch #153: loss=0.374083 (contrastive=0.386725, msm=0.260300, =0.100)\nEpoch #154: loss=0.455389 (contrastive=0.477824, msm=0.253481, =0.100)\nEpoch #155: loss=0.388343 (contrastive=0.402955, msm=0.256843, =0.100)\nEpoch #156: loss=1.049006 (contrastive=1.137209, msm=0.255182, =0.100)\nEpoch #157: loss=0.410007 (contrastive=0.427117, msm=0.256012, =0.100)\nEpoch #158: loss=0.667978 (contrastive=0.713164, msm=0.261300, =0.100)\nEpoch #159: loss=0.424650 (contrastive=0.443767, msm=0.252599, =0.100)\nEpoch #160: loss=0.403310 (contrastive=0.419692, msm=0.255870, =0.100)\nEpoch #161: loss=0.431138 (contrastive=0.450523, msm=0.256673, =0.100)\nEpoch #162: loss=0.436813 (contrastive=0.457715, msm=0.248699, =0.100)\nEpoch #163: loss=0.409932 (contrastive=0.426601, msm=0.259917, =0.100)\nEpoch #164: loss=0.375461 (contrastive=0.389850, msm=0.245959, =0.100)\nEpoch #165: loss=0.464666 (contrastive=0.487710, msm=0.257274, =0.100)\nEpoch #166: loss=1.044232 (contrastive=1.132075, msm=0.253643, =0.100)\nEpoch #167: loss=0.361955 (contrastive=0.375078, msm=0.243852, =0.100)\nEpoch #168: loss=0.380647 (contrastive=0.395389, msm=0.247970, =0.100)\nEpoch #169: loss=1.030933 (contrastive=1.117811, msm=0.249022, =0.100)\nEpoch #170: loss=0.472819 (contrastive=0.497578, msm=0.249982, =0.100)\nEpoch #171: loss=0.493124 (contrastive=0.520179, msm=0.249627, =0.100)\nEpoch #172: loss=0.414247 (contrastive=0.432510, msm=0.249876, =0.100)\nEpoch #173: loss=0.400108 (contrastive=0.416756, msm=0.250271, =0.100)\nEpoch #174: loss=0.361772 (contrastive=0.374145, msm=0.250411, =0.100)\nEpoch #175: loss=0.358374 (contrastive=0.370536, msm=0.248920, =0.100)\nEpoch #176: loss=0.415032 (contrastive=0.433547, msm=0.248396, =0.100)\nEpoch #177: loss=0.360308 (contrastive=0.372598, msm=0.249700, =0.100)\nEpoch #178: loss=0.357628 (contrastive=0.369723, msm=0.248774, =0.100)\nEpoch #179: loss=1.141311 (contrastive=1.239885, msm=0.254145, =0.100)\nEpoch #180: loss=0.470103 (contrastive=0.495649, msm=0.240186, =0.100)\nEpoch #181: loss=0.322888 (contrastive=0.330696, msm=0.252616, =0.100)\nEpoch #182: loss=0.378055 (contrastive=0.392760, msm=0.245703, =0.100)\nEpoch #183: loss=0.637664 (contrastive=0.681439, msm=0.243691, =0.100)\nEpoch #184: loss=0.362087 (contrastive=0.375201, msm=0.244059, =0.100)\nEpoch #185: loss=0.616450 (contrastive=0.658038, msm=0.242159, =0.100)\nEpoch #186: loss=0.788195 (contrastive=0.848491, msm=0.245525, =0.100)\nEpoch #187: loss=0.343119 (contrastive=0.354745, msm=0.238476, =0.100)\nEpoch #188: loss=0.343783 (contrastive=0.355114, msm=0.241804, =0.100)\nEpoch #189: loss=0.824480 (contrastive=0.888560, msm=0.247761, =0.100)\nEpoch #190: loss=0.394902 (contrastive=0.412005, msm=0.240977, =0.100)\nEpoch #191: loss=0.376438 (contrastive=0.390664, msm=0.248406, =0.100)\nEpoch #192: loss=0.435560 (contrastive=0.457011, msm=0.242496, =0.100)\nEpoch #193: loss=0.507504 (contrastive=0.536753, msm=0.244266, =0.100)\nEpoch #194: loss=0.540354 (contrastive=0.573483, msm=0.242193, =0.100)\nEpoch #195: loss=0.522818 (contrastive=0.554710, msm=0.235793, =0.100)\nEpoch #196: loss=0.423852 (contrastive=0.444754, msm=0.235736, =0.100)\nEpoch #197: loss=0.416569 (contrastive=0.436663, msm=0.235720, =0.100)\nEpoch #198: loss=0.698282 (contrastive=0.749128, msm=0.240676, =0.100)\nEpoch #199: loss=0.400737 (contrastive=0.418821, msm=0.237988, =0.100)\nEpoch #200: loss=0.367367 (contrastive=0.382502, msm=0.231154, =0.100)\nEpoch #201: loss=0.376482 (contrastive=0.392002, msm=0.236803, =0.100)\nEpoch #202: loss=0.392705 (contrastive=0.410181, msm=0.235417, =0.100)\nEpoch #203: loss=0.345312 (contrastive=0.357524, msm=0.235401, =0.100)\nEpoch #204: loss=0.348193 (contrastive=0.359800, msm=0.243727, =0.100)\nEpoch #205: loss=0.414234 (contrastive=0.433600, msm=0.239939, =0.100)\nEpoch #206: loss=0.397367 (contrastive=0.415403, msm=0.235044, =0.100)\nEpoch #207: loss=0.545988 (contrastive=0.580979, msm=0.231073, =0.100)\nEpoch #208: loss=0.387740 (contrastive=0.405063, msm=0.231830, =0.100)\nEpoch #209: loss=0.703287 (contrastive=0.755038, msm=0.237530, =0.100)\nEpoch #210: loss=0.303287 (contrastive=0.309279, msm=0.249354, =0.100)\nEpoch #211: loss=0.429426 (contrastive=0.448869, msm=0.254438, =0.100)\nEpoch #212: loss=0.718735 (contrastive=0.771208, msm=0.246484, =0.100)\nEpoch #213: loss=0.465993 (contrastive=0.490790, msm=0.242818, =0.100)\nEpoch #214: loss=0.376717 (contrastive=0.391850, msm=0.240518, =0.100)\nEpoch #215: loss=0.543331 (contrastive=0.576646, msm=0.243493, =0.100)\nEpoch #216: loss=0.674781 (contrastive=0.721236, msm=0.256691, =0.100)\nEpoch #217: loss=0.397020 (contrastive=0.413578, msm=0.247997, =0.100)\nEpoch #218: loss=0.674814 (contrastive=0.723196, msm=0.239375, =0.100)\nEpoch #219: loss=0.342093 (contrastive=0.354585, msm=0.229666, =0.100)\nEpoch #220: loss=0.330632 (contrastive=0.341268, msm=0.234907, =0.100)\nEpoch #221: loss=0.326457 (contrastive=0.335868, msm=0.241759, =0.100)\nEpoch #222: loss=0.329237 (contrastive=0.338336, msm=0.247352, =0.100)\nEpoch #223: loss=0.408580 (contrastive=0.425786, msm=0.253724, =0.100)\nEpoch #224: loss=0.300938 (contrastive=0.306367, msm=0.252078, =0.100)\nEpoch #225: loss=0.433001 (contrastive=0.455234, msm=0.232904, =0.100)\nEpoch #226: loss=0.332617 (contrastive=0.342539, msm=0.243314, =0.100)\nEpoch #227: loss=0.375049 (contrastive=0.390963, msm=0.231823, =0.100)\nEpoch #228: loss=0.492162 (contrastive=0.521160, msm=0.231173, =0.100)\nEpoch #229: loss=0.289136 (contrastive=0.295490, msm=0.231952, =0.100)\nEpoch #230: loss=0.679269 (contrastive=0.727637, msm=0.243959, =0.100)\nEpoch #231: loss=0.304137 (contrastive=0.310875, msm=0.243504, =0.100)\nEpoch #232: loss=0.331936 (contrastive=0.340619, msm=0.253792, =0.100)\nEpoch #233: loss=0.315624 (contrastive=0.323896, msm=0.241180, =0.100)\nEpoch #234: loss=0.283766 (contrastive=0.289762, msm=0.229799, =0.100)\nEpoch #235: loss=0.278872 (contrastive=0.285237, msm=0.221581, =0.100)\nEpoch #236: loss=0.750922 (contrastive=0.808909, msm=0.229043, =0.100)\nEpoch #237: loss=0.318883 (contrastive=0.329513, msm=0.223216, =0.100)\nEpoch #238: loss=0.656249 (contrastive=0.703254, msm=0.233202, =0.100)\nEpoch #239: loss=0.279777 (contrastive=0.284645, msm=0.235964, =0.100)\nEpoch #240: loss=0.302525 (contrastive=0.309657, msm=0.238329, =0.100)\nEpoch #241: loss=0.265008 (contrastive=0.269130, msm=0.227906, =0.100)\nEpoch #242: loss=0.295231 (contrastive=0.302880, msm=0.226391, =0.100)\nEpoch #243: loss=0.305945 (contrastive=0.315375, msm=0.221071, =0.100)\nEpoch #244: loss=0.247023 (contrastive=0.250831, msm=0.212749, =0.100)\nEpoch #245: loss=0.253071 (contrastive=0.256473, msm=0.222451, =0.100)\nEpoch #246: loss=0.286080 (contrastive=0.293176, msm=0.222214, =0.100)\nEpoch #247: loss=0.244928 (contrastive=0.247992, msm=0.217351, =0.100)\nEpoch #248: loss=0.276879 (contrastive=0.283251, msm=0.219527, =0.100)\nEpoch #249: loss=0.243387 (contrastive=0.246007, msm=0.219808, =0.100)\nEpoch #250: loss=0.391881 (contrastive=0.411437, msm=0.215882, =0.100)\nEpoch #251: loss=0.237109 (contrastive=0.239577, msm=0.214897, =0.100)\nEpoch #252: loss=0.310214 (contrastive=0.320519, msm=0.217466, =0.100)\nEpoch #253: loss=0.308543 (contrastive=0.318949, msm=0.214892, =0.100)\nEpoch #254: loss=0.289568 (contrastive=0.297792, msm=0.215553, =0.100)\nEpoch #255: loss=0.285220 (contrastive=0.292883, msm=0.216249, =0.100)\nEpoch #256: loss=0.313305 (contrastive=0.324397, msm=0.213475, =0.100)\nEpoch #257: loss=0.637552 (contrastive=0.684309, msm=0.216741, =0.100)\nEpoch #258: loss=0.935672 (contrastive=1.015708, msm=0.215352, =0.100)\nEpoch #259: loss=0.351936 (contrastive=0.367232, msm=0.214265, =0.100)\nEpoch #260: loss=0.493142 (contrastive=0.523379, msm=0.221012, =0.100)\nEpoch #261: loss=0.478689 (contrastive=0.507379, msm=0.220476, =0.100)\nEpoch #262: loss=0.261067 (contrastive=0.266382, msm=0.213233, =0.100)\nEpoch #263: loss=0.273042 (contrastive=0.279166, msm=0.217920, =0.100)\nEpoch #264: loss=0.320964 (contrastive=0.332820, msm=0.214265, =0.100)\nEpoch #265: loss=0.420890 (contrastive=0.443939, msm=0.213451, =0.100)\nEpoch #266: loss=0.404907 (contrastive=0.426212, msm=0.213161, =0.100)\nEpoch #267: loss=0.304743 (contrastive=0.315426, msm=0.208597, =0.100)\nEpoch #268: loss=0.537387 (contrastive=0.573675, msm=0.210795, =0.100)\nEpoch #269: loss=1.058704 (contrastive=1.153197, msm=0.208267, =0.100)\nEpoch #270: loss=0.364369 (contrastive=0.381369, msm=0.211364, =0.100)\nEpoch #271: loss=0.305138 (contrastive=0.315435, msm=0.212469, =0.100)\nEpoch #272: loss=0.283294 (contrastive=0.291380, msm=0.210519, =0.100)\nEpoch #273: loss=0.549585 (contrastive=0.587122, msm=0.211756, =0.100)\nEpoch #274: loss=0.281921 (contrastive=0.290064, msm=0.208632, =0.100)\nEpoch #275: loss=0.312955 (contrastive=0.323916, msm=0.214304, =0.100)\nEpoch #276: loss=0.600570 (contrastive=0.643968, msm=0.209985, =0.100)\nEpoch #277: loss=0.322239 (contrastive=0.334778, msm=0.209382, =0.100)\nEpoch #278: loss=0.307034 (contrastive=0.317656, msm=0.211432, =0.100)\nEpoch #279: loss=0.267595 (contrastive=0.273725, msm=0.212419, =0.100)\nEpoch #280: loss=0.293368 (contrastive=0.302064, msm=0.215104, =0.100)\nEpoch #281: loss=0.581068 (contrastive=0.622429, msm=0.208811, =0.100)\nEpoch #282: loss=0.267014 (contrastive=0.273004, msm=0.213104, =0.100)\nEpoch #283: loss=0.298932 (contrastive=0.308548, msm=0.212383, =0.100)\nEpoch #284: loss=0.431310 (contrastive=0.455170, msm=0.216570, =0.100)\nEpoch #285: loss=0.266368 (contrastive=0.272631, msm=0.209998, =0.100)\nEpoch #286: loss=0.374133 (contrastive=0.392007, msm=0.213268, =0.100)\nEpoch #287: loss=0.311816 (contrastive=0.322520, msm=0.215479, =0.100)\nEpoch #288: loss=0.429471 (contrastive=0.453349, msm=0.214569, =0.100)\nEpoch #289: loss=0.284630 (contrastive=0.293061, msm=0.208751, =0.100)\nEpoch #290: loss=0.310983 (contrastive=0.322361, msm=0.208580, =0.100)\nEpoch #291: loss=0.261135 (contrastive=0.267208, msm=0.206478, =0.100)\nEpoch #292: loss=0.265467 (contrastive=0.271826, msm=0.208232, =0.100)\nEpoch #293: loss=0.239822 (contrastive=0.243116, msm=0.210176, =0.100)\nEpoch #294: loss=0.223321 (contrastive=0.225190, msm=0.206498, =0.100)\nEpoch #295: loss=0.442725 (contrastive=0.469063, msm=0.205683, =0.100)\nEpoch #296: loss=0.239930 (contrastive=0.244391, msm=0.199782, =0.100)\nEpoch #297: loss=0.224116 (contrastive=0.226348, msm=0.204023, =0.100)\nEpoch #298: loss=0.287016 (contrastive=0.296208, msm=0.204285, =0.100)\nEpoch #299: loss=0.203143 (contrastive=0.202720, msm=0.206951, =0.100)\nEpoch #300: loss=0.442251 (contrastive=0.468722, msm=0.204012, =0.100)\nEpoch #301: loss=0.213757 (contrastive=0.214248, msm=0.209333, =0.100)\nEpoch #302: loss=0.391444 (contrastive=0.412259, msm=0.204105, =0.100)\nEpoch #303: loss=0.207614 (contrastive=0.208339, msm=0.201083, =0.100)\nEpoch #304: loss=0.223312 (contrastive=0.225190, msm=0.206412, =0.100)\nEpoch #305: loss=0.287106 (contrastive=0.296368, msm=0.203751, =0.100)\nEpoch #306: loss=0.336826 (contrastive=0.351976, msm=0.200468, =0.100)\nEpoch #307: loss=0.336606 (contrastive=0.351455, msm=0.202961, =0.100)\nEpoch #308: loss=0.207776 (contrastive=0.208769, msm=0.198842, =0.100)\nEpoch #309: loss=0.319994 (contrastive=0.333223, msm=0.200933, =0.100)\nEpoch #310: loss=0.312791 (contrastive=0.324910, msm=0.203722, =0.100)\nEpoch #311: loss=0.297766 (contrastive=0.308369, msm=0.202337, =0.100)\nEpoch #312: loss=0.346730 (contrastive=0.362655, msm=0.203404, =0.100)\nEpoch #313: loss=0.361586 (contrastive=0.379164, msm=0.203380, =0.100)\nEpoch #314: loss=0.254223 (contrastive=0.259649, msm=0.205391, =0.100)\nEpoch #315: loss=0.601065 (contrastive=0.645385, msm=0.202186, =0.100)\nEpoch #316: loss=0.265770 (contrastive=0.272847, msm=0.202082, =0.100)\nEpoch #317: loss=0.385106 (contrastive=0.405530, msm=0.201285, =0.100)\nEpoch #318: loss=0.302909 (contrastive=0.314029, msm=0.202834, =0.100)\nEpoch #319: loss=0.387060 (contrastive=0.407646, msm=0.201786, =0.100)\nEpoch #320: loss=0.272360 (contrastive=0.279730, msm=0.206031, =0.100)\nEpoch #321: loss=0.282111 (contrastive=0.290987, msm=0.202222, =0.100)\nEpoch #322: loss=0.213796 (contrastive=0.215183, msm=0.201321, =0.100)\nEpoch #323: loss=0.279837 (contrastive=0.288256, msm=0.204059, =0.100)\nEpoch #324: loss=0.260582 (contrastive=0.267105, msm=0.201878, =0.100)\nEpoch #325: loss=0.315884 (contrastive=0.327844, msm=0.208247, =0.100)\nEpoch #326: loss=0.294474 (contrastive=0.304514, msm=0.204120, =0.100)\nEpoch #327: loss=0.227263 (contrastive=0.229199, msm=0.209843, =0.100)\nEpoch #328: loss=0.330447 (contrastive=0.343845, msm=0.209865, =0.100)\nEpoch #329: loss=0.249269 (contrastive=0.253476, msm=0.211404, =0.100)\nEpoch #330: loss=0.282761 (contrastive=0.291505, msm=0.204067, =0.100)\nEpoch #331: loss=0.330435 (contrastive=0.344684, msm=0.202192, =0.100)\nEpoch #332: loss=0.232653 (contrastive=0.235728, msm=0.204978, =0.100)\nEpoch #333: loss=0.251438 (contrastive=0.256515, msm=0.205750, =0.100)\nEpoch #334: loss=0.205856 (contrastive=0.205751, msm=0.206799, =0.100)\nEpoch #335: loss=0.376923 (contrastive=0.396053, msm=0.204754, =0.100)\nEpoch #336: loss=0.225983 (contrastive=0.228116, msm=0.206793, =0.100)\nEpoch #337: loss=0.473461 (contrastive=0.504016, msm=0.198467, =0.100)\nEpoch #338: loss=0.222225 (contrastive=0.223805, msm=0.207998, =0.100)\nEpoch #339: loss=0.262472 (contrastive=0.269184, msm=0.202060, =0.100)\nEpoch #340: loss=0.253312 (contrastive=0.258777, msm=0.204127, =0.100)\nEpoch #341: loss=0.201823 (contrastive=0.202240, msm=0.198070, =0.100)\nEpoch #342: loss=0.536261 (contrastive=0.573033, msm=0.205322, =0.100)\nEpoch #343: loss=0.265130 (contrastive=0.272082, msm=0.202563, =0.100)\nEpoch #344: loss=0.445044 (contrastive=0.471568, msm=0.206325, =0.100)\nEpoch #345: loss=0.214428 (contrastive=0.215098, msm=0.208400, =0.100)\nEpoch #346: loss=0.261849 (contrastive=0.267964, msm=0.206815, =0.100)\nEpoch #347: loss=0.187590 (contrastive=0.186270, msm=0.199466, =0.100)\nEpoch #348: loss=0.353707 (contrastive=0.371229, msm=0.196013, =0.100)\nEpoch #349: loss=0.214099 (contrastive=0.215584, msm=0.200740, =0.100)\nEpoch #350: loss=0.346494 (contrastive=0.363052, msm=0.197478, =0.100)\nEpoch #351: loss=0.268411 (contrastive=0.275876, msm=0.201228, =0.100)\nEpoch #352: loss=0.191570 (contrastive=0.190884, msm=0.197741, =0.100)\nEpoch #353: loss=0.870415 (contrastive=0.945035, msm=0.198834, =0.100)\nEpoch #354: loss=0.263812 (contrastive=0.271043, msm=0.198732, =0.100)\nEpoch #355: loss=0.195397 (contrastive=0.194788, msm=0.200879, =0.100)\nEpoch #356: loss=0.494332 (contrastive=0.526137, msm=0.208083, =0.100)\nEpoch #357: loss=0.277196 (contrastive=0.284762, msm=0.209103, =0.100)\nEpoch #358: loss=0.435077 (contrastive=0.460849, msm=0.203128, =0.100)\nEpoch #359: loss=0.274122 (contrastive=0.281681, msm=0.206086, =0.100)\nEpoch #360: loss=0.348734 (contrastive=0.364481, msm=0.207010, =0.100)\nEpoch #361: loss=0.215025 (contrastive=0.216392, msm=0.202720, =0.100)\nEpoch #362: loss=0.259171 (contrastive=0.265881, msm=0.198786, =0.100)\nEpoch #363: loss=0.357109 (contrastive=0.374719, msm=0.198622, =0.100)\nEpoch #364: loss=0.233203 (contrastive=0.237357, msm=0.195813, =0.100)\nEpoch #365: loss=0.307043 (contrastive=0.318767, msm=0.201533, =0.100)\nEpoch #366: loss=0.240086 (contrastive=0.244770, msm=0.197934, =0.100)\nEpoch #367: loss=0.195948 (contrastive=0.195204, msm=0.202647, =0.100)\nEpoch #368: loss=0.283209 (contrastive=0.292873, msm=0.196235, =0.100)\nEpoch #369: loss=0.230589 (contrastive=0.233941, msm=0.200427, =0.100)\nEpoch #370: loss=0.319237 (contrastive=0.332980, msm=0.195555, =0.100)\nEpoch #371: loss=0.218911 (contrastive=0.221715, msm=0.193680, =0.100)\nEpoch #372: loss=0.224677 (contrastive=0.228344, msm=0.191670, =0.100)\nEpoch #373: loss=0.192497 (contrastive=0.192198, msm=0.195192, =0.100)\nEpoch #374: loss=0.208024 (contrastive=0.209453, msm=0.195165, =0.100)\nEpoch #375: loss=0.190561 (contrastive=0.190489, msm=0.191211, =0.100)\nEpoch #376: loss=0.234966 (contrastive=0.239437, msm=0.194723, =0.100)\nEpoch #377: loss=0.335658 (contrastive=0.351263, msm=0.195220, =0.100)\nEpoch #378: loss=0.428126 (contrastive=0.453749, msm=0.197519, =0.100)\nEpoch #379: loss=0.201309 (contrastive=0.202138, msm=0.193843, =0.100)\nEpoch #380: loss=0.199007 (contrastive=0.199051, msm=0.198611, =0.100)\nEpoch #381: loss=0.207754 (contrastive=0.209232, msm=0.194453, =0.100)\nEpoch #382: loss=0.198598 (contrastive=0.198488, msm=0.199590, =0.100)\nEpoch #383: loss=0.281467 (contrastive=0.290729, msm=0.198111, =0.100)\nEpoch #384: loss=1.341838 (contrastive=1.468837, msm=0.198843, =0.100)\nEpoch #385: loss=0.226245 (contrastive=0.229298, msm=0.198768, =0.100)\nEpoch #386: loss=0.229508 (contrastive=0.232145, msm=0.205777, =0.100)\nEpoch #387: loss=0.339015 (contrastive=0.353346, msm=0.210038, =0.100)\nEpoch #388: loss=0.379694 (contrastive=0.398200, msm=0.213143, =0.100)\nEpoch #389: loss=0.274208 (contrastive=0.281392, msm=0.209556, =0.100)\nEpoch #390: loss=0.278218 (contrastive=0.285702, msm=0.210866, =0.100)\nEpoch #391: loss=0.250355 (contrastive=0.255133, msm=0.207358, =0.100)\nEpoch #392: loss=0.657263 (contrastive=0.705790, msm=0.220524, =0.100)\nEpoch #393: loss=0.381560 (contrastive=0.398371, msm=0.230265, =0.100)\nEpoch #394: loss=0.366681 (contrastive=0.382556, msm=0.223810, =0.100)\nEpoch #395: loss=0.246432 (contrastive=0.249398, msm=0.219743, =0.100)\nEpoch #396: loss=0.330202 (contrastive=0.342775, msm=0.217049, =0.100)\nEpoch #397: loss=0.266365 (contrastive=0.272677, msm=0.209555, =0.100)\nEpoch #398: loss=0.233550 (contrastive=0.235509, msm=0.215918, =0.100)\nEpoch #399: loss=0.249104 (contrastive=0.253069, msm=0.213415, =0.100)\nEpoch #400: loss=0.222203 (contrastive=0.222580, msm=0.218814, =0.100)\nEpoch #401: loss=0.587900 (contrastive=0.628403, msm=0.223372, =0.100)\nEpoch #402: loss=0.282205 (contrastive=0.288035, msm=0.229735, =0.100)\nEpoch #403: loss=0.215655 (contrastive=0.214657, msm=0.224634, =0.100)\nEpoch #404: loss=0.228612 (contrastive=0.230666, msm=0.210126, =0.100)\nEpoch #405: loss=0.278352 (contrastive=0.286418, msm=0.205759, =0.100)\nEpoch #406: loss=0.223258 (contrastive=0.225192, msm=0.205849, =0.100)\nEpoch #407: loss=0.188655 (contrastive=0.186565, msm=0.207463, =0.100)\nEpoch #408: loss=0.387264 (contrastive=0.406792, msm=0.211505, =0.100)\nEpoch #409: loss=0.227819 (contrastive=0.229877, msm=0.209294, =0.100)\nEpoch #410: loss=0.213261 (contrastive=0.213689, msm=0.209407, =0.100)\nEpoch #411: loss=0.191367 (contrastive=0.189383, msm=0.209231, =0.100)\nEpoch #412: loss=0.655822 (contrastive=0.706033, msm=0.203921, =0.100)\nEpoch #413: loss=0.300795 (contrastive=0.311937, msm=0.200523, =0.100)\nEpoch #414: loss=0.301098 (contrastive=0.311989, msm=0.203077, =0.100)\nEpoch #415: loss=0.226935 (contrastive=0.230082, msm=0.198608, =0.100)\nEpoch #416: loss=0.352500 (contrastive=0.369629, msm=0.198338, =0.100)\nEpoch #417: loss=0.188425 (contrastive=0.187130, msm=0.200083, =0.100)\nEpoch #418: loss=0.204530 (contrastive=0.205248, msm=0.198061, =0.100)\nEpoch #419: loss=0.184612 (contrastive=0.183359, msm=0.195884, =0.100)\nEpoch #420: loss=0.256810 (contrastive=0.263854, msm=0.193412, =0.100)\nEpoch #421: loss=0.189259 (contrastive=0.187334, msm=0.206583, =0.100)\nEpoch #422: loss=0.182196 (contrastive=0.181265, msm=0.190570, =0.100)\nEpoch #423: loss=0.242625 (contrastive=0.247556, msm=0.198247, =0.100)\nEpoch #424: loss=0.319162 (contrastive=0.333944, msm=0.186128, =0.100)\nEpoch #425: loss=0.164218 (contrastive=0.161545, msm=0.188275, =0.100)\nEpoch #426: loss=0.179917 (contrastive=0.178950, msm=0.188627, =0.100)\nEpoch #427: loss=0.290589 (contrastive=0.301653, msm=0.191012, =0.100)\nEpoch #428: loss=0.158217 (contrastive=0.154974, msm=0.187407, =0.100)\nEpoch #429: loss=0.202265 (contrastive=0.203490, msm=0.191238, =0.100)\nEpoch #430: loss=0.246058 (contrastive=0.252540, msm=0.187719, =0.100)\nEpoch #431: loss=0.248891 (contrastive=0.255491, msm=0.189497, =0.100)\nEpoch #432: loss=0.171633 (contrastive=0.169745, msm=0.188630, =0.100)\nEpoch #433: loss=0.168771 (contrastive=0.166739, msm=0.187059, =0.100)\nEpoch #434: loss=0.492249 (contrastive=0.526443, msm=0.184499, =0.100)\nEpoch #435: loss=0.460236 (contrastive=0.490902, msm=0.184247, =0.100)\nEpoch #436: loss=0.230894 (contrastive=0.235877, msm=0.186047, =0.100)\nEpoch #437: loss=0.168315 (contrastive=0.166195, msm=0.187396, =0.100)\nEpoch #438: loss=0.502058 (contrastive=0.536692, msm=0.190356, =0.100)\nEpoch #439: loss=0.163198 (contrastive=0.160620, msm=0.186396, =0.100)\nEpoch #440: loss=0.166309 (contrastive=0.163397, msm=0.192521, =0.100)\nEpoch #441: loss=0.167240 (contrastive=0.164816, msm=0.189059, =0.100)\nEpoch #442: loss=0.165737 (contrastive=0.163941, msm=0.181901, =0.100)\nEpoch #443: loss=0.232367 (contrastive=0.237277, msm=0.188179, =0.100)\nEpoch #444: loss=0.195985 (contrastive=0.196336, msm=0.192819, =0.100)\nEpoch #445: loss=0.156346 (contrastive=0.152597, msm=0.190084, =0.100)\nEpoch #446: loss=0.214490 (contrastive=0.217502, msm=0.187384, =0.100)\nEpoch #447: loss=0.258339 (contrastive=0.266121, msm=0.188302, =0.100)\nEpoch #448: loss=0.152819 (contrastive=0.148931, msm=0.187805, =0.100)\nEpoch #449: loss=0.155095 (contrastive=0.152019, msm=0.182783, =0.100)\nEpoch #450: loss=0.195090 (contrastive=0.196719, msm=0.180420, =0.100)\nEpoch #451: loss=0.157082 (contrastive=0.154169, msm=0.183297, =0.100)\nEpoch #452: loss=0.167236 (contrastive=0.165148, msm=0.186029, =0.100)\nEpoch #453: loss=0.154253 (contrastive=0.150782, msm=0.185486, =0.100)\nEpoch #454: loss=0.267348 (contrastive=0.276564, msm=0.184395, =0.100)\nEpoch #455: loss=0.148498 (contrastive=0.144050, msm=0.188528, =0.100)\nEpoch #456: loss=0.161955 (contrastive=0.158961, msm=0.188897, =0.100)\nEpoch #457: loss=0.175496 (contrastive=0.174421, msm=0.185175, =0.100)\nEpoch #458: loss=0.141825 (contrastive=0.136675, msm=0.188183, =0.100)\nEpoch #459: loss=0.150677 (contrastive=0.146447, msm=0.188748, =0.100)\nEpoch #460: loss=0.181049 (contrastive=0.180749, msm=0.183752, =0.100)\nEpoch #461: loss=0.163090 (contrastive=0.160685, msm=0.184743, =0.100)\nEpoch #462: loss=0.142408 (contrastive=0.137832, msm=0.183592, =0.100)\nEpoch #463: loss=0.239557 (contrastive=0.245332, msm=0.187586, =0.100)\nEpoch #464: loss=0.158246 (contrastive=0.155481, msm=0.183137, =0.100)\nEpoch #465: loss=0.168198 (contrastive=0.166805, msm=0.180739, =0.100)\nEpoch #466: loss=0.152361 (contrastive=0.148808, msm=0.184339, =0.100)\nEpoch #467: loss=0.137991 (contrastive=0.132533, msm=0.187110, =0.100)\nEpoch #468: loss=0.217208 (contrastive=0.220494, msm=0.187632, =0.100)\nEpoch #469: loss=0.171312 (contrastive=0.169401, msm=0.188514, =0.100)\nEpoch #470: loss=0.133452 (contrastive=0.128230, msm=0.180453, =0.100)\nEpoch #471: loss=0.173531 (contrastive=0.172864, msm=0.179527, =0.100)\nEpoch #472: loss=0.236830 (contrastive=0.243140, msm=0.180044, =0.100)\nEpoch #473: loss=0.295729 (contrastive=0.308649, msm=0.179456, =0.100)\nEpoch #474: loss=0.209638 (contrastive=0.212247, msm=0.186158, =0.100)\nEpoch #475: loss=0.133301 (contrastive=0.127637, msm=0.184279, =0.100)\nEpoch #476: loss=0.210752 (contrastive=0.214069, msm=0.180900, =0.100)\nEpoch #477: loss=0.142909 (contrastive=0.138320, msm=0.184218, =0.100)\nEpoch #478: loss=0.209549 (contrastive=0.212823, msm=0.180088, =0.100)\nEpoch #479: loss=0.221591 (contrastive=0.226034, msm=0.181602, =0.100)\nEpoch #480: loss=1.034241 (contrastive=1.129162, msm=0.179957, =0.100)\nEpoch #481: loss=0.171534 (contrastive=0.170437, msm=0.181405, =0.100)\nEpoch #482: loss=0.221759 (contrastive=0.226164, msm=0.182107, =0.100)\nEpoch #483: loss=0.161242 (contrastive=0.158776, msm=0.183439, =0.100)\nEpoch #484: loss=0.168460 (contrastive=0.166969, msm=0.181880, =0.100)\nEpoch #485: loss=0.205727 (contrastive=0.208806, msm=0.178013, =0.100)\nEpoch #486: loss=0.177052 (contrastive=0.176490, msm=0.182112, =0.100)\nEpoch #487: loss=0.175915 (contrastive=0.173979, msm=0.193336, =0.100)\nEpoch #488: loss=0.173065 (contrastive=0.171048, msm=0.191216, =0.100)\nEpoch #489: loss=0.204867 (contrastive=0.206819, msm=0.187307, =0.100)\nEpoch #490: loss=0.233424 (contrastive=0.238361, msm=0.188985, =0.100)\nEpoch #491: loss=0.148498 (contrastive=0.144075, msm=0.188309, =0.100)\nEpoch #492: loss=0.143660 (contrastive=0.138838, msm=0.187063, =0.100)\nEpoch #493: loss=0.148245 (contrastive=0.144392, msm=0.182923, =0.100)\nEpoch #494: loss=0.711391 (contrastive=0.769814, msm=0.185586, =0.100)\nEpoch #495: loss=0.300707 (contrastive=0.314035, msm=0.180756, =0.100)\nEpoch #496: loss=0.145964 (contrastive=0.141514, msm=0.186019, =0.100)\nEpoch #497: loss=0.165605 (contrastive=0.163068, msm=0.188445, =0.100)\nEpoch #498: loss=0.152977 (contrastive=0.149003, msm=0.188734, =0.100)\nEpoch #499: loss=0.187669 (contrastive=0.187563, msm=0.188619, =0.100)\nEpoch #500: loss=0.228988 (contrastive=0.233737, msm=0.186251, =0.100)\nEpoch #501: loss=0.214770 (contrastive=0.218926, msm=0.177373, =0.100)\nEpoch #502: loss=0.260772 (contrastive=0.269609, msm=0.181236, =0.100)\nEpoch #503: loss=0.345914 (contrastive=0.363721, msm=0.185647, =0.100)\nEpoch #504: loss=0.251194 (contrastive=0.258795, msm=0.182783, =0.100)\nEpoch #505: loss=0.153358 (contrastive=0.150087, msm=0.182796, =0.100)\nEpoch #506: loss=0.139757 (contrastive=0.134410, msm=0.187875, =0.100)\nEpoch #507: loss=0.169480 (contrastive=0.167470, msm=0.187572, =0.100)\nEpoch #508: loss=0.212976 (contrastive=0.216116, msm=0.184717, =0.100)\nEpoch #509: loss=0.142030 (contrastive=0.137461, msm=0.183147, =0.100)\nEpoch #510: loss=0.134248 (contrastive=0.128751, msm=0.183717, =0.100)\nEpoch #511: loss=0.275789 (contrastive=0.286069, msm=0.183274, =0.100)\nEpoch #512: loss=0.133932 (contrastive=0.128927, msm=0.178971, =0.100)\nEpoch #513: loss=0.167295 (contrastive=0.165514, msm=0.183318, =0.100)\nEpoch #514: loss=0.165990 (contrastive=0.164063, msm=0.183332, =0.100)\nEpoch #515: loss=0.132000 (contrastive=0.125941, msm=0.186529, =0.100)\nEpoch #516: loss=0.215109 (contrastive=0.218501, msm=0.184581, =0.100)\nEpoch #517: loss=0.156701 (contrastive=0.154548, msm=0.176079, =0.100)\nEpoch #518: loss=0.193969 (contrastive=0.195425, msm=0.180860, =0.100)\nEpoch #519: loss=0.182785 (contrastive=0.183216, msm=0.178901, =0.100)\nEpoch #520: loss=0.162256 (contrastive=0.160805, msm=0.175316, =0.100)\nEpoch #521: loss=0.139485 (contrastive=0.134964, msm=0.180169, =0.100)\nEpoch #522: loss=0.154865 (contrastive=0.152393, msm=0.177108, =0.100)\nEpoch #523: loss=0.534291 (contrastive=0.574185, msm=0.175245, =0.100)\nEpoch #524: loss=0.196520 (contrastive=0.198713, msm=0.176787, =0.100)\nEpoch #525: loss=0.167333 (contrastive=0.166647, msm=0.173509, =0.100)\nEpoch #526: loss=0.123771 (contrastive=0.117634, msm=0.179005, =0.100)\nEpoch #527: loss=0.148074 (contrastive=0.144304, msm=0.182001, =0.100)\nEpoch #528: loss=0.181041 (contrastive=0.182030, msm=0.172136, =0.100)\nEpoch #529: loss=0.176146 (contrastive=0.175806, msm=0.179205, =0.100)\nEpoch #530: loss=0.192722 (contrastive=0.194024, msm=0.181005, =0.100)\nEpoch #531: loss=0.121732 (contrastive=0.115421, msm=0.178528, =0.100)\nEpoch #532: loss=0.179165 (contrastive=0.179265, msm=0.178263, =0.100)\nEpoch #533: loss=0.181900 (contrastive=0.182557, msm=0.175988, =0.100)\nEpoch #534: loss=0.132309 (contrastive=0.126737, msm=0.182459, =0.100)\nEpoch #535: loss=0.160985 (contrastive=0.158853, msm=0.180179, =0.100)\nEpoch #536: loss=0.120439 (contrastive=0.114656, msm=0.172493, =0.100)\nEpoch #537: loss=0.187819 (contrastive=0.188885, msm=0.178221, =0.100)\nEpoch #538: loss=0.186955 (contrastive=0.188225, msm=0.175528, =0.100)\nEpoch #539: loss=0.145220 (contrastive=0.141511, msm=0.178599, =0.100)\nEpoch #540: loss=0.122837 (contrastive=0.117193, msm=0.173636, =0.100)\nEpoch #541: loss=0.168542 (contrastive=0.168074, msm=0.172753, =0.100)\nEpoch #542: loss=0.135089 (contrastive=0.131073, msm=0.171229, =0.100)\nEpoch #543: loss=0.133856 (contrastive=0.129631, msm=0.171876, =0.100)\nEpoch #544: loss=0.115950 (contrastive=0.109250, msm=0.176246, =0.100)\nEpoch #545: loss=0.164315 (contrastive=0.162890, msm=0.177141, =0.100)\nEpoch #546: loss=0.199363 (contrastive=0.201910, msm=0.176441, =0.100)\nEpoch #547: loss=0.253682 (contrastive=0.262326, msm=0.175886, =0.100)\nEpoch #548: loss=0.485489 (contrastive=0.519424, msm=0.180074, =0.100)\nEpoch #549: loss=0.124745 (contrastive=0.119010, msm=0.176355, =0.100)\nEpoch #550: loss=0.272987 (contrastive=0.283733, msm=0.176277, =0.100)\nEpoch #551: loss=0.170937 (contrastive=0.170257, msm=0.177057, =0.100)\nEpoch #552: loss=0.844284 (contrastive=0.918283, msm=0.178296, =0.100)\nEpoch #553: loss=0.139171 (contrastive=0.134907, msm=0.177546, =0.100)\nEpoch #554: loss=0.169796 (contrastive=0.168770, msm=0.179033, =0.100)\nEpoch #555: loss=0.278773 (contrastive=0.290157, msm=0.176318, =0.100)\nEpoch #556: loss=0.215101 (contrastive=0.219064, msm=0.179431, =0.100)\nEpoch #557: loss=0.181860 (contrastive=0.182134, msm=0.179389, =0.100)\nEpoch #558: loss=0.169997 (contrastive=0.169123, msm=0.177859, =0.100)\nEpoch #559: loss=0.326603 (contrastive=0.343269, msm=0.176608, =0.100)\nEpoch #560: loss=0.174957 (contrastive=0.173852, msm=0.184897, =0.100)\nEpoch #561: loss=0.136251 (contrastive=0.131118, msm=0.182442, =0.100)\nEpoch #562: loss=0.262660 (contrastive=0.271386, msm=0.184129, =0.100)\nEpoch #563: loss=0.178841 (contrastive=0.178594, msm=0.181065, =0.100)\nEpoch #564: loss=0.138719 (contrastive=0.134086, msm=0.180410, =0.100)\nEpoch #565: loss=0.507692 (contrastive=0.543934, msm=0.181507, =0.100)\nEpoch #566: loss=0.175035 (contrastive=0.174158, msm=0.182929, =0.100)\nEpoch #567: loss=0.133586 (contrastive=0.128175, msm=0.182287, =0.100)\nEpoch #568: loss=0.171748 (contrastive=0.170483, msm=0.183141, =0.100)\nEpoch #569: loss=0.126383 (contrastive=0.119650, msm=0.186982, =0.100)\nEpoch #570: loss=0.132883 (contrastive=0.127314, msm=0.183005, =0.100)\nEpoch #571: loss=0.151509 (contrastive=0.148134, msm=0.181886, =0.100)\nEpoch #572: loss=0.158730 (contrastive=0.155542, msm=0.187425, =0.100)\nEpoch #573: loss=0.152842 (contrastive=0.149655, msm=0.181532, =0.100)\nEpoch #574: loss=0.140928 (contrastive=0.136488, msm=0.180892, =0.100)\nEpoch #575: loss=0.229890 (contrastive=0.235161, msm=0.182449, =0.100)\nEpoch #576: loss=0.130767 (contrastive=0.124216, msm=0.189726, =0.100)\nEpoch #577: loss=0.157767 (contrastive=0.154713, msm=0.185253, =0.100)\nEpoch #578: loss=0.201867 (contrastive=0.204563, msm=0.177599, =0.100)\nEpoch #579: loss=0.333570 (contrastive=0.349908, msm=0.186529, =0.100)\nEpoch #580: loss=0.292537 (contrastive=0.304725, msm=0.182848, =0.100)\nEpoch #581: loss=0.133045 (contrastive=0.127064, msm=0.186879, =0.100)\nEpoch #582: loss=0.129868 (contrastive=0.123883, msm=0.183736, =0.100)\nEpoch #583: loss=0.315929 (contrastive=0.330442, msm=0.185311, =0.100)\nEpoch #584: loss=0.225727 (contrastive=0.230050, msm=0.186818, =0.100)\nEpoch #585: loss=0.219585 (contrastive=0.223993, msm=0.179918, =0.100)\nEpoch #586: loss=0.261165 (contrastive=0.269511, msm=0.186046, =0.100)\nEpoch #587: loss=0.257664 (contrastive=0.265867, msm=0.183841, =0.100)\nEpoch #588: loss=0.222809 (contrastive=0.226971, msm=0.185350, =0.100)\nEpoch #589: loss=0.191346 (contrastive=0.191970, msm=0.185731, =0.100)\nEpoch #590: loss=0.161205 (contrastive=0.158432, msm=0.186167, =0.100)\nEpoch #591: loss=0.256294 (contrastive=0.263660, msm=0.190002, =0.100)\nEpoch #592: loss=0.165578 (contrastive=0.163279, msm=0.186272, =0.100)\nEpoch #593: loss=0.143112 (contrastive=0.138663, msm=0.183147, =0.100)\nEpoch #594: loss=0.457609 (contrastive=0.487446, msm=0.189078, =0.100)\nEpoch #595: loss=0.271635 (contrastive=0.280300, msm=0.193643, =0.100)\nEpoch #596: loss=0.276339 (contrastive=0.285356, msm=0.195183, =0.100)\nEpoch #597: loss=0.249446 (contrastive=0.255405, msm=0.195818, =0.100)\nEpoch #598: loss=0.183180 (contrastive=0.182881, msm=0.185872, =0.100)\nEpoch #599: loss=0.375608 (contrastive=0.396194, msm=0.190334, =0.100)\nTraining time: 0:02:29.981716\nEvaluation completed\nResults: {'ours': {24: {'norm': {'MSE': 1.0550203115811363, 'MAE': 0.7824684413499298}, 'raw': {'MSE': 22.35200307813609, 'MAE': 2.9542184723837854}}, 48: {'norm': {'MSE': 1.0674341645898489, 'MAE': 0.7890497949522783}, 'raw': {'MSE': 22.408725683897018, 'MAE': 2.964914121833393}}, 168: {'norm': {'MSE': 1.1159055962316913, 'MAE': 0.8168441763643887}, 'raw': {'MSE': 22.123026170849055, 'MAE': 2.9896485582973167}}, 336: {'norm': {'MSE': 1.1445621001709239, 'MAE': 0.8379576317321514}, 'raw': {'MSE': 22.100721044912273, 'MAE': 3.0304574044348036}}, 720: {'norm': {'MSE': 1.1564647941724764, 'MAE': 0.8523825620418006}, 'raw': {'MSE': 20.95547257828229, 'MAE': 3.0047894195437945}}}, 'ts2vec_infer_time': 52.75231862068176, 'lr_train_time': {24: 1.2276794910430908, 48: 1.2793867588043213, 168: 2.651310443878174, 336: 3.8735833168029785, 720: 6.572973012924194}, 'lr_infer_time': {24: 0.004753828048706055, 48: 0.008518218994140625, 168: 0.030632734298706055, 336: 0.059284210205078125, 720: 0.09733343124389648}}\nModel and results saved to training/ETTh1__forecast_multivar_msm_conservative_2025-09-22_16_23_53_948676\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!python train_msm.py ETTh2 forecast_multivar_msm_conservative --loader forecast_csv --repr-dims 320 --max-threads 8 --seed 42 --eval --msm-weight 0.1 --msm-mask-rate 0.2 --msm-decoder-depth 3\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:25:06.925197Z","iopub.execute_input":"2025-09-22T16:25:06.925513Z","iopub.status.idle":"2025-09-22T16:28:55.312942Z","shell.execute_reply.started":"2025-09-22T16:25:06.925479Z","shell.execute_reply":"2025-09-22T16:28:55.312228Z"}},"outputs":[{"name":"stdout","text":"Dataset: ETTh2\nArguments: Namespace(dataset='ETTh2', run_name='forecast_multivar_msm_conservative', loader='forecast_csv', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0, msm_weight=0.1, msm_mask_rate=0.2, msm_decoder_depth=3, dynamic_lambda=False)\nLoading data... done\nTraining...\nEpoch #0: loss=10.072110 (contrastive=11.054740, msm=1.228450, =0.100)\nEpoch #1: loss=11.472054 (contrastive=12.612463, msm=1.208370, =0.100)\nEpoch #2: loss=4.249075 (contrastive=4.587859, msm=1.200021, =0.100)\nEpoch #3: loss=4.682185 (contrastive=5.069141, msm=1.199584, =0.100)\nEpoch #4: loss=3.245369 (contrastive=3.472710, msm=1.199303, =0.100)\nEpoch #5: loss=3.222721 (contrastive=3.448815, msm=1.187874, =0.100)\nEpoch #6: loss=2.869347 (contrastive=3.054830, msm=1.200000, =0.100)\nEpoch #7: loss=2.940574 (contrastive=3.138082, msm=1.162998, =0.100)\nEpoch #8: loss=2.756169 (contrastive=2.933730, msm=1.158113, =0.100)\nEpoch #9: loss=2.691980 (contrastive=2.862936, msm=1.153379, =0.100)\nEpoch #10: loss=2.390522 (contrastive=2.529236, msm=1.142096, =0.100)\nEpoch #11: loss=2.454072 (contrastive=2.601426, msm=1.127887, =0.100)\nEpoch #12: loss=2.117265 (contrastive=2.226722, msm=1.132149, =0.100)\nEpoch #13: loss=2.124905 (contrastive=2.237000, msm=1.116054, =0.100)\nEpoch #14: loss=2.063452 (contrastive=2.172454, msm=1.082432, =0.100)\nEpoch #15: loss=1.968947 (contrastive=2.067890, msm=1.078460, =0.100)\nEpoch #16: loss=2.019444 (contrastive=2.125006, msm=1.069390, =0.100)\nEpoch #17: loss=1.900491 (contrastive=1.994147, msm=1.057588, =0.100)\nEpoch #18: loss=1.851440 (contrastive=1.939151, msm=1.062038, =0.100)\nEpoch #19: loss=1.824361 (contrastive=1.910428, msm=1.049757, =0.100)\nEpoch #20: loss=1.879037 (contrastive=1.976679, msm=1.000261, =0.100)\nEpoch #21: loss=1.964833 (contrastive=2.071601, msm=1.003924, =0.100)\nEpoch #22: loss=1.731825 (contrastive=1.817588, msm=0.959960, =0.100)\nEpoch #23: loss=1.749706 (contrastive=1.837732, msm=0.957475, =0.100)\nEpoch #24: loss=1.874722 (contrastive=1.981363, msm=0.914954, =0.100)\nEpoch #25: loss=1.697495 (contrastive=1.786292, msm=0.898319, =0.100)\nEpoch #26: loss=1.724423 (contrastive=1.820522, msm=0.859532, =0.100)\nEpoch #27: loss=1.668071 (contrastive=1.760173, msm=0.839149, =0.100)\nEpoch #28: loss=1.716899 (contrastive=1.814451, msm=0.838932, =0.100)\nEpoch #29: loss=1.742447 (contrastive=1.848026, msm=0.792240, =0.100)\nEpoch #30: loss=1.830156 (contrastive=1.947434, msm=0.774650, =0.100)\nEpoch #31: loss=1.778918 (contrastive=1.892774, msm=0.754216, =0.100)\nEpoch #32: loss=1.627164 (contrastive=1.724021, msm=0.755451, =0.100)\nEpoch #33: loss=1.748781 (contrastive=1.860358, msm=0.744584, =0.100)\nEpoch #34: loss=1.746065 (contrastive=1.861114, msm=0.710623, =0.100)\nEpoch #35: loss=1.757823 (contrastive=1.873719, msm=0.714758, =0.100)\nEpoch #36: loss=1.496338 (contrastive=1.585240, msm=0.696226, =0.100)\nEpoch #37: loss=1.473575 (contrastive=1.562495, msm=0.673291, =0.100)\nEpoch #38: loss=1.635281 (contrastive=1.742770, msm=0.667881, =0.100)\nEpoch #39: loss=1.510990 (contrastive=1.607753, msm=0.640118, =0.100)\nEpoch #40: loss=1.655902 (contrastive=1.767625, msm=0.650395, =0.100)\nEpoch #41: loss=1.488791 (contrastive=1.584402, msm=0.628285, =0.100)\nEpoch #42: loss=1.533792 (contrastive=1.635522, msm=0.618220, =0.100)\nEpoch #43: loss=1.551829 (contrastive=1.658453, msm=0.592215, =0.100)\nEpoch #44: loss=1.473523 (contrastive=1.570716, msm=0.598786, =0.100)\nEpoch #45: loss=1.563866 (contrastive=1.672440, msm=0.586699, =0.100)\nEpoch #46: loss=1.557363 (contrastive=1.667425, msm=0.566809, =0.100)\nEpoch #47: loss=1.604383 (contrastive=1.720081, msm=0.563109, =0.100)\nEpoch #48: loss=1.408541 (contrastive=1.503468, msm=0.554195, =0.100)\nEpoch #49: loss=1.504051 (contrastive=1.611301, msm=0.538799, =0.100)\nEpoch #50: loss=1.415859 (contrastive=1.514411, msm=0.528891, =0.100)\nEpoch #51: loss=1.455920 (contrastive=1.558440, msm=0.533241, =0.100)\nEpoch #52: loss=1.372736 (contrastive=1.468784, msm=0.508304, =0.100)\nEpoch #53: loss=1.517268 (contrastive=1.629520, msm=0.507006, =0.100)\nEpoch #54: loss=1.382420 (contrastive=1.481126, msm=0.494067, =0.100)\nEpoch #55: loss=1.378440 (contrastive=1.478479, msm=0.478086, =0.100)\nEpoch #56: loss=1.414285 (contrastive=1.517300, msm=0.487141, =0.100)\nEpoch #57: loss=1.340339 (contrastive=1.436494, msm=0.474943, =0.100)\nEpoch #58: loss=1.221020 (contrastive=1.305183, msm=0.463552, =0.100)\nEpoch #59: loss=1.298641 (contrastive=1.393854, msm=0.441722, =0.100)\nEpoch #60: loss=1.418950 (contrastive=1.527859, msm=0.438765, =0.100)\nEpoch #61: loss=1.331644 (contrastive=1.431523, msm=0.432732, =0.100)\nEpoch #62: loss=1.250491 (contrastive=1.341941, msm=0.427445, =0.100)\nEpoch #63: loss=1.162591 (contrastive=1.244784, msm=0.422852, =0.100)\nEpoch #64: loss=1.208120 (contrastive=1.294518, msm=0.430532, =0.100)\nEpoch #65: loss=1.264522 (contrastive=1.358609, msm=0.417745, =0.100)\nEpoch #66: loss=1.446652 (contrastive=1.562112, msm=0.407516, =0.100)\nEpoch #67: loss=1.198932 (contrastive=1.287916, msm=0.398079, =0.100)\nEpoch #68: loss=1.279808 (contrastive=1.378219, msm=0.394108, =0.100)\nEpoch #69: loss=1.219299 (contrastive=1.310209, msm=0.401112, =0.100)\nEpoch #70: loss=1.145624 (contrastive=1.229285, msm=0.392677, =0.100)\nEpoch #71: loss=1.051798 (contrastive=1.125698, msm=0.386696, =0.100)\nEpoch #72: loss=1.119241 (contrastive=1.201714, msm=0.376985, =0.100)\nEpoch #73: loss=1.067215 (contrastive=1.144211, msm=0.374250, =0.100)\nEpoch #74: loss=1.159266 (contrastive=1.245574, msm=0.382492, =0.100)\nEpoch #75: loss=1.054881 (contrastive=1.132092, msm=0.359986, =0.100)\nEpoch #76: loss=1.381267 (contrastive=1.494767, msm=0.359767, =0.100)\nEpoch #77: loss=1.035342 (contrastive=1.110568, msm=0.358313, =0.100)\nEpoch #78: loss=0.952964 (contrastive=1.019040, msm=0.358278, =0.100)\nEpoch #79: loss=1.035247 (contrastive=1.111965, msm=0.344780, =0.100)\nEpoch #80: loss=1.154655 (contrastive=1.243497, msm=0.355079, =0.100)\nEpoch #81: loss=0.942832 (contrastive=1.008686, msm=0.350144, =0.100)\nEpoch #82: loss=1.063349 (contrastive=1.143670, msm=0.340461, =0.100)\nEpoch #83: loss=1.171256 (contrastive=1.262819, msm=0.347189, =0.100)\nEpoch #84: loss=0.908746 (contrastive=0.972778, msm=0.332457, =0.100)\nEpoch #85: loss=1.098825 (contrastive=1.183259, msm=0.338919, =0.100)\nEpoch #86: loss=0.908992 (contrastive=0.973659, msm=0.326993, =0.100)\nEpoch #87: loss=0.966499 (contrastive=1.036892, msm=0.332964, =0.100)\nEpoch #88: loss=0.849272 (contrastive=0.908044, msm=0.320324, =0.100)\nEpoch #89: loss=1.326480 (contrastive=1.436957, msm=0.332180, =0.100)\nEpoch #90: loss=0.822497 (contrastive=0.877563, msm=0.326898, =0.100)\nEpoch #91: loss=1.034878 (contrastive=1.114684, msm=0.316629, =0.100)\nEpoch #92: loss=1.144916 (contrastive=1.236184, msm=0.323500, =0.100)\nEpoch #93: loss=1.050424 (contrastive=1.130416, msm=0.330489, =0.100)\nEpoch #94: loss=0.796640 (contrastive=0.849514, msm=0.320775, =0.100)\nEpoch #95: loss=0.869856 (contrastive=0.931753, msm=0.312784, =0.100)\nEpoch #96: loss=0.894904 (contrastive=0.958597, msm=0.321669, =0.100)\nEpoch #97: loss=1.092380 (contrastive=1.179262, msm=0.310443, =0.100)\nEpoch #98: loss=0.747143 (contrastive=0.795964, msm=0.307760, =0.100)\nEpoch #99: loss=1.246568 (contrastive=1.351495, msm=0.302224, =0.100)\nEpoch #100: loss=0.814438 (contrastive=0.870983, msm=0.305530, =0.100)\nEpoch #101: loss=0.814400 (contrastive=0.870854, msm=0.306309, =0.100)\nEpoch #102: loss=0.876761 (contrastive=0.940008, msm=0.307539, =0.100)\nEpoch #103: loss=0.992518 (contrastive=1.070063, msm=0.294615, =0.100)\nEpoch #104: loss=0.975143 (contrastive=1.050538, msm=0.296582, =0.100)\nEpoch #105: loss=0.807798 (contrastive=0.864775, msm=0.295000, =0.100)\nEpoch #106: loss=0.857535 (contrastive=0.920363, msm=0.292083, =0.100)\nEpoch #107: loss=0.852467 (contrastive=0.914888, msm=0.290674, =0.100)\nEpoch #108: loss=0.805632 (contrastive=0.861614, msm=0.301794, =0.100)\nEpoch #109: loss=0.969886 (contrastive=1.045188, msm=0.292163, =0.100)\nEpoch #110: loss=0.758609 (contrastive=0.811100, msm=0.286195, =0.100)\nEpoch #111: loss=1.665080 (contrastive=1.818286, msm=0.286231, =0.100)\nEpoch #112: loss=0.724602 (contrastive=0.773604, msm=0.283584, =0.100)\nEpoch #113: loss=0.739773 (contrastive=0.789760, msm=0.289889, =0.100)\nEpoch #114: loss=0.956978 (contrastive=1.033232, msm=0.270694, =0.100)\nEpoch #115: loss=0.847511 (contrastive=0.909834, msm=0.286608, =0.100)\nEpoch #116: loss=0.824825 (contrastive=0.886001, msm=0.274247, =0.100)\nEpoch #117: loss=0.818879 (contrastive=0.879465, msm=0.273609, =0.100)\nEpoch #118: loss=0.782542 (contrastive=0.840103, msm=0.264490, =0.100)\nEpoch #119: loss=0.891623 (contrastive=0.960467, msm=0.272034, =0.100)\nEpoch #120: loss=0.702133 (contrastive=0.750410, msm=0.267644, =0.100)\nEpoch #121: loss=0.657478 (contrastive=0.700605, msm=0.269333, =0.100)\nEpoch #122: loss=0.943097 (contrastive=1.017172, msm=0.276426, =0.100)\nEpoch #123: loss=0.661644 (contrastive=0.705419, msm=0.267667, =0.100)\nEpoch #124: loss=0.691222 (contrastive=0.737920, msm=0.270939, =0.100)\nEpoch #125: loss=0.667057 (contrastive=0.710737, msm=0.273937, =0.100)\nEpoch #126: loss=0.961138 (contrastive=1.038502, msm=0.264855, =0.100)\nEpoch #127: loss=0.858022 (contrastive=0.923655, msm=0.267328, =0.100)\nEpoch #128: loss=1.742914 (contrastive=1.907653, msm=0.260262, =0.100)\nEpoch #129: loss=0.665649 (contrastive=0.709935, msm=0.267069, =0.100)\nEpoch #130: loss=0.738675 (contrastive=0.790283, msm=0.274205, =0.100)\nEpoch #131: loss=0.795572 (contrastive=0.853542, msm=0.273837, =0.100)\nEpoch #132: loss=0.976130 (contrastive=1.054182, msm=0.273666, =0.100)\nEpoch #133: loss=0.713529 (contrastive=0.762205, msm=0.275445, =0.100)\nEpoch #134: loss=0.784608 (contrastive=0.842673, msm=0.262028, =0.100)\nEpoch #135: loss=0.735296 (contrastive=0.787566, msm=0.264874, =0.100)\nEpoch #136: loss=0.669431 (contrastive=0.714419, msm=0.264533, =0.100)\nEpoch #137: loss=0.638962 (contrastive=0.682025, msm=0.251398, =0.100)\nEpoch #138: loss=0.660902 (contrastive=0.703587, msm=0.276739, =0.100)\nEpoch #139: loss=0.582322 (contrastive=0.617632, msm=0.264539, =0.100)\nEpoch #140: loss=0.863215 (contrastive=0.930273, msm=0.259690, =0.100)\nEpoch #141: loss=1.122103 (contrastive=1.217728, msm=0.261478, =0.100)\nEpoch #142: loss=0.673295 (contrastive=0.717854, msm=0.272261, =0.100)\nEpoch #143: loss=0.618491 (contrastive=0.657198, msm=0.270128, =0.100)\nEpoch #144: loss=0.838158 (contrastive=0.902289, msm=0.260980, =0.100)\nEpoch #145: loss=0.651488 (contrastive=0.695096, msm=0.259019, =0.100)\nEpoch #146: loss=0.584921 (contrastive=0.622182, msm=0.249571, =0.100)\nEpoch #147: loss=0.564504 (contrastive=0.599619, msm=0.248471, =0.100)\nEpoch #148: loss=0.800742 (contrastive=0.861344, msm=0.255328, =0.100)\nEpoch #149: loss=0.935222 (contrastive=1.010112, msm=0.261207, =0.100)\nEpoch #150: loss=0.589473 (contrastive=0.627185, msm=0.250065, =0.100)\nEpoch #151: loss=0.524855 (contrastive=0.555723, msm=0.247042, =0.100)\nEpoch #152: loss=0.703343 (contrastive=0.753361, msm=0.253178, =0.100)\nEpoch #153: loss=0.499859 (contrastive=0.528147, msm=0.245273, =0.100)\nEpoch #154: loss=0.596496 (contrastive=0.634173, msm=0.257405, =0.100)\nEpoch #155: loss=0.503719 (contrastive=0.532575, msm=0.244014, =0.100)\nEpoch #156: loss=1.157602 (contrastive=1.258753, msm=0.247245, =0.100)\nEpoch #157: loss=0.541587 (contrastive=0.573656, msm=0.252967, =0.100)\nEpoch #158: loss=0.887824 (contrastive=0.957886, msm=0.257261, =0.100)\nEpoch #159: loss=0.547012 (contrastive=0.580080, msm=0.249397, =0.100)\nEpoch #160: loss=0.529014 (contrastive=0.561280, msm=0.238616, =0.100)\nEpoch #161: loss=0.562797 (contrastive=0.598298, msm=0.243287, =0.100)\nEpoch #162: loss=0.616037 (contrastive=0.658222, msm=0.236373, =0.100)\nEpoch #163: loss=0.542833 (contrastive=0.576476, msm=0.240050, =0.100)\nEpoch #164: loss=0.525987 (contrastive=0.558598, msm=0.232482, =0.100)\nEpoch #165: loss=0.606797 (contrastive=0.647822, msm=0.237574, =0.100)\nEpoch #166: loss=1.142273 (contrastive=1.243136, msm=0.234502, =0.100)\nEpoch #167: loss=0.492082 (contrastive=0.521131, msm=0.230646, =0.100)\nEpoch #168: loss=0.519390 (contrastive=0.550921, msm=0.235615, =0.100)\nEpoch #169: loss=1.311418 (contrastive=1.431305, msm=0.232435, =0.100)\nEpoch #170: loss=0.622746 (contrastive=0.666403, msm=0.229829, =0.100)\nEpoch #171: loss=0.619914 (contrastive=0.662976, msm=0.232356, =0.100)\nEpoch #172: loss=0.540023 (contrastive=0.573710, msm=0.236843, =0.100)\nEpoch #173: loss=0.559715 (contrastive=0.595443, msm=0.238171, =0.100)\nEpoch #174: loss=0.513502 (contrastive=0.544364, msm=0.235747, =0.100)\nEpoch #175: loss=0.486793 (contrastive=0.514908, msm=0.233765, =0.100)\nEpoch #176: loss=0.552426 (contrastive=0.587937, msm=0.232830, =0.100)\nEpoch #177: loss=0.461141 (contrastive=0.486815, msm=0.230074, =0.100)\nEpoch #178: loss=0.521031 (contrastive=0.553364, msm=0.230025, =0.100)\nEpoch #179: loss=1.189205 (contrastive=1.294120, msm=0.244977, =0.100)\nEpoch #180: loss=0.596486 (contrastive=0.635849, msm=0.242221, =0.100)\nEpoch #181: loss=0.500481 (contrastive=0.529245, msm=0.241609, =0.100)\nEpoch #182: loss=0.577587 (contrastive=0.616448, msm=0.227830, =0.100)\nEpoch #183: loss=0.794804 (contrastive=0.857200, msm=0.233249, =0.100)\nEpoch #184: loss=0.478324 (contrastive=0.504817, msm=0.239885, =0.100)\nEpoch #185: loss=0.722025 (contrastive=0.775790, msm=0.238144, =0.100)\nEpoch #186: loss=0.940153 (contrastive=1.017344, msm=0.245439, =0.100)\nEpoch #187: loss=0.467071 (contrastive=0.492508, msm=0.238133, =0.100)\nEpoch #188: loss=0.469324 (contrastive=0.494732, msm=0.240650, =0.100)\nEpoch #189: loss=0.754428 (contrastive=0.811016, msm=0.245132, =0.100)\nEpoch #190: loss=0.510097 (contrastive=0.539622, msm=0.244374, =0.100)\nEpoch #191: loss=0.447089 (contrastive=0.468345, msm=0.255778, =0.100)\nEpoch #192: loss=0.532759 (contrastive=0.564274, msm=0.249124, =0.100)\nEpoch #193: loss=0.560421 (contrastive=0.596767, msm=0.233301, =0.100)\nEpoch #194: loss=0.655606 (contrastive=0.702002, msm=0.238039, =0.100)\nEpoch #195: loss=0.504886 (contrastive=0.535602, msm=0.228447, =0.100)\nEpoch #196: loss=0.512508 (contrastive=0.544721, msm=0.222591, =0.100)\nEpoch #197: loss=0.459063 (contrastive=0.483317, msm=0.240779, =0.100)\nEpoch #198: loss=0.819275 (contrastive=0.883343, msm=0.242660, =0.100)\nEpoch #199: loss=0.475158 (contrastive=0.501438, msm=0.238632, =0.100)\nEpoch #200: loss=0.459060 (contrastive=0.483927, msm=0.235260, =0.100)\nEpoch #201: loss=0.399959 (contrastive=0.419378, msm=0.225189, =0.100)\nEpoch #202: loss=0.443529 (contrastive=0.467298, msm=0.229608, =0.100)\nEpoch #203: loss=0.362291 (contrastive=0.377746, msm=0.223188, =0.100)\nEpoch #204: loss=0.386925 (contrastive=0.405254, msm=0.221963, =0.100)\nEpoch #205: loss=0.547472 (contrastive=0.582362, msm=0.233465, =0.100)\nEpoch #206: loss=0.407981 (contrastive=0.428276, msm=0.225329, =0.100)\nEpoch #207: loss=0.650578 (contrastive=0.698079, msm=0.223075, =0.100)\nEpoch #208: loss=0.396559 (contrastive=0.415725, msm=0.224069, =0.100)\nEpoch #209: loss=0.854246 (contrastive=0.925259, msm=0.215131, =0.100)\nEpoch #210: loss=0.365949 (contrastive=0.382874, msm=0.213623, =0.100)\nEpoch #211: loss=0.375595 (contrastive=0.392552, msm=0.222982, =0.100)\nEpoch #212: loss=0.831651 (contrastive=0.899877, msm=0.217619, =0.100)\nEpoch #213: loss=0.506903 (contrastive=0.538637, msm=0.221302, =0.100)\nEpoch #214: loss=0.456716 (contrastive=0.483557, msm=0.215150, =0.100)\nEpoch #215: loss=0.619627 (contrastive=0.665442, msm=0.207291, =0.100)\nEpoch #216: loss=0.834750 (contrastive=0.904339, msm=0.208447, =0.100)\nEpoch #217: loss=0.396777 (contrastive=0.418115, msm=0.204732, =0.100)\nEpoch #218: loss=0.693627 (contrastive=0.747349, msm=0.210128, =0.100)\nEpoch #219: loss=0.378229 (contrastive=0.396716, msm=0.211851, =0.100)\nEpoch #220: loss=0.388276 (contrastive=0.408651, msm=0.204905, =0.100)\nEpoch #221: loss=0.348451 (contrastive=0.364417, msm=0.204755, =0.100)\nEpoch #222: loss=0.355348 (contrastive=0.372246, msm=0.203271, =0.100)\nEpoch #223: loss=0.484382 (contrastive=0.515447, msm=0.204802, =0.100)\nEpoch #224: loss=0.336609 (contrastive=0.350971, msm=0.207353, =0.100)\nEpoch #225: loss=0.526264 (contrastive=0.562020, msm=0.204458, =0.100)\nEpoch #226: loss=0.366145 (contrastive=0.383858, msm=0.206734, =0.100)\nEpoch #227: loss=0.465911 (contrastive=0.494391, msm=0.209596, =0.100)\nEpoch #228: loss=0.628449 (contrastive=0.674363, msm=0.215215, =0.100)\nEpoch #229: loss=0.328403 (contrastive=0.340999, msm=0.215035, =0.100)\nEpoch #230: loss=0.692127 (contrastive=0.745010, msm=0.216178, =0.100)\nEpoch #231: loss=0.347341 (contrastive=0.361556, msm=0.219402, =0.100)\nEpoch #232: loss=0.392378 (contrastive=0.411427, msm=0.220937, =0.100)\nEpoch #233: loss=0.405044 (contrastive=0.425712, msm=0.219034, =0.100)\nEpoch #234: loss=0.347109 (contrastive=0.362335, msm=0.210077, =0.100)\nEpoch #235: loss=0.308435 (contrastive=0.318348, msm=0.219219, =0.100)\nEpoch #236: loss=0.980492 (contrastive=1.064015, msm=0.228786, =0.100)\nEpoch #237: loss=0.406323 (contrastive=0.426573, msm=0.224079, =0.100)\nEpoch #238: loss=0.850193 (contrastive=0.920182, msm=0.220300, =0.100)\nEpoch #239: loss=0.326803 (contrastive=0.339404, msm=0.213400, =0.100)\nEpoch #240: loss=0.388572 (contrastive=0.407972, msm=0.213973, =0.100)\nEpoch #241: loss=0.332224 (contrastive=0.344768, msm=0.219330, =0.100)\nEpoch #242: loss=0.364728 (contrastive=0.380842, msm=0.219702, =0.100)\nEpoch #243: loss=0.417373 (contrastive=0.439871, msm=0.214892, =0.100)\nEpoch #244: loss=0.324465 (contrastive=0.338259, msm=0.200321, =0.100)\nEpoch #245: loss=0.321188 (contrastive=0.333237, msm=0.212748, =0.100)\nEpoch #246: loss=0.365552 (contrastive=0.382733, msm=0.210924, =0.100)\nEpoch #247: loss=0.341586 (contrastive=0.355907, msm=0.212696, =0.100)\nEpoch #248: loss=0.362567 (contrastive=0.379462, msm=0.210518, =0.100)\nEpoch #249: loss=0.324236 (contrastive=0.336724, msm=0.211839, =0.100)\nEpoch #250: loss=0.452738 (contrastive=0.479896, msm=0.208308, =0.100)\nEpoch #251: loss=0.297471 (contrastive=0.307315, msm=0.208874, =0.100)\nEpoch #252: loss=0.501870 (contrastive=0.534145, msm=0.211394, =0.100)\nEpoch #253: loss=0.359976 (contrastive=0.376891, msm=0.207734, =0.100)\nEpoch #254: loss=0.366250 (contrastive=0.383525, msm=0.210778, =0.100)\nEpoch #255: loss=0.366084 (contrastive=0.383046, msm=0.213430, =0.100)\nEpoch #256: loss=0.501945 (contrastive=0.534834, msm=0.205948, =0.100)\nEpoch #257: loss=0.793941 (contrastive=0.858997, msm=0.208443, =0.100)\nEpoch #258: loss=1.246335 (contrastive=1.361582, msm=0.209110, =0.100)\nEpoch #259: loss=0.475592 (contrastive=0.505061, msm=0.210367, =0.100)\nEpoch #260: loss=0.609021 (contrastive=0.653438, msm=0.209265, =0.100)\nEpoch #261: loss=0.530288 (contrastive=0.564970, msm=0.218151, =0.100)\nEpoch #262: loss=0.323106 (contrastive=0.335694, msm=0.209815, =0.100)\nEpoch #263: loss=0.358603 (contrastive=0.375363, msm=0.207756, =0.100)\nEpoch #264: loss=0.470783 (contrastive=0.500078, msm=0.207130, =0.100)\nEpoch #265: loss=0.643806 (contrastive=0.692532, msm=0.205270, =0.100)\nEpoch #266: loss=0.554412 (contrastive=0.593248, msm=0.204888, =0.100)\nEpoch #267: loss=0.384932 (contrastive=0.403912, msm=0.214108, =0.100)\nEpoch #268: loss=0.608105 (contrastive=0.651439, msm=0.218092, =0.100)\nEpoch #269: loss=1.390808 (contrastive=1.521132, msm=0.217898, =0.100)\nEpoch #270: loss=0.499088 (contrastive=0.530753, msm=0.214107, =0.100)\nEpoch #271: loss=0.395663 (contrastive=0.415934, msm=0.213226, =0.100)\nEpoch #272: loss=0.380755 (contrastive=0.399733, msm=0.209955, =0.100)\nEpoch #273: loss=0.574261 (contrastive=0.615311, msm=0.204817, =0.100)\nEpoch #274: loss=0.356184 (contrastive=0.372838, msm=0.206293, =0.100)\nEpoch #275: loss=0.384605 (contrastive=0.404455, msm=0.205958, =0.100)\nEpoch #276: loss=0.746839 (contrastive=0.806659, msm=0.208462, =0.100)\nEpoch #277: loss=0.419734 (contrastive=0.442780, msm=0.212321, =0.100)\nEpoch #278: loss=0.386182 (contrastive=0.406300, msm=0.205120, =0.100)\nEpoch #279: loss=0.331768 (contrastive=0.345466, msm=0.208491, =0.100)\nEpoch #280: loss=0.368057 (contrastive=0.385412, msm=0.211866, =0.100)\nEpoch #281: loss=0.710378 (contrastive=0.766020, msm=0.209602, =0.100)\nEpoch #282: loss=0.343131 (contrastive=0.357783, msm=0.211262, =0.100)\nEpoch #283: loss=0.375101 (contrastive=0.394490, msm=0.200599, =0.100)\nEpoch #284: loss=0.526072 (contrastive=0.562086, msm=0.201951, =0.100)\nEpoch #285: loss=0.308167 (contrastive=0.320620, msm=0.196089, =0.100)\nEpoch #286: loss=0.453410 (contrastive=0.481909, msm=0.196919, =0.100)\nEpoch #287: loss=0.394636 (contrastive=0.416593, msm=0.197019, =0.100)\nEpoch #288: loss=0.560299 (contrastive=0.600225, msm=0.200966, =0.100)\nEpoch #289: loss=0.343452 (contrastive=0.358751, msm=0.205758, =0.100)\nEpoch #290: loss=0.448552 (contrastive=0.476226, msm=0.199487, =0.100)\nEpoch #291: loss=0.326018 (contrastive=0.340101, msm=0.199268, =0.100)\nEpoch #292: loss=0.347522 (contrastive=0.363869, msm=0.200394, =0.100)\nEpoch #293: loss=0.309761 (contrastive=0.322205, msm=0.197763, =0.100)\nEpoch #294: loss=0.286293 (contrastive=0.296811, msm=0.191632, =0.100)\nEpoch #295: loss=0.524572 (contrastive=0.561065, msm=0.196132, =0.100)\nEpoch #296: loss=0.308230 (contrastive=0.320798, msm=0.195121, =0.100)\nEpoch #297: loss=0.313404 (contrastive=0.326591, msm=0.194718, =0.100)\nEpoch #298: loss=0.367097 (contrastive=0.386459, msm=0.192844, =0.100)\nEpoch #299: loss=0.254470 (contrastive=0.261181, msm=0.194070, =0.100)\nEpoch #300: loss=0.629101 (contrastive=0.677606, msm=0.192556, =0.100)\nEpoch #301: loss=0.302127 (contrastive=0.314101, msm=0.194364, =0.100)\nEpoch #302: loss=0.482940 (contrastive=0.515770, msm=0.187469, =0.100)\nEpoch #303: loss=0.270060 (contrastive=0.279008, msm=0.189528, =0.100)\nEpoch #304: loss=0.271162 (contrastive=0.279861, msm=0.192874, =0.100)\nEpoch #305: loss=0.386507 (contrastive=0.408263, msm=0.190700, =0.100)\nEpoch #306: loss=0.407555 (contrastive=0.432325, msm=0.184621, =0.100)\nEpoch #307: loss=0.458294 (contrastive=0.487561, msm=0.194894, =0.100)\nEpoch #308: loss=0.269391 (contrastive=0.279183, msm=0.181268, =0.100)\nEpoch #309: loss=0.391658 (contrastive=0.414251, msm=0.188322, =0.100)\nEpoch #310: loss=0.396262 (contrastive=0.418905, msm=0.192478, =0.100)\nEpoch #311: loss=0.294550 (contrastive=0.306274, msm=0.189034, =0.100)\nEpoch #312: loss=0.456525 (contrastive=0.485912, msm=0.192046, =0.100)\nEpoch #313: loss=0.402463 (contrastive=0.425965, msm=0.190948, =0.100)\nEpoch #314: loss=0.296610 (contrastive=0.309255, msm=0.182809, =0.100)\nEpoch #315: loss=0.618410 (contrastive=0.666191, msm=0.188381, =0.100)\nEpoch #316: loss=0.312703 (contrastive=0.327150, msm=0.182672, =0.100)\nEpoch #317: loss=0.405844 (contrastive=0.430109, msm=0.187454, =0.100)\nEpoch #318: loss=0.347384 (contrastive=0.365060, msm=0.188305, =0.100)\nEpoch #319: loss=0.290853 (contrastive=0.303000, msm=0.181527, =0.100)\nEpoch #320: loss=0.267906 (contrastive=0.277385, msm=0.182596, =0.100)\nEpoch #321: loss=0.359533 (contrastive=0.379381, msm=0.180902, =0.100)\nEpoch #322: loss=0.243716 (contrastive=0.249722, msm=0.189671, =0.100)\nEpoch #323: loss=0.282884 (contrastive=0.293218, msm=0.189873, =0.100)\nEpoch #324: loss=0.283522 (contrastive=0.294501, msm=0.184714, =0.100)\nEpoch #325: loss=0.260407 (contrastive=0.268477, msm=0.187778, =0.100)\nEpoch #326: loss=0.318327 (contrastive=0.332900, msm=0.187177, =0.100)\nEpoch #327: loss=0.241027 (contrastive=0.247811, msm=0.179970, =0.100)\nEpoch #328: loss=0.382859 (contrastive=0.404680, msm=0.186471, =0.100)\nEpoch #329: loss=0.267429 (contrastive=0.276608, msm=0.184813, =0.100)\nEpoch #330: loss=0.313238 (contrastive=0.326382, msm=0.194937, =0.100)\nEpoch #331: loss=0.354631 (contrastive=0.372781, msm=0.191278, =0.100)\nEpoch #332: loss=0.261718 (contrastive=0.270429, msm=0.183317, =0.100)\nEpoch #333: loss=0.259403 (contrastive=0.267733, msm=0.184440, =0.100)\nEpoch #334: loss=0.229753 (contrastive=0.234523, msm=0.186818, =0.100)\nEpoch #335: loss=0.384555 (contrastive=0.407057, msm=0.182043, =0.100)\nEpoch #336: loss=0.253344 (contrastive=0.261372, msm=0.181091, =0.100)\nEpoch #337: loss=0.573497 (contrastive=0.617211, msm=0.180073, =0.100)\nEpoch #338: loss=0.240504 (contrastive=0.247554, msm=0.177058, =0.100)\nEpoch #339: loss=0.305229 (contrastive=0.319099, msm=0.180405, =0.100)\nEpoch #340: loss=0.342652 (contrastive=0.360808, msm=0.179248, =0.100)\nEpoch #341: loss=0.214922 (contrastive=0.218941, msm=0.178749, =0.100)\nEpoch #342: loss=0.583927 (contrastive=0.627621, msm=0.190681, =0.100)\nEpoch #343: loss=0.300776 (contrastive=0.313930, msm=0.182392, =0.100)\nEpoch #344: loss=0.590008 (contrastive=0.635274, msm=0.182611, =0.100)\nEpoch #345: loss=0.228169 (contrastive=0.233636, msm=0.178960, =0.100)\nEpoch #346: loss=0.339927 (contrastive=0.356955, msm=0.186674, =0.100)\nEpoch #347: loss=0.223662 (contrastive=0.228285, msm=0.182054, =0.100)\nEpoch #348: loss=0.404653 (contrastive=0.430030, msm=0.176261, =0.100)\nEpoch #349: loss=0.248310 (contrastive=0.255673, msm=0.182042, =0.100)\nEpoch #350: loss=0.418721 (contrastive=0.445233, msm=0.180119, =0.100)\nEpoch #351: loss=0.309947 (contrastive=0.324749, msm=0.176727, =0.100)\nEpoch #352: loss=0.234378 (contrastive=0.240765, msm=0.176896, =0.100)\nEpoch #353: loss=0.982657 (contrastive=1.072255, msm=0.176273, =0.100)\nEpoch #354: loss=0.318690 (contrastive=0.334426, msm=0.177061, =0.100)\nEpoch #355: loss=0.223110 (contrastive=0.227947, msm=0.179581, =0.100)\nEpoch #356: loss=0.585027 (contrastive=0.629745, msm=0.182573, =0.100)\nEpoch #357: loss=0.373196 (contrastive=0.394003, msm=0.185939, =0.100)\nEpoch #358: loss=0.559852 (contrastive=0.602220, msm=0.178548, =0.100)\nEpoch #359: loss=0.325614 (contrastive=0.341401, msm=0.183527, =0.100)\nEpoch #360: loss=0.405881 (contrastive=0.430427, msm=0.184969, =0.100)\nEpoch #361: loss=0.245415 (contrastive=0.252740, msm=0.179494, =0.100)\nEpoch #362: loss=0.346616 (contrastive=0.364780, msm=0.183144, =0.100)\nEpoch #363: loss=0.399232 (contrastive=0.423096, msm=0.184458, =0.100)\nEpoch #364: loss=0.266278 (contrastive=0.275548, msm=0.182843, =0.100)\nEpoch #365: loss=0.320558 (contrastive=0.335815, msm=0.183245, =0.100)\nEpoch #366: loss=0.267401 (contrastive=0.276884, msm=0.182048, =0.100)\nEpoch #367: loss=0.225134 (contrastive=0.229702, msm=0.184020, =0.100)\nEpoch #368: loss=0.341194 (contrastive=0.359171, msm=0.179403, =0.100)\nEpoch #369: loss=0.262809 (contrastive=0.272375, msm=0.176718, =0.100)\nEpoch #370: loss=0.428311 (contrastive=0.456643, msm=0.173318, =0.100)\nEpoch #371: loss=0.226987 (contrastive=0.232604, msm=0.176436, =0.100)\nEpoch #372: loss=0.292157 (contrastive=0.304595, msm=0.180210, =0.100)\nEpoch #373: loss=0.225631 (contrastive=0.231099, msm=0.176418, =0.100)\nEpoch #374: loss=0.258804 (contrastive=0.268340, msm=0.172974, =0.100)\nEpoch #375: loss=0.236508 (contrastive=0.242937, msm=0.178645, =0.100)\nEpoch #376: loss=0.285136 (contrastive=0.297142, msm=0.177081, =0.100)\nEpoch #377: loss=0.333477 (contrastive=0.351094, msm=0.174925, =0.100)\nEpoch #378: loss=0.509951 (contrastive=0.546968, msm=0.176800, =0.100)\nEpoch #379: loss=0.251894 (contrastive=0.260462, msm=0.174782, =0.100)\nEpoch #380: loss=0.250419 (contrastive=0.259226, msm=0.171154, =0.100)\nEpoch #381: loss=0.216725 (contrastive=0.221036, msm=0.177924, =0.100)\nEpoch #382: loss=0.211122 (contrastive=0.214910, msm=0.177032, =0.100)\nEpoch #383: loss=0.305502 (contrastive=0.319589, msm=0.178714, =0.100)\nEpoch #384: loss=1.493269 (contrastive=1.639966, msm=0.172995, =0.100)\nEpoch #385: loss=0.265321 (contrastive=0.275459, msm=0.174081, =0.100)\nEpoch #386: loss=0.252696 (contrastive=0.261475, msm=0.173681, =0.100)\nEpoch #387: loss=0.389632 (contrastive=0.412784, msm=0.181257, =0.100)\nEpoch #388: loss=0.408400 (contrastive=0.433859, msm=0.179272, =0.100)\nEpoch #389: loss=0.336669 (contrastive=0.354411, msm=0.176994, =0.100)\nEpoch #390: loss=0.249790 (contrastive=0.258221, msm=0.173912, =0.100)\nEpoch #391: loss=0.259711 (contrastive=0.269264, msm=0.173737, =0.100)\nEpoch #392: loss=0.700281 (contrastive=0.758017, msm=0.180654, =0.100)\nEpoch #393: loss=0.299694 (contrastive=0.313514, msm=0.175315, =0.100)\nEpoch #394: loss=0.392549 (contrastive=0.416455, msm=0.177395, =0.100)\nEpoch #395: loss=0.252978 (contrastive=0.260542, msm=0.184900, =0.100)\nEpoch #396: loss=0.375574 (contrastive=0.397922, msm=0.174440, =0.100)\nEpoch #397: loss=0.285757 (contrastive=0.297997, msm=0.175597, =0.100)\nEpoch #398: loss=0.250384 (contrastive=0.258778, msm=0.174836, =0.100)\nEpoch #399: loss=0.272499 (contrastive=0.283434, msm=0.174084, =0.100)\nEpoch #400: loss=0.235182 (contrastive=0.242097, msm=0.172944, =0.100)\nEpoch #401: loss=0.596583 (contrastive=0.643740, msm=0.172177, =0.100)\nEpoch #402: loss=0.317163 (contrastive=0.332888, msm=0.175637, =0.100)\nEpoch #403: loss=0.234630 (contrastive=0.241550, msm=0.172351, =0.100)\nEpoch #404: loss=0.238350 (contrastive=0.245099, msm=0.177606, =0.100)\nEpoch #405: loss=0.301044 (contrastive=0.315136, msm=0.174218, =0.100)\nEpoch #406: loss=0.243004 (contrastive=0.250481, msm=0.175711, =0.100)\nEpoch #407: loss=0.201395 (contrastive=0.204489, msm=0.173556, =0.100)\nEpoch #408: loss=0.461505 (contrastive=0.492875, msm=0.179173, =0.100)\nEpoch #409: loss=0.251986 (contrastive=0.260653, msm=0.173978, =0.100)\nEpoch #410: loss=0.239601 (contrastive=0.246817, msm=0.174656, =0.100)\nEpoch #411: loss=0.211270 (contrastive=0.215169, msm=0.176177, =0.100)\nEpoch #412: loss=0.747441 (contrastive=0.811826, msm=0.167969, =0.100)\nEpoch #413: loss=0.400911 (contrastive=0.427117, msm=0.165062, =0.100)\nEpoch #414: loss=0.346671 (contrastive=0.366192, msm=0.170977, =0.100)\nEpoch #415: loss=0.241692 (contrastive=0.249867, msm=0.168123, =0.100)\nEpoch #416: loss=0.336615 (contrastive=0.354692, msm=0.173922, =0.100)\nEpoch #417: loss=0.215916 (contrastive=0.220766, msm=0.172266, =0.100)\nEpoch #418: loss=0.226210 (contrastive=0.232435, msm=0.170189, =0.100)\nEpoch #419: loss=0.207396 (contrastive=0.211119, msm=0.173895, =0.100)\nEpoch #420: loss=0.306529 (contrastive=0.321348, msm=0.173156, =0.100)\nEpoch #421: loss=0.210986 (contrastive=0.215059, msm=0.174333, =0.100)\nEpoch #422: loss=0.206568 (contrastive=0.210348, msm=0.172551, =0.100)\nEpoch #423: loss=0.249415 (contrastive=0.257868, msm=0.173339, =0.100)\nEpoch #424: loss=0.391606 (contrastive=0.416690, msm=0.165853, =0.100)\nEpoch #425: loss=0.190259 (contrastive=0.192900, msm=0.166485, =0.100)\nEpoch #426: loss=0.204486 (contrastive=0.208893, msm=0.164831, =0.100)\nEpoch #427: loss=0.387443 (contrastive=0.412111, msm=0.165430, =0.100)\nEpoch #428: loss=0.186940 (contrastive=0.189102, msm=0.167482, =0.100)\nEpoch #429: loss=0.270372 (contrastive=0.281541, msm=0.169850, =0.100)\nEpoch #430: loss=0.368137 (contrastive=0.390551, msm=0.166407, =0.100)\nEpoch #431: loss=0.279875 (contrastive=0.292252, msm=0.168483, =0.100)\nEpoch #432: loss=0.194141 (contrastive=0.197070, msm=0.167786, =0.100)\nEpoch #433: loss=0.196075 (contrastive=0.199509, msm=0.165169, =0.100)\nEpoch #434: loss=0.551338 (contrastive=0.593617, msm=0.170828, =0.100)\nEpoch #435: loss=0.574248 (contrastive=0.618934, msm=0.172072, =0.100)\nEpoch #436: loss=0.372190 (contrastive=0.395025, msm=0.166679, =0.100)\nEpoch #437: loss=0.277912 (contrastive=0.290631, msm=0.163442, =0.100)\nEpoch #438: loss=0.650603 (contrastive=0.704463, msm=0.165868, =0.100)\nEpoch #439: loss=0.252343 (contrastive=0.262531, msm=0.160649, =0.100)\nEpoch #440: loss=0.212733 (contrastive=0.217788, msm=0.167232, =0.100)\nEpoch #441: loss=0.210786 (contrastive=0.215729, msm=0.166298, =0.100)\nEpoch #442: loss=0.210377 (contrastive=0.215487, msm=0.164383, =0.100)\nEpoch #443: loss=0.301366 (contrastive=0.315604, msm=0.173217, =0.100)\nEpoch #444: loss=0.277534 (contrastive=0.289662, msm=0.168386, =0.100)\nEpoch #445: loss=0.208421 (contrastive=0.212893, msm=0.168174, =0.100)\nEpoch #446: loss=0.345772 (contrastive=0.365693, msm=0.166486, =0.100)\nEpoch #447: loss=0.346891 (contrastive=0.366448, msm=0.170879, =0.100)\nEpoch #448: loss=0.223148 (contrastive=0.229456, msm=0.166371, =0.100)\nEpoch #449: loss=0.203581 (contrastive=0.207922, msm=0.164513, =0.100)\nEpoch #450: loss=0.246088 (contrastive=0.254941, msm=0.166412, =0.100)\nEpoch #451: loss=0.230086 (contrastive=0.237129, msm=0.166704, =0.100)\nEpoch #452: loss=0.227317 (contrastive=0.234140, msm=0.165916, =0.100)\nEpoch #453: loss=0.205368 (contrastive=0.209202, msm=0.170863, =0.100)\nEpoch #454: loss=0.367203 (contrastive=0.389142, msm=0.169755, =0.100)\nEpoch #455: loss=0.205996 (contrastive=0.209903, msm=0.170837, =0.100)\nEpoch #456: loss=0.198774 (contrastive=0.201544, msm=0.173840, =0.100)\nEpoch #457: loss=0.228131 (contrastive=0.234780, msm=0.168287, =0.100)\nEpoch #458: loss=0.180694 (contrastive=0.182384, msm=0.165481, =0.100)\nEpoch #459: loss=0.196035 (contrastive=0.199401, msm=0.165742, =0.100)\nEpoch #460: loss=0.238073 (contrastive=0.246355, msm=0.163538, =0.100)\nEpoch #461: loss=0.214793 (contrastive=0.220261, msm=0.165579, =0.100)\nEpoch #462: loss=0.193638 (contrastive=0.196746, msm=0.165662, =0.100)\nEpoch #463: loss=0.296636 (contrastive=0.311299, msm=0.164667, =0.100)\nEpoch #464: loss=0.185091 (contrastive=0.187398, msm=0.164327, =0.100)\nEpoch #465: loss=0.222914 (contrastive=0.229349, msm=0.164999, =0.100)\nEpoch #466: loss=0.183231 (contrastive=0.184801, msm=0.169102, =0.100)\nEpoch #467: loss=0.169874 (contrastive=0.170269, msm=0.166328, =0.100)\nEpoch #468: loss=0.277704 (contrastive=0.290655, msm=0.161146, =0.100)\nEpoch #469: loss=0.232182 (contrastive=0.239793, msm=0.163681, =0.100)\nEpoch #470: loss=0.169891 (contrastive=0.170727, msm=0.162370, =0.100)\nEpoch #471: loss=0.209943 (contrastive=0.215315, msm=0.161603, =0.100)\nEpoch #472: loss=0.285106 (contrastive=0.298499, msm=0.164567, =0.100)\nEpoch #473: loss=0.357074 (contrastive=0.378832, msm=0.161248, =0.100)\nEpoch #474: loss=0.269597 (contrastive=0.281071, msm=0.166331, =0.100)\nEpoch #475: loss=0.161309 (contrastive=0.160807, msm=0.165823, =0.100)\nEpoch #476: loss=0.262599 (contrastive=0.273927, msm=0.160643, =0.100)\nEpoch #477: loss=0.166246 (contrastive=0.166950, msm=0.159905, =0.100)\nEpoch #478: loss=0.243166 (contrastive=0.252741, msm=0.156986, =0.100)\nEpoch #479: loss=0.264260 (contrastive=0.275467, msm=0.163394, =0.100)\nEpoch #480: loss=1.208562 (contrastive=1.324709, msm=0.163245, =0.100)\nEpoch #481: loss=0.212701 (contrastive=0.217983, msm=0.165165, =0.100)\nEpoch #482: loss=0.248250 (contrastive=0.257358, msm=0.166278, =0.100)\nEpoch #483: loss=0.208070 (contrastive=0.212618, msm=0.167140, =0.100)\nEpoch #484: loss=0.215570 (contrastive=0.220799, msm=0.168512, =0.100)\nEpoch #485: loss=0.285573 (contrastive=0.299449, msm=0.160686, =0.100)\nEpoch #486: loss=0.232324 (contrastive=0.239510, msm=0.167649, =0.100)\nEpoch #487: loss=0.238515 (contrastive=0.246344, msm=0.168050, =0.100)\nEpoch #488: loss=0.221999 (contrastive=0.227512, msm=0.172377, =0.100)\nEpoch #489: loss=0.251188 (contrastive=0.260052, msm=0.171413, =0.100)\nEpoch #490: loss=0.280027 (contrastive=0.291682, msm=0.175126, =0.100)\nEpoch #491: loss=0.191591 (contrastive=0.194311, msm=0.167106, =0.100)\nEpoch #492: loss=0.180016 (contrastive=0.181505, msm=0.166620, =0.100)\nEpoch #493: loss=0.189984 (contrastive=0.192342, msm=0.168765, =0.100)\nEpoch #494: loss=0.745669 (contrastive=0.809826, msm=0.168255, =0.100)\nEpoch #495: loss=0.368585 (contrastive=0.390151, msm=0.174493, =0.100)\nEpoch #496: loss=0.178846 (contrastive=0.180097, msm=0.167580, =0.100)\nEpoch #497: loss=0.203571 (contrastive=0.207828, msm=0.165256, =0.100)\nEpoch #498: loss=0.178385 (contrastive=0.179558, msm=0.167833, =0.100)\nEpoch #499: loss=0.241409 (contrastive=0.250325, msm=0.161163, =0.100)\nEpoch #500: loss=0.269075 (contrastive=0.280872, msm=0.162906, =0.100)\nEpoch #501: loss=0.231672 (contrastive=0.238824, msm=0.167297, =0.100)\nEpoch #502: loss=0.286739 (contrastive=0.300437, msm=0.163453, =0.100)\nEpoch #503: loss=0.394728 (contrastive=0.420603, msm=0.161854, =0.100)\nEpoch #504: loss=0.366532 (contrastive=0.389034, msm=0.164012, =0.100)\nEpoch #505: loss=0.215625 (contrastive=0.221473, msm=0.162993, =0.100)\nEpoch #506: loss=0.170835 (contrastive=0.171472, msm=0.165103, =0.100)\nEpoch #507: loss=0.228231 (contrastive=0.235252, msm=0.165050, =0.100)\nEpoch #508: loss=0.323525 (contrastive=0.340475, msm=0.170972, =0.100)\nEpoch #509: loss=0.242918 (contrastive=0.251276, msm=0.167699, =0.100)\nEpoch #510: loss=0.197228 (contrastive=0.201451, msm=0.159220, =0.100)\nEpoch #511: loss=0.374327 (contrastive=0.397387, msm=0.166786, =0.100)\nEpoch #512: loss=0.189098 (contrastive=0.190274, msm=0.178508, =0.100)\nEpoch #513: loss=0.260666 (contrastive=0.269774, msm=0.178691, =0.100)\nEpoch #514: loss=0.265555 (contrastive=0.275351, msm=0.177391, =0.100)\nEpoch #515: loss=0.203685 (contrastive=0.208557, msm=0.159831, =0.100)\nEpoch #516: loss=0.272042 (contrastive=0.284594, msm=0.159076, =0.100)\nEpoch #517: loss=0.233627 (contrastive=0.241558, msm=0.162246, =0.100)\nEpoch #518: loss=0.268715 (contrastive=0.279407, msm=0.172484, =0.100)\nEpoch #519: loss=0.265901 (contrastive=0.276760, msm=0.168168, =0.100)\nEpoch #520: loss=0.230046 (contrastive=0.236867, msm=0.168659, =0.100)\nEpoch #521: loss=0.209087 (contrastive=0.213255, msm=0.171583, =0.100)\nEpoch #522: loss=0.241295 (contrastive=0.250061, msm=0.162400, =0.100)\nEpoch #523: loss=0.793987 (contrastive=0.864348, msm=0.160743, =0.100)\nEpoch #524: loss=0.251687 (contrastive=0.260892, msm=0.168839, =0.100)\nEpoch #525: loss=0.277237 (contrastive=0.288823, msm=0.172961, =0.100)\nEpoch #526: loss=0.178453 (contrastive=0.178569, msm=0.177410, =0.100)\nEpoch #527: loss=0.201428 (contrastive=0.204671, msm=0.172237, =0.100)\nEpoch #528: loss=0.240993 (contrastive=0.249037, msm=0.168602, =0.100)\nEpoch #529: loss=0.258335 (contrastive=0.268428, msm=0.167502, =0.100)\nEpoch #530: loss=0.271379 (contrastive=0.283205, msm=0.164945, =0.100)\nEpoch #531: loss=0.185075 (contrastive=0.186741, msm=0.170085, =0.100)\nEpoch #532: loss=0.246858 (contrastive=0.255064, msm=0.173003, =0.100)\nEpoch #533: loss=0.241562 (contrastive=0.249150, msm=0.173272, =0.100)\nEpoch #534: loss=0.177311 (contrastive=0.178563, msm=0.166043, =0.100)\nEpoch #535: loss=0.227170 (contrastive=0.233529, msm=0.169937, =0.100)\nEpoch #536: loss=0.171879 (contrastive=0.173648, msm=0.155956, =0.100)\nEpoch #537: loss=0.223574 (contrastive=0.230933, msm=0.157340, =0.100)\nEpoch #538: loss=0.258354 (contrastive=0.268856, msm=0.163829, =0.100)\nEpoch #539: loss=0.195412 (contrastive=0.199335, msm=0.160103, =0.100)\nEpoch #540: loss=0.179922 (contrastive=0.181353, msm=0.167043, =0.100)\nEpoch #541: loss=0.217849 (contrastive=0.224060, msm=0.161947, =0.100)\nEpoch #542: loss=0.199341 (contrastive=0.204209, msm=0.155536, =0.100)\nEpoch #543: loss=0.202377 (contrastive=0.207146, msm=0.159457, =0.100)\nEpoch #544: loss=0.172139 (contrastive=0.173333, msm=0.161386, =0.100)\nEpoch #545: loss=0.230503 (contrastive=0.237864, msm=0.164257, =0.100)\nEpoch #546: loss=0.230111 (contrastive=0.237616, msm=0.162566, =0.100)\nEpoch #547: loss=0.269335 (contrastive=0.281357, msm=0.161142, =0.100)\nEpoch #548: loss=0.698580 (contrastive=0.758403, msm=0.160171, =0.100)\nEpoch #549: loss=0.173155 (contrastive=0.175056, msm=0.156049, =0.100)\nEpoch #550: loss=0.322347 (contrastive=0.341097, msm=0.153598, =0.100)\nEpoch #551: loss=0.198075 (contrastive=0.201900, msm=0.163653, =0.100)\nEpoch #552: loss=0.915348 (contrastive=0.999659, msm=0.156549, =0.100)\nEpoch #553: loss=0.186309 (contrastive=0.189022, msm=0.161891, =0.100)\nEpoch #554: loss=0.225639 (contrastive=0.232827, msm=0.160945, =0.100)\nEpoch #555: loss=0.332040 (contrastive=0.351338, msm=0.158362, =0.100)\nEpoch #556: loss=0.261751 (contrastive=0.272715, msm=0.163080, =0.100)\nEpoch #557: loss=0.230627 (contrastive=0.238355, msm=0.161072, =0.100)\nEpoch #558: loss=0.207053 (contrastive=0.211789, msm=0.164425, =0.100)\nEpoch #559: loss=0.368587 (contrastive=0.392398, msm=0.154282, =0.100)\nEpoch #560: loss=0.190216 (contrastive=0.194149, msm=0.154817, =0.100)\nEpoch #561: loss=0.174428 (contrastive=0.176458, msm=0.156160, =0.100)\nEpoch #562: loss=0.285164 (contrastive=0.299726, msm=0.154112, =0.100)\nEpoch #563: loss=0.203166 (contrastive=0.208135, msm=0.158441, =0.100)\nEpoch #564: loss=0.166249 (contrastive=0.167426, msm=0.155654, =0.100)\nEpoch #565: loss=0.470342 (contrastive=0.505341, msm=0.155350, =0.100)\nEpoch #566: loss=0.169661 (contrastive=0.171340, msm=0.154555, =0.100)\nEpoch #567: loss=0.168461 (contrastive=0.170070, msm=0.153978, =0.100)\nEpoch #568: loss=0.208560 (contrastive=0.214352, msm=0.156432, =0.100)\nEpoch #569: loss=0.154913 (contrastive=0.154850, msm=0.155473, =0.100)\nEpoch #570: loss=0.156610 (contrastive=0.157038, msm=0.152757, =0.100)\nEpoch #571: loss=0.177511 (contrastive=0.179609, msm=0.158633, =0.100)\nEpoch #572: loss=0.181166 (contrastive=0.184397, msm=0.152085, =0.100)\nEpoch #573: loss=0.171113 (contrastive=0.172482, msm=0.158788, =0.100)\nEpoch #574: loss=0.155519 (contrastive=0.154972, msm=0.160440, =0.100)\nEpoch #575: loss=0.227260 (contrastive=0.234930, msm=0.158224, =0.100)\nEpoch #576: loss=0.148796 (contrastive=0.148251, msm=0.153696, =0.100)\nEpoch #577: loss=0.146974 (contrastive=0.145490, msm=0.160323, =0.100)\nEpoch #578: loss=0.206047 (contrastive=0.211470, msm=0.157239, =0.100)\nEpoch #579: loss=0.266231 (contrastive=0.278369, msm=0.156986, =0.100)\nEpoch #580: loss=0.205270 (contrastive=0.210635, msm=0.156985, =0.100)\nEpoch #581: loss=0.142821 (contrastive=0.141164, msm=0.157734, =0.100)\nEpoch #582: loss=0.137598 (contrastive=0.135467, msm=0.156779, =0.100)\nEpoch #583: loss=0.280137 (contrastive=0.294109, msm=0.154388, =0.100)\nEpoch #584: loss=0.214532 (contrastive=0.221400, msm=0.152726, =0.100)\nEpoch #585: loss=0.207495 (contrastive=0.213387, msm=0.154474, =0.100)\nEpoch #586: loss=0.133996 (contrastive=0.131462, msm=0.156806, =0.100)\nEpoch #587: loss=0.244669 (contrastive=0.255015, msm=0.151550, =0.100)\nEpoch #588: loss=0.252596 (contrastive=0.263228, msm=0.156914, =0.100)\nEpoch #589: loss=0.183893 (contrastive=0.187290, msm=0.153315, =0.100)\nEpoch #590: loss=0.159139 (contrastive=0.160115, msm=0.150348, =0.100)\nEpoch #591: loss=0.175793 (contrastive=0.178085, msm=0.155161, =0.100)\nEpoch #592: loss=0.144147 (contrastive=0.142973, msm=0.154712, =0.100)\nEpoch #593: loss=0.137434 (contrastive=0.136403, msm=0.146714, =0.100)\nEpoch #594: loss=0.484069 (contrastive=0.520966, msm=0.151998, =0.100)\nEpoch #595: loss=0.261939 (contrastive=0.274681, msm=0.147261, =0.100)\nEpoch #596: loss=0.230254 (contrastive=0.238622, msm=0.154941, =0.100)\nEpoch #597: loss=0.141845 (contrastive=0.140653, msm=0.152578, =0.100)\nEpoch #598: loss=0.164090 (contrastive=0.165409, msm=0.152220, =0.100)\nEpoch #599: loss=0.378237 (contrastive=0.403465, msm=0.151181, =0.100)\nTraining time: 0:02:31.941914\nEvaluation completed\nResults: {'ours': {24: {'norm': {'MSE': 2.566640503816331, 'MAE': 1.3159643194392332}, 'raw': {'MSE': 104.4739765223061, 'MAE': 8.74251140748875}}, 48: {'norm': {'MSE': 2.5706574036549585, 'MAE': 1.3295400908604895}, 'raw': {'MSE': 115.56116008023935, 'MAE': 9.077771269525817}}, 168: {'norm': {'MSE': 2.5400707627342674, 'MAE': 1.3104738633555828}, 'raw': {'MSE': 114.35775870935953, 'MAE': 8.939898626682268}}, 336: {'norm': {'MSE': 2.4491107111497277, 'MAE': 1.2544883030514715}, 'raw': {'MSE': 96.35145539773214, 'MAE': 8.237091771885646}}, 720: {'norm': {'MSE': 2.685733977450377, 'MAE': 1.327586245925699}, 'raw': {'MSE': 111.06496578824982, 'MAE': 8.850734291474916}}}, 'ts2vec_infer_time': 54.3542742729187, 'lr_train_time': {24: 0.9283173084259033, 48: 1.31758713722229, 168: 2.6484992504119873, 336: 3.9750678539276123, 720: 6.594337463378906}, 'lr_infer_time': {24: 0.0050983428955078125, 48: 0.00686335563659668, 168: 0.0389556884765625, 336: 0.049102783203125, 720: 0.069488525390625}}\nModel and results saved to training/ETTh2__forecast_multivar_msm_conservative_2025-09-22_16_27_41_837149\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!python train_msm.py ETTm1 forecast_multivar_msm_conservative --loader forecast_csv --repr-dims 320 --max-threads 8 --seed 42 --eval --msm-weight 0.1 --msm-mask-rate 0.2 --msm-decoder-depth 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:28:55.314002Z","iopub.execute_input":"2025-09-22T16:28:55.314286Z","iopub.status.idle":"2025-09-22T16:41:23.861832Z","shell.execute_reply.started":"2025-09-22T16:28:55.314250Z","shell.execute_reply":"2025-09-22T16:41:23.861125Z"}},"outputs":[{"name":"stdout","text":"Dataset: ETTm1\nArguments: Namespace(dataset='ETTm1', run_name='forecast_multivar_msm_conservative', loader='forecast_csv', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0, msm_weight=0.1, msm_mask_rate=0.2, msm_decoder_depth=3, dynamic_lambda=False)\nLoading data... done\nTraining...\nEpoch #0: loss=7.030142 (contrastive=7.684359, msm=1.142195, =0.100)\nEpoch #1: loss=4.021956 (contrastive=4.346156, msm=1.104156, =0.100)\nEpoch #2: loss=3.545711 (contrastive=3.818188, msm=1.093413, =0.100)\nEpoch #3: loss=3.151949 (contrastive=3.381475, msm=1.086215, =0.100)\nEpoch #4: loss=2.541868 (contrastive=2.707385, msm=1.052213, =0.100)\nEpoch #5: loss=2.430540 (contrastive=2.583001, msm=1.058387, =0.100)\nEpoch #6: loss=2.322402 (contrastive=2.458901, msm=1.093904, =0.100)\nEpoch #7: loss=2.246930 (contrastive=2.377922, msm=1.068008, =0.100)\nEpoch #8: loss=2.061703 (contrastive=2.173367, msm=1.056731, =0.100)\nEpoch #9: loss=2.027081 (contrastive=2.140603, msm=1.005379, =0.100)\nEpoch #10: loss=2.025530 (contrastive=2.141746, msm=0.979581, =0.100)\nEpoch #11: loss=1.963974 (contrastive=2.074967, msm=0.965040, =0.100)\nEpoch #12: loss=1.870301 (contrastive=1.969601, msm=0.976597, =0.100)\nEpoch #13: loss=1.830149 (contrastive=1.926622, msm=0.961885, =0.100)\nEpoch #14: loss=1.735092 (contrastive=1.829554, msm=0.884938, =0.100)\nEpoch #15: loss=1.782427 (contrastive=1.881580, msm=0.890056, =0.100)\nEpoch #16: loss=1.692394 (contrastive=1.786215, msm=0.848011, =0.100)\nEpoch #17: loss=1.706520 (contrastive=1.805719, msm=0.813728, =0.100)\nEpoch #18: loss=1.646058 (contrastive=1.741417, msm=0.787833, =0.100)\nEpoch #19: loss=1.526414 (contrastive=1.609499, msm=0.778647, =0.100)\nEpoch #20: loss=1.540490 (contrastive=1.631586, msm=0.720623, =0.100)\nEpoch #21: loss=1.508329 (contrastive=1.599144, msm=0.690997, =0.100)\nEpoch #22: loss=1.503180 (contrastive=1.592970, msm=0.695076, =0.100)\nEpoch #23: loss=1.649993 (contrastive=1.761209, msm=0.649047, =0.100)\nEpoch #24: loss=1.601281 (contrastive=1.708317, msm=0.637955, =0.100)\nEpoch #25: loss=1.409153 (contrastive=1.495322, msm=0.633625, =0.100)\nEpoch #26: loss=1.383027 (contrastive=1.474584, msm=0.559012, =0.100)\nEpoch #27: loss=1.237460 (contrastive=1.310183, msm=0.582955, =0.100)\nEpoch #28: loss=1.252247 (contrastive=1.334212, msm=0.514564, =0.100)\nEpoch #29: loss=1.285635 (contrastive=1.366947, msm=0.553830, =0.100)\nEpoch #30: loss=1.244865 (contrastive=1.326081, msm=0.513922, =0.100)\nEpoch #31: loss=1.273896 (contrastive=1.361226, msm=0.487924, =0.100)\nEpoch #32: loss=1.131141 (contrastive=1.199712, msm=0.514002, =0.100)\nEpoch #33: loss=1.119144 (contrastive=1.187028, msm=0.508189, =0.100)\nEpoch #34: loss=1.653511 (contrastive=1.782827, msm=0.489673, =0.100)\nEpoch #35: loss=1.098975 (contrastive=1.170326, msm=0.456814, =0.100)\nEpoch #36: loss=1.494628 (contrastive=1.606753, msm=0.485503, =0.100)\nEpoch #37: loss=1.113002 (contrastive=1.186819, msm=0.448650, =0.100)\nEpoch #38: loss=1.221058 (contrastive=1.307389, msm=0.444077, =0.100)\nEpoch #39: loss=1.197281 (contrastive=1.280514, msm=0.448189, =0.100)\nEpoch #40: loss=1.047548 (contrastive=1.111659, msm=0.470553, =0.100)\nEpoch #41: loss=1.119714 (contrastive=1.192799, msm=0.461949, =0.100)\nEpoch #42: loss=1.059665 (contrastive=1.130198, msm=0.424868, =0.100)\nEpoch #43: loss=1.094197 (contrastive=1.167036, msm=0.438649, =0.100)\nEpoch #44: loss=1.017654 (contrastive=1.082228, msm=0.436486, =0.100)\nEpoch #45: loss=0.992082 (contrastive=1.054947, msm=0.426296, =0.100)\nEpoch #46: loss=1.017284 (contrastive=1.082250, msm=0.432592, =0.100)\nEpoch #47: loss=1.096241 (contrastive=1.170352, msm=0.429241, =0.100)\nEpoch #48: loss=0.884761 (contrastive=0.938502, msm=0.401086, =0.100)\nEpoch #49: loss=0.881861 (contrastive=0.934769, msm=0.405693, =0.100)\nEpoch #50: loss=0.997827 (contrastive=1.063235, msm=0.409150, =0.100)\nEpoch #51: loss=0.966735 (contrastive=1.030503, msm=0.392823, =0.100)\nEpoch #52: loss=1.173723 (contrastive=1.260890, msm=0.389222, =0.100)\nEpoch #53: loss=0.796860 (contrastive=0.840481, msm=0.404268, =0.100)\nEpoch #54: loss=0.919073 (contrastive=0.981548, msm=0.356796, =0.100)\nEpoch #55: loss=1.021596 (contrastive=1.091425, msm=0.393142, =0.100)\nEpoch #56: loss=0.963631 (contrastive=1.029283, msm=0.372768, =0.100)\nEpoch #57: loss=0.956879 (contrastive=1.020419, msm=0.385020, =0.100)\nEpoch #58: loss=1.168666 (contrastive=1.256264, msm=0.380288, =0.100)\nEpoch #59: loss=0.908004 (contrastive=0.968543, msm=0.363152, =0.100)\nEpoch #60: loss=0.874165 (contrastive=0.931515, msm=0.358017, =0.100)\nEpoch #61: loss=0.887472 (contrastive=0.943973, msm=0.378968, =0.100)\nEpoch #62: loss=1.016402 (contrastive=1.086496, msm=0.385555, =0.100)\nEpoch #63: loss=0.860439 (contrastive=0.912143, msm=0.395109, =0.100)\nEpoch #64: loss=0.871501 (contrastive=0.927093, msm=0.371176, =0.100)\nEpoch #65: loss=0.959936 (contrastive=1.027757, msm=0.349549, =0.100)\nEpoch #66: loss=0.823785 (contrastive=0.875391, msm=0.359327, =0.100)\nEpoch #67: loss=1.107516 (contrastive=1.190984, msm=0.356303, =0.100)\nEpoch #68: loss=0.806198 (contrastive=0.856764, msm=0.351099, =0.100)\nEpoch #69: loss=0.882057 (contrastive=0.940580, msm=0.355344, =0.100)\nEpoch #70: loss=0.895420 (contrastive=0.954364, msm=0.364927, =0.100)\nEpoch #71: loss=0.896182 (contrastive=0.955526, msm=0.362089, =0.100)\nEpoch #72: loss=0.744723 (contrastive=0.787289, msm=0.361632, =0.100)\nEpoch #73: loss=0.713542 (contrastive=0.754306, msm=0.346663, =0.100)\nEpoch #74: loss=0.872948 (contrastive=0.932406, msm=0.337825, =0.100)\nEpoch #75: loss=0.740460 (contrastive=0.784532, msm=0.343812, =0.100)\nEpoch #76: loss=0.691982 (contrastive=0.729962, msm=0.350167, =0.100)\nEpoch #77: loss=0.794648 (contrastive=0.846730, msm=0.325909, =0.100)\nEpoch #78: loss=0.754753 (contrastive=0.800551, msm=0.342566, =0.100)\nEpoch #79: loss=0.624672 (contrastive=0.659269, msm=0.313303, =0.100)\nEpoch #80: loss=0.625016 (contrastive=0.656621, msm=0.340570, =0.100)\nEpoch #81: loss=1.017357 (contrastive=1.094208, msm=0.325697, =0.100)\nEpoch #82: loss=0.926061 (contrastive=0.992587, msm=0.327327, =0.100)\nEpoch #83: loss=0.858467 (contrastive=0.919433, msm=0.309776, =0.100)\nEpoch #84: loss=0.782034 (contrastive=0.832838, msm=0.324800, =0.100)\nEpoch #85: loss=0.711983 (contrastive=0.753634, msm=0.337117, =0.100)\nEpoch #86: loss=0.692107 (contrastive=0.732213, msm=0.331155, =0.100)\nEpoch #87: loss=0.664123 (contrastive=0.700873, msm=0.333369, =0.100)\nEpoch #88: loss=0.806362 (contrastive=0.859511, msm=0.328014, =0.100)\nEpoch #89: loss=0.653323 (contrastive=0.690147, msm=0.321900, =0.100)\nEpoch #90: loss=0.717579 (contrastive=0.760551, msm=0.330828, =0.100)\nEpoch #91: loss=0.688959 (contrastive=0.728722, msm=0.331096, =0.100)\nEpoch #92: loss=0.857223 (contrastive=0.918571, msm=0.305091, =0.100)\nEpoch #93: loss=0.736464 (contrastive=0.783064, msm=0.317068, =0.100)\nEpoch #94: loss=0.672879 (contrastive=0.716532, msm=0.280007, =0.100)\nEpoch #95: loss=0.639808 (contrastive=0.676768, msm=0.307167, =0.100)\nEpoch #96: loss=0.580319 (contrastive=0.609597, msm=0.316813, =0.100)\nEpoch #97: loss=0.607099 (contrastive=0.640058, msm=0.310465, =0.100)\nEpoch #98: loss=0.833790 (contrastive=0.894622, msm=0.286294, =0.100)\nEpoch #99: loss=0.973380 (contrastive=1.047546, msm=0.305880, =0.100)\nEpoch #100: loss=0.888684 (contrastive=0.953163, msm=0.308373, =0.100)\nEpoch #101: loss=0.590460 (contrastive=0.625414, msm=0.275874, =0.100)\nEpoch #102: loss=0.612043 (contrastive=0.647666, msm=0.291436, =0.100)\nEpoch #103: loss=0.548103 (contrastive=0.575052, msm=0.305563, =0.100)\nEpoch #104: loss=0.904642 (contrastive=0.971751, msm=0.300659, =0.100)\nEpoch #105: loss=0.580369 (contrastive=0.612562, msm=0.290624, =0.100)\nEpoch #106: loss=0.568567 (contrastive=0.599167, msm=0.293172, =0.100)\nEpoch #107: loss=0.602684 (contrastive=0.639695, msm=0.269579, =0.100)\nEpoch #108: loss=0.823453 (contrastive=0.884790, msm=0.271419, =0.100)\nEpoch #109: loss=0.922601 (contrastive=0.994803, msm=0.272782, =0.100)\nEpoch #110: loss=0.623940 (contrastive=0.663433, msm=0.268511, =0.100)\nEpoch #111: loss=0.693518 (contrastive=0.741795, msm=0.259025, =0.100)\nEpoch #112: loss=0.588630 (contrastive=0.624420, msm=0.266518, =0.100)\nEpoch #113: loss=0.555179 (contrastive=0.586959, msm=0.269157, =0.100)\nEpoch #114: loss=0.745776 (contrastive=0.799787, msm=0.259678, =0.100)\nEpoch #115: loss=0.542042 (contrastive=0.572991, msm=0.263499, =0.100)\nEpoch #116: loss=0.501686 (contrastive=0.529855, msm=0.248166, =0.100)\nEpoch #117: loss=0.532617 (contrastive=0.564145, msm=0.248868, =0.100)\nEpoch #118: loss=0.533198 (contrastive=0.563397, msm=0.261399, =0.100)\nEpoch #119: loss=0.632401 (contrastive=0.674316, msm=0.255170, =0.100)\nEpoch #120: loss=0.685409 (contrastive=0.732740, msm=0.259434, =0.100)\nEpoch #121: loss=0.597948 (contrastive=0.636716, msm=0.249040, =0.100)\nEpoch #122: loss=0.724828 (contrastive=0.776851, msm=0.256627, =0.100)\nEpoch #123: loss=0.645669 (contrastive=0.689875, msm=0.247814, =0.100)\nEpoch #124: loss=0.734703 (contrastive=0.788487, msm=0.250651, =0.100)\nEpoch #125: loss=0.498318 (contrastive=0.527357, msm=0.236970, =0.100)\nEpoch #126: loss=0.814407 (contrastive=0.876293, msm=0.257436, =0.100)\nEpoch #127: loss=0.850242 (contrastive=0.915861, msm=0.259671, =0.100)\nEpoch #128: loss=0.671819 (contrastive=0.720130, msm=0.237018, =0.100)\nEpoch #129: loss=0.537844 (contrastive=0.571105, msm=0.238499, =0.100)\nEpoch #130: loss=0.592435 (contrastive=0.632717, msm=0.229901, =0.100)\nEpoch #131: loss=0.703167 (contrastive=0.753547, msm=0.249750, =0.100)\nEpoch #132: loss=0.563612 (contrastive=0.598552, msm=0.249152, =0.100)\nEpoch #133: loss=0.560346 (contrastive=0.596220, msm=0.237480, =0.100)\nEpoch #134: loss=0.559258 (contrastive=0.593627, msm=0.249938, =0.100)\nEpoch #135: loss=0.559572 (contrastive=0.594136, msm=0.248497, =0.100)\nEpoch #136: loss=0.573032 (contrastive=0.609189, msm=0.247620, =0.100)\nEpoch #137: loss=0.547521 (contrastive=0.580560, msm=0.250170, =0.100)\nEpoch #138: loss=0.467846 (contrastive=0.493015, msm=0.241324, =0.100)\nEpoch #139: loss=0.444560 (contrastive=0.466734, msm=0.244993, =0.100)\nEpoch #140: loss=0.478038 (contrastive=0.504447, msm=0.240354, =0.100)\nEpoch #141: loss=0.427193 (contrastive=0.447770, msm=0.242000, =0.100)\nEpoch #142: loss=0.440397 (contrastive=0.463381, msm=0.233550, =0.100)\nEpoch #143: loss=0.639235 (contrastive=0.685091, msm=0.226532, =0.100)\nEpoch #144: loss=0.446294 (contrastive=0.468906, msm=0.242777, =0.100)\nEpoch #145: loss=0.705277 (contrastive=0.757250, msm=0.237523, =0.100)\nEpoch #146: loss=0.640762 (contrastive=0.684555, msm=0.246617, =0.100)\nEpoch #147: loss=0.626644 (contrastive=0.669839, msm=0.237895, =0.100)\nEpoch #148: loss=0.542976 (contrastive=0.576329, msm=0.242797, =0.100)\nEpoch #149: loss=1.165209 (contrastive=1.268076, msm=0.239405, =0.100)\nEpoch #150: loss=0.595316 (contrastive=0.634279, msm=0.244641, =0.100)\nEpoch #151: loss=0.594448 (contrastive=0.634168, msm=0.236977, =0.100)\nEpoch #152: loss=0.554766 (contrastive=0.589249, msm=0.244418, =0.100)\nEpoch #153: loss=0.622566 (contrastive=0.665702, msm=0.234341, =0.100)\nEpoch #154: loss=0.520595 (contrastive=0.550584, msm=0.250694, =0.100)\nEpoch #155: loss=0.668826 (contrastive=0.715479, msm=0.248949, =0.100)\nEpoch #156: loss=0.570773 (contrastive=0.608365, msm=0.232448, =0.100)\nEpoch #157: loss=0.854070 (contrastive=0.921557, msm=0.246690, =0.100)\nEpoch #158: loss=0.532139 (contrastive=0.563857, msm=0.246678, =0.100)\nEpoch #159: loss=0.449076 (contrastive=0.470797, msm=0.253589, =0.100)\nEpoch #160: loss=0.474106 (contrastive=0.499653, msm=0.244179, =0.100)\nEpoch #161: loss=0.548078 (contrastive=0.581993, msm=0.242844, =0.100)\nEpoch #162: loss=0.518871 (contrastive=0.550510, msm=0.234118, =0.100)\nEpoch #163: loss=0.449728 (contrastive=0.474308, msm=0.228508, =0.100)\nEpoch #164: loss=0.622644 (contrastive=0.663661, msm=0.253494, =0.100)\nEpoch #165: loss=0.416368 (contrastive=0.436334, msm=0.236668, =0.100)\nEpoch #166: loss=0.678853 (contrastive=0.727540, msm=0.240670, =0.100)\nEpoch #167: loss=0.385956 (contrastive=0.401215, msm=0.248628, =0.100)\nEpoch #168: loss=0.477586 (contrastive=0.504013, msm=0.239752, =0.100)\nEpoch #169: loss=0.488707 (contrastive=0.516674, msm=0.237007, =0.100)\nEpoch #170: loss=0.488930 (contrastive=0.517707, msm=0.229932, =0.100)\nEpoch #171: loss=0.560198 (contrastive=0.596708, msm=0.231614, =0.100)\nEpoch #172: loss=0.426930 (contrastive=0.448868, msm=0.229488, =0.100)\nEpoch #173: loss=0.377001 (contrastive=0.392557, msm=0.236992, =0.100)\nEpoch #174: loss=0.366513 (contrastive=0.382271, msm=0.224688, =0.100)\nEpoch #175: loss=0.474140 (contrastive=0.501460, msm=0.228255, =0.100)\nEpoch #176: loss=0.437178 (contrastive=0.459979, msm=0.231966, =0.100)\nEpoch #177: loss=0.421430 (contrastive=0.443236, msm=0.225177, =0.100)\nEpoch #178: loss=0.437550 (contrastive=0.460859, msm=0.227773, =0.100)\nEpoch #179: loss=0.356026 (contrastive=0.369965, msm=0.230572, =0.100)\nEpoch #180: loss=0.418381 (contrastive=0.439971, msm=0.224077, =0.100)\nEpoch #181: loss=0.412385 (contrastive=0.432597, msm=0.230484, =0.100)\nEpoch #182: loss=0.372230 (contrastive=0.388602, msm=0.224880, =0.100)\nEpoch #183: loss=0.552048 (contrastive=0.590158, msm=0.209063, =0.100)\nEpoch #184: loss=0.433039 (contrastive=0.456446, msm=0.222383, =0.100)\nEpoch #185: loss=0.354526 (contrastive=0.369380, msm=0.220837, =0.100)\nEpoch #186: loss=0.542248 (contrastive=0.579189, msm=0.209782, =0.100)\nEpoch #187: loss=0.369310 (contrastive=0.385597, msm=0.222723, =0.100)\nEpoch #188: loss=0.480345 (contrastive=0.509293, msm=0.219820, =0.100)\nEpoch #189: loss=0.419380 (contrastive=0.441810, msm=0.217505, =0.100)\nEpoch #190: loss=0.593343 (contrastive=0.634286, msm=0.224856, =0.100)\nEpoch #191: loss=0.432150 (contrastive=0.455748, msm=0.219770, =0.100)\nEpoch #192: loss=0.371242 (contrastive=0.388466, msm=0.216228, =0.100)\nEpoch #193: loss=0.362353 (contrastive=0.378815, msm=0.214195, =0.100)\nEpoch #194: loss=0.311090 (contrastive=0.322593, msm=0.207571, =0.100)\nEpoch #195: loss=0.367045 (contrastive=0.384129, msm=0.213291, =0.100)\nEpoch #196: loss=0.339489 (contrastive=0.354270, msm=0.206458, =0.100)\nEpoch #197: loss=0.502967 (contrastive=0.535798, msm=0.207483, =0.100)\nEpoch #198: loss=0.377053 (contrastive=0.394942, msm=0.216056, =0.100)\nEpoch #199: loss=0.342752 (contrastive=0.356912, msm=0.215310, =0.100)\nEpoch #200: loss=0.313687 (contrastive=0.325570, msm=0.206739, =0.100)\nEpoch #201: loss=0.297612 (contrastive=0.306951, msm=0.213557, =0.100)\nEpoch #202: loss=0.327660 (contrastive=0.339691, msm=0.219382, =0.100)\nEpoch #203: loss=0.328156 (contrastive=0.340411, msm=0.217857, =0.100)\nEpoch #204: loss=0.458484 (contrastive=0.485857, msm=0.212119, =0.100)\nEpoch #205: loss=0.386097 (contrastive=0.404799, msm=0.217780, =0.100)\nEpoch #206: loss=0.367665 (contrastive=0.384828, msm=0.213193, =0.100)\nEpoch #207: loss=0.338791 (contrastive=0.352391, msm=0.216396, =0.100)\nEpoch #208: loss=0.242270 (contrastive=0.246369, msm=0.205386, =0.100)\nEpoch #209: loss=0.260736 (contrastive=0.266586, msm=0.208086, =0.100)\nEpoch #210: loss=0.265142 (contrastive=0.270953, msm=0.212843, =0.100)\nEpoch #211: loss=0.306906 (contrastive=0.317409, msm=0.212380, =0.100)\nEpoch #212: loss=0.368425 (contrastive=0.385934, msm=0.210839, =0.100)\nEpoch #213: loss=0.343070 (contrastive=0.356872, msm=0.218851, =0.100)\nEpoch #214: loss=0.269453 (contrastive=0.275902, msm=0.211415, =0.100)\nEpoch #215: loss=0.459483 (contrastive=0.488098, msm=0.201951, =0.100)\nEpoch #216: loss=0.493558 (contrastive=0.524124, msm=0.218463, =0.100)\nEpoch #217: loss=0.510911 (contrastive=0.544033, msm=0.212814, =0.100)\nEpoch #218: loss=0.431425 (contrastive=0.455997, msm=0.210273, =0.100)\nEpoch #219: loss=0.344503 (contrastive=0.359548, msm=0.209099, =0.100)\nEpoch #220: loss=0.327953 (contrastive=0.341080, msm=0.209810, =0.100)\nEpoch #221: loss=0.292312 (contrastive=0.301122, msm=0.213024, =0.100)\nEpoch #222: loss=0.360336 (contrastive=0.377902, msm=0.202247, =0.100)\nEpoch #223: loss=0.289749 (contrastive=0.299024, msm=0.206273, =0.100)\nEpoch #224: loss=0.288903 (contrastive=0.297123, msm=0.214917, =0.100)\nEpoch #225: loss=0.374696 (contrastive=0.394139, msm=0.199708, =0.100)\nEpoch #226: loss=0.271262 (contrastive=0.277763, msm=0.212755, =0.100)\nEpoch #227: loss=0.987915 (contrastive=1.074154, msm=0.211767, =0.100)\nEpoch #228: loss=0.362601 (contrastive=0.379360, msm=0.211769, =0.100)\nEpoch #229: loss=0.390274 (contrastive=0.408917, msm=0.222490, =0.100)\nEpoch #230: loss=0.462445 (contrastive=0.489254, msm=0.221163, =0.100)\nEpoch #231: loss=0.412862 (contrastive=0.434174, msm=0.221053, =0.100)\nEpoch #232: loss=0.397457 (contrastive=0.417428, msm=0.217715, =0.100)\nEpoch #233: loss=0.318824 (contrastive=0.330974, msm=0.209477, =0.100)\nEpoch #234: loss=0.279045 (contrastive=0.286990, msm=0.207548, =0.100)\nEpoch #235: loss=0.298738 (contrastive=0.308328, msm=0.212430, =0.100)\nEpoch #236: loss=0.323853 (contrastive=0.336440, msm=0.210567, =0.100)\nEpoch #237: loss=0.309594 (contrastive=0.319883, msm=0.216993, =0.100)\nEpoch #238: loss=0.280167 (contrastive=0.288214, msm=0.207748, =0.100)\nEpoch #239: loss=0.403913 (contrastive=0.425759, msm=0.207294, =0.100)\nEpoch #240: loss=0.370478 (contrastive=0.387920, msm=0.213505, =0.100)\nEpoch #241: loss=0.330311 (contrastive=0.343652, msm=0.210242, =0.100)\nEpoch #242: loss=0.284224 (contrastive=0.293626, msm=0.199604, =0.100)\nEpoch #243: loss=0.270259 (contrastive=0.277210, msm=0.207700, =0.100)\nEpoch #244: loss=0.292457 (contrastive=0.302720, msm=0.200092, =0.100)\nEpoch #245: loss=0.302513 (contrastive=0.313348, msm=0.204990, =0.100)\nEpoch #246: loss=0.477885 (contrastive=0.507828, msm=0.208400, =0.100)\nEpoch #247: loss=0.312275 (contrastive=0.323104, msm=0.214818, =0.100)\nEpoch #248: loss=0.543480 (contrastive=0.580805, msm=0.207553, =0.100)\nEpoch #249: loss=0.335763 (contrastive=0.349015, msm=0.216499, =0.100)\nEpoch #250: loss=0.427463 (contrastive=0.451162, msm=0.214172, =0.100)\nEpoch #251: loss=0.457332 (contrastive=0.484353, msm=0.214150, =0.100)\nEpoch #252: loss=0.391921 (contrastive=0.411323, msm=0.217299, =0.100)\nEpoch #253: loss=0.378084 (contrastive=0.396335, msm=0.213827, =0.100)\nEpoch #254: loss=0.543542 (contrastive=0.580805, msm=0.208172, =0.100)\nEpoch #255: loss=0.365528 (contrastive=0.382626, msm=0.211648, =0.100)\nEpoch #256: loss=0.349421 (contrastive=0.363975, msm=0.218433, =0.100)\nEpoch #257: loss=0.347215 (contrastive=0.360583, msm=0.226910, =0.100)\nEpoch #258: loss=0.361168 (contrastive=0.376537, msm=0.222840, =0.100)\nEpoch #259: loss=0.366416 (contrastive=0.382231, msm=0.224081, =0.100)\nEpoch #260: loss=0.328928 (contrastive=0.341662, msm=0.214320, =0.100)\nEpoch #261: loss=0.715976 (contrastive=0.771460, msm=0.216621, =0.100)\nEpoch #262: loss=0.276206 (contrastive=0.282782, msm=0.217026, =0.100)\nEpoch #263: loss=0.330397 (contrastive=0.343640, msm=0.211207, =0.100)\nEpoch #264: loss=0.320915 (contrastive=0.333382, msm=0.208711, =0.100)\nEpoch #265: loss=0.371274 (contrastive=0.387973, msm=0.220989, =0.100)\nEpoch #266: loss=0.266501 (contrastive=0.272210, msm=0.215118, =0.100)\nEpoch #267: loss=0.364354 (contrastive=0.382527, msm=0.200800, =0.100)\nEpoch #268: loss=0.972020 (contrastive=1.057241, msm=0.205034, =0.100)\nEpoch #269: loss=0.317245 (contrastive=0.330076, msm=0.201769, =0.100)\nEpoch #270: loss=0.297380 (contrastive=0.307525, msm=0.206073, =0.100)\nEpoch #271: loss=0.307896 (contrastive=0.318953, msm=0.208385, =0.100)\nEpoch #272: loss=0.310275 (contrastive=0.321572, msm=0.208601, =0.100)\nEpoch #273: loss=0.324844 (contrastive=0.337373, msm=0.212084, =0.100)\nEpoch #274: loss=0.274573 (contrastive=0.282631, msm=0.202051, =0.100)\nEpoch #275: loss=0.335798 (contrastive=0.349699, msm=0.210682, =0.100)\nEpoch #276: loss=0.310372 (contrastive=0.322242, msm=0.203538, =0.100)\nEpoch #277: loss=0.287308 (contrastive=0.296349, msm=0.205938, =0.100)\nEpoch #278: loss=0.305960 (contrastive=0.317939, msm=0.198143, =0.100)\nEpoch #279: loss=0.309558 (contrastive=0.321274, msm=0.204122, =0.100)\nEpoch #280: loss=0.240663 (contrastive=0.243095, msm=0.218776, =0.100)\nEpoch #281: loss=0.313160 (contrastive=0.324636, msm=0.209870, =0.100)\nEpoch #282: loss=0.367473 (contrastive=0.385732, msm=0.203135, =0.100)\nEpoch #283: loss=0.438041 (contrastive=0.463302, msm=0.210685, =0.100)\nEpoch #284: loss=0.319589 (contrastive=0.331683, msm=0.210738, =0.100)\nEpoch #285: loss=0.385486 (contrastive=0.403155, msm=0.226466, =0.100)\nEpoch #286: loss=0.276932 (contrastive=0.282217, msm=0.229361, =0.100)\nEpoch #287: loss=0.492902 (contrastive=0.523333, msm=0.219022, =0.100)\nEpoch #288: loss=0.624598 (contrastive=0.669059, msm=0.224449, =0.100)\nEpoch #289: loss=0.619745 (contrastive=0.663930, msm=0.222081, =0.100)\nEpoch #290: loss=0.349091 (contrastive=0.361255, msm=0.239617, =0.100)\nEpoch #291: loss=0.481960 (contrastive=0.508939, msm=0.239143, =0.100)\nEpoch #292: loss=0.911714 (contrastive=0.986189, msm=0.241443, =0.100)\nEpoch #293: loss=0.371126 (contrastive=0.381145, msm=0.280953, =0.100)\nEpoch #294: loss=0.369801 (contrastive=0.378302, msm=0.293294, =0.100)\nEpoch #295: loss=0.346471 (contrastive=0.356681, msm=0.254573, =0.100)\nEpoch #296: loss=0.406545 (contrastive=0.423187, msm=0.256774, =0.100)\nEpoch #297: loss=0.274071 (contrastive=0.277675, msm=0.241632, =0.100)\nEpoch #298: loss=0.484037 (contrastive=0.507975, msm=0.268596, =0.100)\nEpoch #299: loss=0.723657 (contrastive=0.776092, msm=0.251749, =0.100)\nEpoch #300: loss=0.282553 (contrastive=0.285631, msm=0.254853, =0.100)\nEpoch #301: loss=0.296701 (contrastive=0.302376, msm=0.245626, =0.100)\nEpoch #302: loss=0.390280 (contrastive=0.407380, msm=0.236379, =0.100)\nEpoch #303: loss=0.316553 (contrastive=0.325370, msm=0.237202, =0.100)\nEpoch #304: loss=0.252611 (contrastive=0.255792, msm=0.223982, =0.100)\nEpoch #305: loss=0.301358 (contrastive=0.309818, msm=0.225221, =0.100)\nEpoch #306: loss=0.205085 (contrastive=0.203187, msm=0.222165, =0.100)\nEpoch #307: loss=0.251818 (contrastive=0.255629, msm=0.217522, =0.100)\nEpoch #308: loss=0.318981 (contrastive=0.329636, msm=0.223083, =0.100)\nEpoch #309: loss=0.261881 (contrastive=0.266704, msm=0.218471, =0.100)\nEpoch #310: loss=0.315125 (contrastive=0.326160, msm=0.215815, =0.100)\nEpoch #311: loss=0.241775 (contrastive=0.245134, msm=0.211545, =0.100)\nEpoch #312: loss=0.260089 (contrastive=0.265676, msm=0.209805, =0.100)\nEpoch #313: loss=0.185310 (contrastive=0.183453, msm=0.202027, =0.100)\nEpoch #314: loss=0.184119 (contrastive=0.181509, msm=0.207608, =0.100)\nEpoch #315: loss=0.229933 (contrastive=0.231889, msm=0.212323, =0.100)\nEpoch #316: loss=0.187626 (contrastive=0.186024, msm=0.202047, =0.100)\nEpoch #317: loss=0.204228 (contrastive=0.205112, msm=0.196270, =0.100)\nEpoch #318: loss=0.165129 (contrastive=0.161169, msm=0.200762, =0.100)\nEpoch #319: loss=0.165552 (contrastive=0.160117, msm=0.214469, =0.100)\nEpoch #320: loss=0.260054 (contrastive=0.265203, msm=0.213713, =0.100)\nEpoch #321: loss=1.634508 (contrastive=1.792606, msm=0.211629, =0.100)\nEpoch #322: loss=0.218886 (contrastive=0.218797, msm=0.219683, =0.100)\nEpoch #323: loss=0.385782 (contrastive=0.405511, msm=0.208224, =0.100)\nEpoch #324: loss=0.668711 (contrastive=0.719798, msm=0.208926, =0.100)\nEpoch #325: loss=0.534613 (contrastive=0.570030, msm=0.215857, =0.100)\nEpoch #326: loss=0.390630 (contrastive=0.410981, msm=0.207469, =0.100)\nEpoch #327: loss=0.313220 (contrastive=0.323416, msm=0.221455, =0.100)\nEpoch #328: loss=0.371192 (contrastive=0.386745, msm=0.231208, =0.100)\nEpoch #329: loss=0.268672 (contrastive=0.274249, msm=0.218472, =0.100)\nEpoch #330: loss=0.305959 (contrastive=0.315095, msm=0.223741, =0.100)\nEpoch #331: loss=0.307016 (contrastive=0.316944, msm=0.217665, =0.100)\nEpoch #332: loss=0.333086 (contrastive=0.347545, msm=0.202953, =0.100)\nEpoch #333: loss=0.268391 (contrastive=0.274495, msm=0.213457, =0.100)\nEpoch #334: loss=0.380294 (contrastive=0.399873, msm=0.204085, =0.100)\nEpoch #335: loss=0.232058 (contrastive=0.235129, msm=0.204423, =0.100)\nEpoch #336: loss=0.233690 (contrastive=0.236156, msm=0.211503, =0.100)\nEpoch #337: loss=0.182953 (contrastive=0.180834, msm=0.202028, =0.100)\nEpoch #338: loss=0.229532 (contrastive=0.231826, msm=0.208880, =0.100)\nEpoch #339: loss=0.356170 (contrastive=0.372840, msm=0.206137, =0.100)\nEpoch #340: loss=0.188015 (contrastive=0.186321, msm=0.203259, =0.100)\nEpoch #341: loss=0.348379 (contrastive=0.365031, msm=0.198512, =0.100)\nEpoch #342: loss=0.153505 (contrastive=0.148325, msm=0.200130, =0.100)\nEpoch #343: loss=0.145238 (contrastive=0.139623, msm=0.195766, =0.100)\nEpoch #344: loss=0.160968 (contrastive=0.155837, msm=0.207150, =0.100)\nEpoch #345: loss=0.336900 (contrastive=0.351440, msm=0.206047, =0.100)\nEpoch #346: loss=0.184729 (contrastive=0.184232, msm=0.189208, =0.100)\nEpoch #347: loss=0.293094 (contrastive=0.304164, msm=0.193462, =0.100)\nEpoch #348: loss=0.295060 (contrastive=0.306390, msm=0.193090, =0.100)\nEpoch #349: loss=0.198648 (contrastive=0.198503, msm=0.199946, =0.100)\nEpoch #350: loss=0.214049 (contrastive=0.215341, msm=0.202420, =0.100)\nEpoch #351: loss=0.161584 (contrastive=0.158356, msm=0.190638, =0.100)\nEpoch #352: loss=0.266395 (contrastive=0.272790, msm=0.208835, =0.100)\nEpoch #353: loss=0.178354 (contrastive=0.176800, msm=0.192346, =0.100)\nEpoch #354: loss=0.174540 (contrastive=0.170879, msm=0.207491, =0.100)\nEpoch #355: loss=0.221258 (contrastive=0.223892, msm=0.197549, =0.100)\nEpoch #356: loss=0.303171 (contrastive=0.314924, msm=0.197390, =0.100)\nEpoch #357: loss=0.179605 (contrastive=0.177616, msm=0.197505, =0.100)\nEpoch #358: loss=0.190416 (contrastive=0.188799, msm=0.204965, =0.100)\nEpoch #359: loss=0.174830 (contrastive=0.172868, msm=0.192487, =0.100)\nEpoch #360: loss=0.175643 (contrastive=0.172603, msm=0.203003, =0.100)\nEpoch #361: loss=0.118417 (contrastive=0.110789, msm=0.187071, =0.100)\nEpoch #362: loss=0.139469 (contrastive=0.133161, msm=0.196239, =0.100)\nEpoch #363: loss=0.125330 (contrastive=0.117238, msm=0.198160, =0.100)\nEpoch #364: loss=0.254187 (contrastive=0.260043, msm=0.201486, =0.100)\nEpoch #365: loss=0.180940 (contrastive=0.178644, msm=0.201610, =0.100)\nEpoch #366: loss=0.162489 (contrastive=0.158442, msm=0.198918, =0.100)\nEpoch #367: loss=0.253607 (contrastive=0.259238, msm=0.202923, =0.100)\nEpoch #368: loss=0.105946 (contrastive=0.096125, msm=0.194343, =0.100)\nEpoch #369: loss=0.153960 (contrastive=0.148613, msm=0.202081, =0.100)\nEpoch #370: loss=0.125137 (contrastive=0.117083, msm=0.197627, =0.100)\nEpoch #371: loss=0.157758 (contrastive=0.153743, msm=0.193888, =0.100)\nEpoch #372: loss=0.141075 (contrastive=0.135776, msm=0.188763, =0.100)\nEpoch #373: loss=0.110358 (contrastive=0.101488, msm=0.190195, =0.100)\nEpoch #374: loss=0.114417 (contrastive=0.105234, msm=0.197068, =0.100)\nEpoch #375: loss=0.122476 (contrastive=0.114186, msm=0.197094, =0.100)\nEpoch #376: loss=0.101731 (contrastive=0.091716, msm=0.191864, =0.100)\nEpoch #377: loss=0.118367 (contrastive=0.109954, msm=0.194078, =0.100)\nEpoch #378: loss=0.129119 (contrastive=0.122523, msm=0.188478, =0.100)\nEpoch #379: loss=0.110940 (contrastive=0.102126, msm=0.190268, =0.100)\nEpoch #380: loss=0.121150 (contrastive=0.112568, msm=0.198382, =0.100)\nEpoch #381: loss=0.088266 (contrastive=0.077107, msm=0.188703, =0.100)\nEpoch #382: loss=0.158692 (contrastive=0.154367, msm=0.197616, =0.100)\nEpoch #383: loss=0.085785 (contrastive=0.074158, msm=0.190431, =0.100)\nEpoch #384: loss=0.126393 (contrastive=0.119141, msm=0.191659, =0.100)\nEpoch #385: loss=0.252017 (contrastive=0.258320, msm=0.195297, =0.100)\nEpoch #386: loss=0.143294 (contrastive=0.137303, msm=0.197218, =0.100)\nEpoch #387: loss=0.149466 (contrastive=0.145193, msm=0.187917, =0.100)\nEpoch #388: loss=0.117891 (contrastive=0.110067, msm=0.188301, =0.100)\nEpoch #389: loss=0.132223 (contrastive=0.124929, msm=0.197870, =0.100)\nEpoch #390: loss=0.164930 (contrastive=0.161813, msm=0.192981, =0.100)\nEpoch #391: loss=0.123140 (contrastive=0.115184, msm=0.194740, =0.100)\nEpoch #392: loss=0.099752 (contrastive=0.088607, msm=0.200060, =0.100)\nEpoch #393: loss=0.102882 (contrastive=0.093177, msm=0.190222, =0.100)\nEpoch #394: loss=0.158083 (contrastive=0.153871, msm=0.195992, =0.100)\nEpoch #395: loss=0.158156 (contrastive=0.153722, msm=0.198061, =0.100)\nEpoch #396: loss=0.112842 (contrastive=0.103755, msm=0.194619, =0.100)\nEpoch #397: loss=0.098054 (contrastive=0.086069, msm=0.205916, =0.100)\nEpoch #398: loss=0.178265 (contrastive=0.176322, msm=0.195749, =0.100)\nEpoch #399: loss=0.125172 (contrastive=0.117409, msm=0.195034, =0.100)\nEpoch #400: loss=0.097805 (contrastive=0.088134, msm=0.184845, =0.100)\nEpoch #401: loss=0.116163 (contrastive=0.107220, msm=0.196647, =0.100)\nEpoch #402: loss=0.111842 (contrastive=0.103725, msm=0.184898, =0.100)\nEpoch #403: loss=0.101518 (contrastive=0.091356, msm=0.192970, =0.100)\nEpoch #404: loss=0.102947 (contrastive=0.093132, msm=0.191283, =0.100)\nEpoch #405: loss=0.115228 (contrastive=0.107373, msm=0.185924, =0.100)\nEpoch #406: loss=0.124486 (contrastive=0.117007, msm=0.191795, =0.100)\nEpoch #407: loss=0.103622 (contrastive=0.094118, msm=0.189158, =0.100)\nEpoch #408: loss=0.185963 (contrastive=0.185080, msm=0.193915, =0.100)\nEpoch #409: loss=0.121474 (contrastive=0.113490, msm=0.193322, =0.100)\nEpoch #410: loss=0.632424 (contrastive=0.682022, msm=0.186042, =0.100)\nEpoch #411: loss=0.225286 (contrastive=0.227906, msm=0.201709, =0.100)\nEpoch #412: loss=0.232075 (contrastive=0.236081, msm=0.196018, =0.100)\nEpoch #413: loss=0.286922 (contrastive=0.295312, msm=0.211412, =0.100)\nEpoch #414: loss=0.208881 (contrastive=0.208170, msm=0.215280, =0.100)\nEpoch #415: loss=0.205519 (contrastive=0.204663, msm=0.213223, =0.100)\nEpoch #416: loss=0.318274 (contrastive=0.330687, msm=0.206561, =0.100)\nEpoch #417: loss=0.162737 (contrastive=0.158687, msm=0.199191, =0.100)\nEpoch #418: loss=0.185872 (contrastive=0.183427, msm=0.207868, =0.100)\nEpoch #419: loss=0.160854 (contrastive=0.155051, msm=0.213088, =0.100)\nEpoch #420: loss=0.231087 (contrastive=0.233140, msm=0.212611, =0.100)\nEpoch #421: loss=0.161827 (contrastive=0.156055, msm=0.213774, =0.100)\nEpoch #422: loss=0.218045 (contrastive=0.219688, msm=0.203267, =0.100)\nEpoch #423: loss=0.119476 (contrastive=0.109857, msm=0.206048, =0.100)\nEpoch #424: loss=0.121883 (contrastive=0.112232, msm=0.208747, =0.100)\nEpoch #425: loss=0.112445 (contrastive=0.103492, msm=0.193016, =0.100)\nEpoch #426: loss=0.136462 (contrastive=0.130083, msm=0.193878, =0.100)\nEpoch #427: loss=0.160179 (contrastive=0.156280, msm=0.195274, =0.100)\nEpoch #428: loss=0.189230 (contrastive=0.188873, msm=0.192446, =0.100)\nEpoch #429: loss=0.679223 (contrastive=0.733604, msm=0.189793, =0.100)\nEpoch #430: loss=0.183788 (contrastive=0.183090, msm=0.190067, =0.100)\nEpoch #431: loss=0.161703 (contrastive=0.158218, msm=0.193068, =0.100)\nEpoch #432: loss=0.140205 (contrastive=0.132426, msm=0.210213, =0.100)\nEpoch #433: loss=0.194468 (contrastive=0.193676, msm=0.201597, =0.100)\nEpoch #434: loss=0.239968 (contrastive=0.244617, msm=0.198135, =0.100)\nEpoch #435: loss=0.123576 (contrastive=0.115893, msm=0.192727, =0.100)\nEpoch #436: loss=0.132995 (contrastive=0.125669, msm=0.198935, =0.100)\nEpoch #437: loss=0.170508 (contrastive=0.167862, msm=0.194321, =0.100)\nEpoch #438: loss=0.608686 (contrastive=0.653949, msm=0.201321, =0.100)\nEpoch #439: loss=0.199365 (contrastive=0.198049, msm=0.211205, =0.100)\nEpoch #440: loss=0.151096 (contrastive=0.144032, msm=0.214668, =0.100)\nEpoch #441: loss=0.147928 (contrastive=0.140877, msm=0.211386, =0.100)\nEpoch #442: loss=0.170653 (contrastive=0.167269, msm=0.201110, =0.100)\nEpoch #443: loss=0.279059 (contrastive=0.286445, msm=0.212581, =0.100)\nEpoch #444: loss=0.184653 (contrastive=0.183046, msm=0.199124, =0.100)\nEpoch #445: loss=0.160710 (contrastive=0.155380, msm=0.208672, =0.100)\nEpoch #446: loss=0.195721 (contrastive=0.195273, msm=0.199753, =0.100)\nEpoch #447: loss=0.134435 (contrastive=0.126487, msm=0.205964, =0.100)\nEpoch #448: loss=0.103723 (contrastive=0.092173, msm=0.207680, =0.100)\nEpoch #449: loss=0.108847 (contrastive=0.099820, msm=0.190088, =0.100)\nEpoch #450: loss=0.151762 (contrastive=0.146711, msm=0.197217, =0.100)\nEpoch #451: loss=0.185131 (contrastive=0.183706, msm=0.197951, =0.100)\nEpoch #452: loss=0.083266 (contrastive=0.071274, msm=0.191194, =0.100)\nEpoch #453: loss=0.136399 (contrastive=0.129818, msm=0.195631, =0.100)\nEpoch #454: loss=0.119650 (contrastive=0.111392, msm=0.193971, =0.100)\nEpoch #455: loss=0.142438 (contrastive=0.136064, msm=0.199801, =0.100)\nEpoch #456: loss=0.094806 (contrastive=0.083417, msm=0.197304, =0.100)\nEpoch #457: loss=0.544538 (contrastive=0.583155, msm=0.196989, =0.100)\nEpoch #458: loss=0.115447 (contrastive=0.106283, msm=0.197926, =0.100)\nEpoch #459: loss=0.105892 (contrastive=0.095223, msm=0.201911, =0.100)\nEpoch #460: loss=0.173030 (contrastive=0.169288, msm=0.206710, =0.100)\nEpoch #461: loss=0.122792 (contrastive=0.114591, msm=0.196597, =0.100)\nEpoch #462: loss=0.096999 (contrastive=0.086118, msm=0.194925, =0.100)\nEpoch #463: loss=0.113285 (contrastive=0.104422, msm=0.193047, =0.100)\nEpoch #464: loss=0.164335 (contrastive=0.161102, msm=0.193427, =0.100)\nEpoch #465: loss=0.095235 (contrastive=0.084234, msm=0.194245, =0.100)\nEpoch #466: loss=0.082370 (contrastive=0.070740, msm=0.187037, =0.100)\nEpoch #467: loss=0.126479 (contrastive=0.118639, msm=0.197033, =0.100)\nEpoch #468: loss=0.147523 (contrastive=0.142359, msm=0.193997, =0.100)\nEpoch #469: loss=0.282727 (contrastive=0.292853, msm=0.191595, =0.100)\nEpoch #470: loss=0.087231 (contrastive=0.074607, msm=0.200842, =0.100)\nEpoch #471: loss=0.079095 (contrastive=0.066580, msm=0.191732, =0.100)\nEpoch #472: loss=0.070750 (contrastive=0.056739, msm=0.196851, =0.100)\nEpoch #473: loss=1.542320 (contrastive=1.692462, msm=0.191047, =0.100)\nEpoch #474: loss=0.129525 (contrastive=0.122043, msm=0.196861, =0.100)\nEpoch #475: loss=0.214521 (contrastive=0.215683, msm=0.204062, =0.100)\nEpoch #476: loss=0.327812 (contrastive=0.342456, msm=0.196016, =0.100)\nEpoch #477: loss=0.314366 (contrastive=0.327080, msm=0.199947, =0.100)\nEpoch #478: loss=0.205960 (contrastive=0.205935, msm=0.206190, =0.100)\nEpoch #479: loss=0.205297 (contrastive=0.205415, msm=0.204234, =0.100)\nEpoch #480: loss=0.302804 (contrastive=0.314401, msm=0.198437, =0.100)\nEpoch #481: loss=0.211838 (contrastive=0.212827, msm=0.202931, =0.100)\nEpoch #482: loss=0.249795 (contrastive=0.254953, msm=0.203375, =0.100)\nEpoch #483: loss=0.171996 (contrastive=0.167415, msm=0.213226, =0.100)\nEpoch #484: loss=0.254955 (contrastive=0.260071, msm=0.208912, =0.100)\nEpoch #485: loss=0.135830 (contrastive=0.127706, msm=0.208950, =0.100)\nEpoch #486: loss=0.148424 (contrastive=0.144033, msm=0.187939, =0.100)\nEpoch #487: loss=0.203951 (contrastive=0.203888, msm=0.204522, =0.100)\nEpoch #488: loss=0.165571 (contrastive=0.162096, msm=0.196850, =0.100)\nEpoch #489: loss=0.103166 (contrastive=0.092310, msm=0.200869, =0.100)\nEpoch #490: loss=0.378114 (contrastive=0.397548, msm=0.203207, =0.100)\nEpoch #491: loss=0.105769 (contrastive=0.095194, msm=0.200947, =0.100)\nEpoch #492: loss=0.142872 (contrastive=0.135858, msm=0.206002, =0.100)\nEpoch #493: loss=0.201569 (contrastive=0.202858, msm=0.189965, =0.100)\nEpoch #494: loss=0.128138 (contrastive=0.120716, msm=0.194943, =0.100)\nEpoch #495: loss=0.127692 (contrastive=0.119969, msm=0.197194, =0.100)\nEpoch #496: loss=0.118321 (contrastive=0.110278, msm=0.190705, =0.100)\nEpoch #497: loss=0.079930 (contrastive=0.066936, msm=0.196884, =0.100)\nEpoch #498: loss=0.091647 (contrastive=0.079639, msm=0.199716, =0.100)\nEpoch #499: loss=0.117534 (contrastive=0.108995, msm=0.194384, =0.100)\nEpoch #500: loss=0.132310 (contrastive=0.125734, msm=0.191492, =0.100)\nEpoch #501: loss=0.600461 (contrastive=0.644698, msm=0.202333, =0.100)\nEpoch #502: loss=0.095703 (contrastive=0.083801, msm=0.202819, =0.100)\nEpoch #503: loss=0.176339 (contrastive=0.172710, msm=0.209001, =0.100)\nEpoch #504: loss=0.161833 (contrastive=0.156316, msm=0.211480, =0.100)\nEpoch #505: loss=0.158644 (contrastive=0.152447, msm=0.214420, =0.100)\nEpoch #506: loss=0.199160 (contrastive=0.198759, msm=0.202769, =0.100)\nEpoch #507: loss=0.182948 (contrastive=0.180207, msm=0.207615, =0.100)\nEpoch #508: loss=0.149457 (contrastive=0.143250, msm=0.205318, =0.100)\nEpoch #509: loss=0.114310 (contrastive=0.104561, msm=0.202048, =0.100)\nEpoch #510: loss=0.080823 (contrastive=0.067091, msm=0.204414, =0.100)\nEpoch #511: loss=0.105634 (contrastive=0.095633, msm=0.195640, =0.100)\nEpoch #512: loss=0.113530 (contrastive=0.104480, msm=0.194978, =0.100)\nEpoch #513: loss=0.079347 (contrastive=0.066526, msm=0.194739, =0.100)\nEpoch #514: loss=0.131119 (contrastive=0.123957, msm=0.195576, =0.100)\nEpoch #515: loss=0.121365 (contrastive=0.113502, msm=0.192130, =0.100)\nEpoch #516: loss=0.112665 (contrastive=0.104369, msm=0.187327, =0.100)\nEpoch #517: loss=0.139215 (contrastive=0.134412, msm=0.182446, =0.100)\nEpoch #518: loss=0.108904 (contrastive=0.100026, msm=0.188802, =0.100)\nEpoch #519: loss=0.139260 (contrastive=0.133426, msm=0.191763, =0.100)\nEpoch #520: loss=0.096764 (contrastive=0.086419, msm=0.189873, =0.100)\nEpoch #521: loss=0.093667 (contrastive=0.084042, msm=0.180288, =0.100)\nEpoch #522: loss=0.070848 (contrastive=0.057761, msm=0.188639, =0.100)\nEpoch #523: loss=0.103489 (contrastive=0.093144, msm=0.196591, =0.100)\nEpoch #524: loss=0.104246 (contrastive=0.094569, msm=0.191342, =0.100)\nEpoch #525: loss=0.130804 (contrastive=0.124741, msm=0.185368, =0.100)\nEpoch #526: loss=0.150189 (contrastive=0.145525, msm=0.192169, =0.100)\nEpoch #527: loss=0.097730 (contrastive=0.087251, msm=0.192041, =0.100)\nEpoch #528: loss=0.091363 (contrastive=0.078639, msm=0.205877, =0.100)\nEpoch #529: loss=0.136876 (contrastive=0.129743, msm=0.201077, =0.100)\nEpoch #530: loss=0.211878 (contrastive=0.213645, msm=0.195970, =0.100)\nEpoch #531: loss=0.207260 (contrastive=0.208238, msm=0.198465, =0.100)\nEpoch #532: loss=0.141157 (contrastive=0.134072, msm=0.204920, =0.100)\nEpoch #533: loss=0.180593 (contrastive=0.178680, msm=0.197803, =0.100)\nEpoch #534: loss=0.104426 (contrastive=0.093222, msm=0.205257, =0.100)\nEpoch #535: loss=0.151477 (contrastive=0.145759, msm=0.202939, =0.100)\nEpoch #536: loss=0.199880 (contrastive=0.199144, msm=0.206500, =0.100)\nEpoch #537: loss=0.180850 (contrastive=0.177614, msm=0.209972, =0.100)\nEpoch #538: loss=0.126065 (contrastive=0.117254, msm=0.205363, =0.100)\nEpoch #539: loss=0.166953 (contrastive=0.163749, msm=0.195795, =0.100)\nEpoch #540: loss=0.095889 (contrastive=0.083885, msm=0.203927, =0.100)\nEpoch #541: loss=0.135029 (contrastive=0.127306, msm=0.204536, =0.100)\nEpoch #542: loss=0.117917 (contrastive=0.108715, msm=0.200734, =0.100)\nEpoch #543: loss=0.071371 (contrastive=0.058801, msm=0.184506, =0.100)\nEpoch #544: loss=0.068395 (contrastive=0.054593, msm=0.192615, =0.100)\nEpoch #545: loss=0.125335 (contrastive=0.117756, msm=0.193550, =0.100)\nEpoch #546: loss=0.077547 (contrastive=0.064792, msm=0.192341, =0.100)\nEpoch #547: loss=0.096796 (contrastive=0.087642, msm=0.179182, =0.100)\nEpoch #548: loss=0.212767 (contrastive=0.214368, msm=0.198352, =0.100)\nEpoch #549: loss=0.140024 (contrastive=0.135762, msm=0.178383, =0.100)\nEpoch #550: loss=0.080563 (contrastive=0.069210, msm=0.182743, =0.100)\nEpoch #551: loss=0.087858 (contrastive=0.076076, msm=0.193894, =0.100)\nEpoch #552: loss=0.054012 (contrastive=0.039710, msm=0.182725, =0.100)\nEpoch #553: loss=0.061088 (contrastive=0.047200, msm=0.186085, =0.100)\nEpoch #554: loss=0.087939 (contrastive=0.077424, msm=0.182573, =0.100)\nEpoch #555: loss=0.111905 (contrastive=0.104111, msm=0.182044, =0.100)\nEpoch #556: loss=0.082996 (contrastive=0.072620, msm=0.176377, =0.100)\nEpoch #557: loss=0.094803 (contrastive=0.085496, msm=0.178563, =0.100)\nEpoch #558: loss=0.074483 (contrastive=0.062859, msm=0.179105, =0.100)\nEpoch #559: loss=0.088983 (contrastive=0.077409, msm=0.193149, =0.100)\nEpoch #560: loss=0.146383 (contrastive=0.142111, msm=0.184822, =0.100)\nEpoch #561: loss=0.064158 (contrastive=0.050568, msm=0.186469, =0.100)\nEpoch #562: loss=0.126947 (contrastive=0.120180, msm=0.187849, =0.100)\nEpoch #563: loss=0.155725 (contrastive=0.152744, msm=0.182550, =0.100)\nEpoch #564: loss=0.115203 (contrastive=0.107389, msm=0.185532, =0.100)\nEpoch #565: loss=0.079376 (contrastive=0.067992, msm=0.181838, =0.100)\nEpoch #566: loss=0.146181 (contrastive=0.141905, msm=0.184659, =0.100)\nEpoch #567: loss=0.181476 (contrastive=0.180918, msm=0.186495, =0.100)\nEpoch #568: loss=0.080157 (contrastive=0.067793, msm=0.191430, =0.100)\nEpoch #569: loss=0.093125 (contrastive=0.082009, msm=0.193172, =0.100)\nEpoch #570: loss=0.390526 (contrastive=0.412336, msm=0.194228, =0.100)\nEpoch #571: loss=0.091818 (contrastive=0.081533, msm=0.184386, =0.100)\nEpoch #572: loss=0.217317 (contrastive=0.220465, msm=0.188987, =0.100)\nEpoch #573: loss=0.107465 (contrastive=0.097084, msm=0.200892, =0.100)\nEpoch #574: loss=0.073719 (contrastive=0.060099, msm=0.196291, =0.100)\nEpoch #575: loss=0.204943 (contrastive=0.206147, msm=0.194111, =0.100)\nEpoch #576: loss=0.142830 (contrastive=0.137505, msm=0.190759, =0.100)\nEpoch #577: loss=0.150249 (contrastive=0.145955, msm=0.188888, =0.100)\nEpoch #578: loss=0.083287 (contrastive=0.070770, msm=0.195949, =0.100)\nEpoch #579: loss=0.086000 (contrastive=0.074238, msm=0.191858, =0.100)\nEpoch #580: loss=0.080907 (contrastive=0.068170, msm=0.195536, =0.100)\nEpoch #581: loss=0.097647 (contrastive=0.087774, msm=0.186508, =0.100)\nEpoch #582: loss=0.171178 (contrastive=0.169810, msm=0.183493, =0.100)\nEpoch #583: loss=0.075440 (contrastive=0.063601, msm=0.181988, =0.100)\nEpoch #584: loss=0.067737 (contrastive=0.054994, msm=0.182427, =0.100)\nEpoch #585: loss=0.081695 (contrastive=0.069682, msm=0.189811, =0.100)\nEpoch #586: loss=0.266376 (contrastive=0.274909, msm=0.189584, =0.100)\nEpoch #587: loss=0.115191 (contrastive=0.108075, msm=0.179234, =0.100)\nEpoch #588: loss=0.119502 (contrastive=0.111357, msm=0.192811, =0.100)\nEpoch #589: loss=0.069990 (contrastive=0.056784, msm=0.188848, =0.100)\nEpoch #590: loss=0.100164 (contrastive=0.090355, msm=0.188448, =0.100)\nEpoch #591: loss=0.079072 (contrastive=0.067094, msm=0.186873, =0.100)\nEpoch #592: loss=0.062124 (contrastive=0.048860, msm=0.181495, =0.100)\nEpoch #593: loss=0.055023 (contrastive=0.040805, msm=0.182980, =0.100)\nEpoch #594: loss=0.057166 (contrastive=0.043617, msm=0.179106, =0.100)\nEpoch #595: loss=0.072274 (contrastive=0.060078, msm=0.182042, =0.100)\nEpoch #596: loss=0.065232 (contrastive=0.053132, msm=0.174136, =0.100)\nEpoch #597: loss=0.073560 (contrastive=0.062458, msm=0.173485, =0.100)\nEpoch #598: loss=0.212529 (contrastive=0.215041, msm=0.189916, =0.100)\nEpoch #599: loss=0.104226 (contrastive=0.095682, msm=0.181124, =0.100)\nTraining time: 0:07:50.522904\nEvaluation completed\nResults: {'ours': {24: {'norm': {'MSE': 0.9299419483157016, 'MAE': 0.7093789743983263}, 'raw': {'MSE': 21.009507382162443, 'MAE': 2.7867149263504074}}, 48: {'norm': {'MSE': 1.0158065266009433, 'MAE': 0.7467870669832166}, 'raw': {'MSE': 21.371066812347, 'MAE': 2.8246293349832987}}, 96: {'norm': {'MSE': 0.9529912393719455, 'MAE': 0.7167999627250109}, 'raw': {'MSE': 19.53211118711952, 'MAE': 2.6613892084816166}}, 288: {'norm': {'MSE': 0.9810578363371223, 'MAE': 0.7335131572713658}, 'raw': {'MSE': 19.837315355990167, 'MAE': 2.7034376121412715}}, 672: {'norm': {'MSE': 1.0069118812055078, 'MAE': 0.7542587252058042}, 'raw': {'MSE': 20.497709446753685, 'MAE': 2.7866324025814215}}}, 'ts2vec_infer_time': 213.11217832565308, 'lr_train_time': {24: 2.608853340148926, 48: 3.140737771987915, 96: 4.871037006378174, 288: 11.305665493011475, 672: 22.543465852737427}, 'lr_infer_time': {24: 0.021838665008544922, 48: 0.03299856185913086, 96: 0.04915332794189453, 288: 0.16104364395141602, 672: 0.30356359481811523}}\nModel and results saved to training/ETTm1__forecast_multivar_msm_conservative_2025-09-22_16_36_48_875862\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Univariate - Conservative MSM\n!python train_msm.py ETTh1 forecast_univar_msm_conservative --loader forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 42 --eval --msm-weight 0.1 --msm-mask-rate 0.2 --msm-decoder-depth 3\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:41:23.863127Z","iopub.execute_input":"2025-09-22T16:41:23.863866Z","iopub.status.idle":"2025-09-22T16:45:03.663520Z","shell.execute_reply.started":"2025-09-22T16:41:23.863820Z","shell.execute_reply":"2025-09-22T16:45:03.662790Z"}},"outputs":[{"name":"stdout","text":"Dataset: ETTh1\nArguments: Namespace(dataset='ETTh1', run_name='forecast_univar_msm_conservative', loader='forecast_csv_univar', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0, msm_weight=0.1, msm_mask_rate=0.2, msm_decoder_depth=3, dynamic_lambda=False)\nLoading data... done\nTraining...\nEpoch #0: loss=7.255070 (contrastive=7.956111, msm=0.945696, =0.100)\nEpoch #1: loss=6.566818 (contrastive=7.192913, msm=0.931962, =0.100)\nEpoch #2: loss=3.461704 (contrastive=3.742613, msm=0.933527, =0.100)\nEpoch #3: loss=2.542217 (contrastive=2.721284, msm=0.930612, =0.100)\nEpoch #4: loss=3.033298 (contrastive=3.267704, msm=0.923644, =0.100)\nEpoch #5: loss=2.979052 (contrastive=3.208064, msm=0.917946, =0.100)\nEpoch #6: loss=2.759485 (contrastive=2.964278, msm=0.916346, =0.100)\nEpoch #7: loss=2.460707 (contrastive=2.634521, msm=0.896380, =0.100)\nEpoch #8: loss=2.175269 (contrastive=2.316466, msm=0.904494, =0.100)\nEpoch #9: loss=2.038595 (contrastive=2.165079, msm=0.900237, =0.100)\nEpoch #10: loss=2.280029 (contrastive=2.433630, msm=0.897623, =0.100)\nEpoch #11: loss=1.974127 (contrastive=2.094786, msm=0.888193, =0.100)\nEpoch #12: loss=2.196870 (contrastive=2.343454, msm=0.877613, =0.100)\nEpoch #13: loss=2.125987 (contrastive=2.266788, msm=0.858779, =0.100)\nEpoch #14: loss=2.100236 (contrastive=2.238063, msm=0.859792, =0.100)\nEpoch #15: loss=1.972575 (contrastive=2.097399, msm=0.849155, =0.100)\nEpoch #16: loss=1.951411 (contrastive=2.076267, msm=0.827709, =0.100)\nEpoch #17: loss=1.967020 (contrastive=2.095693, msm=0.808966, =0.100)\nEpoch #18: loss=1.845182 (contrastive=1.963488, msm=0.780428, =0.100)\nEpoch #19: loss=1.907945 (contrastive=2.035248, msm=0.762213, =0.100)\nEpoch #20: loss=1.912091 (contrastive=2.043234, msm=0.731808, =0.100)\nEpoch #21: loss=1.787878 (contrastive=1.908131, msm=0.705603, =0.100)\nEpoch #22: loss=1.475956 (contrastive=1.564432, msm=0.679668, =0.100)\nEpoch #23: loss=1.822808 (contrastive=1.953474, msm=0.646821, =0.100)\nEpoch #24: loss=1.710482 (contrastive=1.832081, msm=0.616098, =0.100)\nEpoch #25: loss=1.610561 (contrastive=1.723354, msm=0.595430, =0.100)\nEpoch #26: loss=1.597121 (contrastive=1.711693, msm=0.565978, =0.100)\nEpoch #27: loss=1.539371 (contrastive=1.650383, msm=0.540267, =0.100)\nEpoch #28: loss=1.527832 (contrastive=1.640147, msm=0.516996, =0.100)\nEpoch #29: loss=1.530042 (contrastive=1.644531, msm=0.499641, =0.100)\nEpoch #30: loss=1.770749 (contrastive=1.913991, msm=0.481573, =0.100)\nEpoch #31: loss=1.570454 (contrastive=1.692719, msm=0.470073, =0.100)\nEpoch #32: loss=1.411681 (contrastive=1.517635, msm=0.458094, =0.100)\nEpoch #33: loss=1.507498 (contrastive=1.626552, msm=0.436009, =0.100)\nEpoch #34: loss=1.596350 (contrastive=1.726617, msm=0.423949, =0.100)\nEpoch #35: loss=1.549466 (contrastive=1.677102, msm=0.400746, =0.100)\nEpoch #36: loss=1.385340 (contrastive=1.496496, msm=0.384943, =0.100)\nEpoch #37: loss=1.275633 (contrastive=1.375645, msm=0.375521, =0.100)\nEpoch #38: loss=1.411066 (contrastive=1.528747, msm=0.351938, =0.100)\nEpoch #39: loss=1.379362 (contrastive=1.494676, msm=0.341535, =0.100)\nEpoch #40: loss=1.376425 (contrastive=1.493619, msm=0.321673, =0.100)\nEpoch #41: loss=1.251750 (contrastive=1.354778, msm=0.324496, =0.100)\nEpoch #42: loss=1.514416 (contrastive=1.646849, msm=0.322521, =0.100)\nEpoch #43: loss=1.346465 (contrastive=1.462319, msm=0.303778, =0.100)\nEpoch #44: loss=1.310288 (contrastive=1.422002, msm=0.304862, =0.100)\nEpoch #45: loss=1.416874 (contrastive=1.542509, msm=0.286160, =0.100)\nEpoch #46: loss=1.354217 (contrastive=1.473678, msm=0.279071, =0.100)\nEpoch #47: loss=1.241602 (contrastive=1.349156, msm=0.273616, =0.100)\nEpoch #48: loss=1.216222 (contrastive=1.320829, msm=0.274754, =0.100)\nEpoch #49: loss=1.165048 (contrastive=1.264961, msm=0.265826, =0.100)\nEpoch #50: loss=1.197029 (contrastive=1.301230, msm=0.259216, =0.100)\nEpoch #51: loss=1.258272 (contrastive=1.370465, msm=0.248539, =0.100)\nEpoch #52: loss=1.099461 (contrastive=1.193666, msm=0.251616, =0.100)\nEpoch #53: loss=1.202699 (contrastive=1.309395, msm=0.242430, =0.100)\nEpoch #54: loss=1.092679 (contrastive=1.186749, msm=0.246050, =0.100)\nEpoch #55: loss=1.099236 (contrastive=1.195221, msm=0.235373, =0.100)\nEpoch #56: loss=1.113543 (contrastive=1.211353, msm=0.233258, =0.100)\nEpoch #57: loss=1.102390 (contrastive=1.200962, msm=0.215244, =0.100)\nEpoch #58: loss=0.974563 (contrastive=1.058835, msm=0.216119, =0.100)\nEpoch #59: loss=1.045972 (contrastive=1.138190, msm=0.216010, =0.100)\nEpoch #60: loss=1.127053 (contrastive=1.228567, msm=0.213431, =0.100)\nEpoch #61: loss=1.148317 (contrastive=1.252209, msm=0.213291, =0.100)\nEpoch #62: loss=0.960211 (contrastive=1.042831, msm=0.216634, =0.100)\nEpoch #63: loss=1.029097 (contrastive=1.119615, msm=0.214443, =0.100)\nEpoch #64: loss=0.916325 (contrastive=0.995605, msm=0.202804, =0.100)\nEpoch #65: loss=1.052774 (contrastive=1.146819, msm=0.206376, =0.100)\nEpoch #66: loss=1.362613 (contrastive=1.491435, msm=0.203216, =0.100)\nEpoch #67: loss=1.073600 (contrastive=1.169907, msm=0.206833, =0.100)\nEpoch #68: loss=0.969866 (contrastive=1.055095, msm=0.202813, =0.100)\nEpoch #69: loss=1.225598 (contrastive=1.339351, msm=0.201826, =0.100)\nEpoch #70: loss=0.941068 (contrastive=1.022601, msm=0.207280, =0.100)\nEpoch #71: loss=0.871862 (contrastive=0.944572, msm=0.217474, =0.100)\nEpoch #72: loss=0.966724 (contrastive=1.050375, msm=0.213867, =0.100)\nEpoch #73: loss=0.858001 (contrastive=0.930555, msm=0.205017, =0.100)\nEpoch #74: loss=0.960525 (contrastive=1.044570, msm=0.204122, =0.100)\nEpoch #75: loss=0.853218 (contrastive=0.926481, msm=0.193854, =0.100)\nEpoch #76: loss=1.225463 (contrastive=1.338485, msm=0.208258, =0.100)\nEpoch #77: loss=0.790520 (contrastive=0.855801, msm=0.202989, =0.100)\nEpoch #78: loss=0.723475 (contrastive=0.780714, msm=0.208330, =0.100)\nEpoch #79: loss=0.830147 (contrastive=0.899842, msm=0.202885, =0.100)\nEpoch #80: loss=0.900859 (contrastive=0.979652, msm=0.191720, =0.100)\nEpoch #81: loss=0.743090 (contrastive=0.804564, msm=0.189820, =0.100)\nEpoch #82: loss=0.978097 (contrastive=1.065921, msm=0.187686, =0.100)\nEpoch #83: loss=1.029331 (contrastive=1.122892, msm=0.187282, =0.100)\nEpoch #84: loss=0.717369 (contrastive=0.777212, msm=0.178783, =0.100)\nEpoch #85: loss=0.862149 (contrastive=0.937825, msm=0.181071, =0.100)\nEpoch #86: loss=0.681563 (contrastive=0.737512, msm=0.178025, =0.100)\nEpoch #87: loss=0.837627 (contrastive=0.910733, msm=0.179673, =0.100)\nEpoch #88: loss=0.640448 (contrastive=0.691799, msm=0.178294, =0.100)\nEpoch #89: loss=1.262880 (contrastive=1.383516, msm=0.177156, =0.100)\nEpoch #90: loss=0.668280 (contrastive=0.722424, msm=0.180981, =0.100)\nEpoch #91: loss=0.868687 (contrastive=0.945734, msm=0.175263, =0.100)\nEpoch #92: loss=1.027794 (contrastive=1.122817, msm=0.172590, =0.100)\nEpoch #93: loss=0.791570 (contrastive=0.860415, msm=0.171966, =0.100)\nEpoch #94: loss=0.653712 (contrastive=0.707859, msm=0.166389, =0.100)\nEpoch #95: loss=0.688526 (contrastive=0.745636, msm=0.174545, =0.100)\nEpoch #96: loss=0.771930 (contrastive=0.839173, msm=0.166740, =0.100)\nEpoch #97: loss=0.885427 (contrastive=0.965294, msm=0.166621, =0.100)\nEpoch #98: loss=0.562228 (contrastive=0.606448, msm=0.164244, =0.100)\nEpoch #99: loss=0.977433 (contrastive=1.067714, msm=0.164897, =0.100)\nEpoch #100: loss=0.693097 (contrastive=0.751642, msm=0.166188, =0.100)\nEpoch #101: loss=0.733562 (contrastive=0.796791, msm=0.164498, =0.100)\nEpoch #102: loss=0.658185 (contrastive=0.712632, msm=0.168160, =0.100)\nEpoch #103: loss=0.955811 (contrastive=1.043688, msm=0.164917, =0.100)\nEpoch #104: loss=0.745017 (contrastive=0.809450, msm=0.165114, =0.100)\nEpoch #105: loss=0.685476 (contrastive=0.743977, msm=0.158968, =0.100)\nEpoch #106: loss=0.765026 (contrastive=0.832492, msm=0.157833, =0.100)\nEpoch #107: loss=0.664785 (contrastive=0.720547, msm=0.162928, =0.100)\nEpoch #108: loss=0.665685 (contrastive=0.722139, msm=0.157592, =0.100)\nEpoch #109: loss=0.910094 (contrastive=0.993707, msm=0.157581, =0.100)\nEpoch #110: loss=0.637291 (contrastive=0.690563, msm=0.157834, =0.100)\nEpoch #111: loss=1.430494 (contrastive=1.572424, msm=0.153127, =0.100)\nEpoch #112: loss=0.581750 (contrastive=0.629744, msm=0.149801, =0.100)\nEpoch #113: loss=0.677016 (contrastive=0.735242, msm=0.152979, =0.100)\nEpoch #114: loss=0.955254 (contrastive=1.044134, msm=0.155334, =0.100)\nEpoch #115: loss=0.687607 (contrastive=0.746592, msm=0.156741, =0.100)\nEpoch #116: loss=0.607244 (contrastive=0.657280, msm=0.156920, =0.100)\nEpoch #117: loss=0.652818 (contrastive=0.708105, msm=0.155228, =0.100)\nEpoch #118: loss=0.744199 (contrastive=0.810400, msm=0.148392, =0.100)\nEpoch #119: loss=0.686621 (contrastive=0.746869, msm=0.144388, =0.100)\nEpoch #120: loss=0.564439 (contrastive=0.610950, msm=0.145842, =0.100)\nEpoch #121: loss=0.551377 (contrastive=0.595620, msm=0.153192, =0.100)\nEpoch #122: loss=0.850154 (contrastive=0.927952, msm=0.149979, =0.100)\nEpoch #123: loss=0.529805 (contrastive=0.572408, msm=0.146371, =0.100)\nEpoch #124: loss=0.560425 (contrastive=0.606390, msm=0.146743, =0.100)\nEpoch #125: loss=0.546208 (contrastive=0.589840, msm=0.153517, =0.100)\nEpoch #126: loss=0.735557 (contrastive=0.800547, msm=0.150645, =0.100)\nEpoch #127: loss=0.686434 (contrastive=0.745399, msm=0.155744, =0.100)\nEpoch #128: loss=1.673043 (contrastive=1.842094, msm=0.151584, =0.100)\nEpoch #129: loss=0.585477 (contrastive=0.633057, msm=0.157255, =0.100)\nEpoch #130: loss=0.597562 (contrastive=0.646427, msm=0.157781, =0.100)\nEpoch #131: loss=0.629714 (contrastive=0.682243, msm=0.156950, =0.100)\nEpoch #132: loss=0.773671 (contrastive=0.842609, msm=0.153229, =0.100)\nEpoch #133: loss=0.557223 (contrastive=0.601856, msm=0.155522, =0.100)\nEpoch #134: loss=0.571541 (contrastive=0.618084, msm=0.152661, =0.100)\nEpoch #135: loss=0.573833 (contrastive=0.620593, msm=0.152996, =0.100)\nEpoch #136: loss=0.530637 (contrastive=0.573528, msm=0.144616, =0.100)\nEpoch #137: loss=0.494129 (contrastive=0.532297, msm=0.150611, =0.100)\nEpoch #138: loss=0.517047 (contrastive=0.558385, msm=0.145007, =0.100)\nEpoch #139: loss=0.503345 (contrastive=0.542767, msm=0.148547, =0.100)\nEpoch #140: loss=0.702952 (contrastive=0.764915, msm=0.145285, =0.100)\nEpoch #141: loss=1.261035 (contrastive=1.385562, msm=0.140287, =0.100)\nEpoch #142: loss=0.479794 (contrastive=0.517724, msm=0.138426, =0.100)\nEpoch #143: loss=0.546317 (contrastive=0.591797, msm=0.137000, =0.100)\nEpoch #144: loss=0.843246 (contrastive=0.921988, msm=0.134562, =0.100)\nEpoch #145: loss=0.547341 (contrastive=0.593045, msm=0.135998, =0.100)\nEpoch #146: loss=0.458561 (contrastive=0.493979, msm=0.139801, =0.100)\nEpoch #147: loss=0.457689 (contrastive=0.492778, msm=0.141891, =0.100)\nEpoch #148: loss=0.576422 (contrastive=0.624645, msm=0.142410, =0.100)\nEpoch #149: loss=0.686460 (contrastive=0.747268, msm=0.139186, =0.100)\nEpoch #150: loss=0.458007 (contrastive=0.493241, msm=0.140897, =0.100)\nEpoch #151: loss=0.472643 (contrastive=0.509484, msm=0.141066, =0.100)\nEpoch #152: loss=0.559321 (contrastive=0.606359, msm=0.135982, =0.100)\nEpoch #153: loss=0.389376 (contrastive=0.417040, msm=0.140404, =0.100)\nEpoch #154: loss=0.459227 (contrastive=0.494541, msm=0.141403, =0.100)\nEpoch #155: loss=0.396181 (contrastive=0.424868, msm=0.137995, =0.100)\nEpoch #156: loss=1.033171 (contrastive=1.132488, msm=0.139322, =0.100)\nEpoch #157: loss=0.467966 (contrastive=0.504566, msm=0.138565, =0.100)\nEpoch #158: loss=0.620733 (contrastive=0.674479, msm=0.137019, =0.100)\nEpoch #159: loss=0.554989 (contrastive=0.601704, msm=0.134547, =0.100)\nEpoch #160: loss=0.436967 (contrastive=0.470132, msm=0.138484, =0.100)\nEpoch #161: loss=0.476363 (contrastive=0.514071, msm=0.137000, =0.100)\nEpoch #162: loss=0.476107 (contrastive=0.513619, msm=0.138491, =0.100)\nEpoch #163: loss=0.443166 (contrastive=0.477529, msm=0.133900, =0.100)\nEpoch #164: loss=0.370450 (contrastive=0.397258, msm=0.129177, =0.100)\nEpoch #165: loss=0.539042 (contrastive=0.584269, msm=0.131992, =0.100)\nEpoch #166: loss=1.170833 (contrastive=1.286255, msm=0.132038, =0.100)\nEpoch #167: loss=0.390120 (contrastive=0.418028, msm=0.138950, =0.100)\nEpoch #168: loss=0.543604 (contrastive=0.588953, msm=0.135463, =0.100)\nEpoch #169: loss=1.090407 (contrastive=1.196876, msm=0.132183, =0.100)\nEpoch #170: loss=0.483288 (contrastive=0.521871, msm=0.136045, =0.100)\nEpoch #171: loss=0.582603 (contrastive=0.632258, msm=0.135711, =0.100)\nEpoch #172: loss=0.479400 (contrastive=0.517901, msm=0.132889, =0.100)\nEpoch #173: loss=0.388185 (contrastive=0.416365, msm=0.134565, =0.100)\nEpoch #174: loss=0.411789 (contrastive=0.442748, msm=0.133154, =0.100)\nEpoch #175: loss=0.411058 (contrastive=0.442369, msm=0.129258, =0.100)\nEpoch #176: loss=0.501737 (contrastive=0.543006, msm=0.130312, =0.100)\nEpoch #177: loss=0.350917 (contrastive=0.375843, msm=0.126588, =0.100)\nEpoch #178: loss=0.358583 (contrastive=0.384566, msm=0.124741, =0.100)\nEpoch #179: loss=1.151845 (contrastive=1.266621, msm=0.118864, =0.100)\nEpoch #180: loss=0.504057 (contrastive=0.546502, msm=0.122056, =0.100)\nEpoch #181: loss=0.400351 (contrastive=0.431079, msm=0.123807, =0.100)\nEpoch #182: loss=0.385369 (contrastive=0.414121, msm=0.126597, =0.100)\nEpoch #183: loss=0.649704 (contrastive=0.707867, msm=0.126233, =0.100)\nEpoch #184: loss=0.375139 (contrastive=0.402550, msm=0.128442, =0.100)\nEpoch #185: loss=0.544198 (contrastive=0.590821, msm=0.124595, =0.100)\nEpoch #186: loss=0.740913 (contrastive=0.810424, msm=0.115315, =0.100)\nEpoch #187: loss=0.385063 (contrastive=0.414206, msm=0.122771, =0.100)\nEpoch #188: loss=0.398101 (contrastive=0.428568, msm=0.123902, =0.100)\nEpoch #189: loss=0.529413 (contrastive=0.574010, msm=0.128041, =0.100)\nEpoch #190: loss=0.442111 (contrastive=0.477322, msm=0.125217, =0.100)\nEpoch #191: loss=0.367083 (contrastive=0.394076, msm=0.124142, =0.100)\nEpoch #192: loss=0.453032 (contrastive=0.489330, msm=0.126350, =0.100)\nEpoch #193: loss=0.429912 (contrastive=0.463961, msm=0.123476, =0.100)\nEpoch #194: loss=0.501285 (contrastive=0.543092, msm=0.125021, =0.100)\nEpoch #195: loss=0.393873 (contrastive=0.423830, msm=0.124260, =0.100)\nEpoch #196: loss=0.375817 (contrastive=0.404244, msm=0.119967, =0.100)\nEpoch #197: loss=0.337660 (contrastive=0.361839, msm=0.120047, =0.100)\nEpoch #198: loss=0.595532 (contrastive=0.648560, msm=0.118282, =0.100)\nEpoch #199: loss=0.368075 (contrastive=0.395863, msm=0.117981, =0.100)\nEpoch #200: loss=0.363763 (contrastive=0.390844, msm=0.120035, =0.100)\nEpoch #201: loss=0.283119 (contrastive=0.301304, msm=0.119455, =0.100)\nEpoch #202: loss=0.346517 (contrastive=0.372010, msm=0.117084, =0.100)\nEpoch #203: loss=0.294837 (contrastive=0.314129, msm=0.121209, =0.100)\nEpoch #204: loss=0.280549 (contrastive=0.298517, msm=0.118845, =0.100)\nEpoch #205: loss=0.382391 (contrastive=0.411590, msm=0.119598, =0.100)\nEpoch #206: loss=0.328423 (contrastive=0.352536, msm=0.111409, =0.100)\nEpoch #207: loss=0.538091 (contrastive=0.585400, msm=0.112312, =0.100)\nEpoch #208: loss=0.276152 (contrastive=0.294672, msm=0.109473, =0.100)\nEpoch #209: loss=0.675415 (contrastive=0.737785, msm=0.114090, =0.100)\nEpoch #210: loss=0.274502 (contrastive=0.291901, msm=0.117916, =0.100)\nEpoch #211: loss=0.272090 (contrastive=0.289174, msm=0.118329, =0.100)\nEpoch #212: loss=0.678885 (contrastive=0.741044, msm=0.119454, =0.100)\nEpoch #213: loss=0.332535 (contrastive=0.356349, msm=0.118205, =0.100)\nEpoch #214: loss=0.372676 (contrastive=0.401174, msm=0.116200, =0.100)\nEpoch #215: loss=0.411967 (contrastive=0.444618, msm=0.118113, =0.100)\nEpoch #216: loss=0.690196 (contrastive=0.754040, msm=0.115598, =0.100)\nEpoch #217: loss=0.280271 (contrastive=0.298441, msm=0.116739, =0.100)\nEpoch #218: loss=0.705492 (contrastive=0.770619, msm=0.119350, =0.100)\nEpoch #219: loss=0.295381 (contrastive=0.315903, msm=0.110677, =0.100)\nEpoch #220: loss=0.360555 (contrastive=0.388111, msm=0.112553, =0.100)\nEpoch #221: loss=0.269300 (contrastive=0.287101, msm=0.109083, =0.100)\nEpoch #222: loss=0.266098 (contrastive=0.283343, msm=0.110894, =0.100)\nEpoch #223: loss=0.408127 (contrastive=0.440808, msm=0.114005, =0.100)\nEpoch #224: loss=0.308977 (contrastive=0.329970, msm=0.120046, =0.100)\nEpoch #225: loss=0.394230 (contrastive=0.423832, msm=0.127810, =0.100)\nEpoch #226: loss=0.297961 (contrastive=0.317712, msm=0.120202, =0.100)\nEpoch #227: loss=0.435187 (contrastive=0.470183, msm=0.120222, =0.100)\nEpoch #228: loss=0.548178 (contrastive=0.595768, msm=0.119867, =0.100)\nEpoch #229: loss=0.265584 (contrastive=0.282586, msm=0.112558, =0.100)\nEpoch #230: loss=0.751994 (contrastive=0.822764, msm=0.115071, =0.100)\nEpoch #231: loss=0.367159 (contrastive=0.395002, msm=0.116571, =0.100)\nEpoch #232: loss=0.365257 (contrastive=0.392302, msm=0.121855, =0.100)\nEpoch #233: loss=0.352813 (contrastive=0.377743, msm=0.128444, =0.100)\nEpoch #234: loss=0.315770 (contrastive=0.336839, msm=0.126151, =0.100)\nEpoch #235: loss=0.292917 (contrastive=0.311488, msm=0.125776, =0.100)\nEpoch #236: loss=0.845881 (contrastive=0.926669, msm=0.118793, =0.100)\nEpoch #237: loss=0.418836 (contrastive=0.452207, msm=0.118498, =0.100)\nEpoch #238: loss=0.904285 (contrastive=0.991191, msm=0.122136, =0.100)\nEpoch #239: loss=0.288103 (contrastive=0.306155, msm=0.125631, =0.100)\nEpoch #240: loss=0.355868 (contrastive=0.381184, msm=0.128029, =0.100)\nEpoch #241: loss=0.362278 (contrastive=0.388743, msm=0.124094, =0.100)\nEpoch #242: loss=0.314473 (contrastive=0.336319, msm=0.117858, =0.100)\nEpoch #243: loss=0.435946 (contrastive=0.471726, msm=0.113927, =0.100)\nEpoch #244: loss=0.420112 (contrastive=0.454466, msm=0.110922, =0.100)\nEpoch #245: loss=0.311356 (contrastive=0.332915, msm=0.117326, =0.100)\nEpoch #246: loss=0.325375 (contrastive=0.348369, msm=0.118428, =0.100)\nEpoch #247: loss=0.291198 (contrastive=0.311008, msm=0.112911, =0.100)\nEpoch #248: loss=0.326340 (contrastive=0.349702, msm=0.116076, =0.100)\nEpoch #249: loss=0.278488 (contrastive=0.296909, msm=0.112701, =0.100)\nEpoch #250: loss=0.402441 (contrastive=0.434882, msm=0.110477, =0.100)\nEpoch #251: loss=0.274206 (contrastive=0.291841, msm=0.115497, =0.100)\nEpoch #252: loss=0.466498 (contrastive=0.506366, msm=0.107682, =0.100)\nEpoch #253: loss=0.322644 (contrastive=0.346229, msm=0.110373, =0.100)\nEpoch #254: loss=0.308662 (contrastive=0.330655, msm=0.110724, =0.100)\nEpoch #255: loss=0.296748 (contrastive=0.317423, msm=0.110678, =0.100)\nEpoch #256: loss=0.314080 (contrastive=0.336430, msm=0.112931, =0.100)\nEpoch #257: loss=0.980340 (contrastive=1.077376, msm=0.107014, =0.100)\nEpoch #258: loss=1.469242 (contrastive=1.620596, msm=0.107056, =0.100)\nEpoch #259: loss=0.491305 (contrastive=0.533790, msm=0.108934, =0.100)\nEpoch #260: loss=0.695435 (contrastive=0.759884, msm=0.115398, =0.100)\nEpoch #261: loss=0.474103 (contrastive=0.513183, msm=0.122383, =0.100)\nEpoch #262: loss=0.356373 (contrastive=0.381904, msm=0.126590, =0.100)\nEpoch #263: loss=0.372811 (contrastive=0.400032, msm=0.127823, =0.100)\nEpoch #264: loss=0.487337 (contrastive=0.527911, msm=0.122172, =0.100)\nEpoch #265: loss=0.520118 (contrastive=0.564283, msm=0.122627, =0.100)\nEpoch #266: loss=0.685667 (contrastive=0.748766, msm=0.117772, =0.100)\nEpoch #267: loss=0.371470 (contrastive=0.399563, msm=0.118634, =0.100)\nEpoch #268: loss=0.614072 (contrastive=0.668581, msm=0.123487, =0.100)\nEpoch #269: loss=1.234030 (contrastive=1.357071, msm=0.126667, =0.100)\nEpoch #270: loss=0.461921 (contrastive=0.499591, msm=0.122898, =0.100)\nEpoch #271: loss=0.411482 (contrastive=0.443575, msm=0.122652, =0.100)\nEpoch #272: loss=0.386517 (contrastive=0.415850, msm=0.122514, =0.100)\nEpoch #273: loss=0.648501 (contrastive=0.707134, msm=0.120806, =0.100)\nEpoch #274: loss=0.399606 (contrastive=0.430725, msm=0.119535, =0.100)\nEpoch #275: loss=0.404484 (contrastive=0.436239, msm=0.118690, =0.100)\nEpoch #276: loss=0.737780 (contrastive=0.806813, msm=0.116486, =0.100)\nEpoch #277: loss=0.417674 (contrastive=0.451082, msm=0.117000, =0.100)\nEpoch #278: loss=0.453248 (contrastive=0.491537, msm=0.108639, =0.100)\nEpoch #279: loss=0.388535 (contrastive=0.418538, msm=0.118514, =0.100)\nEpoch #280: loss=0.338603 (contrastive=0.363530, msm=0.114258, =0.100)\nEpoch #281: loss=0.536174 (contrastive=0.582655, msm=0.117852, =0.100)\nEpoch #282: loss=0.325671 (contrastive=0.349114, msm=0.114685, =0.100)\nEpoch #283: loss=0.379146 (contrastive=0.408573, msm=0.114297, =0.100)\nEpoch #284: loss=0.501176 (contrastive=0.544534, msm=0.110951, =0.100)\nEpoch #285: loss=0.293307 (contrastive=0.314153, msm=0.105688, =0.100)\nEpoch #286: loss=0.400234 (contrastive=0.432750, msm=0.107583, =0.100)\nEpoch #287: loss=0.352793 (contrastive=0.379633, msm=0.111228, =0.100)\nEpoch #288: loss=0.586911 (contrastive=0.639622, msm=0.112516, =0.100)\nEpoch #289: loss=0.307137 (contrastive=0.329342, msm=0.107291, =0.100)\nEpoch #290: loss=0.385260 (contrastive=0.415691, msm=0.111372, =0.100)\nEpoch #291: loss=0.286600 (contrastive=0.305752, msm=0.114238, =0.100)\nEpoch #292: loss=0.311859 (contrastive=0.334276, msm=0.110101, =0.100)\nEpoch #293: loss=0.280253 (contrastive=0.298801, msm=0.113322, =0.100)\nEpoch #294: loss=0.266329 (contrastive=0.283884, msm=0.108336, =0.100)\nEpoch #295: loss=0.583030 (contrastive=0.636407, msm=0.102629, =0.100)\nEpoch #296: loss=0.259096 (contrastive=0.276306, msm=0.104209, =0.100)\nEpoch #297: loss=0.233808 (contrastive=0.248147, msm=0.104764, =0.100)\nEpoch #298: loss=0.295602 (contrastive=0.317321, msm=0.100128, =0.100)\nEpoch #299: loss=0.238284 (contrastive=0.253569, msm=0.100712, =0.100)\nEpoch #300: loss=0.649916 (contrastive=0.710765, msm=0.102266, =0.100)\nEpoch #301: loss=0.254445 (contrastive=0.271117, msm=0.104396, =0.100)\nEpoch #302: loss=0.376389 (contrastive=0.406343, msm=0.106802, =0.100)\nEpoch #303: loss=0.227331 (contrastive=0.240848, msm=0.105676, =0.100)\nEpoch #304: loss=0.249919 (contrastive=0.265933, msm=0.105795, =0.100)\nEpoch #305: loss=0.322417 (contrastive=0.347039, msm=0.100820, =0.100)\nEpoch #306: loss=0.591377 (contrastive=0.646105, msm=0.098826, =0.100)\nEpoch #307: loss=0.493701 (contrastive=0.537188, msm=0.102315, =0.100)\nEpoch #308: loss=0.228433 (contrastive=0.242461, msm=0.102177, =0.100)\nEpoch #309: loss=0.333912 (contrastive=0.359336, msm=0.105095, =0.100)\nEpoch #310: loss=0.333359 (contrastive=0.359180, msm=0.100967, =0.100)\nEpoch #311: loss=0.260107 (contrastive=0.277760, msm=0.101232, =0.100)\nEpoch #312: loss=0.421141 (contrastive=0.456713, msm=0.100985, =0.100)\nEpoch #313: loss=0.384011 (contrastive=0.415549, msm=0.100173, =0.100)\nEpoch #314: loss=0.319515 (contrastive=0.343432, msm=0.104265, =0.100)\nEpoch #315: loss=0.547696 (contrastive=0.597187, msm=0.102283, =0.100)\nEpoch #316: loss=0.358470 (contrastive=0.387114, msm=0.100678, =0.100)\nEpoch #317: loss=0.412685 (contrastive=0.447732, msm=0.097258, =0.100)\nEpoch #318: loss=0.343936 (contrastive=0.371284, msm=0.097804, =0.100)\nEpoch #319: loss=0.275526 (contrastive=0.295350, msm=0.097109, =0.100)\nEpoch #320: loss=0.264886 (contrastive=0.282874, msm=0.102998, =0.100)\nEpoch #321: loss=0.351825 (contrastive=0.379236, msm=0.105127, =0.100)\nEpoch #322: loss=0.238728 (contrastive=0.253598, msm=0.104898, =0.100)\nEpoch #323: loss=0.317384 (contrastive=0.341259, msm=0.102516, =0.100)\nEpoch #324: loss=0.290912 (contrastive=0.312253, msm=0.098847, =0.100)\nEpoch #325: loss=0.240884 (contrastive=0.256285, msm=0.102278, =0.100)\nEpoch #326: loss=0.335239 (contrastive=0.361362, msm=0.100133, =0.100)\nEpoch #327: loss=0.227271 (contrastive=0.241516, msm=0.099073, =0.100)\nEpoch #328: loss=0.327675 (contrastive=0.353640, msm=0.093991, =0.100)\nEpoch #329: loss=0.244881 (contrastive=0.261338, msm=0.096768, =0.100)\nEpoch #330: loss=0.284262 (contrastive=0.304330, msm=0.103654, =0.100)\nEpoch #331: loss=0.321643 (contrastive=0.346434, msm=0.098521, =0.100)\nEpoch #332: loss=0.248819 (contrastive=0.265554, msm=0.098206, =0.100)\nEpoch #333: loss=0.251068 (contrastive=0.268217, msm=0.096731, =0.100)\nEpoch #334: loss=0.213948 (contrastive=0.227053, msm=0.096002, =0.100)\nEpoch #335: loss=0.344910 (contrastive=0.372945, msm=0.092596, =0.100)\nEpoch #336: loss=0.268320 (contrastive=0.287403, msm=0.096566, =0.100)\nEpoch #337: loss=0.462234 (contrastive=0.502835, msm=0.096828, =0.100)\nEpoch #338: loss=0.240850 (contrastive=0.256789, msm=0.097400, =0.100)\nEpoch #339: loss=0.287710 (contrastive=0.309151, msm=0.094741, =0.100)\nEpoch #340: loss=0.238309 (contrastive=0.253803, msm=0.098861, =0.100)\nEpoch #341: loss=0.219080 (contrastive=0.232497, msm=0.098327, =0.100)\nEpoch #342: loss=0.505412 (contrastive=0.550504, msm=0.099583, =0.100)\nEpoch #343: loss=0.257371 (contrastive=0.275235, msm=0.096588, =0.100)\nEpoch #344: loss=0.488481 (contrastive=0.531988, msm=0.096918, =0.100)\nEpoch #345: loss=0.199989 (contrastive=0.211885, msm=0.092917, =0.100)\nEpoch #346: loss=0.258434 (contrastive=0.276678, msm=0.094241, =0.100)\nEpoch #347: loss=0.193598 (contrastive=0.205047, msm=0.090560, =0.100)\nEpoch #348: loss=0.318770 (contrastive=0.344201, msm=0.089887, =0.100)\nEpoch #349: loss=0.215059 (contrastive=0.228921, msm=0.090303, =0.100)\nEpoch #350: loss=0.371058 (contrastive=0.402103, msm=0.091650, =0.100)\nEpoch #351: loss=0.286764 (contrastive=0.308072, msm=0.095000, =0.100)\nEpoch #352: loss=0.199694 (contrastive=0.211458, msm=0.093816, =0.100)\nEpoch #353: loss=0.902232 (contrastive=0.991859, msm=0.095583, =0.100)\nEpoch #354: loss=0.300227 (contrastive=0.323614, msm=0.089747, =0.100)\nEpoch #355: loss=0.191093 (contrastive=0.202182, msm=0.091289, =0.100)\nEpoch #356: loss=0.565212 (contrastive=0.618094, msm=0.089275, =0.100)\nEpoch #357: loss=0.260200 (contrastive=0.278729, msm=0.093439, =0.100)\nEpoch #358: loss=0.468842 (contrastive=0.510302, msm=0.095699, =0.100)\nEpoch #359: loss=0.349174 (contrastive=0.377425, msm=0.094910, =0.100)\nEpoch #360: loss=0.369049 (contrastive=0.399367, msm=0.096188, =0.100)\nEpoch #361: loss=0.224401 (contrastive=0.239077, msm=0.092309, =0.100)\nEpoch #362: loss=0.318060 (contrastive=0.343018, msm=0.093438, =0.100)\nEpoch #363: loss=0.370999 (contrastive=0.401667, msm=0.094987, =0.100)\nEpoch #364: loss=0.221453 (contrastive=0.235747, msm=0.092813, =0.100)\nEpoch #365: loss=0.305804 (contrastive=0.329308, msm=0.094261, =0.100)\nEpoch #366: loss=0.227245 (contrastive=0.242716, msm=0.088008, =0.100)\nEpoch #367: loss=0.201028 (contrastive=0.213374, msm=0.089916, =0.100)\nEpoch #368: loss=0.240596 (contrastive=0.256715, msm=0.095528, =0.100)\nEpoch #369: loss=0.239458 (contrastive=0.256056, msm=0.090081, =0.100)\nEpoch #370: loss=0.338067 (contrastive=0.365359, msm=0.092445, =0.100)\nEpoch #371: loss=0.188164 (contrastive=0.199022, msm=0.090444, =0.100)\nEpoch #372: loss=0.226658 (contrastive=0.241783, msm=0.090541, =0.100)\nEpoch #373: loss=0.193236 (contrastive=0.204567, msm=0.091255, =0.100)\nEpoch #374: loss=0.218597 (contrastive=0.232873, msm=0.090113, =0.100)\nEpoch #375: loss=0.198532 (contrastive=0.210372, msm=0.091976, =0.100)\nEpoch #376: loss=0.272423 (contrastive=0.292491, msm=0.091812, =0.100)\nEpoch #377: loss=0.297918 (contrastive=0.321097, msm=0.089312, =0.100)\nEpoch #378: loss=0.419855 (contrastive=0.456113, msm=0.093526, =0.100)\nEpoch #379: loss=0.206352 (contrastive=0.219517, msm=0.087868, =0.100)\nEpoch #380: loss=0.205258 (contrastive=0.218308, msm=0.087805, =0.100)\nEpoch #381: loss=0.185066 (contrastive=0.195709, msm=0.089287, =0.100)\nEpoch #382: loss=0.176585 (contrastive=0.186330, msm=0.088887, =0.100)\nEpoch #383: loss=0.244005 (contrastive=0.261225, msm=0.089022, =0.100)\nEpoch #384: loss=1.444960 (contrastive=1.596096, msm=0.084734, =0.100)\nEpoch #385: loss=0.219453 (contrastive=0.234099, msm=0.087645, =0.100)\nEpoch #386: loss=0.201527 (contrastive=0.213657, msm=0.092352, =0.100)\nEpoch #387: loss=0.327663 (contrastive=0.354140, msm=0.089375, =0.100)\nEpoch #388: loss=0.268677 (contrastive=0.288240, msm=0.092612, =0.100)\nEpoch #389: loss=0.240700 (contrastive=0.257507, msm=0.089439, =0.100)\nEpoch #390: loss=0.198880 (contrastive=0.211340, msm=0.086736, =0.100)\nEpoch #391: loss=0.208611 (contrastive=0.222174, msm=0.086544, =0.100)\nEpoch #392: loss=0.542907 (contrastive=0.593813, msm=0.084752, =0.100)\nEpoch #393: loss=0.219486 (contrastive=0.233673, msm=0.091806, =0.100)\nEpoch #394: loss=0.293274 (contrastive=0.316195, msm=0.086990, =0.100)\nEpoch #395: loss=0.225180 (contrastive=0.240375, msm=0.088430, =0.100)\nEpoch #396: loss=0.300360 (contrastive=0.323494, msm=0.092150, =0.100)\nEpoch #397: loss=0.238504 (contrastive=0.254580, msm=0.093821, =0.100)\nEpoch #398: loss=0.200390 (contrastive=0.212763, msm=0.089036, =0.100)\nEpoch #399: loss=0.207071 (contrastive=0.220506, msm=0.086159, =0.100)\nEpoch #400: loss=0.194229 (contrastive=0.205989, msm=0.088389, =0.100)\nEpoch #401: loss=0.519579 (contrastive=0.567675, msm=0.086714, =0.100)\nEpoch #402: loss=0.219690 (contrastive=0.234643, msm=0.085117, =0.100)\nEpoch #403: loss=0.187057 (contrastive=0.198094, msm=0.087722, =0.100)\nEpoch #404: loss=0.204371 (contrastive=0.217110, msm=0.089723, =0.100)\nEpoch #405: loss=0.253086 (contrastive=0.271315, msm=0.089024, =0.100)\nEpoch #406: loss=0.198673 (contrastive=0.211381, msm=0.084296, =0.100)\nEpoch #407: loss=0.163600 (contrastive=0.172122, msm=0.086906, =0.100)\nEpoch #408: loss=0.526134 (contrastive=0.575354, msm=0.083151, =0.100)\nEpoch #409: loss=0.194963 (contrastive=0.206978, msm=0.086826, =0.100)\nEpoch #410: loss=0.185946 (contrastive=0.196923, msm=0.087152, =0.100)\nEpoch #411: loss=0.171410 (contrastive=0.180863, msm=0.086330, =0.100)\nEpoch #412: loss=0.440810 (contrastive=0.480455, msm=0.084000, =0.100)\nEpoch #413: loss=0.336148 (contrastive=0.363745, msm=0.087772, =0.100)\nEpoch #414: loss=0.338553 (contrastive=0.366386, msm=0.088061, =0.100)\nEpoch #415: loss=0.208726 (contrastive=0.222211, msm=0.087363, =0.100)\nEpoch #416: loss=0.262417 (contrastive=0.282092, msm=0.085343, =0.100)\nEpoch #417: loss=0.166582 (contrastive=0.175535, msm=0.086009, =0.100)\nEpoch #418: loss=0.189499 (contrastive=0.200843, msm=0.087407, =0.100)\nEpoch #419: loss=0.174542 (contrastive=0.184490, msm=0.085009, =0.100)\nEpoch #420: loss=0.225719 (contrastive=0.241507, msm=0.083629, =0.100)\nEpoch #421: loss=0.178777 (contrastive=0.189075, msm=0.086091, =0.100)\nEpoch #422: loss=0.180330 (contrastive=0.190881, msm=0.085372, =0.100)\nEpoch #423: loss=0.222978 (contrastive=0.238348, msm=0.084654, =0.100)\nEpoch #424: loss=0.280515 (contrastive=0.302425, msm=0.083329, =0.100)\nEpoch #425: loss=0.159811 (contrastive=0.168144, msm=0.084815, =0.100)\nEpoch #426: loss=0.176871 (contrastive=0.187187, msm=0.084027, =0.100)\nEpoch #427: loss=0.343084 (contrastive=0.371887, msm=0.083862, =0.100)\nEpoch #428: loss=0.150595 (contrastive=0.158001, msm=0.083936, =0.100)\nEpoch #429: loss=0.172288 (contrastive=0.182216, msm=0.082942, =0.100)\nEpoch #430: loss=0.224088 (contrastive=0.239603, msm=0.084446, =0.100)\nEpoch #431: loss=0.219495 (contrastive=0.234504, msm=0.084416, =0.100)\nEpoch #432: loss=0.172193 (contrastive=0.181876, msm=0.085049, =0.100)\nEpoch #433: loss=0.180385 (contrastive=0.190881, msm=0.085925, =0.100)\nEpoch #434: loss=0.538097 (contrastive=0.588775, msm=0.082001, =0.100)\nEpoch #435: loss=0.435859 (contrastive=0.475415, msm=0.079855, =0.100)\nEpoch #436: loss=0.242709 (contrastive=0.260779, msm=0.080075, =0.100)\nEpoch #437: loss=0.194125 (contrastive=0.206514, msm=0.082620, =0.100)\nEpoch #438: loss=0.449371 (contrastive=0.489806, msm=0.085460, =0.100)\nEpoch #439: loss=0.201485 (contrastive=0.214934, msm=0.080445, =0.100)\nEpoch #440: loss=0.183412 (contrastive=0.194612, msm=0.082614, =0.100)\nEpoch #441: loss=0.170459 (contrastive=0.180635, msm=0.078872, =0.100)\nEpoch #442: loss=0.175453 (contrastive=0.185882, msm=0.081592, =0.100)\nEpoch #443: loss=0.244378 (contrastive=0.262208, msm=0.083908, =0.100)\nEpoch #444: loss=0.196289 (contrastive=0.208831, msm=0.083414, =0.100)\nEpoch #445: loss=0.190903 (contrastive=0.203259, msm=0.079692, =0.100)\nEpoch #446: loss=0.219829 (contrastive=0.234980, msm=0.083467, =0.100)\nEpoch #447: loss=0.278377 (contrastive=0.300102, msm=0.082853, =0.100)\nEpoch #448: loss=0.155177 (contrastive=0.163276, msm=0.082286, =0.100)\nEpoch #449: loss=0.157322 (contrastive=0.166027, msm=0.078981, =0.100)\nEpoch #450: loss=0.209076 (contrastive=0.223039, msm=0.083405, =0.100)\nEpoch #451: loss=0.164636 (contrastive=0.173492, msm=0.084926, =0.100)\nEpoch #452: loss=0.167215 (contrastive=0.176603, msm=0.082725, =0.100)\nEpoch #453: loss=0.157272 (contrastive=0.165747, msm=0.081005, =0.100)\nEpoch #454: loss=0.289990 (contrastive=0.312875, msm=0.084021, =0.100)\nEpoch #455: loss=0.146732 (contrastive=0.153954, msm=0.081733, =0.100)\nEpoch #456: loss=0.151655 (contrastive=0.159889, msm=0.077547, =0.100)\nEpoch #457: loss=0.189803 (contrastive=0.201523, msm=0.084325, =0.100)\nEpoch #458: loss=0.146470 (contrastive=0.153825, msm=0.080275, =0.100)\nEpoch #459: loss=0.167713 (contrastive=0.177060, msm=0.083588, =0.100)\nEpoch #460: loss=0.189446 (contrastive=0.201797, msm=0.078282, =0.100)\nEpoch #461: loss=0.160799 (contrastive=0.169590, msm=0.081681, =0.100)\nEpoch #462: loss=0.145221 (contrastive=0.152479, msm=0.079902, =0.100)\nEpoch #463: loss=0.289267 (contrastive=0.312284, msm=0.082115, =0.100)\nEpoch #464: loss=0.143663 (contrastive=0.150802, msm=0.079413, =0.100)\nEpoch #465: loss=0.186703 (contrastive=0.198386, msm=0.081554, =0.100)\nEpoch #466: loss=0.141487 (contrastive=0.148664, msm=0.076891, =0.100)\nEpoch #467: loss=0.131621 (contrastive=0.137631, msm=0.077537, =0.100)\nEpoch #468: loss=0.348595 (contrastive=0.378321, msm=0.081064, =0.100)\nEpoch #469: loss=0.216546 (contrastive=0.231254, msm=0.084173, =0.100)\nEpoch #470: loss=0.131895 (contrastive=0.137267, msm=0.083545, =0.100)\nEpoch #471: loss=0.186368 (contrastive=0.197957, msm=0.082063, =0.100)\nEpoch #472: loss=0.424812 (contrastive=0.463441, msm=0.077148, =0.100)\nEpoch #473: loss=0.321853 (contrastive=0.348723, msm=0.080020, =0.100)\nEpoch #474: loss=0.271020 (contrastive=0.292443, msm=0.078210, =0.100)\nEpoch #475: loss=0.141777 (contrastive=0.148415, msm=0.082043, =0.100)\nEpoch #476: loss=0.240771 (contrastive=0.258210, msm=0.083825, =0.100)\nEpoch #477: loss=0.198546 (contrastive=0.211257, msm=0.084152, =0.100)\nEpoch #478: loss=0.216628 (contrastive=0.231506, msm=0.082723, =0.100)\nEpoch #479: loss=0.257121 (contrastive=0.276726, msm=0.080683, =0.100)\nEpoch #480: loss=0.992233 (contrastive=1.093168, msm=0.083817, =0.100)\nEpoch #481: loss=0.192952 (contrastive=0.204980, msm=0.084697, =0.100)\nEpoch #482: loss=0.284094 (contrastive=0.305454, msm=0.091846, =0.100)\nEpoch #483: loss=0.260972 (contrastive=0.279898, msm=0.090641, =0.100)\nEpoch #484: loss=0.226397 (contrastive=0.241942, msm=0.086488, =0.100)\nEpoch #485: loss=0.244455 (contrastive=0.262663, msm=0.080585, =0.100)\nEpoch #486: loss=0.215591 (contrastive=0.230045, msm=0.085510, =0.100)\nEpoch #487: loss=0.202408 (contrastive=0.214718, msm=0.091614, =0.100)\nEpoch #488: loss=0.235102 (contrastive=0.251402, msm=0.088406, =0.100)\nEpoch #489: loss=0.252615 (contrastive=0.270818, msm=0.088783, =0.100)\nEpoch #490: loss=0.256862 (contrastive=0.275903, msm=0.085497, =0.100)\nEpoch #491: loss=0.174788 (contrastive=0.184731, msm=0.085297, =0.100)\nEpoch #492: loss=0.166260 (contrastive=0.175338, msm=0.084563, =0.100)\nEpoch #493: loss=0.174789 (contrastive=0.184554, msm=0.086904, =0.100)\nEpoch #494: loss=0.622315 (contrastive=0.682153, msm=0.083767, =0.100)\nEpoch #495: loss=0.303757 (contrastive=0.328460, msm=0.081436, =0.100)\nEpoch #496: loss=0.167469 (contrastive=0.177366, msm=0.078393, =0.100)\nEpoch #497: loss=0.195422 (contrastive=0.208098, msm=0.081336, =0.100)\nEpoch #498: loss=0.171828 (contrastive=0.182105, msm=0.079337, =0.100)\nEpoch #499: loss=0.201669 (contrastive=0.214973, msm=0.081929, =0.100)\nEpoch #500: loss=0.227562 (contrastive=0.244007, msm=0.079555, =0.100)\nEpoch #501: loss=0.178117 (contrastive=0.189105, msm=0.079231, =0.100)\nEpoch #502: loss=0.345515 (contrastive=0.374903, msm=0.081025, =0.100)\nEpoch #503: loss=0.301429 (contrastive=0.325880, msm=0.081376, =0.100)\nEpoch #504: loss=0.228694 (contrastive=0.245115, msm=0.080900, =0.100)\nEpoch #505: loss=0.167623 (contrastive=0.176998, msm=0.083248, =0.100)\nEpoch #506: loss=0.149102 (contrastive=0.156243, msm=0.084826, =0.100)\nEpoch #507: loss=0.186441 (contrastive=0.197266, msm=0.089022, =0.100)\nEpoch #508: loss=0.237206 (contrastive=0.254473, msm=0.081796, =0.100)\nEpoch #509: loss=0.144469 (contrastive=0.151444, msm=0.081700, =0.100)\nEpoch #510: loss=0.142869 (contrastive=0.149404, msm=0.084049, =0.100)\nEpoch #511: loss=0.270065 (contrastive=0.291227, msm=0.079610, =0.100)\nEpoch #512: loss=0.146477 (contrastive=0.153980, msm=0.078943, =0.100)\nEpoch #513: loss=0.302854 (contrastive=0.327733, msm=0.078950, =0.100)\nEpoch #514: loss=0.158432 (contrastive=0.167191, msm=0.079602, =0.100)\nEpoch #515: loss=0.140713 (contrastive=0.146308, msm=0.090361, =0.100)\nEpoch #516: loss=0.220315 (contrastive=0.235030, msm=0.087875, =0.100)\nEpoch #517: loss=0.166905 (contrastive=0.175905, msm=0.085902, =0.100)\nEpoch #518: loss=0.197761 (contrastive=0.210739, msm=0.080953, =0.100)\nEpoch #519: loss=0.351173 (contrastive=0.381616, msm=0.077191, =0.100)\nEpoch #520: loss=0.191663 (contrastive=0.204190, msm=0.078921, =0.100)\nEpoch #521: loss=0.163920 (contrastive=0.173149, msm=0.080857, =0.100)\nEpoch #522: loss=0.193546 (contrastive=0.206125, msm=0.080328, =0.100)\nEpoch #523: loss=0.550294 (contrastive=0.602708, msm=0.078576, =0.100)\nEpoch #524: loss=0.339703 (contrastive=0.368453, msm=0.080945, =0.100)\nEpoch #525: loss=0.403542 (contrastive=0.439816, msm=0.077076, =0.100)\nEpoch #526: loss=0.158264 (contrastive=0.166574, msm=0.083470, =0.100)\nEpoch #527: loss=0.186268 (contrastive=0.196028, msm=0.098431, =0.100)\nEpoch #528: loss=0.320829 (contrastive=0.344803, msm=0.105058, =0.100)\nEpoch #529: loss=0.304982 (contrastive=0.329244, msm=0.086621, =0.100)\nEpoch #530: loss=0.234547 (contrastive=0.251534, msm=0.081664, =0.100)\nEpoch #531: loss=0.234242 (contrastive=0.250428, msm=0.088572, =0.100)\nEpoch #532: loss=0.203603 (contrastive=0.215009, msm=0.100948, =0.100)\nEpoch #533: loss=0.251940 (contrastive=0.266639, msm=0.119647, =0.100)\nEpoch #534: loss=0.184664 (contrastive=0.191073, msm=0.126984, =0.100)\nEpoch #535: loss=0.205465 (contrastive=0.214364, msm=0.125374, =0.100)\nEpoch #536: loss=0.186076 (contrastive=0.193855, msm=0.116068, =0.100)\nEpoch #537: loss=0.240743 (contrastive=0.256088, msm=0.102632, =0.100)\nEpoch #538: loss=0.245032 (contrastive=0.261359, msm=0.098094, =0.100)\nEpoch #539: loss=0.210783 (contrastive=0.222495, msm=0.105374, =0.100)\nEpoch #540: loss=0.173764 (contrastive=0.179966, msm=0.117949, =0.100)\nEpoch #541: loss=0.211777 (contrastive=0.221678, msm=0.122668, =0.100)\nEpoch #542: loss=0.199915 (contrastive=0.208664, msm=0.121172, =0.100)\nEpoch #543: loss=0.175227 (contrastive=0.181692, msm=0.117046, =0.100)\nEpoch #544: loss=0.208359 (contrastive=0.218963, msm=0.112922, =0.100)\nEpoch #545: loss=0.196219 (contrastive=0.206547, msm=0.103271, =0.100)\nEpoch #546: loss=0.263885 (contrastive=0.282340, msm=0.097796, =0.100)\nEpoch #547: loss=0.219594 (contrastive=0.233871, msm=0.091098, =0.100)\nEpoch #548: loss=0.617452 (contrastive=0.676174, msm=0.088954, =0.100)\nEpoch #549: loss=0.155694 (contrastive=0.162633, msm=0.093241, =0.100)\nEpoch #550: loss=0.397010 (contrastive=0.430755, msm=0.093304, =0.100)\nEpoch #551: loss=0.165127 (contrastive=0.173355, msm=0.091073, =0.100)\nEpoch #552: loss=1.142603 (contrastive=1.259345, msm=0.091928, =0.100)\nEpoch #553: loss=0.199192 (contrastive=0.211140, msm=0.091659, =0.100)\nEpoch #554: loss=0.229903 (contrastive=0.245584, msm=0.088775, =0.100)\nEpoch #555: loss=0.444738 (contrastive=0.484283, msm=0.088833, =0.100)\nEpoch #556: loss=0.205704 (contrastive=0.218822, msm=0.087638, =0.100)\nEpoch #557: loss=0.276815 (contrastive=0.297560, msm=0.090117, =0.100)\nEpoch #558: loss=0.223226 (contrastive=0.238252, msm=0.088000, =0.100)\nEpoch #559: loss=0.341604 (contrastive=0.369388, msm=0.091547, =0.100)\nEpoch #560: loss=0.199742 (contrastive=0.211832, msm=0.090930, =0.100)\nEpoch #561: loss=0.184768 (contrastive=0.194755, msm=0.094886, =0.100)\nEpoch #562: loss=0.377131 (contrastive=0.408262, msm=0.096952, =0.100)\nEpoch #563: loss=0.235502 (contrastive=0.251089, msm=0.095211, =0.100)\nEpoch #564: loss=0.191282 (contrastive=0.202049, msm=0.094374, =0.100)\nEpoch #565: loss=0.608446 (contrastive=0.665249, msm=0.097220, =0.100)\nEpoch #566: loss=0.193385 (contrastive=0.204995, msm=0.088894, =0.100)\nEpoch #567: loss=0.191953 (contrastive=0.203482, msm=0.088199, =0.100)\nEpoch #568: loss=0.282251 (contrastive=0.304005, msm=0.086468, =0.100)\nEpoch #569: loss=0.168891 (contrastive=0.177914, msm=0.087684, =0.100)\nEpoch #570: loss=0.177157 (contrastive=0.187212, msm=0.086659, =0.100)\nEpoch #571: loss=0.185645 (contrastive=0.196500, msm=0.087948, =0.100)\nEpoch #572: loss=0.204566 (contrastive=0.217973, msm=0.083902, =0.100)\nEpoch #573: loss=0.189821 (contrastive=0.201559, msm=0.084181, =0.100)\nEpoch #574: loss=0.168823 (contrastive=0.178547, msm=0.081308, =0.100)\nEpoch #575: loss=0.214438 (contrastive=0.229271, msm=0.080939, =0.100)\nEpoch #576: loss=0.151830 (contrastive=0.159633, msm=0.081611, =0.100)\nEpoch #577: loss=0.144611 (contrastive=0.151698, msm=0.080827, =0.100)\nEpoch #578: loss=0.245199 (contrastive=0.262997, msm=0.085014, =0.100)\nEpoch #579: loss=0.212611 (contrastive=0.226674, msm=0.086047, =0.100)\nEpoch #580: loss=0.214485 (contrastive=0.229112, msm=0.082835, =0.100)\nEpoch #581: loss=0.151321 (contrastive=0.158827, msm=0.083771, =0.100)\nEpoch #582: loss=0.135558 (contrastive=0.141544, msm=0.081679, =0.100)\nEpoch #583: loss=0.260092 (contrastive=0.279960, msm=0.081282, =0.100)\nEpoch #584: loss=0.192835 (contrastive=0.205595, msm=0.077989, =0.100)\nEpoch #585: loss=0.184642 (contrastive=0.196789, msm=0.075316, =0.100)\nEpoch #586: loss=0.131452 (contrastive=0.137448, msm=0.077491, =0.100)\nEpoch #587: loss=0.189602 (contrastive=0.202154, msm=0.076638, =0.100)\nEpoch #588: loss=0.193218 (contrastive=0.206273, msm=0.075728, =0.100)\nEpoch #589: loss=0.168437 (contrastive=0.178390, msm=0.078855, =0.100)\nEpoch #590: loss=0.131624 (contrastive=0.137374, msm=0.079873, =0.100)\nEpoch #591: loss=0.176819 (contrastive=0.188029, msm=0.075931, =0.100)\nEpoch #592: loss=0.132107 (contrastive=0.138189, msm=0.077377, =0.100)\nEpoch #593: loss=0.125292 (contrastive=0.130599, msm=0.077534, =0.100)\nEpoch #594: loss=0.443457 (contrastive=0.484304, msm=0.075828, =0.100)\nEpoch #595: loss=0.216862 (contrastive=0.232632, msm=0.074935, =0.100)\nEpoch #596: loss=0.183330 (contrastive=0.195208, msm=0.076435, =0.100)\nEpoch #597: loss=0.120146 (contrastive=0.125343, msm=0.073377, =0.100)\nEpoch #598: loss=0.148409 (contrastive=0.156730, msm=0.073520, =0.100)\nEpoch #599: loss=0.293651 (contrastive=0.317926, msm=0.075182, =0.100)\nTraining time: 0:02:31.589811\nEvaluation completed\nResults: {'ours': {24: {'norm': {'MSE': 0.2321821538699555, 'MAE': 0.3914192962957365}, 'raw': {'MSE': 19.551591627908895, 'MAE': 3.5918556156183006}}, 48: {'norm': {'MSE': 0.2367496643375957, 'MAE': 0.39289403772288034}, 'raw': {'MSE': 19.936212512923984, 'MAE': 3.6053885699923085}}, 168: {'norm': {'MSE': 0.23464762474667542, 'MAE': 0.3913893049357614}, 'raw': {'MSE': 19.759203997984972, 'MAE': 3.5915804041394472}}, 336: {'norm': {'MSE': 0.24332786266346537, 'MAE': 0.40333740993741624}, 'raw': {'MSE': 20.490149405496602, 'MAE': 3.7012220866532486}}, 720: {'norm': {'MSE': 0.24928071864365425, 'MAE': 0.4171779816962595}, 'raw': {'MSE': 20.991427455335927, 'MAE': 3.828229969285578}}}, 'ts2vec_infer_time': 53.46785926818848, 'lr_train_time': {24: 0.7032909393310547, 48: 0.7416937351226807, 168: 0.9440882205963135, 336: 1.23793625831604, 720: 1.8046083450317383}, 'lr_infer_time': {24: 0.0020067691802978516, 48: 0.0021979808807373047, 168: 0.004242658615112305, 336: 0.00830698013305664, 720: 0.011430501937866211}}\nModel and results saved to training/ETTh1__forecast_univar_msm_conservative_2025-09-22_16_44_02_818906\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!python train_msm.py ETTh2 forecast_univar_msm_conservative --loader forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 42 --eval --msm-weight 0.1 --msm-mask-rate 0.2 --msm-decoder-depth 3\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:45:03.664630Z","iopub.execute_input":"2025-09-22T16:45:03.665432Z","iopub.status.idle":"2025-09-22T16:48:38.095691Z","shell.execute_reply.started":"2025-09-22T16:45:03.665403Z","shell.execute_reply":"2025-09-22T16:48:38.095026Z"}},"outputs":[{"name":"stdout","text":"Dataset: ETTh2\nArguments: Namespace(dataset='ETTh2', run_name='forecast_univar_msm_conservative', loader='forecast_csv_univar', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0, msm_weight=0.1, msm_mask_rate=0.2, msm_decoder_depth=3, dynamic_lambda=False)\nLoading data... done\nTraining...\nEpoch #0: loss=6.839948 (contrastive=7.494716, msm=0.947034, =0.100)\nEpoch #1: loss=5.953620 (contrastive=6.511748, msm=0.930464, =0.100)\nEpoch #2: loss=3.857171 (contrastive=4.182342, msm=0.930632, =0.100)\nEpoch #3: loss=2.839200 (contrastive=3.051096, msm=0.932136, =0.100)\nEpoch #4: loss=3.088487 (contrastive=3.329221, msm=0.921881, =0.100)\nEpoch #5: loss=2.951119 (contrastive=3.177088, msm=0.917399, =0.100)\nEpoch #6: loss=2.575917 (contrastive=2.760175, msm=0.917598, =0.100)\nEpoch #7: loss=2.482965 (contrastive=2.659266, msm=0.896254, =0.100)\nEpoch #8: loss=2.218353 (contrastive=2.364681, msm=0.901396, =0.100)\nEpoch #9: loss=2.027271 (contrastive=2.153007, msm=0.895650, =0.100)\nEpoch #10: loss=2.234026 (contrastive=2.382516, msm=0.897620, =0.100)\nEpoch #11: loss=1.958411 (contrastive=2.077132, msm=0.889922, =0.100)\nEpoch #12: loss=2.181350 (contrastive=2.326195, msm=0.877747, =0.100)\nEpoch #13: loss=2.133718 (contrastive=2.275186, msm=0.860503, =0.100)\nEpoch #14: loss=2.133264 (contrastive=2.274957, msm=0.858028, =0.100)\nEpoch #15: loss=1.996208 (contrastive=2.123833, msm=0.847587, =0.100)\nEpoch #16: loss=2.007212 (contrastive=2.139140, msm=0.819866, =0.100)\nEpoch #17: loss=1.987363 (contrastive=2.118900, msm=0.803528, =0.100)\nEpoch #18: loss=1.834983 (contrastive=1.953125, msm=0.771712, =0.100)\nEpoch #19: loss=1.857965 (contrastive=1.980481, msm=0.755323, =0.100)\nEpoch #20: loss=1.912253 (contrastive=2.044665, msm=0.720549, =0.100)\nEpoch #21: loss=1.790098 (contrastive=1.912011, msm=0.692878, =0.100)\nEpoch #22: loss=1.468952 (contrastive=1.557750, msm=0.669771, =0.100)\nEpoch #23: loss=1.828196 (contrastive=1.960627, msm=0.636310, =0.100)\nEpoch #24: loss=1.717961 (contrastive=1.841450, msm=0.606561, =0.100)\nEpoch #25: loss=1.588890 (contrastive=1.700538, msm=0.584057, =0.100)\nEpoch #26: loss=1.569302 (contrastive=1.681080, msm=0.563306, =0.100)\nEpoch #27: loss=1.537275 (contrastive=1.648560, msm=0.535710, =0.100)\nEpoch #28: loss=1.522673 (contrastive=1.634156, msm=0.519325, =0.100)\nEpoch #29: loss=1.529982 (contrastive=1.644392, msm=0.500291, =0.100)\nEpoch #30: loss=1.780795 (contrastive=1.925034, msm=0.482640, =0.100)\nEpoch #31: loss=1.575050 (contrastive=1.697618, msm=0.471931, =0.100)\nEpoch #32: loss=1.386789 (contrastive=1.489283, msm=0.464342, =0.100)\nEpoch #33: loss=1.501887 (contrastive=1.619457, msm=0.443753, =0.100)\nEpoch #34: loss=1.660056 (contrastive=1.797027, msm=0.427313, =0.100)\nEpoch #35: loss=1.574229 (contrastive=1.703562, msm=0.410230, =0.100)\nEpoch #36: loss=1.416659 (contrastive=1.530334, msm=0.393586, =0.100)\nEpoch #37: loss=1.277624 (contrastive=1.376302, msm=0.389522, =0.100)\nEpoch #38: loss=1.363666 (contrastive=1.474265, msm=0.368277, =0.100)\nEpoch #39: loss=1.392169 (contrastive=1.507096, msm=0.357824, =0.100)\nEpoch #40: loss=1.381811 (contrastive=1.498389, msm=0.332604, =0.100)\nEpoch #41: loss=1.258050 (contrastive=1.360935, msm=0.332092, =0.100)\nEpoch #42: loss=1.468754 (contrastive=1.595598, msm=0.327163, =0.100)\nEpoch #43: loss=1.372993 (contrastive=1.490745, msm=0.313225, =0.100)\nEpoch #44: loss=1.337711 (contrastive=1.451878, msm=0.310212, =0.100)\nEpoch #45: loss=1.398313 (contrastive=1.521529, msm=0.289361, =0.100)\nEpoch #46: loss=1.350819 (contrastive=1.469813, msm=0.279876, =0.100)\nEpoch #47: loss=1.256048 (contrastive=1.365514, msm=0.270854, =0.100)\nEpoch #48: loss=1.262928 (contrastive=1.372890, msm=0.273270, =0.100)\nEpoch #49: loss=1.165101 (contrastive=1.264697, msm=0.268740, =0.100)\nEpoch #50: loss=1.174419 (contrastive=1.275936, msm=0.260765, =0.100)\nEpoch #51: loss=1.230091 (contrastive=1.339075, msm=0.249238, =0.100)\nEpoch #52: loss=1.081158 (contrastive=1.173439, msm=0.250632, =0.100)\nEpoch #53: loss=1.199824 (contrastive=1.306557, msm=0.239224, =0.100)\nEpoch #54: loss=1.163063 (contrastive=1.265069, msm=0.245014, =0.100)\nEpoch #55: loss=1.095904 (contrastive=1.191424, msm=0.236220, =0.100)\nEpoch #56: loss=1.076925 (contrastive=1.170149, msm=0.237914, =0.100)\nEpoch #57: loss=1.054575 (contrastive=1.146846, msm=0.224143, =0.100)\nEpoch #58: loss=1.015769 (contrastive=1.104086, msm=0.220910, =0.100)\nEpoch #59: loss=1.077997 (contrastive=1.173181, msm=0.221345, =0.100)\nEpoch #60: loss=1.096767 (contrastive=1.195006, msm=0.212615, =0.100)\nEpoch #61: loss=1.145228 (contrastive=1.249130, msm=0.210118, =0.100)\nEpoch #62: loss=0.946842 (contrastive=1.028070, msm=0.215785, =0.100)\nEpoch #63: loss=1.013900 (contrastive=1.102635, msm=0.215291, =0.100)\nEpoch #64: loss=0.946555 (contrastive=1.029384, msm=0.201092, =0.100)\nEpoch #65: loss=1.038347 (contrastive=1.131107, msm=0.203514, =0.100)\nEpoch #66: loss=1.402455 (contrastive=1.535791, msm=0.202436, =0.100)\nEpoch #67: loss=1.059081 (contrastive=1.153806, msm=0.206556, =0.100)\nEpoch #68: loss=0.944800 (contrastive=1.027229, msm=0.202943, =0.100)\nEpoch #69: loss=1.222504 (contrastive=1.335823, msm=0.202624, =0.100)\nEpoch #70: loss=0.925526 (contrastive=1.005310, msm=0.207470, =0.100)\nEpoch #71: loss=0.957022 (contrastive=1.040059, msm=0.209694, =0.100)\nEpoch #72: loss=0.979111 (contrastive=1.065375, msm=0.202737, =0.100)\nEpoch #73: loss=0.834343 (contrastive=0.904973, msm=0.198674, =0.100)\nEpoch #74: loss=0.960981 (contrastive=1.045531, msm=0.200030, =0.100)\nEpoch #75: loss=0.835970 (contrastive=0.907068, msm=0.196091, =0.100)\nEpoch #76: loss=1.175764 (contrastive=1.283900, msm=0.202540, =0.100)\nEpoch #77: loss=0.802946 (contrastive=0.870463, msm=0.195293, =0.100)\nEpoch #78: loss=0.729233 (contrastive=0.788466, msm=0.196134, =0.100)\nEpoch #79: loss=0.829810 (contrastive=0.900496, msm=0.193632, =0.100)\nEpoch #80: loss=0.884158 (contrastive=0.961533, msm=0.187782, =0.100)\nEpoch #81: loss=0.767284 (contrastive=0.831638, msm=0.188096, =0.100)\nEpoch #82: loss=1.042352 (contrastive=1.137580, msm=0.185300, =0.100)\nEpoch #83: loss=1.092301 (contrastive=1.193179, msm=0.184394, =0.100)\nEpoch #84: loss=0.793373 (contrastive=0.862111, msm=0.174724, =0.100)\nEpoch #85: loss=0.827542 (contrastive=0.899514, msm=0.179799, =0.100)\nEpoch #86: loss=0.721872 (contrastive=0.782248, msm=0.178487, =0.100)\nEpoch #87: loss=0.906028 (contrastive=0.986165, msm=0.184800, =0.100)\nEpoch #88: loss=0.699098 (contrastive=0.756331, msm=0.183997, =0.100)\nEpoch #89: loss=1.242833 (contrastive=1.361184, msm=0.177680, =0.100)\nEpoch #90: loss=0.778418 (contrastive=0.844790, msm=0.181073, =0.100)\nEpoch #91: loss=0.868522 (contrastive=0.945809, msm=0.172945, =0.100)\nEpoch #92: loss=1.045344 (contrastive=1.142053, msm=0.174960, =0.100)\nEpoch #93: loss=0.836312 (contrastive=0.909548, msm=0.177185, =0.100)\nEpoch #94: loss=0.847496 (contrastive=0.923037, msm=0.167625, =0.100)\nEpoch #95: loss=0.694831 (contrastive=0.752871, msm=0.172475, =0.100)\nEpoch #96: loss=0.778304 (contrastive=0.845813, msm=0.170718, =0.100)\nEpoch #97: loss=0.860454 (contrastive=0.936556, msm=0.175535, =0.100)\nEpoch #98: loss=0.679530 (contrastive=0.736223, msm=0.169295, =0.100)\nEpoch #99: loss=0.918357 (contrastive=1.002159, msm=0.164131, =0.100)\nEpoch #100: loss=0.753900 (contrastive=0.819384, msm=0.164538, =0.100)\nEpoch #101: loss=0.928322 (contrastive=1.012804, msm=0.167984, =0.100)\nEpoch #102: loss=0.742267 (contrastive=0.805309, msm=0.174891, =0.100)\nEpoch #103: loss=1.086934 (contrastive=1.188590, msm=0.172025, =0.100)\nEpoch #104: loss=0.772240 (contrastive=0.838641, msm=0.174637, =0.100)\nEpoch #105: loss=0.663891 (contrastive=0.719408, msm=0.164235, =0.100)\nEpoch #106: loss=0.820893 (contrastive=0.894445, msm=0.158928, =0.100)\nEpoch #107: loss=0.692451 (contrastive=0.751489, msm=0.161113, =0.100)\nEpoch #108: loss=0.786750 (contrastive=0.856603, msm=0.158079, =0.100)\nEpoch #109: loss=0.882393 (contrastive=0.962723, msm=0.159425, =0.100)\nEpoch #110: loss=0.753666 (contrastive=0.818689, msm=0.168464, =0.100)\nEpoch #111: loss=1.380071 (contrastive=1.514915, msm=0.166470, =0.100)\nEpoch #112: loss=0.632593 (contrastive=0.685251, msm=0.158677, =0.100)\nEpoch #113: loss=0.676221 (contrastive=0.733525, msm=0.160483, =0.100)\nEpoch #114: loss=1.046551 (contrastive=1.144883, msm=0.161559, =0.100)\nEpoch #115: loss=0.689556 (contrastive=0.748304, msm=0.160821, =0.100)\nEpoch #116: loss=0.671671 (contrastive=0.728096, msm=0.163842, =0.100)\nEpoch #117: loss=0.687580 (contrastive=0.745901, msm=0.162693, =0.100)\nEpoch #118: loss=0.800892 (contrastive=0.872609, msm=0.155443, =0.100)\nEpoch #119: loss=0.811916 (contrastive=0.885063, msm=0.153598, =0.100)\nEpoch #120: loss=0.602901 (contrastive=0.652466, msm=0.156813, =0.100)\nEpoch #121: loss=0.610312 (contrastive=0.659703, msm=0.165795, =0.100)\nEpoch #122: loss=0.862705 (contrastive=0.940470, msm=0.162816, =0.100)\nEpoch #123: loss=0.612199 (contrastive=0.662670, msm=0.157964, =0.100)\nEpoch #124: loss=0.591698 (contrastive=0.640233, msm=0.154887, =0.100)\nEpoch #125: loss=0.644025 (contrastive=0.697830, msm=0.159786, =0.100)\nEpoch #126: loss=0.837350 (contrastive=0.913748, msm=0.149766, =0.100)\nEpoch #127: loss=0.704462 (contrastive=0.765291, msm=0.157001, =0.100)\nEpoch #128: loss=1.631025 (contrastive=1.795028, msm=0.154998, =0.100)\nEpoch #129: loss=0.570578 (contrastive=0.615865, msm=0.162991, =0.100)\nEpoch #130: loss=0.625588 (contrastive=0.676124, msm=0.170763, =0.100)\nEpoch #131: loss=0.650644 (contrastive=0.703651, msm=0.173581, =0.100)\nEpoch #132: loss=0.704994 (contrastive=0.764209, msm=0.172058, =0.100)\nEpoch #133: loss=0.672094 (contrastive=0.727191, msm=0.176224, =0.100)\nEpoch #134: loss=0.606797 (contrastive=0.654885, msm=0.174003, =0.100)\nEpoch #135: loss=0.598771 (contrastive=0.645980, msm=0.173892, =0.100)\nEpoch #136: loss=0.588212 (contrastive=0.635162, msm=0.165657, =0.100)\nEpoch #137: loss=0.508554 (contrastive=0.546235, msm=0.169425, =0.100)\nEpoch #138: loss=0.522751 (contrastive=0.563071, msm=0.159867, =0.100)\nEpoch #139: loss=0.525564 (contrastive=0.566182, msm=0.159999, =0.100)\nEpoch #140: loss=0.788893 (contrastive=0.858848, msm=0.159296, =0.100)\nEpoch #141: loss=1.238912 (contrastive=1.359464, msm=0.153946, =0.100)\nEpoch #142: loss=0.486255 (contrastive=0.522498, msm=0.160063, =0.100)\nEpoch #143: loss=0.524804 (contrastive=0.566069, msm=0.153423, =0.100)\nEpoch #144: loss=0.891941 (contrastive=0.974578, msm=0.148203, =0.100)\nEpoch #145: loss=0.544178 (contrastive=0.588423, msm=0.145976, =0.100)\nEpoch #146: loss=0.455529 (contrastive=0.489951, msm=0.145726, =0.100)\nEpoch #147: loss=0.499410 (contrastive=0.538696, msm=0.145838, =0.100)\nEpoch #148: loss=0.565467 (contrastive=0.612172, msm=0.145117, =0.100)\nEpoch #149: loss=0.659165 (contrastive=0.716497, msm=0.143179, =0.100)\nEpoch #150: loss=0.494500 (contrastive=0.533277, msm=0.145510, =0.100)\nEpoch #151: loss=0.430656 (contrastive=0.462089, msm=0.147755, =0.100)\nEpoch #152: loss=0.547707 (contrastive=0.592843, msm=0.141485, =0.100)\nEpoch #153: loss=0.385443 (contrastive=0.411955, msm=0.146839, =0.100)\nEpoch #154: loss=0.460715 (contrastive=0.495629, msm=0.146494, =0.100)\nEpoch #155: loss=0.403365 (contrastive=0.432678, msm=0.139543, =0.100)\nEpoch #156: loss=1.010619 (contrastive=1.107143, msm=0.141904, =0.100)\nEpoch #157: loss=0.457226 (contrastive=0.492150, msm=0.142907, =0.100)\nEpoch #158: loss=0.549766 (contrastive=0.595171, msm=0.141121, =0.100)\nEpoch #159: loss=0.580719 (contrastive=0.629857, msm=0.138477, =0.100)\nEpoch #160: loss=0.533122 (contrastive=0.577077, msm=0.137534, =0.100)\nEpoch #161: loss=0.477620 (contrastive=0.515332, msm=0.138213, =0.100)\nEpoch #162: loss=0.451092 (contrastive=0.485863, msm=0.138152, =0.100)\nEpoch #163: loss=0.425801 (contrastive=0.457588, msm=0.139720, =0.100)\nEpoch #164: loss=0.373844 (contrastive=0.400031, msm=0.138165, =0.100)\nEpoch #165: loss=0.490578 (contrastive=0.529638, msm=0.139043, =0.100)\nEpoch #166: loss=1.089589 (contrastive=1.194973, msm=0.141134, =0.100)\nEpoch #167: loss=0.446364 (contrastive=0.480220, msm=0.141658, =0.100)\nEpoch #168: loss=0.594716 (contrastive=0.645634, msm=0.136451, =0.100)\nEpoch #169: loss=1.035166 (contrastive=1.135686, msm=0.130483, =0.100)\nEpoch #170: loss=0.512174 (contrastive=0.554414, msm=0.132013, =0.100)\nEpoch #171: loss=0.565965 (contrastive=0.614166, msm=0.132152, =0.100)\nEpoch #172: loss=0.488582 (contrastive=0.528205, msm=0.131977, =0.100)\nEpoch #173: loss=0.453202 (contrastive=0.488348, msm=0.136892, =0.100)\nEpoch #174: loss=0.392470 (contrastive=0.420870, msm=0.136874, =0.100)\nEpoch #175: loss=0.447602 (contrastive=0.482298, msm=0.135337, =0.100)\nEpoch #176: loss=0.610349 (contrastive=0.663229, msm=0.134431, =0.100)\nEpoch #177: loss=0.356498 (contrastive=0.381474, msm=0.131716, =0.100)\nEpoch #178: loss=0.381039 (contrastive=0.408684, msm=0.132234, =0.100)\nEpoch #179: loss=1.125088 (contrastive=1.235640, msm=0.130118, =0.100)\nEpoch #180: loss=0.593471 (contrastive=0.644524, msm=0.133992, =0.100)\nEpoch #181: loss=0.409824 (contrastive=0.440686, msm=0.132064, =0.100)\nEpoch #182: loss=0.482432 (contrastive=0.521573, msm=0.130160, =0.100)\nEpoch #183: loss=0.720796 (contrastive=0.786903, msm=0.125832, =0.100)\nEpoch #184: loss=0.398997 (contrastive=0.429340, msm=0.125902, =0.100)\nEpoch #185: loss=0.620091 (contrastive=0.675196, msm=0.124145, =0.100)\nEpoch #186: loss=0.762833 (contrastive=0.834330, msm=0.119363, =0.100)\nEpoch #187: loss=0.432605 (contrastive=0.466440, msm=0.128092, =0.100)\nEpoch #188: loss=0.492070 (contrastive=0.531718, msm=0.135244, =0.100)\nEpoch #189: loss=0.783341 (contrastive=0.854963, msm=0.138741, =0.100)\nEpoch #190: loss=0.455164 (contrastive=0.490015, msm=0.141499, =0.100)\nEpoch #191: loss=0.424395 (contrastive=0.456065, msm=0.139369, =0.100)\nEpoch #192: loss=0.505399 (contrastive=0.546078, msm=0.139290, =0.100)\nEpoch #193: loss=0.520998 (contrastive=0.563697, msm=0.136710, =0.100)\nEpoch #194: loss=0.509875 (contrastive=0.551373, msm=0.136391, =0.100)\nEpoch #195: loss=0.468276 (contrastive=0.505551, msm=0.132799, =0.100)\nEpoch #196: loss=0.426109 (contrastive=0.458584, msm=0.133835, =0.100)\nEpoch #197: loss=0.415116 (contrastive=0.446579, msm=0.131949, =0.100)\nEpoch #198: loss=0.697244 (contrastive=0.760287, msm=0.129862, =0.100)\nEpoch #199: loss=0.396108 (contrastive=0.426057, msm=0.126567, =0.100)\nEpoch #200: loss=0.397147 (contrastive=0.427097, msm=0.127594, =0.100)\nEpoch #201: loss=0.351297 (contrastive=0.376844, msm=0.121374, =0.100)\nEpoch #202: loss=0.422710 (contrastive=0.456564, msm=0.118028, =0.100)\nEpoch #203: loss=0.336286 (contrastive=0.359882, msm=0.123914, =0.100)\nEpoch #204: loss=0.310994 (contrastive=0.331488, msm=0.126545, =0.100)\nEpoch #205: loss=0.427722 (contrastive=0.460591, msm=0.131902, =0.100)\nEpoch #206: loss=0.329058 (contrastive=0.352117, msm=0.121529, =0.100)\nEpoch #207: loss=0.523529 (contrastive=0.568218, msm=0.121331, =0.100)\nEpoch #208: loss=0.364446 (contrastive=0.391623, msm=0.119854, =0.100)\nEpoch #209: loss=0.659845 (contrastive=0.719852, msm=0.119779, =0.100)\nEpoch #210: loss=0.341747 (contrastive=0.365844, msm=0.124880, =0.100)\nEpoch #211: loss=0.299875 (contrastive=0.319741, msm=0.121088, =0.100)\nEpoch #212: loss=0.720094 (contrastive=0.786776, msm=0.119951, =0.100)\nEpoch #213: loss=0.345839 (contrastive=0.371061, msm=0.118835, =0.100)\nEpoch #214: loss=0.394457 (contrastive=0.425102, msm=0.118649, =0.100)\nEpoch #215: loss=0.471934 (contrastive=0.511133, msm=0.119143, =0.100)\nEpoch #216: loss=0.741148 (contrastive=0.810669, msm=0.115457, =0.100)\nEpoch #217: loss=0.336028 (contrastive=0.360793, msm=0.113142, =0.100)\nEpoch #218: loss=0.624699 (contrastive=0.681191, msm=0.116269, =0.100)\nEpoch #219: loss=0.341562 (contrastive=0.367302, msm=0.109902, =0.100)\nEpoch #220: loss=0.304466 (contrastive=0.325926, msm=0.111322, =0.100)\nEpoch #221: loss=0.289132 (contrastive=0.308684, msm=0.113163, =0.100)\nEpoch #222: loss=0.305023 (contrastive=0.326182, msm=0.114596, =0.100)\nEpoch #223: loss=0.430355 (contrastive=0.465650, msm=0.112699, =0.100)\nEpoch #224: loss=0.310618 (contrastive=0.332140, msm=0.116921, =0.100)\nEpoch #225: loss=0.384219 (contrastive=0.414252, msm=0.113927, =0.100)\nEpoch #226: loss=0.301892 (contrastive=0.323427, msm=0.108072, =0.100)\nEpoch #227: loss=0.421391 (contrastive=0.455990, msm=0.109999, =0.100)\nEpoch #228: loss=0.498967 (contrastive=0.541566, msm=0.115581, =0.100)\nEpoch #229: loss=0.260973 (contrastive=0.277342, msm=0.113655, =0.100)\nEpoch #230: loss=0.664019 (contrastive=0.725554, msm=0.110204, =0.100)\nEpoch #231: loss=0.374710 (contrastive=0.404104, msm=0.110170, =0.100)\nEpoch #232: loss=0.361564 (contrastive=0.389772, msm=0.107684, =0.100)\nEpoch #233: loss=0.362785 (contrastive=0.391001, msm=0.108848, =0.100)\nEpoch #234: loss=0.280093 (contrastive=0.298939, msm=0.110483, =0.100)\nEpoch #235: loss=0.295918 (contrastive=0.316207, msm=0.113319, =0.100)\nEpoch #236: loss=0.805594 (contrastive=0.882813, msm=0.110617, =0.100)\nEpoch #237: loss=0.412262 (contrastive=0.445828, msm=0.110173, =0.100)\nEpoch #238: loss=0.837150 (contrastive=0.917912, msm=0.110293, =0.100)\nEpoch #239: loss=0.335958 (contrastive=0.360680, msm=0.113460, =0.100)\nEpoch #240: loss=0.344572 (contrastive=0.370226, msm=0.113682, =0.100)\nEpoch #241: loss=0.300182 (contrastive=0.320862, msm=0.114059, =0.100)\nEpoch #242: loss=0.341509 (contrastive=0.366984, msm=0.112235, =0.100)\nEpoch #243: loss=0.439733 (contrastive=0.475909, msm=0.114150, =0.100)\nEpoch #244: loss=0.489428 (contrastive=0.531428, msm=0.111419, =0.100)\nEpoch #245: loss=0.318144 (contrastive=0.340378, msm=0.118030, =0.100)\nEpoch #246: loss=0.330838 (contrastive=0.355110, msm=0.112390, =0.100)\nEpoch #247: loss=0.307309 (contrastive=0.329392, msm=0.108568, =0.100)\nEpoch #248: loss=0.290710 (contrastive=0.310341, msm=0.114030, =0.100)\nEpoch #249: loss=0.279601 (contrastive=0.298499, msm=0.109516, =0.100)\nEpoch #250: loss=0.431963 (contrastive=0.467446, msm=0.112624, =0.100)\nEpoch #251: loss=0.260910 (contrastive=0.276847, msm=0.117476, =0.100)\nEpoch #252: loss=0.411029 (contrastive=0.444193, msm=0.112545, =0.100)\nEpoch #253: loss=0.328096 (contrastive=0.352176, msm=0.111380, =0.100)\nEpoch #254: loss=0.347192 (contrastive=0.373379, msm=0.111510, =0.100)\nEpoch #255: loss=0.291118 (contrastive=0.311197, msm=0.110409, =0.100)\nEpoch #256: loss=0.304333 (contrastive=0.325493, msm=0.113888, =0.100)\nEpoch #257: loss=0.794816 (contrastive=0.870916, msm=0.109921, =0.100)\nEpoch #258: loss=1.581585 (contrastive=1.745376, msm=0.107467, =0.100)\nEpoch #259: loss=0.642537 (contrastive=0.701482, msm=0.112031, =0.100)\nEpoch #260: loss=0.611439 (contrastive=0.665919, msm=0.121114, =0.100)\nEpoch #261: loss=0.447684 (contrastive=0.482843, msm=0.131253, =0.100)\nEpoch #262: loss=0.333839 (contrastive=0.355250, msm=0.141134, =0.100)\nEpoch #263: loss=0.384079 (contrastive=0.411346, msm=0.138676, =0.100)\nEpoch #264: loss=0.454116 (contrastive=0.490595, msm=0.125806, =0.100)\nEpoch #265: loss=0.527555 (contrastive=0.572589, msm=0.122252, =0.100)\nEpoch #266: loss=1.067352 (contrastive=1.172312, msm=0.122712, =0.100)\nEpoch #267: loss=0.373419 (contrastive=0.399209, msm=0.141309, =0.100)\nEpoch #268: loss=0.579891 (contrastive=0.626737, msm=0.158277, =0.100)\nEpoch #269: loss=1.178963 (contrastive=1.292500, msm=0.157136, =0.100)\nEpoch #270: loss=0.547552 (contrastive=0.592347, msm=0.144399, =0.100)\nEpoch #271: loss=0.453919 (contrastive=0.490216, msm=0.127250, =0.100)\nEpoch #272: loss=0.444636 (contrastive=0.480455, msm=0.122265, =0.100)\nEpoch #273: loss=0.749752 (contrastive=0.819177, msm=0.124926, =0.100)\nEpoch #274: loss=0.420548 (contrastive=0.452658, msm=0.131564, =0.100)\nEpoch #275: loss=0.426408 (contrastive=0.458490, msm=0.137672, =0.100)\nEpoch #276: loss=0.813137 (contrastive=0.888202, msm=0.137553, =0.100)\nEpoch #277: loss=0.453984 (contrastive=0.489401, msm=0.135232, =0.100)\nEpoch #278: loss=0.496637 (contrastive=0.538330, msm=0.121396, =0.100)\nEpoch #279: loss=0.397897 (contrastive=0.427835, msm=0.128460, =0.100)\nEpoch #280: loss=0.355767 (contrastive=0.381860, msm=0.120930, =0.100)\nEpoch #281: loss=0.517478 (contrastive=0.561003, msm=0.125759, =0.100)\nEpoch #282: loss=0.344110 (contrastive=0.368515, msm=0.124462, =0.100)\nEpoch #283: loss=0.392230 (contrastive=0.421668, msm=0.127286, =0.100)\nEpoch #284: loss=0.491583 (contrastive=0.532129, msm=0.126668, =0.100)\nEpoch #285: loss=0.305012 (contrastive=0.325508, msm=0.120554, =0.100)\nEpoch #286: loss=0.374996 (contrastive=0.403410, msm=0.119275, =0.100)\nEpoch #287: loss=0.409383 (contrastive=0.441823, msm=0.117423, =0.100)\nEpoch #288: loss=0.660898 (contrastive=0.721362, msm=0.116722, =0.100)\nEpoch #289: loss=0.332011 (contrastive=0.356140, msm=0.114848, =0.100)\nEpoch #290: loss=0.377327 (contrastive=0.406476, msm=0.114989, =0.100)\nEpoch #291: loss=0.299384 (contrastive=0.319293, msm=0.120205, =0.100)\nEpoch #292: loss=0.321565 (contrastive=0.344016, msm=0.119506, =0.100)\nEpoch #293: loss=0.272198 (contrastive=0.289137, msm=0.119752, =0.100)\nEpoch #294: loss=0.266808 (contrastive=0.283363, msm=0.117813, =0.100)\nEpoch #295: loss=0.666960 (contrastive=0.728739, msm=0.110952, =0.100)\nEpoch #296: loss=0.314398 (contrastive=0.336785, msm=0.112916, =0.100)\nEpoch #297: loss=0.309088 (contrastive=0.330917, msm=0.112625, =0.100)\nEpoch #298: loss=0.321420 (contrastive=0.345100, msm=0.108298, =0.100)\nEpoch #299: loss=0.241320 (contrastive=0.256290, msm=0.106592, =0.100)\nEpoch #300: loss=0.680558 (contrastive=0.744440, msm=0.105621, =0.100)\nEpoch #301: loss=0.282981 (contrastive=0.302459, msm=0.107674, =0.100)\nEpoch #302: loss=0.392234 (contrastive=0.423521, msm=0.110649, =0.100)\nEpoch #303: loss=0.231053 (contrastive=0.244962, msm=0.105864, =0.100)\nEpoch #304: loss=0.316166 (contrastive=0.339447, msm=0.106641, =0.100)\nEpoch #305: loss=0.308878 (contrastive=0.331454, msm=0.105690, =0.100)\nEpoch #306: loss=0.364804 (contrastive=0.393826, msm=0.103605, =0.100)\nEpoch #307: loss=0.475327 (contrastive=0.516089, msm=0.108472, =0.100)\nEpoch #308: loss=0.255337 (contrastive=0.272137, msm=0.104141, =0.100)\nEpoch #309: loss=0.330156 (contrastive=0.354999, msm=0.106567, =0.100)\nEpoch #310: loss=0.344746 (contrastive=0.371669, msm=0.102446, =0.100)\nEpoch #311: loss=0.255861 (contrastive=0.272803, msm=0.103385, =0.100)\nEpoch #312: loss=0.413572 (contrastive=0.448279, msm=0.101209, =0.100)\nEpoch #313: loss=0.381327 (contrastive=0.412329, msm=0.102314, =0.100)\nEpoch #314: loss=0.286126 (contrastive=0.305897, msm=0.108191, =0.100)\nEpoch #315: loss=0.515369 (contrastive=0.560934, msm=0.105285, =0.100)\nEpoch #316: loss=0.281515 (contrastive=0.300898, msm=0.107063, =0.100)\nEpoch #317: loss=0.433203 (contrastive=0.469688, msm=0.104833, =0.100)\nEpoch #318: loss=0.338344 (contrastive=0.364448, msm=0.103410, =0.100)\nEpoch #319: loss=0.263875 (contrastive=0.281785, msm=0.102684, =0.100)\nEpoch #320: loss=0.269676 (contrastive=0.287988, msm=0.104862, =0.100)\nEpoch #321: loss=0.321303 (contrastive=0.345183, msm=0.106386, =0.100)\nEpoch #322: loss=0.268882 (contrastive=0.287209, msm=0.103942, =0.100)\nEpoch #323: loss=0.285580 (contrastive=0.305918, msm=0.102538, =0.100)\nEpoch #324: loss=0.277015 (contrastive=0.296942, msm=0.097672, =0.100)\nEpoch #325: loss=0.243292 (contrastive=0.258811, msm=0.103614, =0.100)\nEpoch #326: loss=0.325645 (contrastive=0.350622, msm=0.100855, =0.100)\nEpoch #327: loss=0.232351 (contrastive=0.247165, msm=0.099021, =0.100)\nEpoch #328: loss=0.366907 (contrastive=0.397219, msm=0.094097, =0.100)\nEpoch #329: loss=0.252090 (contrastive=0.269213, msm=0.097984, =0.100)\nEpoch #330: loss=0.282219 (contrastive=0.302136, msm=0.102966, =0.100)\nEpoch #331: loss=0.299227 (contrastive=0.321390, msm=0.099766, =0.100)\nEpoch #332: loss=0.224046 (contrastive=0.237996, msm=0.098498, =0.100)\nEpoch #333: loss=0.223999 (contrastive=0.237895, msm=0.098931, =0.100)\nEpoch #334: loss=0.204593 (contrastive=0.216541, msm=0.097054, =0.100)\nEpoch #335: loss=0.369757 (contrastive=0.400367, msm=0.094270, =0.100)\nEpoch #336: loss=0.224658 (contrastive=0.239087, msm=0.094797, =0.100)\nEpoch #337: loss=0.482375 (contrastive=0.525126, msm=0.097616, =0.100)\nEpoch #338: loss=0.229595 (contrastive=0.244238, msm=0.097813, =0.100)\nEpoch #339: loss=0.288339 (contrastive=0.309943, msm=0.093901, =0.100)\nEpoch #340: loss=0.240963 (contrastive=0.256667, msm=0.099633, =0.100)\nEpoch #341: loss=0.208346 (contrastive=0.220413, msm=0.099749, =0.100)\nEpoch #342: loss=0.518631 (contrastive=0.565347, msm=0.098187, =0.100)\nEpoch #343: loss=0.248735 (contrastive=0.265803, msm=0.095124, =0.100)\nEpoch #344: loss=0.451776 (contrastive=0.491199, msm=0.096967, =0.100)\nEpoch #345: loss=0.196692 (contrastive=0.208004, msm=0.094882, =0.100)\nEpoch #346: loss=0.296152 (contrastive=0.318387, msm=0.096039, =0.100)\nEpoch #347: loss=0.199640 (contrastive=0.211402, msm=0.093774, =0.100)\nEpoch #348: loss=0.324773 (contrastive=0.350466, msm=0.093539, =0.100)\nEpoch #349: loss=0.217546 (contrastive=0.231167, msm=0.094959, =0.100)\nEpoch #350: loss=0.361836 (contrastive=0.391732, msm=0.092771, =0.100)\nEpoch #351: loss=0.300975 (contrastive=0.323770, msm=0.095824, =0.100)\nEpoch #352: loss=0.232537 (contrastive=0.248061, msm=0.092823, =0.100)\nEpoch #353: loss=0.907165 (contrastive=0.997295, msm=0.095995, =0.100)\nEpoch #354: loss=0.289037 (contrastive=0.310539, msm=0.095518, =0.100)\nEpoch #355: loss=0.219079 (contrastive=0.232638, msm=0.097049, =0.100)\nEpoch #356: loss=0.574476 (contrastive=0.627447, msm=0.097730, =0.100)\nEpoch #357: loss=0.272834 (contrastive=0.291808, msm=0.102072, =0.100)\nEpoch #358: loss=0.479628 (contrastive=0.521495, msm=0.102827, =0.100)\nEpoch #359: loss=0.383384 (contrastive=0.414988, msm=0.098948, =0.100)\nEpoch #360: loss=0.365128 (contrastive=0.394491, msm=0.100860, =0.100)\nEpoch #361: loss=0.243019 (contrastive=0.259203, msm=0.097366, =0.100)\nEpoch #362: loss=0.343892 (contrastive=0.371170, msm=0.098383, =0.100)\nEpoch #363: loss=0.398059 (contrastive=0.431287, msm=0.099004, =0.100)\nEpoch #364: loss=0.223749 (contrastive=0.237551, msm=0.099533, =0.100)\nEpoch #365: loss=0.298998 (contrastive=0.320797, msm=0.102805, =0.100)\nEpoch #366: loss=0.244159 (contrastive=0.260350, msm=0.098437, =0.100)\nEpoch #367: loss=0.197954 (contrastive=0.209186, msm=0.096868, =0.100)\nEpoch #368: loss=0.269575 (contrastive=0.288114, msm=0.102719, =0.100)\nEpoch #369: loss=0.245701 (contrastive=0.262618, msm=0.093445, =0.100)\nEpoch #370: loss=0.392131 (contrastive=0.425076, msm=0.095626, =0.100)\nEpoch #371: loss=0.204876 (contrastive=0.216962, msm=0.096098, =0.100)\nEpoch #372: loss=0.244543 (contrastive=0.261322, msm=0.093533, =0.100)\nEpoch #373: loss=0.261078 (contrastive=0.279416, msm=0.096036, =0.100)\nEpoch #374: loss=0.233180 (contrastive=0.248480, msm=0.095476, =0.100)\nEpoch #375: loss=0.211325 (contrastive=0.224181, msm=0.095624, =0.100)\nEpoch #376: loss=0.243519 (contrastive=0.259821, msm=0.096797, =0.100)\nEpoch #377: loss=0.291171 (contrastive=0.313214, msm=0.092782, =0.100)\nEpoch #378: loss=0.433826 (contrastive=0.471395, msm=0.095704, =0.100)\nEpoch #379: loss=0.212701 (contrastive=0.226338, msm=0.089968, =0.100)\nEpoch #380: loss=0.217214 (contrastive=0.231224, msm=0.091124, =0.100)\nEpoch #381: loss=0.205018 (contrastive=0.217734, msm=0.090570, =0.100)\nEpoch #382: loss=0.180993 (contrastive=0.190677, msm=0.093839, =0.100)\nEpoch #383: loss=0.234819 (contrastive=0.250673, msm=0.092138, =0.100)\nEpoch #384: loss=1.657734 (contrastive=1.831987, msm=0.089455, =0.100)\nEpoch #385: loss=0.220418 (contrastive=0.234783, msm=0.091138, =0.100)\nEpoch #386: loss=0.224493 (contrastive=0.238780, msm=0.095909, =0.100)\nEpoch #387: loss=0.337838 (contrastive=0.364677, msm=0.096285, =0.100)\nEpoch #388: loss=0.287711 (contrastive=0.308742, msm=0.098427, =0.100)\nEpoch #389: loss=0.260870 (contrastive=0.279237, msm=0.095562, =0.100)\nEpoch #390: loss=0.238814 (contrastive=0.254948, msm=0.093606, =0.100)\nEpoch #391: loss=0.247551 (contrastive=0.264296, msm=0.096854, =0.100)\nEpoch #392: loss=0.579118 (contrastive=0.633169, msm=0.092656, =0.100)\nEpoch #393: loss=0.252118 (contrastive=0.269134, msm=0.098973, =0.100)\nEpoch #394: loss=0.320565 (contrastive=0.345543, msm=0.095756, =0.100)\nEpoch #395: loss=0.233031 (contrastive=0.248362, msm=0.095051, =0.100)\nEpoch #396: loss=0.347008 (contrastive=0.374528, msm=0.099331, =0.100)\nEpoch #397: loss=0.232939 (contrastive=0.248075, msm=0.096715, =0.100)\nEpoch #398: loss=0.216341 (contrastive=0.230134, msm=0.092210, =0.100)\nEpoch #399: loss=0.230824 (contrastive=0.246398, msm=0.090656, =0.100)\nEpoch #400: loss=0.210929 (contrastive=0.223894, msm=0.094238, =0.100)\nEpoch #401: loss=0.597577 (contrastive=0.653727, msm=0.092224, =0.100)\nEpoch #402: loss=0.230566 (contrastive=0.245986, msm=0.091788, =0.100)\nEpoch #403: loss=0.198840 (contrastive=0.210537, msm=0.093564, =0.100)\nEpoch #404: loss=0.224436 (contrastive=0.238685, msm=0.096200, =0.100)\nEpoch #405: loss=0.268714 (contrastive=0.288136, msm=0.093919, =0.100)\nEpoch #406: loss=0.202648 (contrastive=0.215442, msm=0.087499, =0.100)\nEpoch #407: loss=0.175970 (contrastive=0.185527, msm=0.089961, =0.100)\nEpoch #408: loss=0.605536 (contrastive=0.663245, msm=0.086156, =0.100)\nEpoch #409: loss=0.214236 (contrastive=0.227871, msm=0.091521, =0.100)\nEpoch #410: loss=0.199156 (contrastive=0.211458, msm=0.088437, =0.100)\nEpoch #411: loss=0.192956 (contrastive=0.204574, msm=0.088396, =0.100)\nEpoch #412: loss=0.482614 (contrastive=0.526778, msm=0.085143, =0.100)\nEpoch #413: loss=0.321206 (contrastive=0.347108, msm=0.088086, =0.100)\nEpoch #414: loss=0.315553 (contrastive=0.340782, msm=0.088484, =0.100)\nEpoch #415: loss=0.233787 (contrastive=0.250040, msm=0.087503, =0.100)\nEpoch #416: loss=0.260101 (contrastive=0.279211, msm=0.088107, =0.100)\nEpoch #417: loss=0.179942 (contrastive=0.190212, msm=0.087513, =0.100)\nEpoch #418: loss=0.194846 (contrastive=0.206543, msm=0.089571, =0.100)\nEpoch #419: loss=0.196045 (contrastive=0.207990, msm=0.088539, =0.100)\nEpoch #420: loss=0.227964 (contrastive=0.243604, msm=0.087205, =0.100)\nEpoch #421: loss=0.213089 (contrastive=0.227121, msm=0.086794, =0.100)\nEpoch #422: loss=0.193527 (contrastive=0.205607, msm=0.084807, =0.100)\nEpoch #423: loss=0.211298 (contrastive=0.225257, msm=0.085669, =0.100)\nEpoch #424: loss=0.333487 (contrastive=0.361380, msm=0.082451, =0.100)\nEpoch #425: loss=0.164037 (contrastive=0.172426, msm=0.088534, =0.100)\nEpoch #426: loss=0.178463 (contrastive=0.188659, msm=0.086701, =0.100)\nEpoch #427: loss=0.287827 (contrastive=0.310030, msm=0.087995, =0.100)\nEpoch #428: loss=0.160882 (contrastive=0.168886, msm=0.088849, =0.100)\nEpoch #429: loss=0.189541 (contrastive=0.201119, msm=0.085338, =0.100)\nEpoch #430: loss=0.221995 (contrastive=0.237339, msm=0.083898, =0.100)\nEpoch #431: loss=0.244719 (contrastive=0.262549, msm=0.084247, =0.100)\nEpoch #432: loss=0.174845 (contrastive=0.184725, msm=0.085928, =0.100)\nEpoch #433: loss=0.192731 (contrastive=0.204323, msm=0.088400, =0.100)\nEpoch #434: loss=0.535911 (contrastive=0.585876, msm=0.086224, =0.100)\nEpoch #435: loss=0.483090 (contrastive=0.527502, msm=0.083385, =0.100)\nEpoch #436: loss=0.275695 (contrastive=0.296915, msm=0.084718, =0.100)\nEpoch #437: loss=0.157752 (contrastive=0.165443, msm=0.088535, =0.100)\nEpoch #438: loss=0.423251 (contrastive=0.460147, msm=0.091185, =0.100)\nEpoch #439: loss=0.205290 (contrastive=0.217948, msm=0.091373, =0.100)\nEpoch #440: loss=0.178404 (contrastive=0.188038, msm=0.091696, =0.100)\nEpoch #441: loss=0.181234 (contrastive=0.191677, msm=0.087247, =0.100)\nEpoch #442: loss=0.178090 (contrastive=0.188091, msm=0.088083, =0.100)\nEpoch #443: loss=0.260656 (contrastive=0.279588, msm=0.090261, =0.100)\nEpoch #444: loss=0.196405 (contrastive=0.208152, msm=0.090681, =0.100)\nEpoch #445: loss=0.194008 (contrastive=0.205842, msm=0.087500, =0.100)\nEpoch #446: loss=0.255493 (contrastive=0.273805, msm=0.090693, =0.100)\nEpoch #447: loss=0.240468 (contrastive=0.257400, msm=0.088079, =0.100)\nEpoch #448: loss=0.161439 (contrastive=0.169766, msm=0.086491, =0.100)\nEpoch #449: loss=0.168079 (contrastive=0.177490, msm=0.083381, =0.100)\nEpoch #450: loss=0.261974 (contrastive=0.281348, msm=0.087612, =0.100)\nEpoch #451: loss=0.169916 (contrastive=0.178983, msm=0.088315, =0.100)\nEpoch #452: loss=0.195719 (contrastive=0.207863, msm=0.086426, =0.100)\nEpoch #453: loss=0.159227 (contrastive=0.167516, msm=0.084625, =0.100)\nEpoch #454: loss=0.243447 (contrastive=0.260428, msm=0.090619, =0.100)\nEpoch #455: loss=0.151388 (contrastive=0.158615, msm=0.086347, =0.100)\nEpoch #456: loss=0.153965 (contrastive=0.161978, msm=0.081847, =0.100)\nEpoch #457: loss=0.182602 (contrastive=0.193146, msm=0.087708, =0.100)\nEpoch #458: loss=0.143686 (contrastive=0.150278, msm=0.084350, =0.100)\nEpoch #459: loss=0.152542 (contrastive=0.159824, msm=0.087006, =0.100)\nEpoch #460: loss=0.186679 (contrastive=0.198319, msm=0.081918, =0.100)\nEpoch #461: loss=0.163714 (contrastive=0.172598, msm=0.083758, =0.100)\nEpoch #462: loss=0.148459 (contrastive=0.155955, msm=0.080987, =0.100)\nEpoch #463: loss=0.293345 (contrastive=0.316728, msm=0.082896, =0.100)\nEpoch #464: loss=0.164702 (contrastive=0.173999, msm=0.081033, =0.100)\nEpoch #465: loss=0.165309 (contrastive=0.174440, msm=0.083126, =0.100)\nEpoch #466: loss=0.136284 (contrastive=0.142491, msm=0.080428, =0.100)\nEpoch #467: loss=0.134706 (contrastive=0.140549, msm=0.082113, =0.100)\nEpoch #468: loss=0.422212 (contrastive=0.460037, msm=0.081788, =0.100)\nEpoch #469: loss=0.203569 (contrastive=0.216508, msm=0.087121, =0.100)\nEpoch #470: loss=0.131970 (contrastive=0.137314, msm=0.083877, =0.100)\nEpoch #471: loss=0.188549 (contrastive=0.200255, msm=0.083197, =0.100)\nEpoch #472: loss=0.287435 (contrastive=0.310593, msm=0.079011, =0.100)\nEpoch #473: loss=0.492834 (contrastive=0.538224, msm=0.084322, =0.100)\nEpoch #474: loss=0.229395 (contrastive=0.245716, msm=0.082511, =0.100)\nEpoch #475: loss=0.153686 (contrastive=0.161180, msm=0.086235, =0.100)\nEpoch #476: loss=0.264403 (contrastive=0.284384, msm=0.084567, =0.100)\nEpoch #477: loss=0.147496 (contrastive=0.154645, msm=0.083160, =0.100)\nEpoch #478: loss=0.248118 (contrastive=0.266446, msm=0.083164, =0.100)\nEpoch #479: loss=0.245652 (contrastive=0.263692, msm=0.083295, =0.100)\nEpoch #480: loss=1.019850 (contrastive=1.123883, msm=0.083549, =0.100)\nEpoch #481: loss=0.192188 (contrastive=0.204313, msm=0.083066, =0.100)\nEpoch #482: loss=0.284318 (contrastive=0.306216, msm=0.087234, =0.100)\nEpoch #483: loss=0.203492 (contrastive=0.216545, msm=0.086011, =0.100)\nEpoch #484: loss=0.246198 (contrastive=0.263659, msm=0.089049, =0.100)\nEpoch #485: loss=0.224728 (contrastive=0.240189, msm=0.085580, =0.100)\nEpoch #486: loss=0.218017 (contrastive=0.232674, msm=0.086098, =0.100)\nEpoch #487: loss=0.222012 (contrastive=0.237012, msm=0.087008, =0.100)\nEpoch #488: loss=0.201494 (contrastive=0.214638, msm=0.083192, =0.100)\nEpoch #489: loss=0.229864 (contrastive=0.246097, msm=0.083773, =0.100)\nEpoch #490: loss=0.308066 (contrastive=0.332504, msm=0.088124, =0.100)\nEpoch #491: loss=0.176938 (contrastive=0.186759, msm=0.088546, =0.100)\nEpoch #492: loss=0.174038 (contrastive=0.183823, msm=0.085970, =0.100)\nEpoch #493: loss=0.167658 (contrastive=0.176578, msm=0.087370, =0.100)\nEpoch #494: loss=0.625133 (contrastive=0.685370, msm=0.082998, =0.100)\nEpoch #495: loss=0.319921 (contrastive=0.346550, msm=0.080264, =0.100)\nEpoch #496: loss=0.166870 (contrastive=0.176714, msm=0.078269, =0.100)\nEpoch #497: loss=0.221529 (contrastive=0.237192, msm=0.080566, =0.100)\nEpoch #498: loss=0.167655 (contrastive=0.177529, msm=0.078792, =0.100)\nEpoch #499: loss=0.215217 (contrastive=0.229697, msm=0.084898, =0.100)\nEpoch #500: loss=0.224005 (contrastive=0.239957, msm=0.080435, =0.100)\nEpoch #501: loss=0.199735 (contrastive=0.213100, msm=0.079454, =0.100)\nEpoch #502: loss=0.344362 (contrastive=0.373692, msm=0.080397, =0.100)\nEpoch #503: loss=0.343212 (contrastive=0.372222, msm=0.082122, =0.100)\nEpoch #504: loss=0.245955 (contrastive=0.264127, msm=0.082401, =0.100)\nEpoch #505: loss=0.277040 (contrastive=0.298498, msm=0.083917, =0.100)\nEpoch #506: loss=0.145983 (contrastive=0.152466, msm=0.087632, =0.100)\nEpoch #507: loss=0.235665 (contrastive=0.251432, msm=0.093763, =0.100)\nEpoch #508: loss=0.322364 (contrastive=0.348491, msm=0.087226, =0.100)\nEpoch #509: loss=0.264117 (contrastive=0.283958, msm=0.085549, =0.100)\nEpoch #510: loss=0.179616 (contrastive=0.189829, msm=0.087702, =0.100)\nEpoch #511: loss=0.308064 (contrastive=0.331465, msm=0.097461, =0.100)\nEpoch #512: loss=0.282052 (contrastive=0.301320, msm=0.108641, =0.100)\nEpoch #513: loss=0.409548 (contrastive=0.443405, msm=0.104833, =0.100)\nEpoch #514: loss=0.202083 (contrastive=0.213875, msm=0.095953, =0.100)\nEpoch #515: loss=0.313759 (contrastive=0.336990, msm=0.104682, =0.100)\nEpoch #516: loss=0.289947 (contrastive=0.310288, msm=0.106884, =0.100)\nEpoch #517: loss=0.212610 (contrastive=0.224010, msm=0.110012, =0.100)\nEpoch #518: loss=0.278615 (contrastive=0.296851, msm=0.114489, =0.100)\nEpoch #519: loss=0.455689 (contrastive=0.494663, msm=0.104925, =0.100)\nEpoch #520: loss=0.264375 (contrastive=0.282608, msm=0.100282, =0.100)\nEpoch #521: loss=0.240309 (contrastive=0.255549, msm=0.103147, =0.100)\nEpoch #522: loss=0.241760 (contrastive=0.257042, msm=0.104223, =0.100)\nEpoch #523: loss=0.678211 (contrastive=0.741490, msm=0.108701, =0.100)\nEpoch #524: loss=0.436986 (contrastive=0.472511, msm=0.117253, =0.100)\nEpoch #525: loss=0.297873 (contrastive=0.318533, msm=0.111928, =0.100)\nEpoch #526: loss=0.234305 (contrastive=0.247846, msm=0.112438, =0.100)\nEpoch #527: loss=0.230641 (contrastive=0.244249, msm=0.108173, =0.100)\nEpoch #528: loss=0.261467 (contrastive=0.278770, msm=0.105744, =0.100)\nEpoch #529: loss=0.258363 (contrastive=0.276284, msm=0.097067, =0.100)\nEpoch #530: loss=0.217413 (contrastive=0.230584, msm=0.098873, =0.100)\nEpoch #531: loss=0.191032 (contrastive=0.200844, msm=0.102720, =0.100)\nEpoch #532: loss=0.207713 (contrastive=0.219785, msm=0.099058, =0.100)\nEpoch #533: loss=0.287684 (contrastive=0.308509, msm=0.100262, =0.100)\nEpoch #534: loss=0.186773 (contrastive=0.197177, msm=0.093133, =0.100)\nEpoch #535: loss=0.232031 (contrastive=0.248033, msm=0.088014, =0.100)\nEpoch #536: loss=0.176063 (contrastive=0.185684, msm=0.089471, =0.100)\nEpoch #537: loss=0.255376 (contrastive=0.274092, msm=0.086924, =0.100)\nEpoch #538: loss=0.230356 (contrastive=0.245854, msm=0.090874, =0.100)\nEpoch #539: loss=0.238800 (contrastive=0.255130, msm=0.091834, =0.100)\nEpoch #540: loss=0.185307 (contrastive=0.195924, msm=0.089754, =0.100)\nEpoch #541: loss=0.199918 (contrastive=0.212144, msm=0.089876, =0.100)\nEpoch #542: loss=0.215895 (contrastive=0.230270, msm=0.086515, =0.100)\nEpoch #543: loss=0.188024 (contrastive=0.199192, msm=0.087505, =0.100)\nEpoch #544: loss=0.255397 (contrastive=0.274082, msm=0.087229, =0.100)\nEpoch #545: loss=0.195256 (contrastive=0.207473, msm=0.085308, =0.100)\nEpoch #546: loss=0.254698 (contrastive=0.273258, msm=0.087662, =0.100)\nEpoch #547: loss=0.253603 (contrastive=0.272356, msm=0.084828, =0.100)\nEpoch #548: loss=0.637610 (contrastive=0.699007, msm=0.085040, =0.100)\nEpoch #549: loss=0.163326 (contrastive=0.171816, msm=0.086911, =0.100)\nEpoch #550: loss=0.431058 (contrastive=0.469568, msm=0.084465, =0.100)\nEpoch #551: loss=0.173874 (contrastive=0.184195, msm=0.080988, =0.100)\nEpoch #552: loss=1.108080 (contrastive=1.221951, msm=0.083235, =0.100)\nEpoch #553: loss=0.205680 (contrastive=0.219234, msm=0.083693, =0.100)\nEpoch #554: loss=0.261867 (contrastive=0.281061, msm=0.089122, =0.100)\nEpoch #555: loss=0.280639 (contrastive=0.301665, msm=0.091409, =0.100)\nEpoch #556: loss=0.266018 (contrastive=0.285323, msm=0.092278, =0.100)\nEpoch #557: loss=0.290426 (contrastive=0.312316, msm=0.093413, =0.100)\nEpoch #558: loss=0.226353 (contrastive=0.241885, msm=0.086568, =0.100)\nEpoch #559: loss=0.350888 (contrastive=0.380652, msm=0.083012, =0.100)\nEpoch #560: loss=0.199144 (contrastive=0.212001, msm=0.083428, =0.100)\nEpoch #561: loss=0.175990 (contrastive=0.185873, msm=0.087042, =0.100)\nEpoch #562: loss=0.443630 (contrastive=0.482986, msm=0.089428, =0.100)\nEpoch #563: loss=0.208070 (contrastive=0.221076, msm=0.091011, =0.100)\nEpoch #564: loss=0.177079 (contrastive=0.186582, msm=0.091546, =0.100)\nEpoch #565: loss=0.455965 (contrastive=0.496325, msm=0.092717, =0.100)\nEpoch #566: loss=0.201091 (contrastive=0.213908, msm=0.085745, =0.100)\nEpoch #567: loss=0.199652 (contrastive=0.212389, msm=0.085024, =0.100)\nEpoch #568: loss=0.216856 (contrastive=0.231742, msm=0.082885, =0.100)\nEpoch #569: loss=0.160758 (contrastive=0.169117, msm=0.085531, =0.100)\nEpoch #570: loss=0.168808 (contrastive=0.178423, msm=0.082274, =0.100)\nEpoch #571: loss=0.181282 (contrastive=0.192150, msm=0.083472, =0.100)\nEpoch #572: loss=0.199243 (contrastive=0.212300, msm=0.081734, =0.100)\nEpoch #573: loss=0.175802 (contrastive=0.186135, msm=0.082808, =0.100)\nEpoch #574: loss=0.163745 (contrastive=0.172758, msm=0.082629, =0.100)\nEpoch #575: loss=0.232679 (contrastive=0.249687, msm=0.079604, =0.100)\nEpoch #576: loss=0.148838 (contrastive=0.156302, msm=0.081663, =0.100)\nEpoch #577: loss=0.151317 (contrastive=0.159433, msm=0.078276, =0.100)\nEpoch #578: loss=0.229817 (contrastive=0.246269, msm=0.081752, =0.100)\nEpoch #579: loss=0.222480 (contrastive=0.238295, msm=0.080142, =0.100)\nEpoch #580: loss=0.231636 (contrastive=0.248765, msm=0.077480, =0.100)\nEpoch #581: loss=0.174737 (contrastive=0.185311, msm=0.079569, =0.100)\nEpoch #582: loss=0.139051 (contrastive=0.146043, msm=0.076119, =0.100)\nEpoch #583: loss=0.242536 (contrastive=0.261040, msm=0.075998, =0.100)\nEpoch #584: loss=0.211881 (contrastive=0.227072, msm=0.075160, =0.100)\nEpoch #585: loss=0.219308 (contrastive=0.235281, msm=0.075554, =0.100)\nEpoch #586: loss=0.138053 (contrastive=0.144961, msm=0.075887, =0.100)\nEpoch #587: loss=0.189667 (contrastive=0.202270, msm=0.076239, =0.100)\nEpoch #588: loss=0.188298 (contrastive=0.200781, msm=0.075952, =0.100)\nEpoch #589: loss=0.164798 (contrastive=0.174626, msm=0.076351, =0.100)\nEpoch #590: loss=0.135286 (contrastive=0.141789, msm=0.076760, =0.100)\nEpoch #591: loss=0.197257 (contrastive=0.210858, msm=0.074851, =0.100)\nEpoch #592: loss=0.151438 (contrastive=0.159871, msm=0.075538, =0.100)\nEpoch #593: loss=0.123532 (contrastive=0.128690, msm=0.077114, =0.100)\nEpoch #594: loss=0.408987 (contrastive=0.446106, msm=0.074915, =0.100)\nEpoch #595: loss=0.230912 (contrastive=0.248203, msm=0.075300, =0.100)\nEpoch #596: loss=0.186874 (contrastive=0.199056, msm=0.077240, =0.100)\nEpoch #597: loss=0.144341 (contrastive=0.151808, msm=0.077143, =0.100)\nEpoch #598: loss=0.152087 (contrastive=0.160570, msm=0.075742, =0.100)\nEpoch #599: loss=0.303985 (contrastive=0.329054, msm=0.078364, =0.100)\nTraining time: 0:02:30.942621\nEvaluation completed\nResults: {'ours': {24: {'norm': {'MSE': 0.34029067931554435, 'MAE': 0.46905111840300784}, 'raw': {'MSE': 45.66895232246424, 'MAE': 5.43382532548893}}, 48: {'norm': {'MSE': 0.34128708003573693, 'MAE': 0.46958785459684704}, 'raw': {'MSE': 45.80267503939077, 'MAE': 5.440043263952069}}, 168: {'norm': {'MSE': 0.34337964896587064, 'MAE': 0.47191273773135084}, 'raw': {'MSE': 46.08350969167539, 'MAE': 5.466976378791084}}, 336: {'norm': {'MSE': 0.34897641118801864, 'MAE': 0.4773409282669865}, 'raw': {'MSE': 46.834627107108346, 'MAE': 5.529860437427616}}, 720: {'norm': {'MSE': 0.3298759672069607, 'MAE': 0.4655317967202336}, 'raw': {'MSE': 44.271238427404256, 'MAE': 5.393054965367672}}}, 'ts2vec_infer_time': 53.36848568916321, 'lr_train_time': {24: 0.7044172286987305, 48: 0.692758321762085, 168: 0.9587774276733398, 336: 1.2190546989440918, 720: 1.7103221416473389}, 'lr_infer_time': {24: 0.0018966197967529297, 48: 0.0023567676544189453, 168: 0.005881786346435547, 336: 0.007070302963256836, 720: 0.014477014541625977}}\nModel and results saved to training/ETTh2__forecast_univar_msm_conservative_2025-09-22_16_47_37_517820\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!python train_msm.py ETTm1 forecast_univar_msm_conservative --loader forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 42 --eval --msm-weight 0.1 --msm-mask-rate 0.2 --msm-decoder-depth 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T16:48:38.096944Z","iopub.execute_input":"2025-09-22T16:48:38.097600Z","iopub.status.idle":"2025-09-22T17:00:24.308692Z","shell.execute_reply.started":"2025-09-22T16:48:38.097565Z","shell.execute_reply":"2025-09-22T17:00:24.307740Z"}},"outputs":[{"name":"stdout","text":"Dataset: ETTm1\nArguments: Namespace(dataset='ETTm1', run_name='forecast_univar_msm_conservative', loader='forecast_csv_univar', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0, msm_weight=0.1, msm_mask_rate=0.2, msm_decoder_depth=3, dynamic_lambda=False)\nLoading data... done\nTraining...\nEpoch #0: loss=7.682915 (contrastive=8.424562, msm=1.008097, =0.100)\nEpoch #1: loss=5.233062 (contrastive=5.697532, msm=1.052829, =0.100)\nEpoch #2: loss=3.087786 (contrastive=3.316567, msm=1.028757, =0.100)\nEpoch #3: loss=3.080388 (contrastive=3.311252, msm=1.002613, =0.100)\nEpoch #4: loss=2.662683 (contrastive=2.856973, msm=0.914071, =0.100)\nEpoch #5: loss=2.478889 (contrastive=2.634523, msm=1.078179, =0.100)\nEpoch #6: loss=2.426060 (contrastive=2.590525, msm=0.945878, =0.100)\nEpoch #7: loss=2.279871 (contrastive=2.424633, msm=0.977015, =0.100)\nEpoch #8: loss=2.184588 (contrastive=2.322029, msm=0.947617, =0.100)\nEpoch #9: loss=2.095766 (contrastive=2.233463, msm=0.856495, =0.100)\nEpoch #10: loss=2.101863 (contrastive=2.230307, msm=0.945875, =0.100)\nEpoch #11: loss=1.939165 (contrastive=2.070135, msm=0.760428, =0.100)\nEpoch #12: loss=1.970706 (contrastive=2.103058, msm=0.779539, =0.100)\nEpoch #13: loss=1.851578 (contrastive=1.983640, msm=0.663019, =0.100)\nEpoch #14: loss=1.978055 (contrastive=2.122724, msm=0.676028, =0.100)\nEpoch #15: loss=1.880386 (contrastive=2.022058, msm=0.605347, =0.100)\nEpoch #16: loss=1.748771 (contrastive=1.883130, msm=0.539542, =0.100)\nEpoch #17: loss=1.689507 (contrastive=1.822666, msm=0.491077, =0.100)\nEpoch #18: loss=1.636345 (contrastive=1.760833, msm=0.515949, =0.100)\nEpoch #19: loss=1.516778 (contrastive=1.631550, msm=0.483829, =0.100)\nEpoch #20: loss=1.585664 (contrastive=1.714865, msm=0.422856, =0.100)\nEpoch #21: loss=1.494638 (contrastive=1.614318, msm=0.417522, =0.100)\nEpoch #22: loss=1.515995 (contrastive=1.637626, msm=0.421324, =0.100)\nEpoch #23: loss=1.687434 (contrastive=1.832849, msm=0.378699, =0.100)\nEpoch #24: loss=1.593681 (contrastive=1.727005, msm=0.393760, =0.100)\nEpoch #25: loss=1.390112 (contrastive=1.505070, msm=0.355488, =0.100)\nEpoch #26: loss=1.388941 (contrastive=1.501948, msm=0.371881, =0.100)\nEpoch #27: loss=1.352432 (contrastive=1.465095, msm=0.338465, =0.100)\nEpoch #28: loss=1.383482 (contrastive=1.498921, msm=0.344534, =0.100)\nEpoch #29: loss=1.297245 (contrastive=1.406124, msm=0.317337, =0.100)\nEpoch #30: loss=1.294570 (contrastive=1.406486, msm=0.287326, =0.100)\nEpoch #31: loss=1.307093 (contrastive=1.416836, msm=0.319409, =0.100)\nEpoch #32: loss=1.150908 (contrastive=1.245018, msm=0.303924, =0.100)\nEpoch #33: loss=1.112129 (contrastive=1.202716, msm=0.296844, =0.100)\nEpoch #34: loss=1.639260 (contrastive=1.789416, msm=0.287851, =0.100)\nEpoch #35: loss=1.143763 (contrastive=1.237832, msm=0.297147, =0.100)\nEpoch #36: loss=1.659903 (contrastive=1.813716, msm=0.275583, =0.100)\nEpoch #37: loss=1.208215 (contrastive=1.309605, msm=0.295704, =0.100)\nEpoch #38: loss=1.232516 (contrastive=1.338304, msm=0.280428, =0.100)\nEpoch #39: loss=1.341939 (contrastive=1.459414, msm=0.284660, =0.100)\nEpoch #40: loss=1.148072 (contrastive=1.244916, msm=0.276474, =0.100)\nEpoch #41: loss=1.113332 (contrastive=1.207093, msm=0.269483, =0.100)\nEpoch #42: loss=1.206482 (contrastive=1.309432, msm=0.279932, =0.100)\nEpoch #43: loss=1.069215 (contrastive=1.158719, msm=0.263686, =0.100)\nEpoch #44: loss=1.040052 (contrastive=1.127893, msm=0.249483, =0.100)\nEpoch #45: loss=1.083907 (contrastive=1.175419, msm=0.260301, =0.100)\nEpoch #46: loss=1.029909 (contrastive=1.114603, msm=0.267667, =0.100)\nEpoch #47: loss=1.124602 (contrastive=1.221071, msm=0.256381, =0.100)\nEpoch #48: loss=0.881094 (contrastive=0.949010, msm=0.269854, =0.100)\nEpoch #49: loss=0.859229 (contrastive=0.924860, msm=0.268551, =0.100)\nEpoch #50: loss=1.041218 (contrastive=1.130400, msm=0.238580, =0.100)\nEpoch #51: loss=1.080541 (contrastive=1.173960, msm=0.239763, =0.100)\nEpoch #52: loss=1.214656 (contrastive=1.323740, msm=0.232899, =0.100)\nEpoch #53: loss=0.827520 (contrastive=0.893309, msm=0.235420, =0.100)\nEpoch #54: loss=0.967174 (contrastive=1.049458, msm=0.226620, =0.100)\nEpoch #55: loss=1.047011 (contrastive=1.139183, msm=0.217467, =0.100)\nEpoch #56: loss=1.007994 (contrastive=1.097359, msm=0.203712, =0.100)\nEpoch #57: loss=1.014280 (contrastive=1.103119, msm=0.214732, =0.100)\nEpoch #58: loss=1.128605 (contrastive=1.230140, msm=0.214795, =0.100)\nEpoch #59: loss=0.852466 (contrastive=0.925500, msm=0.195161, =0.100)\nEpoch #60: loss=0.888328 (contrastive=0.965039, msm=0.197927, =0.100)\nEpoch #61: loss=0.862084 (contrastive=0.936120, msm=0.195767, =0.100)\nEpoch #62: loss=1.007300 (contrastive=1.097735, msm=0.193387, =0.100)\nEpoch #63: loss=0.818080 (contrastive=0.887907, msm=0.189636, =0.100)\nEpoch #64: loss=0.969323 (contrastive=1.056481, msm=0.184894, =0.100)\nEpoch #65: loss=0.923837 (contrastive=1.006649, msm=0.178529, =0.100)\nEpoch #66: loss=0.813895 (contrastive=0.884373, msm=0.179591, =0.100)\nEpoch #67: loss=1.119543 (contrastive=1.223721, msm=0.181943, =0.100)\nEpoch #68: loss=0.718086 (contrastive=0.778343, msm=0.175770, =0.100)\nEpoch #69: loss=0.849837 (contrastive=0.923312, msm=0.188564, =0.100)\nEpoch #70: loss=1.047821 (contrastive=1.144279, msm=0.179696, =0.100)\nEpoch #71: loss=0.831535 (contrastive=0.904832, msm=0.171861, =0.100)\nEpoch #72: loss=0.770688 (contrastive=0.836634, msm=0.177172, =0.100)\nEpoch #73: loss=0.699201 (contrastive=0.757061, msm=0.178454, =0.100)\nEpoch #74: loss=0.977639 (contrastive=1.066940, msm=0.173927, =0.100)\nEpoch #75: loss=0.793826 (contrastive=0.863275, msm=0.168783, =0.100)\nEpoch #76: loss=0.693787 (contrastive=0.752422, msm=0.166079, =0.100)\nEpoch #77: loss=0.907536 (contrastive=0.989265, msm=0.171977, =0.100)\nEpoch #78: loss=0.740049 (contrastive=0.805190, msm=0.153783, =0.100)\nEpoch #79: loss=0.678025 (contrastive=0.735064, msm=0.164674, =0.100)\nEpoch #80: loss=0.645135 (contrastive=0.699226, msm=0.158315, =0.100)\nEpoch #81: loss=0.860127 (contrastive=0.936916, msm=0.169027, =0.100)\nEpoch #82: loss=0.881176 (contrastive=0.961554, msm=0.157773, =0.100)\nEpoch #83: loss=0.990585 (contrastive=1.083149, msm=0.157515, =0.100)\nEpoch #84: loss=0.819087 (contrastive=0.893673, msm=0.147814, =0.100)\nEpoch #85: loss=0.662636 (contrastive=0.718980, msm=0.155536, =0.100)\nEpoch #86: loss=0.666737 (contrastive=0.723190, msm=0.158652, =0.100)\nEpoch #87: loss=0.671211 (contrastive=0.726701, msm=0.171806, =0.100)\nEpoch #88: loss=0.804887 (contrastive=0.876283, msm=0.162321, =0.100)\nEpoch #89: loss=0.605293 (contrastive=0.655769, msm=0.151015, =0.100)\nEpoch #90: loss=0.793949 (contrastive=0.865336, msm=0.151472, =0.100)\nEpoch #91: loss=0.636688 (contrastive=0.691464, msm=0.143706, =0.100)\nEpoch #92: loss=1.100310 (contrastive=1.206667, msm=0.143093, =0.100)\nEpoch #93: loss=0.710650 (contrastive=0.772854, msm=0.150816, =0.100)\nEpoch #94: loss=0.660327 (contrastive=0.716015, msm=0.159136, =0.100)\nEpoch #95: loss=0.638127 (contrastive=0.691889, msm=0.154266, =0.100)\nEpoch #96: loss=0.650767 (contrastive=0.705917, msm=0.154418, =0.100)\nEpoch #97: loss=0.634971 (contrastive=0.688526, msm=0.152976, =0.100)\nEpoch #98: loss=0.871901 (contrastive=0.950733, msm=0.162419, =0.100)\nEpoch #99: loss=1.092819 (contrastive=1.196787, msm=0.157111, =0.100)\nEpoch #100: loss=0.981728 (contrastive=1.073322, msm=0.157383, =0.100)\nEpoch #101: loss=0.708898 (contrastive=0.770155, msm=0.157579, =0.100)\nEpoch #102: loss=0.674534 (contrastive=0.732006, msm=0.157285, =0.100)\nEpoch #103: loss=0.598067 (contrastive=0.647332, msm=0.154677, =0.100)\nEpoch #104: loss=1.006321 (contrastive=1.101446, msm=0.150200, =0.100)\nEpoch #105: loss=0.681702 (contrastive=0.741060, msm=0.147471, =0.100)\nEpoch #106: loss=0.581109 (contrastive=0.630177, msm=0.139492, =0.100)\nEpoch #107: loss=0.632191 (contrastive=0.685348, msm=0.153772, =0.100)\nEpoch #108: loss=0.777242 (contrastive=0.847409, msm=0.145742, =0.100)\nEpoch #109: loss=1.013302 (contrastive=1.109234, msm=0.149917, =0.100)\nEpoch #110: loss=0.769203 (contrastive=0.839081, msm=0.140307, =0.100)\nEpoch #111: loss=0.810513 (contrastive=0.884677, msm=0.143045, =0.100)\nEpoch #112: loss=0.646079 (contrastive=0.702862, msm=0.135037, =0.100)\nEpoch #113: loss=0.669466 (contrastive=0.728302, msm=0.139943, =0.100)\nEpoch #114: loss=0.889607 (contrastive=0.972827, msm=0.140627, =0.100)\nEpoch #115: loss=0.546961 (contrastive=0.592249, msm=0.139367, =0.100)\nEpoch #116: loss=0.529266 (contrastive=0.573073, msm=0.135005, =0.100)\nEpoch #117: loss=0.558881 (contrastive=0.605425, msm=0.139993, =0.100)\nEpoch #118: loss=0.639687 (contrastive=0.695723, msm=0.135356, =0.100)\nEpoch #119: loss=0.767957 (contrastive=0.837966, msm=0.137877, =0.100)\nEpoch #120: loss=0.776145 (contrastive=0.847524, msm=0.133739, =0.100)\nEpoch #121: loss=0.695957 (contrastive=0.757519, msm=0.141891, =0.100)\nEpoch #122: loss=0.766031 (contrastive=0.836313, msm=0.133492, =0.100)\nEpoch #123: loss=0.709024 (contrastive=0.771745, msm=0.144532, =0.100)\nEpoch #124: loss=0.857483 (contrastive=0.937438, msm=0.137889, =0.100)\nEpoch #125: loss=0.602296 (contrastive=0.653810, msm=0.138670, =0.100)\nEpoch #126: loss=0.791220 (contrastive=0.864663, msm=0.130234, =0.100)\nEpoch #127: loss=0.850509 (contrastive=0.929276, msm=0.141607, =0.100)\nEpoch #128: loss=0.651126 (contrastive=0.707177, msm=0.146662, =0.100)\nEpoch #129: loss=0.546279 (contrastive=0.590556, msm=0.147785, =0.100)\nEpoch #130: loss=0.889594 (contrastive=0.971480, msm=0.152617, =0.100)\nEpoch #131: loss=0.666606 (contrastive=0.724509, msm=0.145478, =0.100)\nEpoch #132: loss=0.604443 (contrastive=0.655080, msm=0.148704, =0.100)\nEpoch #133: loss=0.634129 (contrastive=0.688587, msm=0.144011, =0.100)\nEpoch #134: loss=0.564410 (contrastive=0.611229, msm=0.143046, =0.100)\nEpoch #135: loss=0.596891 (contrastive=0.648852, msm=0.129233, =0.100)\nEpoch #136: loss=0.672781 (contrastive=0.732340, msm=0.136752, =0.100)\nEpoch #137: loss=0.540176 (contrastive=0.585768, msm=0.129843, =0.100)\nEpoch #138: loss=0.547643 (contrastive=0.593454, msm=0.135345, =0.100)\nEpoch #139: loss=0.476841 (contrastive=0.515321, msm=0.130525, =0.100)\nEpoch #140: loss=0.455997 (contrastive=0.491334, msm=0.137967, =0.100)\nEpoch #141: loss=0.450889 (contrastive=0.485629, msm=0.138227, =0.100)\nEpoch #142: loss=0.437289 (contrastive=0.471843, msm=0.126299, =0.100)\nEpoch #143: loss=0.679490 (contrastive=0.740068, msm=0.134292, =0.100)\nEpoch #144: loss=0.465831 (contrastive=0.503828, msm=0.123865, =0.100)\nEpoch #145: loss=0.706396 (contrastive=0.771398, msm=0.121377, =0.100)\nEpoch #146: loss=0.620090 (contrastive=0.674967, msm=0.126195, =0.100)\nEpoch #147: loss=0.652467 (contrastive=0.710107, msm=0.133701, =0.100)\nEpoch #148: loss=0.558989 (contrastive=0.605301, msm=0.142183, =0.100)\nEpoch #149: loss=0.942513 (contrastive=1.032516, msm=0.132484, =0.100)\nEpoch #150: loss=0.490924 (contrastive=0.530930, msm=0.130875, =0.100)\nEpoch #151: loss=0.563802 (contrastive=0.611631, msm=0.133334, =0.100)\nEpoch #152: loss=0.443280 (contrastive=0.478065, msm=0.130220, =0.100)\nEpoch #153: loss=0.563701 (contrastive=0.611592, msm=0.132681, =0.100)\nEpoch #154: loss=0.466739 (contrastive=0.503502, msm=0.135877, =0.100)\nEpoch #155: loss=0.542877 (contrastive=0.588510, msm=0.132180, =0.100)\nEpoch #156: loss=0.494548 (contrastive=0.536032, msm=0.121192, =0.100)\nEpoch #157: loss=0.718660 (contrastive=0.784732, msm=0.124008, =0.100)\nEpoch #158: loss=0.394231 (contrastive=0.423667, msm=0.129309, =0.100)\nEpoch #159: loss=0.365286 (contrastive=0.391814, msm=0.126542, =0.100)\nEpoch #160: loss=0.408686 (contrastive=0.441046, msm=0.117439, =0.100)\nEpoch #161: loss=0.462371 (contrastive=0.500873, msm=0.115851, =0.100)\nEpoch #162: loss=0.497734 (contrastive=0.539479, msm=0.122027, =0.100)\nEpoch #163: loss=0.422480 (contrastive=0.456369, msm=0.117474, =0.100)\nEpoch #164: loss=0.480978 (contrastive=0.521332, msm=0.117796, =0.100)\nEpoch #165: loss=0.399457 (contrastive=0.430714, msm=0.118147, =0.100)\nEpoch #166: loss=0.634782 (contrastive=0.692161, msm=0.118373, =0.100)\nEpoch #167: loss=0.343550 (contrastive=0.368528, msm=0.118749, =0.100)\nEpoch #168: loss=0.418881 (contrastive=0.452217, msm=0.118862, =0.100)\nEpoch #169: loss=0.475136 (contrastive=0.515004, msm=0.116325, =0.100)\nEpoch #170: loss=0.462053 (contrastive=0.500158, msm=0.119106, =0.100)\nEpoch #171: loss=0.484892 (contrastive=0.525969, msm=0.115201, =0.100)\nEpoch #172: loss=0.435949 (contrastive=0.471580, msm=0.115263, =0.100)\nEpoch #173: loss=0.360792 (contrastive=0.388208, msm=0.114045, =0.100)\nEpoch #174: loss=0.379100 (contrastive=0.407647, msm=0.122174, =0.100)\nEpoch #175: loss=0.470643 (contrastive=0.509427, msm=0.121592, =0.100)\nEpoch #176: loss=0.383308 (contrastive=0.413249, msm=0.113847, =0.100)\nEpoch #177: loss=0.367797 (contrastive=0.395392, msm=0.119440, =0.100)\nEpoch #178: loss=0.375360 (contrastive=0.403928, msm=0.118255, =0.100)\nEpoch #179: loss=0.334003 (contrastive=0.358303, msm=0.115304, =0.100)\nEpoch #180: loss=0.403334 (contrastive=0.434728, msm=0.120788, =0.100)\nEpoch #181: loss=0.391598 (contrastive=0.422397, msm=0.114405, =0.100)\nEpoch #182: loss=0.331844 (contrastive=0.354287, msm=0.129862, =0.100)\nEpoch #183: loss=0.503687 (contrastive=0.545152, msm=0.130503, =0.100)\nEpoch #184: loss=0.409296 (contrastive=0.441757, msm=0.117147, =0.100)\nEpoch #185: loss=0.333074 (contrastive=0.356904, msm=0.118608, =0.100)\nEpoch #186: loss=0.652276 (contrastive=0.711980, msm=0.114943, =0.100)\nEpoch #187: loss=0.431288 (contrastive=0.465326, msm=0.124952, =0.100)\nEpoch #188: loss=0.508267 (contrastive=0.551792, msm=0.116545, =0.100)\nEpoch #189: loss=0.483678 (contrastive=0.524095, msm=0.119922, =0.100)\nEpoch #190: loss=0.562507 (contrastive=0.612543, msm=0.112184, =0.100)\nEpoch #191: loss=0.475579 (contrastive=0.515048, msm=0.120358, =0.100)\nEpoch #192: loss=0.487352 (contrastive=0.528620, msm=0.115941, =0.100)\nEpoch #193: loss=0.419177 (contrastive=0.452195, msm=0.122015, =0.100)\nEpoch #194: loss=0.462348 (contrastive=0.500718, msm=0.117015, =0.100)\nEpoch #195: loss=0.412560 (contrastive=0.444710, msm=0.123204, =0.100)\nEpoch #196: loss=0.398386 (contrastive=0.429218, msm=0.120895, =0.100)\nEpoch #197: loss=0.571133 (contrastive=0.619454, msm=0.136247, =0.100)\nEpoch #198: loss=0.454855 (contrastive=0.490092, msm=0.137725, =0.100)\nEpoch #199: loss=0.387860 (contrastive=0.417332, msm=0.122606, =0.100)\nEpoch #200: loss=0.403659 (contrastive=0.434862, msm=0.122830, =0.100)\nEpoch #201: loss=0.357825 (contrastive=0.382582, msm=0.135009, =0.100)\nEpoch #202: loss=0.380487 (contrastive=0.407972, msm=0.133128, =0.100)\nEpoch #203: loss=0.332767 (contrastive=0.355469, msm=0.128443, =0.100)\nEpoch #204: loss=0.490839 (contrastive=0.531805, msm=0.122149, =0.100)\nEpoch #205: loss=0.494198 (contrastive=0.536098, msm=0.117096, =0.100)\nEpoch #206: loss=0.383666 (contrastive=0.411365, msm=0.134369, =0.100)\nEpoch #207: loss=0.359461 (contrastive=0.385717, msm=0.123163, =0.100)\nEpoch #208: loss=0.309693 (contrastive=0.330829, msm=0.119465, =0.100)\nEpoch #209: loss=0.290656 (contrastive=0.309695, msm=0.119300, =0.100)\nEpoch #210: loss=0.255144 (contrastive=0.269551, msm=0.125479, =0.100)\nEpoch #211: loss=0.321118 (contrastive=0.342380, msm=0.129765, =0.100)\nEpoch #212: loss=0.360993 (contrastive=0.387565, msm=0.121840, =0.100)\nEpoch #213: loss=0.337001 (contrastive=0.360068, msm=0.129404, =0.100)\nEpoch #214: loss=0.266706 (contrastive=0.281833, msm=0.130561, =0.100)\nEpoch #215: loss=0.438033 (contrastive=0.474039, msm=0.113975, =0.100)\nEpoch #216: loss=0.538957 (contrastive=0.585616, msm=0.119026, =0.100)\nEpoch #217: loss=0.477511 (contrastive=0.517692, msm=0.115887, =0.100)\nEpoch #218: loss=0.399864 (contrastive=0.430013, msm=0.128524, =0.100)\nEpoch #219: loss=0.299527 (contrastive=0.319667, msm=0.118268, =0.100)\nEpoch #220: loss=0.353570 (contrastive=0.379782, msm=0.117657, =0.100)\nEpoch #221: loss=0.281622 (contrastive=0.299679, msm=0.119111, =0.100)\nEpoch #222: loss=0.332092 (contrastive=0.356349, msm=0.113780, =0.100)\nEpoch #223: loss=0.351745 (contrastive=0.378264, msm=0.113077, =0.100)\nEpoch #224: loss=0.259022 (contrastive=0.275692, msm=0.108995, =0.100)\nEpoch #225: loss=0.367297 (contrastive=0.393999, msm=0.126977, =0.100)\nEpoch #226: loss=0.263559 (contrastive=0.279284, msm=0.122027, =0.100)\nEpoch #227: loss=1.074775 (contrastive=1.181484, msm=0.114398, =0.100)\nEpoch #228: loss=0.337744 (contrastive=0.361213, msm=0.126519, =0.100)\nEpoch #229: loss=0.398821 (contrastive=0.430596, msm=0.112848, =0.100)\nEpoch #230: loss=0.487036 (contrastive=0.527907, msm=0.119198, =0.100)\nEpoch #231: loss=0.467057 (contrastive=0.506031, msm=0.116290, =0.100)\nEpoch #232: loss=0.530098 (contrastive=0.575082, msm=0.125241, =0.100)\nEpoch #233: loss=0.315070 (contrastive=0.336761, msm=0.119855, =0.100)\nEpoch #234: loss=0.300194 (contrastive=0.321126, msm=0.111808, =0.100)\nEpoch #235: loss=0.309107 (contrastive=0.330342, msm=0.117991, =0.100)\nEpoch #236: loss=0.360270 (contrastive=0.387064, msm=0.119127, =0.100)\nEpoch #237: loss=0.350287 (contrastive=0.375365, msm=0.124581, =0.100)\nEpoch #238: loss=0.268099 (contrastive=0.283986, msm=0.125111, =0.100)\nEpoch #239: loss=0.494443 (contrastive=0.536643, msm=0.114649, =0.100)\nEpoch #240: loss=0.375703 (contrastive=0.404527, msm=0.116288, =0.100)\nEpoch #241: loss=0.372213 (contrastive=0.400744, msm=0.115432, =0.100)\nEpoch #242: loss=0.290724 (contrastive=0.310249, msm=0.115001, =0.100)\nEpoch #243: loss=0.259798 (contrastive=0.275107, msm=0.122017, =0.100)\nEpoch #244: loss=0.309575 (contrastive=0.330580, msm=0.120533, =0.100)\nEpoch #245: loss=0.333988 (contrastive=0.357245, msm=0.124674, =0.100)\nEpoch #246: loss=0.538098 (contrastive=0.583756, msm=0.127176, =0.100)\nEpoch #247: loss=0.276078 (contrastive=0.293297, msm=0.121106, =0.100)\nEpoch #248: loss=0.455353 (contrastive=0.491758, msm=0.127706, =0.100)\nEpoch #249: loss=0.286046 (contrastive=0.304379, msm=0.121051, =0.100)\nEpoch #250: loss=0.304496 (contrastive=0.324476, msm=0.124668, =0.100)\nEpoch #251: loss=0.396630 (contrastive=0.427626, msm=0.117661, =0.100)\nEpoch #252: loss=0.286577 (contrastive=0.304023, msm=0.129558, =0.100)\nEpoch #253: loss=0.335100 (contrastive=0.357443, msm=0.134011, =0.100)\nEpoch #254: loss=0.418315 (contrastive=0.450847, msm=0.125526, =0.100)\nEpoch #255: loss=0.343440 (contrastive=0.367637, msm=0.125664, =0.100)\nEpoch #256: loss=0.294187 (contrastive=0.312495, msm=0.129417, =0.100)\nEpoch #257: loss=0.301865 (contrastive=0.320729, msm=0.132089, =0.100)\nEpoch #258: loss=0.337665 (contrastive=0.361019, msm=0.127486, =0.100)\nEpoch #259: loss=0.241328 (contrastive=0.254208, msm=0.125408, =0.100)\nEpoch #260: loss=0.274115 (contrastive=0.291059, msm=0.121619, =0.100)\nEpoch #261: loss=0.629128 (contrastive=0.685024, msm=0.126062, =0.100)\nEpoch #262: loss=0.234441 (contrastive=0.247614, msm=0.115882, =0.100)\nEpoch #263: loss=0.230875 (contrastive=0.243770, msm=0.114813, =0.100)\nEpoch #264: loss=0.202230 (contrastive=0.212936, msm=0.105875, =0.100)\nEpoch #265: loss=0.284889 (contrastive=0.303765, msm=0.115004, =0.100)\nEpoch #266: loss=0.277332 (contrastive=0.295108, msm=0.117351, =0.100)\nEpoch #267: loss=0.305477 (contrastive=0.326912, msm=0.112563, =0.100)\nEpoch #268: loss=0.744832 (contrastive=0.814184, msm=0.120661, =0.100)\nEpoch #269: loss=0.242895 (contrastive=0.257186, msm=0.114283, =0.100)\nEpoch #270: loss=0.303572 (contrastive=0.324722, msm=0.113224, =0.100)\nEpoch #271: loss=0.216403 (contrastive=0.227402, msm=0.117414, =0.100)\nEpoch #272: loss=0.262630 (contrastive=0.278482, msm=0.119966, =0.100)\nEpoch #273: loss=0.327786 (contrastive=0.351114, msm=0.117827, =0.100)\nEpoch #274: loss=0.264185 (contrastive=0.281370, msm=0.109514, =0.100)\nEpoch #275: loss=0.247553 (contrastive=0.261841, msm=0.118964, =0.100)\nEpoch #276: loss=0.313196 (contrastive=0.335018, msm=0.116800, =0.100)\nEpoch #277: loss=0.250620 (contrastive=0.266578, msm=0.106995, =0.100)\nEpoch #278: loss=0.286318 (contrastive=0.305961, msm=0.109526, =0.100)\nEpoch #279: loss=0.302718 (contrastive=0.323769, msm=0.113259, =0.100)\nEpoch #280: loss=0.241842 (contrastive=0.256921, msm=0.106137, =0.100)\nEpoch #281: loss=0.209110 (contrastive=0.220306, msm=0.108348, =0.100)\nEpoch #282: loss=0.226260 (contrastive=0.238874, msm=0.112734, =0.100)\nEpoch #283: loss=0.318896 (contrastive=0.341790, msm=0.112848, =0.100)\nEpoch #284: loss=0.192765 (contrastive=0.202282, msm=0.107113, =0.100)\nEpoch #285: loss=0.238656 (contrastive=0.253833, msm=0.102062, =0.100)\nEpoch #286: loss=0.168296 (contrastive=0.175230, msm=0.105892, =0.100)\nEpoch #287: loss=0.558648 (contrastive=0.609227, msm=0.103430, =0.100)\nEpoch #288: loss=0.404978 (contrastive=0.437622, msm=0.111180, =0.100)\nEpoch #289: loss=0.303449 (contrastive=0.325053, msm=0.109012, =0.100)\nEpoch #290: loss=0.208709 (contrastive=0.219760, msm=0.109247, =0.100)\nEpoch #291: loss=0.216981 (contrastive=0.228991, msm=0.108891, =0.100)\nEpoch #292: loss=0.843142 (contrastive=0.924538, msm=0.110575, =0.100)\nEpoch #293: loss=0.270679 (contrastive=0.287866, msm=0.115998, =0.100)\nEpoch #294: loss=0.227311 (contrastive=0.239868, msm=0.114299, =0.100)\nEpoch #295: loss=0.232252 (contrastive=0.245710, msm=0.111128, =0.100)\nEpoch #296: loss=0.297921 (contrastive=0.317933, msm=0.117809, =0.100)\nEpoch #297: loss=0.229746 (contrastive=0.241062, msm=0.127904, =0.100)\nEpoch #298: loss=0.417076 (contrastive=0.449417, msm=0.126001, =0.100)\nEpoch #299: loss=0.993865 (contrastive=1.091960, msm=0.111013, =0.100)\nEpoch #300: loss=0.295391 (contrastive=0.314741, msm=0.121234, =0.100)\nEpoch #301: loss=0.291987 (contrastive=0.310272, msm=0.127427, =0.100)\nEpoch #302: loss=0.319509 (contrastive=0.340971, msm=0.126356, =0.100)\nEpoch #303: loss=0.255073 (contrastive=0.269964, msm=0.121052, =0.100)\nEpoch #304: loss=0.269159 (contrastive=0.286220, msm=0.115608, =0.100)\nEpoch #305: loss=0.260601 (contrastive=0.275468, msm=0.126792, =0.100)\nEpoch #306: loss=0.182128 (contrastive=0.188090, msm=0.128473, =0.100)\nEpoch #307: loss=0.237500 (contrastive=0.250265, msm=0.122615, =0.100)\nEpoch #308: loss=0.287426 (contrastive=0.306365, msm=0.116974, =0.100)\nEpoch #309: loss=0.256204 (contrastive=0.271526, msm=0.118302, =0.100)\nEpoch #310: loss=0.290196 (contrastive=0.309098, msm=0.120074, =0.100)\nEpoch #311: loss=0.177077 (contrastive=0.184071, msm=0.114124, =0.100)\nEpoch #312: loss=0.248129 (contrastive=0.263142, msm=0.113008, =0.100)\nEpoch #313: loss=0.162579 (contrastive=0.168396, msm=0.110226, =0.100)\nEpoch #314: loss=0.141963 (contrastive=0.144469, msm=0.119404, =0.100)\nEpoch #315: loss=0.183127 (contrastive=0.190142, msm=0.119993, =0.100)\nEpoch #316: loss=0.170845 (contrastive=0.177016, msm=0.115312, =0.100)\nEpoch #317: loss=0.184168 (contrastive=0.192306, msm=0.110926, =0.100)\nEpoch #318: loss=0.129992 (contrastive=0.131708, msm=0.114551, =0.100)\nEpoch #319: loss=0.140302 (contrastive=0.143329, msm=0.113063, =0.100)\nEpoch #320: loss=0.224118 (contrastive=0.236756, msm=0.110383, =0.100)\nEpoch #321: loss=1.582779 (contrastive=1.746212, msm=0.111882, =0.100)\nEpoch #322: loss=0.190406 (contrastive=0.199268, msm=0.110644, =0.100)\nEpoch #323: loss=0.315907 (contrastive=0.337399, msm=0.122471, =0.100)\nEpoch #324: loss=0.540789 (contrastive=0.588650, msm=0.110045, =0.100)\nEpoch #325: loss=0.441318 (contrastive=0.477941, msm=0.111702, =0.100)\nEpoch #326: loss=0.337331 (contrastive=0.359999, msm=0.133318, =0.100)\nEpoch #327: loss=0.272794 (contrastive=0.288358, msm=0.132711, =0.100)\nEpoch #328: loss=0.277935 (contrastive=0.294527, msm=0.128610, =0.100)\nEpoch #329: loss=0.273476 (contrastive=0.290743, msm=0.118073, =0.100)\nEpoch #330: loss=0.241331 (contrastive=0.254413, msm=0.123591, =0.100)\nEpoch #331: loss=0.206399 (contrastive=0.216296, msm=0.117322, =0.100)\nEpoch #332: loss=0.249853 (contrastive=0.264766, msm=0.115640, =0.100)\nEpoch #333: loss=0.167329 (contrastive=0.172451, msm=0.121232, =0.100)\nEpoch #334: loss=0.300247 (contrastive=0.320599, msm=0.117084, =0.100)\nEpoch #335: loss=0.165428 (contrastive=0.171518, msm=0.110619, =0.100)\nEpoch #336: loss=0.181372 (contrastive=0.189332, msm=0.109733, =0.100)\nEpoch #337: loss=0.122595 (contrastive=0.123712, msm=0.112540, =0.100)\nEpoch #338: loss=0.145855 (contrastive=0.149296, msm=0.114884, =0.100)\nEpoch #339: loss=0.279345 (contrastive=0.298037, msm=0.111117, =0.100)\nEpoch #340: loss=0.122507 (contrastive=0.124004, msm=0.109034, =0.100)\nEpoch #341: loss=0.345241 (contrastive=0.372374, msm=0.101045, =0.100)\nEpoch #342: loss=0.109447 (contrastive=0.109586, msm=0.108189, =0.100)\nEpoch #343: loss=0.117535 (contrastive=0.118912, msm=0.105141, =0.100)\nEpoch #344: loss=0.107867 (contrastive=0.108258, msm=0.104347, =0.100)\nEpoch #345: loss=0.260157 (contrastive=0.277334, msm=0.105573, =0.100)\nEpoch #346: loss=0.133829 (contrastive=0.137145, msm=0.103986, =0.100)\nEpoch #347: loss=0.193557 (contrastive=0.203462, msm=0.104411, =0.100)\nEpoch #348: loss=0.243373 (contrastive=0.258798, msm=0.104541, =0.100)\nEpoch #349: loss=0.182470 (contrastive=0.190704, msm=0.108365, =0.100)\nEpoch #350: loss=0.192217 (contrastive=0.202114, msm=0.103143, =0.100)\nEpoch #351: loss=0.093082 (contrastive=0.091276, msm=0.109336, =0.100)\nEpoch #352: loss=0.180396 (contrastive=0.188771, msm=0.105019, =0.100)\nEpoch #353: loss=0.113499 (contrastive=0.114060, msm=0.108441, =0.100)\nEpoch #354: loss=0.118293 (contrastive=0.118886, msm=0.112957, =0.100)\nEpoch #355: loss=0.165759 (contrastive=0.171911, msm=0.110389, =0.100)\nEpoch #356: loss=0.212285 (contrastive=0.224374, msm=0.103488, =0.100)\nEpoch #357: loss=0.116343 (contrastive=0.117784, msm=0.103382, =0.100)\nEpoch #358: loss=0.155936 (contrastive=0.161783, msm=0.103313, =0.100)\nEpoch #359: loss=0.150119 (contrastive=0.155830, msm=0.098716, =0.100)\nEpoch #360: loss=0.109761 (contrastive=0.110170, msm=0.106087, =0.100)\nEpoch #361: loss=0.105159 (contrastive=0.104981, msm=0.106753, =0.100)\nEpoch #362: loss=0.117027 (contrastive=0.118571, msm=0.103138, =0.100)\nEpoch #363: loss=0.128091 (contrastive=0.130653, msm=0.105031, =0.100)\nEpoch #364: loss=0.218607 (contrastive=0.230738, msm=0.109427, =0.100)\nEpoch #365: loss=0.126790 (contrastive=0.128663, msm=0.109936, =0.100)\nEpoch #366: loss=0.179190 (contrastive=0.187052, msm=0.108432, =0.100)\nEpoch #367: loss=0.257578 (contrastive=0.274375, msm=0.106404, =0.100)\nEpoch #368: loss=0.102925 (contrastive=0.102668, msm=0.105241, =0.100)\nEpoch #369: loss=0.137156 (contrastive=0.140515, msm=0.106917, =0.100)\nEpoch #370: loss=0.124760 (contrastive=0.126298, msm=0.110916, =0.100)\nEpoch #371: loss=0.159383 (contrastive=0.166186, msm=0.098158, =0.100)\nEpoch #372: loss=0.152633 (contrastive=0.158332, msm=0.101345, =0.100)\nEpoch #373: loss=0.090948 (contrastive=0.090025, msm=0.099247, =0.100)\nEpoch #374: loss=0.095920 (contrastive=0.095342, msm=0.101115, =0.100)\nEpoch #375: loss=0.104572 (contrastive=0.104925, msm=0.101395, =0.100)\nEpoch #376: loss=0.124798 (contrastive=0.126691, msm=0.107762, =0.100)\nEpoch #377: loss=0.097228 (contrastive=0.097174, msm=0.097711, =0.100)\nEpoch #378: loss=0.160261 (contrastive=0.166240, msm=0.106450, =0.100)\nEpoch #379: loss=0.125582 (contrastive=0.127961, msm=0.104173, =0.100)\nEpoch #380: loss=0.159327 (contrastive=0.165319, msm=0.105397, =0.100)\nEpoch #381: loss=0.071407 (contrastive=0.067575, msm=0.105893, =0.100)\nEpoch #382: loss=0.213209 (contrastive=0.226062, msm=0.097535, =0.100)\nEpoch #383: loss=0.136941 (contrastive=0.140040, msm=0.109056, =0.100)\nEpoch #384: loss=0.103708 (contrastive=0.103489, msm=0.105674, =0.100)\nEpoch #385: loss=0.218224 (contrastive=0.230380, msm=0.108819, =0.100)\nEpoch #386: loss=0.126366 (contrastive=0.128493, msm=0.107229, =0.100)\nEpoch #387: loss=0.405612 (contrastive=0.438584, msm=0.108864, =0.100)\nEpoch #388: loss=0.127883 (contrastive=0.129548, msm=0.112896, =0.100)\nEpoch #389: loss=0.153823 (contrastive=0.158765, msm=0.109350, =0.100)\nEpoch #390: loss=0.198963 (contrastive=0.209278, msm=0.106133, =0.100)\nEpoch #391: loss=0.155445 (contrastive=0.159732, msm=0.116864, =0.100)\nEpoch #392: loss=0.146568 (contrastive=0.147615, msm=0.137152, =0.100)\nEpoch #393: loss=0.191898 (contrastive=0.198596, msm=0.131622, =0.100)\nEpoch #394: loss=0.166251 (contrastive=0.172600, msm=0.109111, =0.100)\nEpoch #395: loss=0.160018 (contrastive=0.164333, msm=0.121185, =0.100)\nEpoch #396: loss=0.133677 (contrastive=0.136159, msm=0.111336, =0.100)\nEpoch #397: loss=0.167661 (contrastive=0.173508, msm=0.115041, =0.100)\nEpoch #398: loss=0.159991 (contrastive=0.165340, msm=0.111853, =0.100)\nEpoch #399: loss=0.119908 (contrastive=0.121532, msm=0.105289, =0.100)\nEpoch #400: loss=0.109970 (contrastive=0.110274, msm=0.107233, =0.100)\nEpoch #401: loss=0.138002 (contrastive=0.141406, msm=0.107366, =0.100)\nEpoch #402: loss=0.123679 (contrastive=0.125670, msm=0.105760, =0.100)\nEpoch #403: loss=0.077933 (contrastive=0.076068, msm=0.094724, =0.100)\nEpoch #404: loss=0.103353 (contrastive=0.104081, msm=0.096803, =0.100)\nEpoch #405: loss=0.106747 (contrastive=0.107595, msm=0.099111, =0.100)\nEpoch #406: loss=0.135919 (contrastive=0.140540, msm=0.094326, =0.100)\nEpoch #407: loss=0.123823 (contrastive=0.126771, msm=0.097289, =0.100)\nEpoch #408: loss=0.165667 (contrastive=0.173131, msm=0.098489, =0.100)\nEpoch #409: loss=0.107468 (contrastive=0.109183, msm=0.092031, =0.100)\nEpoch #410: loss=0.374665 (contrastive=0.405455, msm=0.097560, =0.100)\nEpoch #411: loss=0.126726 (contrastive=0.129733, msm=0.099667, =0.100)\nEpoch #412: loss=0.077103 (contrastive=0.074987, msm=0.096142, =0.100)\nEpoch #413: loss=0.135802 (contrastive=0.140294, msm=0.095374, =0.100)\nEpoch #414: loss=0.100592 (contrastive=0.100424, msm=0.102108, =0.100)\nEpoch #415: loss=0.111400 (contrastive=0.112533, msm=0.101204, =0.100)\nEpoch #416: loss=0.154346 (contrastive=0.160461, msm=0.099309, =0.100)\nEpoch #417: loss=0.070831 (contrastive=0.068667, msm=0.090308, =0.100)\nEpoch #418: loss=0.100443 (contrastive=0.100361, msm=0.101178, =0.100)\nEpoch #419: loss=0.075599 (contrastive=0.073476, msm=0.094712, =0.100)\nEpoch #420: loss=0.109359 (contrastive=0.109996, msm=0.103626, =0.100)\nEpoch #421: loss=0.093297 (contrastive=0.092015, msm=0.104834, =0.100)\nEpoch #422: loss=0.162630 (contrastive=0.169862, msm=0.097544, =0.100)\nEpoch #423: loss=0.059221 (contrastive=0.055105, msm=0.096263, =0.100)\nEpoch #424: loss=0.080545 (contrastive=0.079109, msm=0.093464, =0.100)\nEpoch #425: loss=0.085060 (contrastive=0.083502, msm=0.099089, =0.100)\nEpoch #426: loss=0.069322 (contrastive=0.065950, msm=0.099676, =0.100)\nEpoch #427: loss=0.106075 (contrastive=0.107302, msm=0.095037, =0.100)\nEpoch #428: loss=0.115678 (contrastive=0.117910, msm=0.095586, =0.100)\nEpoch #429: loss=0.500855 (contrastive=0.545841, msm=0.095978, =0.100)\nEpoch #430: loss=0.097241 (contrastive=0.097608, msm=0.093941, =0.100)\nEpoch #431: loss=0.110178 (contrastive=0.111588, msm=0.097488, =0.100)\nEpoch #432: loss=0.059834 (contrastive=0.055829, msm=0.095881, =0.100)\nEpoch #433: loss=0.114654 (contrastive=0.116580, msm=0.097322, =0.100)\nEpoch #434: loss=0.127318 (contrastive=0.130546, msm=0.098269, =0.100)\nEpoch #435: loss=0.076935 (contrastive=0.074339, msm=0.100297, =0.100)\nEpoch #436: loss=0.095290 (contrastive=0.094610, msm=0.101409, =0.100)\nEpoch #437: loss=0.114162 (contrastive=0.115704, msm=0.100283, =0.100)\nEpoch #438: loss=0.415570 (contrastive=0.450296, msm=0.103035, =0.100)\nEpoch #439: loss=0.085204 (contrastive=0.083467, msm=0.100837, =0.100)\nEpoch #440: loss=0.113384 (contrastive=0.114899, msm=0.099754, =0.100)\nEpoch #441: loss=0.066606 (contrastive=0.062488, msm=0.103662, =0.100)\nEpoch #442: loss=0.100663 (contrastive=0.100753, msm=0.099857, =0.100)\nEpoch #443: loss=0.316505 (contrastive=0.339731, msm=0.107474, =0.100)\nEpoch #444: loss=0.152278 (contrastive=0.156210, msm=0.116892, =0.100)\nEpoch #445: loss=0.119448 (contrastive=0.121313, msm=0.102659, =0.100)\nEpoch #446: loss=0.159738 (contrastive=0.166069, msm=0.102760, =0.100)\nEpoch #447: loss=0.152278 (contrastive=0.156925, msm=0.110454, =0.100)\nEpoch #448: loss=0.072517 (contrastive=0.068039, msm=0.112821, =0.100)\nEpoch #449: loss=0.111455 (contrastive=0.111512, msm=0.110948, =0.100)\nEpoch #450: loss=0.127721 (contrastive=0.130860, msm=0.099470, =0.100)\nEpoch #451: loss=0.170457 (contrastive=0.178917, msm=0.094321, =0.100)\nEpoch #452: loss=0.064115 (contrastive=0.060556, msm=0.096146, =0.100)\nEpoch #453: loss=0.099031 (contrastive=0.098680, msm=0.102195, =0.100)\nEpoch #454: loss=0.100763 (contrastive=0.100725, msm=0.101102, =0.100)\nEpoch #455: loss=0.150467 (contrastive=0.156233, msm=0.098568, =0.100)\nEpoch #456: loss=0.085601 (contrastive=0.084262, msm=0.097654, =0.100)\nEpoch #457: loss=0.427284 (contrastive=0.464231, msm=0.094765, =0.100)\nEpoch #458: loss=0.087303 (contrastive=0.086825, msm=0.091603, =0.100)\nEpoch #459: loss=0.058649 (contrastive=0.054259, msm=0.098157, =0.100)\nEpoch #460: loss=0.161412 (contrastive=0.168011, msm=0.102024, =0.100)\nEpoch #461: loss=0.099414 (contrastive=0.099241, msm=0.100971, =0.100)\nEpoch #462: loss=0.084146 (contrastive=0.083101, msm=0.093547, =0.100)\nEpoch #463: loss=0.080053 (contrastive=0.078449, msm=0.094494, =0.100)\nEpoch #464: loss=0.120348 (contrastive=0.123220, msm=0.094505, =0.100)\nEpoch #465: loss=0.059011 (contrastive=0.055160, msm=0.093669, =0.100)\nEpoch #466: loss=0.067374 (contrastive=0.064423, msm=0.093930, =0.100)\nEpoch #467: loss=0.177241 (contrastive=0.186250, msm=0.096160, =0.100)\nEpoch #468: loss=0.107969 (contrastive=0.109550, msm=0.093740, =0.100)\nEpoch #469: loss=0.216318 (contrastive=0.230031, msm=0.092899, =0.100)\nEpoch #470: loss=0.096598 (contrastive=0.096685, msm=0.095816, =0.100)\nEpoch #471: loss=0.062323 (contrastive=0.058762, msm=0.094372, =0.100)\nEpoch #472: loss=0.067114 (contrastive=0.064210, msm=0.093250, =0.100)\nEpoch #473: loss=1.165650 (contrastive=1.284096, msm=0.099645, =0.100)\nEpoch #474: loss=0.081087 (contrastive=0.079363, msm=0.096595, =0.100)\nEpoch #475: loss=0.106839 (contrastive=0.107601, msm=0.099978, =0.100)\nEpoch #476: loss=0.152655 (contrastive=0.158692, msm=0.098323, =0.100)\nEpoch #477: loss=0.137224 (contrastive=0.141440, msm=0.099278, =0.100)\nEpoch #478: loss=0.143519 (contrastive=0.148604, msm=0.097748, =0.100)\nEpoch #479: loss=0.096330 (contrastive=0.096070, msm=0.098668, =0.100)\nEpoch #480: loss=0.204316 (contrastive=0.216112, msm=0.098154, =0.100)\nEpoch #481: loss=0.109842 (contrastive=0.111188, msm=0.097729, =0.100)\nEpoch #482: loss=0.169411 (contrastive=0.177256, msm=0.098806, =0.100)\nEpoch #483: loss=0.139710 (contrastive=0.144538, msm=0.096252, =0.100)\nEpoch #484: loss=0.215993 (contrastive=0.228493, msm=0.103487, =0.100)\nEpoch #485: loss=0.103910 (contrastive=0.105479, msm=0.089792, =0.100)\nEpoch #486: loss=0.064928 (contrastive=0.061933, msm=0.091880, =0.100)\nEpoch #487: loss=0.141562 (contrastive=0.146366, msm=0.098330, =0.100)\nEpoch #488: loss=0.086519 (contrastive=0.085669, msm=0.094165, =0.100)\nEpoch #489: loss=0.069961 (contrastive=0.066751, msm=0.098852, =0.100)\nEpoch #490: loss=0.225158 (contrastive=0.239378, msm=0.097182, =0.100)\nEpoch #491: loss=0.103561 (contrastive=0.105114, msm=0.089583, =0.100)\nEpoch #492: loss=0.071211 (contrastive=0.069392, msm=0.087582, =0.100)\nEpoch #493: loss=0.131053 (contrastive=0.135730, msm=0.088962, =0.100)\nEpoch #494: loss=0.075747 (contrastive=0.074054, msm=0.090989, =0.100)\nEpoch #495: loss=0.074423 (contrastive=0.072500, msm=0.091730, =0.100)\nEpoch #496: loss=0.076318 (contrastive=0.075293, msm=0.085539, =0.100)\nEpoch #497: loss=0.062173 (contrastive=0.059409, msm=0.087042, =0.100)\nEpoch #498: loss=0.045456 (contrastive=0.040029, msm=0.094302, =0.100)\nEpoch #499: loss=0.052294 (contrastive=0.048077, msm=0.090251, =0.100)\nEpoch #500: loss=0.123533 (contrastive=0.126738, msm=0.094686, =0.100)\nEpoch #501: loss=0.289582 (contrastive=0.311316, msm=0.093974, =0.100)\nEpoch #502: loss=0.057478 (contrastive=0.053653, msm=0.091898, =0.100)\nEpoch #503: loss=0.070517 (contrastive=0.067792, msm=0.095041, =0.100)\nEpoch #504: loss=0.093158 (contrastive=0.093009, msm=0.094503, =0.100)\nEpoch #505: loss=0.108852 (contrastive=0.110646, msm=0.092708, =0.100)\nEpoch #506: loss=0.166532 (contrastive=0.174396, msm=0.095757, =0.100)\nEpoch #507: loss=0.160309 (contrastive=0.167626, msm=0.094448, =0.100)\nEpoch #508: loss=0.159123 (contrastive=0.166310, msm=0.094439, =0.100)\nEpoch #509: loss=0.054684 (contrastive=0.049721, msm=0.099353, =0.100)\nEpoch #510: loss=0.085009 (contrastive=0.083177, msm=0.101498, =0.100)\nEpoch #511: loss=0.067198 (contrastive=0.064145, msm=0.094673, =0.100)\nEpoch #512: loss=0.074643 (contrastive=0.072701, msm=0.092125, =0.100)\nEpoch #513: loss=0.065594 (contrastive=0.062149, msm=0.096594, =0.100)\nEpoch #514: loss=0.095538 (contrastive=0.095028, msm=0.100132, =0.100)\nEpoch #515: loss=0.063141 (contrastive=0.059503, msm=0.095884, =0.100)\nEpoch #516: loss=0.071514 (contrastive=0.068756, msm=0.096329, =0.100)\nEpoch #517: loss=0.124060 (contrastive=0.127643, msm=0.091808, =0.100)\nEpoch #518: loss=0.058586 (contrastive=0.054259, msm=0.097526, =0.100)\nEpoch #519: loss=0.087056 (contrastive=0.085541, msm=0.100687, =0.100)\nEpoch #520: loss=0.070307 (contrastive=0.067035, msm=0.099749, =0.100)\nEpoch #521: loss=0.055492 (contrastive=0.051140, msm=0.094661, =0.100)\nEpoch #522: loss=0.105677 (contrastive=0.106628, msm=0.097116, =0.100)\nEpoch #523: loss=0.051963 (contrastive=0.047589, msm=0.091329, =0.100)\nEpoch #524: loss=0.075336 (contrastive=0.073549, msm=0.091414, =0.100)\nEpoch #525: loss=0.066449 (contrastive=0.063715, msm=0.091052, =0.100)\nEpoch #526: loss=0.061285 (contrastive=0.058196, msm=0.089093, =0.100)\nEpoch #527: loss=0.052771 (contrastive=0.049151, msm=0.085351, =0.100)\nEpoch #528: loss=0.072747 (contrastive=0.070435, msm=0.093559, =0.100)\nEpoch #529: loss=0.078759 (contrastive=0.077852, msm=0.086916, =0.100)\nEpoch #530: loss=0.040137 (contrastive=0.034422, msm=0.091579, =0.100)\nEpoch #531: loss=0.119567 (contrastive=0.122996, msm=0.088706, =0.100)\nEpoch #532: loss=0.033425 (contrastive=0.027177, msm=0.089658, =0.100)\nEpoch #533: loss=0.103948 (contrastive=0.105603, msm=0.089055, =0.100)\nEpoch #534: loss=0.040368 (contrastive=0.035065, msm=0.088096, =0.100)\nEpoch #535: loss=0.048652 (contrastive=0.044311, msm=0.087720, =0.100)\nEpoch #536: loss=0.122329 (contrastive=0.125606, msm=0.092835, =0.100)\nEpoch #537: loss=0.097028 (contrastive=0.098044, msm=0.087883, =0.100)\nEpoch #538: loss=0.086872 (contrastive=0.086565, msm=0.089637, =0.100)\nEpoch #539: loss=0.119971 (contrastive=0.123189, msm=0.091010, =0.100)\nEpoch #540: loss=0.061990 (contrastive=0.059303, msm=0.086181, =0.100)\nEpoch #541: loss=0.099513 (contrastive=0.100860, msm=0.087396, =0.100)\nEpoch #542: loss=0.085544 (contrastive=0.084654, msm=0.093556, =0.100)\nEpoch #543: loss=0.077331 (contrastive=0.074921, msm=0.099017, =0.100)\nEpoch #544: loss=0.108486 (contrastive=0.109824, msm=0.096447, =0.100)\nEpoch #545: loss=0.118862 (contrastive=0.121450, msm=0.095576, =0.100)\nEpoch #546: loss=0.126421 (contrastive=0.130482, msm=0.089872, =0.100)\nEpoch #547: loss=0.077562 (contrastive=0.076350, msm=0.088473, =0.100)\nEpoch #548: loss=0.228607 (contrastive=0.243709, msm=0.092686, =0.100)\nEpoch #549: loss=0.157718 (contrastive=0.163640, msm=0.104420, =0.100)\nEpoch #550: loss=0.080580 (contrastive=0.077716, msm=0.106358, =0.100)\nEpoch #551: loss=0.121921 (contrastive=0.124754, msm=0.096424, =0.100)\nEpoch #552: loss=0.074559 (contrastive=0.072804, msm=0.090350, =0.100)\nEpoch #553: loss=0.068523 (contrastive=0.065704, msm=0.093891, =0.100)\nEpoch #554: loss=0.049444 (contrastive=0.044249, msm=0.096194, =0.100)\nEpoch #555: loss=0.064242 (contrastive=0.060392, msm=0.098898, =0.100)\nEpoch #556: loss=0.087646 (contrastive=0.087266, msm=0.091062, =0.100)\nEpoch #557: loss=0.099833 (contrastive=0.101127, msm=0.088182, =0.100)\nEpoch #558: loss=0.074232 (contrastive=0.072693, msm=0.088074, =0.100)\nEpoch #559: loss=0.122631 (contrastive=0.126405, msm=0.088664, =0.100)\nEpoch #560: loss=0.137847 (contrastive=0.142945, msm=0.091959, =0.100)\nEpoch #561: loss=0.086063 (contrastive=0.084639, msm=0.098874, =0.100)\nEpoch #562: loss=0.127851 (contrastive=0.131465, msm=0.095328, =0.100)\nEpoch #563: loss=0.113901 (contrastive=0.116508, msm=0.090436, =0.100)\nEpoch #564: loss=0.046479 (contrastive=0.041372, msm=0.092442, =0.100)\nEpoch #565: loss=0.129234 (contrastive=0.133668, msm=0.089326, =0.100)\nEpoch #566: loss=0.141053 (contrastive=0.146740, msm=0.089861, =0.100)\nEpoch #567: loss=0.072196 (contrastive=0.069795, msm=0.093808, =0.100)\nEpoch #568: loss=0.118789 (contrastive=0.121684, msm=0.092732, =0.100)\nEpoch #569: loss=0.066953 (contrastive=0.064290, msm=0.090919, =0.100)\nEpoch #570: loss=0.489930 (contrastive=0.534169, msm=0.091785, =0.100)\nEpoch #571: loss=0.058645 (contrastive=0.054338, msm=0.097413, =0.100)\nEpoch #572: loss=0.332445 (contrastive=0.359150, msm=0.092100, =0.100)\nEpoch #573: loss=0.100475 (contrastive=0.101306, msm=0.092997, =0.100)\nEpoch #574: loss=0.082786 (contrastive=0.080665, msm=0.101874, =0.100)\nEpoch #575: loss=0.164679 (contrastive=0.172072, msm=0.098146, =0.100)\nEpoch #576: loss=0.143244 (contrastive=0.149154, msm=0.090057, =0.100)\nEpoch #577: loss=0.135308 (contrastive=0.140346, msm=0.089963, =0.100)\nEpoch #578: loss=0.088002 (contrastive=0.087118, msm=0.095959, =0.100)\nEpoch #579: loss=0.071463 (contrastive=0.068976, msm=0.093838, =0.100)\nEpoch #580: loss=0.077482 (contrastive=0.075336, msm=0.096799, =0.100)\nEpoch #581: loss=0.057345 (contrastive=0.054019, msm=0.087280, =0.100)\nEpoch #582: loss=0.154079 (contrastive=0.161287, msm=0.089204, =0.100)\nEpoch #583: loss=0.096946 (contrastive=0.097732, msm=0.089863, =0.100)\nEpoch #584: loss=0.043696 (contrastive=0.039013, msm=0.085834, =0.100)\nEpoch #585: loss=0.101518 (contrastive=0.103109, msm=0.087194, =0.100)\nEpoch #586: loss=0.244415 (contrastive=0.261153, msm=0.093774, =0.100)\nEpoch #587: loss=0.081945 (contrastive=0.080058, msm=0.098925, =0.100)\nEpoch #588: loss=0.087686 (contrastive=0.087052, msm=0.093387, =0.100)\nEpoch #589: loss=0.050076 (contrastive=0.045707, msm=0.089402, =0.100)\nEpoch #590: loss=0.067556 (contrastive=0.064076, msm=0.098874, =0.100)\nEpoch #591: loss=0.076848 (contrastive=0.074752, msm=0.095709, =0.100)\nEpoch #592: loss=0.038422 (contrastive=0.032774, msm=0.089253, =0.100)\nEpoch #593: loss=0.046379 (contrastive=0.041672, msm=0.088743, =0.100)\nEpoch #594: loss=0.047833 (contrastive=0.042744, msm=0.093634, =0.100)\nEpoch #595: loss=0.073542 (contrastive=0.072096, msm=0.086551, =0.100)\nEpoch #596: loss=0.045090 (contrastive=0.039777, msm=0.092910, =0.100)\nEpoch #597: loss=0.055835 (contrastive=0.052242, msm=0.088168, =0.100)\nEpoch #598: loss=0.150861 (contrastive=0.157924, msm=0.087296, =0.100)\nEpoch #599: loss=0.089284 (contrastive=0.089313, msm=0.089030, =0.100)\nTraining time: 0:07:49.245330\nEvaluation completed\nResults: {'ours': {24: {'norm': {'MSE': 0.1292776956673386, 'MAE': 0.2850626546932898}, 'raw': {'MSE': 10.878017242325337, 'MAE': 2.614889842519545}}, 48: {'norm': {'MSE': 0.13940896884852164, 'MAE': 0.2965676916542434}, 'raw': {'MSE': 11.730508945295284, 'MAE': 2.7204259539924314}}, 96: {'norm': {'MSE': 0.14432299490682843, 'MAE': 0.301840413306571}, 'raw': {'MSE': 12.143997597834709, 'MAE': 2.7687928165883475}}, 288: {'norm': {'MSE': 0.15727709932655834, 'MAE': 0.3131363089365513}, 'raw': {'MSE': 13.234015244803391, 'MAE': 2.872410466312595}}, 672: {'norm': {'MSE': 0.1713063626204752, 'MAE': 0.3267012468098908}, 'raw': {'MSE': 14.414501688174047, 'MAE': 2.9968421197093322}}}, 'ts2vec_infer_time': 215.30868458747864, 'lr_train_time': {24: 1.9009051322937012, 48: 2.08296275138855, 96: 2.2489941120147705, 288: 3.0098350048065186, 672: 4.8645689487457275}, 'lr_infer_time': {24: 0.0063054561614990234, 48: 0.0076923370361328125, 96: 0.013239383697509766, 288: 0.02783346176147461, 672: 0.050688982009887695}}\nModel and results saved to training/ETTm1__forecast_univar_msm_conservative_2025-09-22_16_56_30_427475\n","output_type":"stream"}],"execution_count":13}]}