{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c042f34c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-12T03:33:20.113263Z",
     "iopub.status.busy": "2025-10-12T03:33:20.113039Z",
     "iopub.status.idle": "2025-10-12T03:33:21.451390Z",
     "shell.execute_reply": "2025-10-12T03:33:21.450520Z"
    },
    "papermill": {
     "duration": 1.344038,
     "end_time": "2025-10-12T03:33:21.452967",
     "exception": false,
     "start_time": "2025-10-12T03:33:20.108929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ettsmall/ETTh2.csv\n",
      "/kaggle/input/ettsmall/ETTm2.csv\n",
      "/kaggle/input/ettsmall/ETTm1.csv\n",
      "/kaggle/input/ettsmall/ETTh1.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1eeb23c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:33:21.462412Z",
     "iopub.status.busy": "2025-10-12T03:33:21.462103Z",
     "iopub.status.idle": "2025-10-12T03:33:22.197191Z",
     "shell.execute_reply": "2025-10-12T03:33:22.195996Z"
    },
    "papermill": {
     "duration": 0.740607,
     "end_time": "2025-10-12T03:33:22.199094",
     "exception": false,
     "start_time": "2025-10-12T03:33:21.458487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ts2vec'...\r\n",
      "remote: Enumerating objects: 461, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (60/60), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (32/32), done.\u001b[K\r\n",
      "remote: Total 461 (delta 39), reused 31 (delta 28), pack-reused 401 (from 3)\u001b[K\r\n",
      "Receiving objects: 100% (461/461), 454.65 KiB | 4.84 MiB/s, done.\r\n",
      "Resolving deltas: 100% (268/268), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Niroshan2001/ts2vec.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0718c68b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:33:22.209843Z",
     "iopub.status.busy": "2025-10-12T03:33:22.209382Z",
     "iopub.status.idle": "2025-10-12T03:33:22.708792Z",
     "shell.execute_reply": "2025-10-12T03:33:22.707809Z"
    },
    "papermill": {
     "duration": 0.505384,
     "end_time": "2025-10-12T03:33:22.710298",
     "exception": false,
     "start_time": "2025-10-12T03:33:22.204914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/ts2vec\n",
      "Branch 'optimized-ensemble' set up to track remote branch 'optimized-ensemble' from 'origin'.\r\n",
      "Switched to a new branch 'optimized-ensemble'\r\n"
     ]
    }
   ],
   "source": [
    "%cd ts2vec\n",
    "!git fetch origin\n",
    "!git checkout optimized-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b052db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:33:22.718335Z",
     "iopub.status.busy": "2025-10-12T03:33:22.717613Z",
     "iopub.status.idle": "2025-10-12T03:33:32.961547Z",
     "shell.execute_reply": "2025-10-12T03:33:32.960484Z"
    },
    "papermill": {
     "duration": 10.249407,
     "end_time": "2025-10-12T03:33:32.963108",
     "exception": false,
     "start_time": "2025-10-12T03:33:22.713701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bottleneck in /usr/local/lib/python3.11/dist-packages (1.4.2)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bottleneck) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bottleneck) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bottleneck) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bottleneck) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bottleneck) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bottleneck) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bottleneck) (2024.2.0)\r\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.5)\r\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.26.4)\r\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.15.3)\r\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.3)\r\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (25.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.22.3->statsmodels) (2.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.22.3->statsmodels) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.22.3->statsmodels) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.22.3->statsmodels) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.22.3->statsmodels) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.22.3->statsmodels) (2024.2.0)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bottleneck\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84108fc",
   "metadata": {
    "papermill": {
     "duration": 0.003343,
     "end_time": "2025-10-12T03:33:32.970302",
     "exception": false,
     "start_time": "2025-10-12T03:33:32.966959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0438beb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:33:32.978266Z",
     "iopub.status.busy": "2025-10-12T03:33:32.978001Z",
     "iopub.status.idle": "2025-10-12T03:33:33.221540Z",
     "shell.execute_reply": "2025-10-12T03:33:33.220528Z"
    },
    "papermill": {
     "duration": 0.249287,
     "end_time": "2025-10-12T03:33:33.222885",
     "exception": false,
     "start_time": "2025-10-12T03:33:32.973598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /kaggle/input/ettsmall/ETTh1.csv -> datasets/ETTh1.csv\n",
      "Copied /kaggle/input/ettsmall/ETTh2.csv -> datasets/ETTh2.csv\n",
      "Copied /kaggle/input/ettsmall/ETTm1.csv -> datasets/ETTm1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Kaggle path to your CSV\n",
    "source_path = \"/kaggle/input/ettsmall/ETTh1.csv\"  # adjust if needed\n",
    "\n",
    "# Destination path expected by ts2vec\n",
    "dest_folder = \"datasets\"\n",
    "os.makedirs(dest_folder, exist_ok=True)\n",
    "dest_path = os.path.join(dest_folder, \"ETTh1.csv\")\n",
    "\n",
    "# Copy the CSV\n",
    "shutil.copyfile(source_path, dest_path)\n",
    "print(f\"Copied {source_path} -> {dest_path}\")\n",
    "\n",
    "# Kaggle path to your CSV\n",
    "source_path = \"/kaggle/input/ettsmall/ETTh2.csv\"  # adjust if needed\n",
    "\n",
    "# Destination path expected by ts2vec\n",
    "dest_folder = \"datasets\"\n",
    "os.makedirs(dest_folder, exist_ok=True)\n",
    "dest_path = os.path.join(dest_folder, \"ETTh2.csv\")\n",
    "\n",
    "# Copy the CSV\n",
    "shutil.copyfile(source_path, dest_path)\n",
    "print(f\"Copied {source_path} -> {dest_path}\")\n",
    "\n",
    "# Kaggle path to your CSV\n",
    "source_path = \"/kaggle/input/ettsmall/ETTm1.csv\"  # adjust if needed\n",
    "\n",
    "# Destination path expected by ts2vec\n",
    "dest_folder = \"datasets\"\n",
    "os.makedirs(dest_folder, exist_ok=True)\n",
    "dest_path = os.path.join(dest_folder, \"ETTm1.csv\")\n",
    "\n",
    "# Copy the CSV\n",
    "shutil.copyfile(source_path, dest_path)\n",
    "print(f\"Copied {source_path} -> {dest_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597ac44",
   "metadata": {
    "papermill": {
     "duration": 0.003328,
     "end_time": "2025-10-12T03:33:33.229834",
     "exception": false,
     "start_time": "2025-10-12T03:33:33.226506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Univariate Forcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3052bd0",
   "metadata": {
    "papermill": {
     "duration": 0.003109,
     "end_time": "2025-10-12T03:33:33.236229",
     "exception": false,
     "start_time": "2025-10-12T03:33:33.233120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ETTm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3478652f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:33:33.243717Z",
     "iopub.status.busy": "2025-10-12T03:33:33.243456Z",
     "iopub.status.idle": "2025-10-12T03:37:28.850645Z",
     "shell.execute_reply": "2025-10-12T03:37:28.849677Z"
    },
    "papermill": {
     "duration": 235.612579,
     "end_time": "2025-10-12T03:37:28.852130",
     "exception": false,
     "start_time": "2025-10-12T03:33:33.239551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm1\r\n",
      "Arguments: Namespace(dataset='ETTm1', run_name='forecast_univar', loader='forecast_csv_univar', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0)\r\n",
      "Loading data... done\r\n",
      "Epoch #0: loss=9.974915504455566\r\n",
      "Epoch #1: loss=7.788388729095459\r\n",
      "Epoch #2: loss=4.470953464508057\r\n",
      "Epoch #3: loss=3.357196807861328\r\n",
      "Epoch #4: loss=3.5537476539611816\r\n",
      "Epoch #5: loss=3.2539517879486084\r\n",
      "Epoch #6: loss=2.844970464706421\r\n",
      "Epoch #7: loss=2.8072268962860107\r\n",
      "Epoch #8: loss=2.8186511993408203\r\n",
      "Epoch #9: loss=2.663585662841797\r\n",
      "Epoch #10: loss=2.3601760864257812\r\n",
      "Epoch #11: loss=2.5582194328308105\r\n",
      "Epoch #12: loss=2.524721384048462\r\n",
      "Epoch #13: loss=2.419724702835083\r\n",
      "Epoch #14: loss=2.420372247695923\r\n",
      "Epoch #15: loss=2.3317387104034424\r\n",
      "Epoch #16: loss=2.2114667892456055\r\n",
      "Epoch #17: loss=2.189521312713623\r\n",
      "Epoch #18: loss=2.102508068084717\r\n",
      "Epoch #19: loss=2.1260018348693848\r\n",
      "Epoch #20: loss=2.184966564178467\r\n",
      "Epoch #21: loss=2.0020179748535156\r\n",
      "Epoch #22: loss=2.1778721809387207\r\n",
      "Epoch #23: loss=2.0103256702423096\r\n",
      "Epoch #24: loss=2.017800807952881\r\n",
      "Epoch #25: loss=1.889033555984497\r\n",
      "Epoch #26: loss=1.9819496870040894\r\n",
      "Epoch #27: loss=1.9936357736587524\r\n",
      "Epoch #28: loss=1.8454177379608154\r\n",
      "Epoch #29: loss=1.981456995010376\r\n",
      "Epoch #30: loss=1.9084941148757935\r\n",
      "Epoch #31: loss=1.9123764038085938\r\n",
      "Epoch #32: loss=1.7980892658233643\r\n",
      "Epoch #33: loss=1.7401862144470215\r\n",
      "Epoch #34: loss=1.9210145473480225\r\n",
      "Epoch #35: loss=1.595031976699829\r\n",
      "Epoch #36: loss=1.7230315208435059\r\n",
      "Epoch #37: loss=1.5743494033813477\r\n",
      "Epoch #38: loss=1.600445032119751\r\n",
      "Epoch #39: loss=1.5253396034240723\r\n",
      "Epoch #40: loss=1.533871054649353\r\n",
      "Epoch #41: loss=1.7261584997177124\r\n",
      "Epoch #42: loss=1.7686526775360107\r\n",
      "Epoch #43: loss=1.60025155544281\r\n",
      "Epoch #44: loss=1.6270893812179565\r\n",
      "Epoch #45: loss=1.4126019477844238\r\n",
      "Epoch #46: loss=1.435981273651123\r\n",
      "Epoch #47: loss=1.3387396335601807\r\n",
      "Epoch #48: loss=1.3445848226547241\r\n",
      "Epoch #49: loss=1.3508915901184082\r\n",
      "Epoch #50: loss=1.4115257263183594\r\n",
      "Epoch #51: loss=1.336796522140503\r\n",
      "Epoch #52: loss=1.3111388683319092\r\n",
      "Epoch #53: loss=1.3945505619049072\r\n",
      "Epoch #54: loss=1.555567979812622\r\n",
      "Epoch #55: loss=1.301802396774292\r\n",
      "Epoch #56: loss=1.266157865524292\r\n",
      "Epoch #57: loss=1.1954519748687744\r\n",
      "Epoch #58: loss=1.452716588973999\r\n",
      "Epoch #59: loss=1.2029725313186646\r\n",
      "Epoch #60: loss=1.1544196605682373\r\n",
      "Epoch #61: loss=1.079150915145874\r\n",
      "Epoch #62: loss=1.2056539058685303\r\n",
      "Epoch #63: loss=1.1998170614242554\r\n",
      "Epoch #64: loss=1.0844767093658447\r\n",
      "Epoch #65: loss=1.0892186164855957\r\n",
      "Epoch #66: loss=1.0335828065872192\r\n",
      "Epoch #67: loss=1.1668496131896973\r\n",
      "Epoch #68: loss=1.128265380859375\r\n",
      "Epoch #69: loss=1.0497053861618042\r\n",
      "Epoch #70: loss=1.3383175134658813\r\n",
      "Epoch #71: loss=1.211545467376709\r\n",
      "Epoch #72: loss=1.3344309329986572\r\n",
      "Epoch #73: loss=0.937053382396698\r\n",
      "Epoch #74: loss=1.4424738883972168\r\n",
      "Epoch #75: loss=1.07781982421875\r\n",
      "Epoch #76: loss=1.0793914794921875\r\n",
      "Epoch #77: loss=1.0426604747772217\r\n",
      "Epoch #78: loss=0.9853948354721069\r\n",
      "Epoch #79: loss=1.0093858242034912\r\n",
      "Epoch #80: loss=0.9577756524085999\r\n",
      "Epoch #81: loss=1.1204218864440918\r\n",
      "Epoch #82: loss=1.102059245109558\r\n",
      "Epoch #83: loss=1.3112598657608032\r\n",
      "Epoch #84: loss=0.9791291356086731\r\n",
      "Epoch #85: loss=0.9061698317527771\r\n",
      "Epoch #86: loss=1.3972731828689575\r\n",
      "Epoch #87: loss=0.967282772064209\r\n",
      "Epoch #88: loss=0.972100019454956\r\n",
      "Epoch #89: loss=1.0108554363250732\r\n",
      "Epoch #90: loss=0.8993636965751648\r\n",
      "Epoch #91: loss=0.9373084902763367\r\n",
      "Epoch #92: loss=1.0943905115127563\r\n",
      "Epoch #93: loss=1.1144884824752808\r\n",
      "Epoch #94: loss=1.7903861999511719\r\n",
      "Epoch #95: loss=1.3057180643081665\r\n",
      "Epoch #96: loss=1.0772149562835693\r\n",
      "Epoch #97: loss=0.9531377553939819\r\n",
      "Epoch #98: loss=0.9416815638542175\r\n",
      "Epoch #99: loss=1.0482571125030518\r\n",
      "Epoch #100: loss=0.9055315852165222\r\n",
      "Epoch #101: loss=1.0257725715637207\r\n",
      "Epoch #102: loss=1.1452727317810059\r\n",
      "Epoch #103: loss=0.931402325630188\r\n",
      "Epoch #104: loss=0.9205090403556824\r\n",
      "Epoch #105: loss=0.9960004687309265\r\n",
      "Epoch #106: loss=1.0000375509262085\r\n",
      "Epoch #107: loss=0.8875467777252197\r\n",
      "Epoch #108: loss=1.4390223026275635\r\n",
      "Epoch #109: loss=0.9330977201461792\r\n",
      "Epoch #110: loss=0.9592097401618958\r\n",
      "Epoch #111: loss=1.6299792528152466\r\n",
      "Epoch #112: loss=0.8719220757484436\r\n",
      "Epoch #113: loss=0.7695698738098145\r\n",
      "Epoch #114: loss=1.1142624616622925\r\n",
      "Epoch #115: loss=0.9031351804733276\r\n",
      "Epoch #116: loss=0.9110831618309021\r\n",
      "Epoch #117: loss=0.727066695690155\r\n",
      "Epoch #118: loss=1.03603196144104\r\n",
      "Epoch #119: loss=0.7640655040740967\r\n",
      "Epoch #120: loss=0.7973556518554688\r\n",
      "Epoch #121: loss=0.6884305477142334\r\n",
      "Epoch #122: loss=0.8223275542259216\r\n",
      "Epoch #123: loss=0.7647289037704468\r\n",
      "Epoch #124: loss=0.922002375125885\r\n",
      "Epoch #125: loss=0.9854381084442139\r\n",
      "Epoch #126: loss=1.1319135427474976\r\n",
      "Epoch #127: loss=1.2332497835159302\r\n",
      "Epoch #128: loss=0.6558952927589417\r\n",
      "Epoch #129: loss=0.7684520483016968\r\n",
      "Epoch #130: loss=0.7383008003234863\r\n",
      "Epoch #131: loss=0.7042238712310791\r\n",
      "Epoch #132: loss=0.7239725589752197\r\n",
      "Epoch #133: loss=0.9306244850158691\r\n",
      "Epoch #134: loss=0.7825210690498352\r\n",
      "Epoch #135: loss=1.456687331199646\r\n",
      "Epoch #136: loss=0.8284844756126404\r\n",
      "Epoch #137: loss=0.7630558013916016\r\n",
      "Epoch #138: loss=0.6918672919273376\r\n",
      "Epoch #139: loss=0.8458296656608582\r\n",
      "Epoch #140: loss=0.9031716585159302\r\n",
      "Epoch #141: loss=0.8333383798599243\r\n",
      "Epoch #142: loss=0.6861823797225952\r\n",
      "Epoch #143: loss=0.7145525217056274\r\n",
      "Epoch #144: loss=0.7641324400901794\r\n",
      "Epoch #145: loss=0.9756192564964294\r\n",
      "Epoch #146: loss=0.6776186227798462\r\n",
      "Epoch #147: loss=0.7823714017868042\r\n",
      "Epoch #148: loss=0.7581117153167725\r\n",
      "Epoch #149: loss=1.1621909141540527\r\n",
      "Epoch #150: loss=0.6311991810798645\r\n",
      "Epoch #151: loss=0.6898572444915771\r\n",
      "Epoch #152: loss=0.7259647846221924\r\n",
      "Epoch #153: loss=0.7744569778442383\r\n",
      "Epoch #154: loss=0.6083213686943054\r\n",
      "Epoch #155: loss=0.7801415324211121\r\n",
      "Epoch #156: loss=0.9911990761756897\r\n",
      "Epoch #157: loss=0.7662515640258789\r\n",
      "Epoch #158: loss=0.5985455513000488\r\n",
      "Epoch #159: loss=0.7982200980186462\r\n",
      "Epoch #160: loss=0.6168964505195618\r\n",
      "Epoch #161: loss=0.679307222366333\r\n",
      "Epoch #162: loss=0.7183154225349426\r\n",
      "Epoch #163: loss=0.6086603403091431\r\n",
      "Epoch #164: loss=0.6374098062515259\r\n",
      "Epoch #165: loss=1.0345418453216553\r\n",
      "Epoch #166: loss=0.7141920924186707\r\n",
      "Epoch #167: loss=0.5841909646987915\r\n",
      "Epoch #168: loss=1.042270302772522\r\n",
      "Epoch #169: loss=0.6506102085113525\r\n",
      "Epoch #170: loss=0.8825448155403137\r\n",
      "Epoch #171: loss=0.9175170063972473\r\n",
      "Epoch #172: loss=0.6930093169212341\r\n",
      "Epoch #173: loss=0.8814525008201599\r\n",
      "Epoch #174: loss=0.8345538973808289\r\n",
      "Epoch #175: loss=0.6555811166763306\r\n",
      "Epoch #176: loss=0.6827486753463745\r\n",
      "Epoch #177: loss=0.5663427114486694\r\n",
      "Epoch #178: loss=0.5757014751434326\r\n",
      "Epoch #179: loss=0.8822957873344421\r\n",
      "Epoch #180: loss=0.6226481199264526\r\n",
      "Epoch #181: loss=0.7130886912345886\r\n",
      "Epoch #182: loss=1.3040462732315063\r\n",
      "Epoch #183: loss=0.6644665598869324\r\n",
      "Epoch #184: loss=0.9698137044906616\r\n",
      "Epoch #185: loss=0.597743809223175\r\n",
      "Epoch #186: loss=0.6481406092643738\r\n",
      "Epoch #187: loss=0.7542608976364136\r\n",
      "Epoch #188: loss=0.8393048048019409\r\n",
      "Epoch #189: loss=0.9306526184082031\r\n",
      "Epoch #190: loss=0.6048747301101685\r\n",
      "Epoch #191: loss=1.023144006729126\r\n",
      "Epoch #192: loss=1.3738605976104736\r\n",
      "Epoch #193: loss=0.8256046175956726\r\n",
      "Epoch #194: loss=1.1591129302978516\r\n",
      "Epoch #195: loss=0.6551777124404907\r\n",
      "Epoch #196: loss=0.8373793959617615\r\n",
      "Epoch #197: loss=0.627194881439209\r\n",
      "Epoch #198: loss=0.5871835947036743\r\n",
      "Epoch #199: loss=0.6245968341827393\r\n",
      "Epoch #200: loss=0.7260451316833496\r\n",
      "Epoch #201: loss=1.2651113271713257\r\n",
      "Epoch #202: loss=0.7039257287979126\r\n",
      "Epoch #203: loss=0.5915085077285767\r\n",
      "Epoch #204: loss=0.6710962653160095\r\n",
      "Epoch #205: loss=0.9815382361412048\r\n",
      "Epoch #206: loss=0.7423115372657776\r\n",
      "Epoch #207: loss=0.5937491059303284\r\n",
      "Epoch #208: loss=0.5483126640319824\r\n",
      "Epoch #209: loss=0.5159261226654053\r\n",
      "Epoch #210: loss=0.9563772678375244\r\n",
      "Epoch #211: loss=0.49919360876083374\r\n",
      "Epoch #212: loss=0.6592121124267578\r\n",
      "Epoch #213: loss=0.5239851474761963\r\n",
      "Epoch #214: loss=0.7444173097610474\r\n",
      "Epoch #215: loss=0.5496500134468079\r\n",
      "Epoch #216: loss=1.2770309448242188\r\n",
      "Epoch #217: loss=0.6116113066673279\r\n",
      "Epoch #218: loss=0.5881600975990295\r\n",
      "Epoch #219: loss=0.561883807182312\r\n",
      "Epoch #220: loss=0.659464955329895\r\n",
      "Epoch #221: loss=0.518301784992218\r\n",
      "Epoch #222: loss=0.9467757344245911\r\n",
      "Epoch #223: loss=0.4737246036529541\r\n",
      "Epoch #224: loss=0.5988836884498596\r\n",
      "Epoch #225: loss=0.4722723960876465\r\n",
      "Epoch #226: loss=0.5145800709724426\r\n",
      "Epoch #227: loss=0.7866781949996948\r\n",
      "Epoch #228: loss=0.6900297403335571\r\n",
      "Epoch #229: loss=0.480762243270874\r\n",
      "Epoch #230: loss=0.7307276725769043\r\n",
      "Epoch #231: loss=0.44003748893737793\r\n",
      "Epoch #232: loss=0.44446131587028503\r\n",
      "Epoch #233: loss=0.48549970984458923\r\n",
      "Epoch #234: loss=0.5892845392227173\r\n",
      "Epoch #235: loss=0.5028150677680969\r\n",
      "Epoch #236: loss=0.6493520736694336\r\n",
      "Epoch #237: loss=0.45869383215904236\r\n",
      "Epoch #238: loss=0.43032312393188477\r\n",
      "Epoch #239: loss=0.5644866228103638\r\n",
      "Epoch #240: loss=0.49559831619262695\r\n",
      "Epoch #241: loss=0.4070231318473816\r\n",
      "Epoch #242: loss=0.38451075553894043\r\n",
      "Epoch #243: loss=0.8734648823738098\r\n",
      "Epoch #244: loss=0.39711642265319824\r\n",
      "Epoch #245: loss=0.3992241322994232\r\n",
      "Epoch #246: loss=0.6191041469573975\r\n",
      "Epoch #247: loss=0.39166003465652466\r\n",
      "Epoch #248: loss=0.5598213076591492\r\n",
      "Epoch #249: loss=1.1215330362319946\r\n",
      "Epoch #250: loss=0.44891467690467834\r\n",
      "Epoch #251: loss=0.4384263753890991\r\n",
      "Epoch #252: loss=0.5203258991241455\r\n",
      "Epoch #253: loss=0.6438458561897278\r\n",
      "Epoch #254: loss=0.4227721393108368\r\n",
      "Epoch #255: loss=0.9649192094802856\r\n",
      "Epoch #256: loss=0.4711722135543823\r\n",
      "Epoch #257: loss=0.45404648780822754\r\n",
      "Epoch #258: loss=0.8953010439872742\r\n",
      "Epoch #259: loss=0.5206575393676758\r\n",
      "Epoch #260: loss=0.5478913187980652\r\n",
      "Epoch #261: loss=0.4707814157009125\r\n",
      "Epoch #262: loss=0.5023378133773804\r\n",
      "Epoch #263: loss=0.458590030670166\r\n",
      "Epoch #264: loss=0.6288827657699585\r\n",
      "Epoch #265: loss=0.6601123809814453\r\n",
      "Epoch #266: loss=0.8577776551246643\r\n",
      "Epoch #267: loss=0.6279020309448242\r\n",
      "Epoch #268: loss=0.399894654750824\r\n",
      "Epoch #269: loss=0.4059799313545227\r\n",
      "Epoch #270: loss=0.40759313106536865\r\n",
      "Epoch #271: loss=0.49572885036468506\r\n",
      "Epoch #272: loss=0.41054099798202515\r\n",
      "Epoch #273: loss=0.7973728179931641\r\n",
      "Epoch #274: loss=0.39828020334243774\r\n",
      "Epoch #275: loss=0.4549076557159424\r\n",
      "Epoch #276: loss=1.172992467880249\r\n",
      "Epoch #277: loss=0.4177285432815552\r\n",
      "Epoch #278: loss=0.45814046263694763\r\n",
      "Epoch #279: loss=0.427647203207016\r\n",
      "Epoch #280: loss=0.450749933719635\r\n",
      "Epoch #281: loss=0.4941210448741913\r\n",
      "Epoch #282: loss=0.6357969045639038\r\n",
      "Epoch #283: loss=0.4476693868637085\r\n",
      "Epoch #284: loss=0.45559975504875183\r\n",
      "Epoch #285: loss=0.40482330322265625\r\n",
      "Epoch #286: loss=0.40517133474349976\r\n",
      "Epoch #287: loss=0.5391586422920227\r\n",
      "Epoch #288: loss=0.3965786397457123\r\n",
      "Epoch #289: loss=0.43336424231529236\r\n",
      "Epoch #290: loss=0.5542430281639099\r\n",
      "Epoch #291: loss=0.4039422571659088\r\n",
      "Epoch #292: loss=0.5907133221626282\r\n",
      "Epoch #293: loss=0.4866620600223541\r\n",
      "Epoch #294: loss=0.4531688690185547\r\n",
      "Epoch #295: loss=0.4338829517364502\r\n",
      "Epoch #296: loss=0.5160211324691772\r\n",
      "Epoch #297: loss=0.5700159072875977\r\n",
      "Epoch #298: loss=1.4750337600708008\r\n",
      "Epoch #299: loss=0.5477309823036194\r\n",
      "Epoch #300: loss=0.44967788457870483\r\n",
      "Epoch #301: loss=0.5188431143760681\r\n",
      "Epoch #302: loss=0.9741730093955994\r\n",
      "Epoch #303: loss=0.5155066847801208\r\n",
      "Epoch #304: loss=0.45013970136642456\r\n",
      "Epoch #305: loss=0.42228055000305176\r\n",
      "Epoch #306: loss=0.49226611852645874\r\n",
      "Epoch #307: loss=0.452645480632782\r\n",
      "Epoch #308: loss=0.3999811112880707\r\n",
      "Epoch #309: loss=0.5184924602508545\r\n",
      "Epoch #310: loss=0.37964996695518494\r\n",
      "Epoch #311: loss=0.4917697608470917\r\n",
      "Epoch #312: loss=0.5833591222763062\r\n",
      "Epoch #313: loss=0.39341607689857483\r\n",
      "Epoch #314: loss=1.7685773372650146\r\n",
      "Epoch #315: loss=0.5295851230621338\r\n",
      "Epoch #316: loss=0.42173904180526733\r\n",
      "Epoch #317: loss=1.124274730682373\r\n",
      "Epoch #318: loss=0.4632290005683899\r\n",
      "Epoch #319: loss=0.44480177760124207\r\n",
      "Epoch #320: loss=0.3802410066127777\r\n",
      "Epoch #321: loss=0.5304267406463623\r\n",
      "Epoch #322: loss=0.5698824524879456\r\n",
      "Epoch #323: loss=0.5280369520187378\r\n",
      "Epoch #324: loss=0.38477346301078796\r\n",
      "Epoch #325: loss=0.4357452094554901\r\n",
      "Epoch #326: loss=0.6690819263458252\r\n",
      "Epoch #327: loss=0.3838213384151459\r\n",
      "Epoch #328: loss=0.8474833369255066\r\n",
      "Epoch #329: loss=0.4010750651359558\r\n",
      "Epoch #330: loss=0.40649762749671936\r\n",
      "Epoch #331: loss=0.428108274936676\r\n",
      "Epoch #332: loss=0.4009959399700165\r\n",
      "Epoch #333: loss=0.5368416905403137\r\n",
      "Epoch #334: loss=1.4392672777175903\r\n",
      "Epoch #335: loss=1.3658968210220337\r\n",
      "Epoch #336: loss=0.5086442828178406\r\n",
      "Epoch #337: loss=0.5058633685112\r\n",
      "Epoch #338: loss=0.42647871375083923\r\n",
      "Epoch #339: loss=0.5846244692802429\r\n",
      "Epoch #340: loss=0.5972135066986084\r\n",
      "Epoch #341: loss=0.5253716707229614\r\n",
      "Epoch #342: loss=0.45229536294937134\r\n",
      "Epoch #343: loss=0.4304482936859131\r\n",
      "Epoch #344: loss=0.4074851870536804\r\n",
      "Epoch #345: loss=0.4223838448524475\r\n",
      "Epoch #346: loss=0.37477633357048035\r\n",
      "Epoch #347: loss=0.37004393339157104\r\n",
      "Epoch #348: loss=0.48377731442451477\r\n",
      "Epoch #349: loss=0.4938393533229828\r\n",
      "Epoch #350: loss=0.3617059588432312\r\n",
      "Epoch #351: loss=0.4365288317203522\r\n",
      "Epoch #352: loss=0.5910743474960327\r\n",
      "Epoch #353: loss=0.5795266628265381\r\n",
      "Epoch #354: loss=0.41678586602211\r\n",
      "Epoch #355: loss=0.47544631361961365\r\n",
      "Epoch #356: loss=0.3713339567184448\r\n",
      "Epoch #357: loss=0.5424301028251648\r\n",
      "Epoch #358: loss=0.33143338561058044\r\n",
      "Epoch #359: loss=0.3243384063243866\r\n",
      "Epoch #360: loss=0.598770022392273\r\n",
      "Epoch #361: loss=0.3686119019985199\r\n",
      "Epoch #362: loss=0.3207482099533081\r\n",
      "Epoch #363: loss=0.3289107084274292\r\n",
      "Epoch #364: loss=0.3183877766132355\r\n",
      "Epoch #365: loss=0.3774261176586151\r\n",
      "Epoch #366: loss=0.2872489392757416\r\n",
      "Epoch #367: loss=0.28407323360443115\r\n",
      "Epoch #368: loss=0.2692957818508148\r\n",
      "Epoch #369: loss=0.3024684488773346\r\n",
      "Epoch #370: loss=0.3825758397579193\r\n",
      "Epoch #371: loss=0.2993223965167999\r\n",
      "Epoch #372: loss=0.30466365814208984\r\n",
      "Epoch #373: loss=0.2987900972366333\r\n",
      "Epoch #374: loss=0.25006303191185\r\n",
      "Epoch #375: loss=0.4040151536464691\r\n",
      "Epoch #376: loss=0.33063313364982605\r\n",
      "Epoch #377: loss=0.30134156346321106\r\n",
      "Epoch #378: loss=0.2936089038848877\r\n",
      "Epoch #379: loss=0.30062830448150635\r\n",
      "Epoch #380: loss=0.34311506152153015\r\n",
      "Epoch #381: loss=0.28613781929016113\r\n",
      "Epoch #382: loss=0.32468247413635254\r\n",
      "Epoch #383: loss=0.3053600788116455\r\n",
      "Epoch #384: loss=0.2609027028083801\r\n",
      "Epoch #385: loss=2.5486457347869873\r\n",
      "Epoch #386: loss=0.39550262689590454\r\n",
      "Epoch #387: loss=0.48624560236930847\r\n",
      "Epoch #388: loss=0.4156544804573059\r\n",
      "Epoch #389: loss=0.34676313400268555\r\n",
      "Epoch #390: loss=0.7769532799720764\r\n",
      "Epoch #391: loss=0.5044648051261902\r\n",
      "Epoch #392: loss=0.5079779028892517\r\n",
      "Epoch #393: loss=0.5212104916572571\r\n",
      "Epoch #394: loss=0.37852782011032104\r\n",
      "Epoch #395: loss=0.38793638348579407\r\n",
      "Epoch #396: loss=0.32174134254455566\r\n",
      "Epoch #397: loss=0.396134614944458\r\n",
      "Epoch #398: loss=0.3706742227077484\r\n",
      "Epoch #399: loss=0.4527381658554077\r\n",
      "Epoch #400: loss=0.4311217665672302\r\n",
      "Epoch #401: loss=0.35447996854782104\r\n",
      "Epoch #402: loss=0.3132542371749878\r\n",
      "Epoch #403: loss=0.36485612392425537\r\n",
      "Epoch #404: loss=0.6808147430419922\r\n",
      "Epoch #405: loss=0.4111087918281555\r\n",
      "Epoch #406: loss=0.41089531779289246\r\n",
      "Epoch #407: loss=0.4921910762786865\r\n",
      "Epoch #408: loss=0.28168463706970215\r\n",
      "Epoch #409: loss=0.3548855781555176\r\n",
      "Epoch #410: loss=0.4782331883907318\r\n",
      "Epoch #411: loss=0.27374014258384705\r\n",
      "Epoch #412: loss=0.6510587334632874\r\n",
      "Epoch #413: loss=0.4017328917980194\r\n",
      "Epoch #414: loss=1.088983416557312\r\n",
      "Epoch #415: loss=0.43609505891799927\r\n",
      "Epoch #416: loss=0.4153536856174469\r\n",
      "Epoch #417: loss=0.322665274143219\r\n",
      "Epoch #418: loss=0.2958349883556366\r\n",
      "Epoch #419: loss=0.2844362258911133\r\n",
      "Epoch #420: loss=0.4690934419631958\r\n",
      "Epoch #421: loss=0.2716588079929352\r\n",
      "Epoch #422: loss=0.3816674053668976\r\n",
      "Epoch #423: loss=0.6080730557441711\r\n",
      "Epoch #424: loss=0.291140615940094\r\n",
      "Epoch #425: loss=0.5726261138916016\r\n",
      "Epoch #426: loss=0.2574876546859741\r\n",
      "Epoch #427: loss=0.30802857875823975\r\n",
      "Epoch #428: loss=0.5537288784980774\r\n",
      "Epoch #429: loss=0.530278742313385\r\n",
      "Epoch #430: loss=0.6020709872245789\r\n",
      "Epoch #431: loss=0.2650994658470154\r\n",
      "Epoch #432: loss=0.32415053248405457\r\n",
      "Epoch #433: loss=0.2702401280403137\r\n",
      "Epoch #434: loss=0.29901593923568726\r\n",
      "Epoch #435: loss=0.35773810744285583\r\n",
      "Epoch #436: loss=0.21251457929611206\r\n",
      "Epoch #437: loss=0.47436293959617615\r\n",
      "Epoch #438: loss=0.26110005378723145\r\n",
      "Epoch #439: loss=0.37276777625083923\r\n",
      "Epoch #440: loss=0.6524478197097778\r\n",
      "Epoch #441: loss=0.24132512509822845\r\n",
      "Epoch #442: loss=0.4556455910205841\r\n",
      "Epoch #443: loss=0.23211833834648132\r\n",
      "Epoch #444: loss=0.3527814745903015\r\n",
      "Epoch #445: loss=0.2150408923625946\r\n",
      "Epoch #446: loss=0.20686686038970947\r\n",
      "Epoch #447: loss=0.2630017399787903\r\n",
      "Epoch #448: loss=0.2555689215660095\r\n",
      "Epoch #449: loss=0.2670811712741852\r\n",
      "Epoch #450: loss=0.20392298698425293\r\n",
      "Epoch #451: loss=0.45491066575050354\r\n",
      "Epoch #452: loss=0.1872413009405136\r\n",
      "Epoch #453: loss=0.20244674384593964\r\n",
      "Epoch #454: loss=0.324421763420105\r\n",
      "Epoch #455: loss=0.2810744345188141\r\n",
      "Epoch #456: loss=0.21432903409004211\r\n",
      "Epoch #457: loss=0.1944981962442398\r\n",
      "Epoch #458: loss=0.41152915358543396\r\n",
      "Epoch #459: loss=0.16734907031059265\r\n",
      "Epoch #460: loss=0.16033263504505157\r\n",
      "Epoch #461: loss=0.22561582922935486\r\n",
      "Epoch #462: loss=0.24988742172718048\r\n",
      "Epoch #463: loss=0.2143217921257019\r\n",
      "Epoch #464: loss=0.16368432343006134\r\n",
      "Epoch #465: loss=0.2351885288953781\r\n",
      "Epoch #466: loss=0.16754110157489777\r\n",
      "Epoch #467: loss=0.19101130962371826\r\n",
      "Epoch #468: loss=0.1430782526731491\r\n",
      "Epoch #469: loss=0.16564249992370605\r\n",
      "Epoch #470: loss=0.28901156783103943\r\n",
      "Epoch #471: loss=0.1749722957611084\r\n",
      "Epoch #472: loss=0.1946396827697754\r\n",
      "Epoch #473: loss=0.45842599868774414\r\n",
      "Epoch #474: loss=0.12329085916280746\r\n",
      "Epoch #475: loss=0.13469789922237396\r\n",
      "Epoch #476: loss=0.12283042073249817\r\n",
      "Epoch #477: loss=0.495577335357666\r\n",
      "Epoch #478: loss=0.32783904671669006\r\n",
      "Epoch #479: loss=0.162266343832016\r\n",
      "Epoch #480: loss=0.27643656730651855\r\n",
      "Epoch #481: loss=0.47506141662597656\r\n",
      "Epoch #482: loss=0.1757388710975647\r\n",
      "Epoch #483: loss=0.14666126668453217\r\n",
      "Epoch #484: loss=0.3825264871120453\r\n",
      "Epoch #485: loss=0.12947683036327362\r\n",
      "Epoch #486: loss=0.24318432807922363\r\n",
      "Epoch #487: loss=0.19711816310882568\r\n",
      "Epoch #488: loss=0.20012299716472626\r\n",
      "Epoch #489: loss=0.17537835240364075\r\n",
      "Epoch #490: loss=0.17697113752365112\r\n",
      "Epoch #491: loss=0.1249585971236229\r\n",
      "Epoch #492: loss=0.29662153124809265\r\n",
      "Epoch #493: loss=0.14093413949012756\r\n",
      "Epoch #494: loss=0.2794960141181946\r\n",
      "Epoch #495: loss=0.2451786994934082\r\n",
      "Epoch #496: loss=0.21301569044589996\r\n",
      "Epoch #497: loss=0.2380792796611786\r\n",
      "Epoch #498: loss=0.1505005955696106\r\n",
      "Epoch #499: loss=0.21926608681678772\r\n",
      "Epoch #500: loss=0.19153472781181335\r\n",
      "Epoch #501: loss=0.16119708120822906\r\n",
      "Epoch #502: loss=0.16739504039287567\r\n",
      "Epoch #503: loss=0.1433381587266922\r\n",
      "Epoch #504: loss=0.16020551323890686\r\n",
      "Epoch #505: loss=0.3742712140083313\r\n",
      "Epoch #506: loss=0.21198657155036926\r\n",
      "Epoch #507: loss=0.128635972738266\r\n",
      "Epoch #508: loss=0.257011741399765\r\n",
      "Epoch #509: loss=0.1391785889863968\r\n",
      "Epoch #510: loss=0.44000566005706787\r\n",
      "Epoch #511: loss=0.29809269309043884\r\n",
      "Epoch #512: loss=0.18095891177654266\r\n",
      "Epoch #513: loss=0.12888780236244202\r\n",
      "Epoch #514: loss=0.14665555953979492\r\n",
      "Epoch #515: loss=0.12685570120811462\r\n",
      "Epoch #516: loss=0.1805649995803833\r\n",
      "Epoch #517: loss=0.1512853503227234\r\n",
      "Epoch #518: loss=0.1483059525489807\r\n",
      "Epoch #519: loss=0.20933392643928528\r\n",
      "Epoch #520: loss=0.18214261531829834\r\n",
      "Epoch #521: loss=0.11845001578330994\r\n",
      "Epoch #522: loss=0.20059095323085785\r\n",
      "Epoch #523: loss=0.41123566031455994\r\n",
      "Epoch #524: loss=0.10684549808502197\r\n",
      "Epoch #525: loss=0.1130475401878357\r\n",
      "Epoch #526: loss=0.23730488121509552\r\n",
      "Epoch #527: loss=0.1933497190475464\r\n",
      "Epoch #528: loss=0.12174852937459946\r\n",
      "Epoch #529: loss=0.12491418421268463\r\n",
      "Epoch #530: loss=0.14797624945640564\r\n",
      "Epoch #531: loss=0.10464464128017426\r\n",
      "Epoch #532: loss=0.13218367099761963\r\n",
      "Epoch #533: loss=0.1603548377752304\r\n",
      "Epoch #534: loss=0.2756359577178955\r\n",
      "Epoch #535: loss=0.10863464325666428\r\n",
      "Epoch #536: loss=0.10764538496732712\r\n",
      "Epoch #537: loss=0.13245515525341034\r\n",
      "Epoch #538: loss=0.18474479019641876\r\n",
      "Epoch #539: loss=0.2101241499185562\r\n",
      "Epoch #540: loss=0.451431542634964\r\n",
      "Epoch #541: loss=0.23929648101329803\r\n",
      "Epoch #542: loss=0.12700918316841125\r\n",
      "Epoch #543: loss=0.15575778484344482\r\n",
      "Epoch #544: loss=0.3256433308124542\r\n",
      "Epoch #545: loss=0.37918731570243835\r\n",
      "Epoch #546: loss=0.20392847061157227\r\n",
      "Epoch #547: loss=1.4667328596115112\r\n",
      "Epoch #548: loss=0.1701626032590866\r\n",
      "Epoch #549: loss=0.18852399289608002\r\n",
      "Epoch #550: loss=0.2571777105331421\r\n",
      "Epoch #551: loss=0.310452938079834\r\n",
      "Epoch #552: loss=0.15188519656658173\r\n",
      "Epoch #553: loss=0.19454710185527802\r\n",
      "Epoch #554: loss=0.1612076759338379\r\n",
      "Epoch #555: loss=0.14993810653686523\r\n",
      "Epoch #556: loss=0.18001258373260498\r\n",
      "Epoch #557: loss=0.21726179122924805\r\n",
      "Epoch #558: loss=0.275646835565567\r\n",
      "Epoch #559: loss=0.2330033779144287\r\n",
      "Epoch #560: loss=0.7659727334976196\r\n",
      "Epoch #561: loss=0.2065718024969101\r\n",
      "Epoch #562: loss=0.22691689431667328\r\n",
      "Epoch #563: loss=0.24318750202655792\r\n",
      "Epoch #564: loss=0.1761217713356018\r\n",
      "Epoch #565: loss=0.43945035338401794\r\n",
      "Epoch #566: loss=0.12893357872962952\r\n",
      "Epoch #567: loss=0.15038713812828064\r\n",
      "Epoch #568: loss=0.20983436703681946\r\n",
      "Epoch #569: loss=0.14923524856567383\r\n",
      "Epoch #570: loss=0.37050220370292664\r\n",
      "Epoch #571: loss=0.14630521833896637\r\n",
      "Epoch #572: loss=0.09788116812705994\r\n",
      "Epoch #573: loss=0.10399767756462097\r\n",
      "Epoch #574: loss=0.26850220561027527\r\n",
      "Epoch #575: loss=0.10485424101352692\r\n",
      "Epoch #576: loss=0.13669033348560333\r\n",
      "Epoch #577: loss=0.16438211500644684\r\n",
      "Epoch #578: loss=0.345598429441452\r\n",
      "Epoch #579: loss=0.15999184548854828\r\n",
      "Epoch #580: loss=0.09389461576938629\r\n",
      "Epoch #581: loss=0.17666038870811462\r\n",
      "Epoch #582: loss=0.34151431918144226\r\n",
      "Epoch #583: loss=0.13252493739128113\r\n",
      "Epoch #584: loss=0.17656636238098145\r\n",
      "Epoch #585: loss=0.13545426726341248\r\n",
      "Epoch #586: loss=0.1698981523513794\r\n",
      "Epoch #587: loss=0.2311602383852005\r\n",
      "Epoch #588: loss=0.15113410353660583\r\n",
      "Epoch #589: loss=0.11752407997846603\r\n",
      "Epoch #590: loss=0.09542278945446014\r\n",
      "Epoch #591: loss=0.1760372519493103\r\n",
      "Epoch #592: loss=0.27781978249549866\r\n",
      "Epoch #593: loss=0.3306688666343689\r\n",
      "Epoch #594: loss=0.13865578174591064\r\n",
      "Epoch #595: loss=0.16135473549365997\r\n",
      "Epoch #596: loss=0.15895076096057892\r\n",
      "Epoch #597: loss=0.24019969999790192\r\n",
      "Epoch #598: loss=0.2165074646472931\r\n",
      "Epoch #599: loss=0.13404735922813416\r\n",
      "\r\n",
      "Training time: 0:03:00.554618\r\n",
      "\r\n",
      "Evaluation result: {'ours': {24: {'norm': {'MSE': 0.016321452257413216, 'MAE': 0.09501317641057971}, 'raw': {'MSE': 1.3733616821300867, 'MAE': 0.8715592187003574}}, 48: {'norm': {'MSE': 0.030903823060025634, 'MAE': 0.1324037437775786}, 'raw': {'MSE': 2.6003890923793334, 'MAE': 1.2145442120692977}}, 96: {'norm': {'MSE': 0.045433213213911854, 'MAE': 0.1645182372956747}, 'raw': {'MSE': 3.8229584683980833, 'MAE': 1.5091315939145054}}, 288: {'norm': {'MSE': 0.09286950934037999, 'MAE': 0.23413328089843052}, 'raw': {'MSE': 7.814465499439227, 'MAE': 2.147712844477277}}, 672: {'norm': {'MSE': 0.13058402084521598, 'MAE': 0.2803236618624631}, 'raw': {'MSE': 10.987937084204022, 'MAE': 2.5714188383756285}}}, 'ts2vec_infer_time': 9.36354374885559, 'lr_train_time': {24: 4.7706077098846436, 48: 4.849169731140137, 96: 5.255021572113037, 288: 7.439532041549683, 672: 12.124444484710693}, 'lr_infer_time': {24: 0.13727164268493652, 48: 0.14416956901550293, 96: 0.19290542602539062, 288: 0.5572803020477295, 672: 1.3553414344787598}}\r\n",
      "Finished.\r\n"
     ]
    }
   ],
   "source": [
    "!python -u train.py ETTm1 forecast_univar --loader forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 42 --eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28103212",
   "metadata": {
    "papermill": {
     "duration": 0.02633,
     "end_time": "2025-10-12T03:37:28.904401",
     "exception": false,
     "start_time": "2025-10-12T03:37:28.878071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ETTh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7524a57b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:37:28.956370Z",
     "iopub.status.busy": "2025-10-12T03:37:28.956096Z",
     "iopub.status.idle": "2025-10-12T03:38:11.823205Z",
     "shell.execute_reply": "2025-10-12T03:38:11.822051Z"
    },
    "papermill": {
     "duration": 42.895648,
     "end_time": "2025-10-12T03:38:11.825301",
     "exception": false,
     "start_time": "2025-10-12T03:37:28.929653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh1\r\n",
      "Arguments: Namespace(dataset='ETTh1', run_name='forecast_univar', loader='forecast_csv_univar', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0)\r\n",
      "Loading data... done\r\n",
      "Epoch #0: loss=6.492616176605225\r\n",
      "Epoch #1: loss=4.345760345458984\r\n",
      "Epoch #2: loss=3.7984509468078613\r\n",
      "Epoch #3: loss=2.7432656288146973\r\n",
      "Epoch #4: loss=2.088869571685791\r\n",
      "Epoch #5: loss=2.1114795207977295\r\n",
      "Epoch #6: loss=2.1982622146606445\r\n",
      "Epoch #7: loss=1.9088596105575562\r\n",
      "Epoch #8: loss=2.1451854705810547\r\n",
      "Epoch #9: loss=1.8066883087158203\r\n",
      "Epoch #10: loss=2.0014445781707764\r\n",
      "Epoch #11: loss=2.002016067504883\r\n",
      "Epoch #12: loss=2.148951292037964\r\n",
      "Epoch #13: loss=1.953505516052246\r\n",
      "Epoch #14: loss=1.7191097736358643\r\n",
      "Epoch #15: loss=1.842022180557251\r\n",
      "Epoch #16: loss=1.842962622642517\r\n",
      "Epoch #17: loss=1.6882919073104858\r\n",
      "Epoch #18: loss=1.778104543685913\r\n",
      "Epoch #19: loss=1.73807692527771\r\n",
      "Epoch #20: loss=1.7635587453842163\r\n",
      "Epoch #21: loss=1.7476924657821655\r\n",
      "Epoch #22: loss=1.5104392766952515\r\n",
      "Epoch #23: loss=1.7321226596832275\r\n",
      "Epoch #24: loss=1.667929768562317\r\n",
      "Epoch #25: loss=1.4874722957611084\r\n",
      "Epoch #26: loss=1.6128438711166382\r\n",
      "Epoch #27: loss=1.5175498723983765\r\n",
      "Epoch #28: loss=1.4864755868911743\r\n",
      "Epoch #29: loss=1.387010931968689\r\n",
      "Epoch #30: loss=1.3322521448135376\r\n",
      "Epoch #31: loss=1.4676541090011597\r\n",
      "Epoch #32: loss=1.4367586374282837\r\n",
      "Epoch #33: loss=1.555317997932434\r\n",
      "Epoch #34: loss=1.306872010231018\r\n",
      "Epoch #35: loss=1.3654826879501343\r\n",
      "Epoch #36: loss=1.2807683944702148\r\n",
      "Epoch #37: loss=1.3600118160247803\r\n",
      "Epoch #38: loss=1.4179919958114624\r\n",
      "Epoch #39: loss=1.2653599977493286\r\n",
      "Epoch #40: loss=1.3450067043304443\r\n",
      "Epoch #41: loss=1.2868975400924683\r\n",
      "Epoch #42: loss=1.2659703493118286\r\n",
      "Epoch #43: loss=1.294922113418579\r\n",
      "Epoch #44: loss=1.2746888399124146\r\n",
      "Epoch #45: loss=1.1455589532852173\r\n",
      "Epoch #46: loss=1.2352592945098877\r\n",
      "Epoch #47: loss=1.306959629058838\r\n",
      "Epoch #48: loss=0.9855992197990417\r\n",
      "Epoch #49: loss=1.0099791288375854\r\n",
      "Epoch #50: loss=0.9801536798477173\r\n",
      "Epoch #51: loss=1.229960560798645\r\n",
      "Epoch #52: loss=1.243743896484375\r\n",
      "Epoch #53: loss=1.0880613327026367\r\n",
      "Epoch #54: loss=1.0798258781433105\r\n",
      "Epoch #55: loss=2.3355541229248047\r\n",
      "Epoch #56: loss=1.385101318359375\r\n",
      "Epoch #57: loss=1.057636022567749\r\n",
      "Epoch #58: loss=1.045166254043579\r\n",
      "Epoch #59: loss=1.0876591205596924\r\n",
      "Epoch #60: loss=1.2519737482070923\r\n",
      "Epoch #61: loss=1.1927448511123657\r\n",
      "Epoch #62: loss=1.239461898803711\r\n",
      "Epoch #63: loss=1.1015968322753906\r\n",
      "Epoch #64: loss=0.9842421412467957\r\n",
      "Epoch #65: loss=1.147273302078247\r\n",
      "Epoch #66: loss=1.2488608360290527\r\n",
      "Epoch #67: loss=1.3987295627593994\r\n",
      "Epoch #68: loss=1.1425498723983765\r\n",
      "Epoch #69: loss=1.0759111642837524\r\n",
      "Epoch #70: loss=1.0712517499923706\r\n",
      "Epoch #71: loss=1.1944420337677002\r\n",
      "Epoch #72: loss=1.5039997100830078\r\n",
      "Epoch #73: loss=1.379272699356079\r\n",
      "Epoch #74: loss=1.0908043384552002\r\n",
      "Epoch #75: loss=1.2226027250289917\r\n",
      "Epoch #76: loss=2.0112318992614746\r\n",
      "Epoch #77: loss=1.0520572662353516\r\n",
      "Epoch #78: loss=1.0471081733703613\r\n",
      "Epoch #79: loss=1.3068300485610962\r\n",
      "Epoch #80: loss=1.2415838241577148\r\n",
      "Epoch #81: loss=1.129151701927185\r\n",
      "Epoch #82: loss=1.136370062828064\r\n",
      "Epoch #83: loss=1.0773789882659912\r\n",
      "Epoch #84: loss=0.999572217464447\r\n",
      "Epoch #85: loss=1.0304368734359741\r\n",
      "Epoch #86: loss=0.9323185682296753\r\n",
      "Epoch #87: loss=0.9092530012130737\r\n",
      "Epoch #88: loss=0.9389249682426453\r\n",
      "Epoch #89: loss=0.9948350787162781\r\n",
      "Epoch #90: loss=0.9771572947502136\r\n",
      "Epoch #91: loss=0.9498864412307739\r\n",
      "Epoch #92: loss=0.9883578419685364\r\n",
      "Epoch #93: loss=1.269477128982544\r\n",
      "Epoch #94: loss=0.9223194122314453\r\n",
      "Epoch #95: loss=0.7989996075630188\r\n",
      "Epoch #96: loss=0.8242334127426147\r\n",
      "Epoch #97: loss=0.8862308859825134\r\n",
      "Epoch #98: loss=0.8462756872177124\r\n",
      "Epoch #99: loss=0.8280093669891357\r\n",
      "Epoch #100: loss=0.8234646916389465\r\n",
      "Epoch #101: loss=0.8955962657928467\r\n",
      "Epoch #102: loss=0.7806495428085327\r\n",
      "Epoch #103: loss=0.7153899073600769\r\n",
      "Epoch #104: loss=0.7686395049095154\r\n",
      "Epoch #105: loss=1.4884049892425537\r\n",
      "Epoch #106: loss=0.7341184616088867\r\n",
      "Epoch #107: loss=0.7189277410507202\r\n",
      "Epoch #108: loss=0.7484779357910156\r\n",
      "Epoch #109: loss=0.7159392237663269\r\n",
      "Epoch #110: loss=0.7544997334480286\r\n",
      "Epoch #111: loss=1.2723113298416138\r\n",
      "Epoch #112: loss=1.4109652042388916\r\n",
      "Epoch #113: loss=0.9498001933097839\r\n",
      "Epoch #114: loss=0.8958572745323181\r\n",
      "Epoch #115: loss=0.7427258491516113\r\n",
      "Epoch #116: loss=0.8703639507293701\r\n",
      "Epoch #117: loss=0.7607962489128113\r\n",
      "Epoch #118: loss=0.842833936214447\r\n",
      "Epoch #119: loss=0.8373054265975952\r\n",
      "Epoch #120: loss=0.6150689125061035\r\n",
      "Epoch #121: loss=0.680620551109314\r\n",
      "Epoch #122: loss=0.7128604650497437\r\n",
      "Epoch #123: loss=0.7438786625862122\r\n",
      "Epoch #124: loss=1.1233839988708496\r\n",
      "Epoch #125: loss=0.7275317907333374\r\n",
      "Epoch #126: loss=0.6254828572273254\r\n",
      "Epoch #127: loss=0.8816285133361816\r\n",
      "Epoch #128: loss=0.6642197966575623\r\n",
      "Epoch #129: loss=0.6286134719848633\r\n",
      "Epoch #130: loss=0.9760546684265137\r\n",
      "Epoch #131: loss=1.161277413368225\r\n",
      "Epoch #132: loss=0.7073728442192078\r\n",
      "Epoch #133: loss=0.6142382025718689\r\n",
      "Epoch #134: loss=0.5973140001296997\r\n",
      "Epoch #135: loss=0.6402648687362671\r\n",
      "Epoch #136: loss=0.8947003483772278\r\n",
      "Epoch #137: loss=0.6390693187713623\r\n",
      "Epoch #138: loss=0.8049882054328918\r\n",
      "Epoch #139: loss=0.7485769987106323\r\n",
      "Epoch #140: loss=0.6768841743469238\r\n",
      "Epoch #141: loss=0.8442705869674683\r\n",
      "Epoch #142: loss=0.6265857219696045\r\n",
      "Epoch #143: loss=1.0896000862121582\r\n",
      "Epoch #144: loss=0.650766134262085\r\n",
      "Epoch #145: loss=0.5752713680267334\r\n",
      "Epoch #146: loss=0.6063288450241089\r\n",
      "Epoch #147: loss=0.6794020533561707\r\n",
      "Epoch #148: loss=0.5924084186553955\r\n",
      "Epoch #149: loss=0.5497120022773743\r\n",
      "Epoch #150: loss=0.7990190386772156\r\n",
      "Epoch #151: loss=0.7461143136024475\r\n",
      "Epoch #152: loss=0.5783901214599609\r\n",
      "Epoch #153: loss=0.6205259561538696\r\n",
      "Epoch #154: loss=0.5997411608695984\r\n",
      "Epoch #155: loss=0.5609413981437683\r\n",
      "Epoch #156: loss=0.9019062519073486\r\n",
      "Epoch #157: loss=0.5704675316810608\r\n",
      "Epoch #158: loss=0.6329569816589355\r\n",
      "Epoch #159: loss=0.5654211044311523\r\n",
      "Epoch #160: loss=0.6737098693847656\r\n",
      "Epoch #161: loss=0.7947327494621277\r\n",
      "Epoch #162: loss=0.5154926180839539\r\n",
      "Epoch #163: loss=0.6910848617553711\r\n",
      "Epoch #164: loss=0.7979399561882019\r\n",
      "Epoch #165: loss=0.5338058471679688\r\n",
      "Epoch #166: loss=0.5624625086784363\r\n",
      "Epoch #167: loss=0.4822557866573334\r\n",
      "Epoch #168: loss=0.5707831382751465\r\n",
      "Epoch #169: loss=0.5162557363510132\r\n",
      "Epoch #170: loss=0.4296053647994995\r\n",
      "Epoch #171: loss=0.45340728759765625\r\n",
      "Epoch #172: loss=0.5575684309005737\r\n",
      "Epoch #173: loss=0.46889838576316833\r\n",
      "Epoch #174: loss=0.4450221657752991\r\n",
      "Epoch #175: loss=0.4678937792778015\r\n",
      "Epoch #176: loss=0.45745742321014404\r\n",
      "Epoch #177: loss=0.6505476832389832\r\n",
      "Epoch #178: loss=0.39935141801834106\r\n",
      "Epoch #179: loss=0.5336191058158875\r\n",
      "Epoch #180: loss=0.5288430452346802\r\n",
      "Epoch #181: loss=0.3954184651374817\r\n",
      "Epoch #182: loss=0.41741567850112915\r\n",
      "Epoch #183: loss=0.6650969386100769\r\n",
      "Epoch #184: loss=0.37388986349105835\r\n",
      "Epoch #185: loss=0.5885741710662842\r\n",
      "Epoch #186: loss=0.48103460669517517\r\n",
      "Epoch #187: loss=0.5721787810325623\r\n",
      "Epoch #188: loss=0.41256147623062134\r\n",
      "Epoch #189: loss=0.4892444312572479\r\n",
      "Epoch #190: loss=0.5381022691726685\r\n",
      "Epoch #191: loss=0.513616681098938\r\n",
      "Epoch #192: loss=0.40549105405807495\r\n",
      "Epoch #193: loss=2.7258846759796143\r\n",
      "Epoch #194: loss=0.46943891048431396\r\n",
      "Epoch #195: loss=0.454195499420166\r\n",
      "Epoch #196: loss=0.5045976638793945\r\n",
      "Epoch #197: loss=0.6027522683143616\r\n",
      "Epoch #198: loss=0.8556715846061707\r\n",
      "Epoch #199: loss=0.47202056646347046\r\n",
      "\r\n",
      "Training time: 0:00:22.321856\r\n",
      "\r\n",
      "Evaluation result: {'ours': {24: {'norm': {'MSE': 0.04020604017729233, 'MAE': 0.15022436283903393}, 'raw': {'MSE': 3.3856697299156497, 'MAE': 1.3785325173203757}}, 48: {'norm': {'MSE': 0.06212260730884792, 'MAE': 0.18877987186350473}, 'raw': {'MSE': 5.231219741649463, 'MAE': 1.7323367998455927}}, 168: {'norm': {'MSE': 0.12000769997072643, 'MAE': 0.2647322942092299}, 'raw': {'MSE': 10.105606902744988, 'MAE': 2.4293135218239206}}, 336: {'norm': {'MSE': 0.13995393287908336, 'MAE': 0.29092350247010756}, 'raw': {'MSE': 11.785239034780012, 'MAE': 2.6696569093623124}}, 720: {'norm': {'MSE': 0.16106348757814595, 'MAE': 0.32271465377745157}, 'raw': {'MSE': 13.56283215366119, 'MAE': 2.9613881240068016}}}, 'ts2vec_infer_time': 2.4791412353515625, 'lr_train_time': {24: 1.628180742263794, 48: 1.4293575286865234, 168: 2.4001357555389404, 336: 3.57183837890625, 720: 4.163153648376465}, 'lr_infer_time': {24: 0.02168750762939453, 48: 0.055223703384399414, 168: 0.1298978328704834, 336: 0.17551279067993164, 720: 0.2805163860321045}}\r\n",
      "Finished.\r\n"
     ]
    }
   ],
   "source": [
    "!python -u train.py ETTh1 forecast_univar --loader forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 42 --eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bb587",
   "metadata": {
    "papermill": {
     "duration": 0.032044,
     "end_time": "2025-10-12T03:38:11.894048",
     "exception": false,
     "start_time": "2025-10-12T03:38:11.862004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ETTh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c24d9d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:38:11.963819Z",
     "iopub.status.busy": "2025-10-12T03:38:11.963265Z",
     "iopub.status.idle": "2025-10-12T03:38:54.680220Z",
     "shell.execute_reply": "2025-10-12T03:38:54.679400Z"
    },
    "papermill": {
     "duration": 42.755225,
     "end_time": "2025-10-12T03:38:54.681743",
     "exception": false,
     "start_time": "2025-10-12T03:38:11.926518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh2\r\n",
      "Arguments: Namespace(dataset='ETTh2', run_name='forecast_univar', loader='forecast_csv_univar', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0)\r\n",
      "Loading data... done\r\n",
      "Epoch #0: loss=6.0860795974731445\r\n",
      "Epoch #1: loss=4.056138038635254\r\n",
      "Epoch #2: loss=3.4592063426971436\r\n",
      "Epoch #3: loss=2.686993360519409\r\n",
      "Epoch #4: loss=2.0203301906585693\r\n",
      "Epoch #5: loss=2.2545979022979736\r\n",
      "Epoch #6: loss=2.1713011264801025\r\n",
      "Epoch #7: loss=1.9193872213363647\r\n",
      "Epoch #8: loss=2.1428399085998535\r\n",
      "Epoch #9: loss=1.7316492795944214\r\n",
      "Epoch #10: loss=1.9317255020141602\r\n",
      "Epoch #11: loss=2.0130350589752197\r\n",
      "Epoch #12: loss=2.0045292377471924\r\n",
      "Epoch #13: loss=1.8871383666992188\r\n",
      "Epoch #14: loss=1.71969735622406\r\n",
      "Epoch #15: loss=1.8377513885498047\r\n",
      "Epoch #16: loss=1.834147334098816\r\n",
      "Epoch #17: loss=1.646709680557251\r\n",
      "Epoch #18: loss=1.7359559535980225\r\n",
      "Epoch #19: loss=1.6907037496566772\r\n",
      "Epoch #20: loss=1.7237533330917358\r\n",
      "Epoch #21: loss=1.6996088027954102\r\n",
      "Epoch #22: loss=1.5336329936981201\r\n",
      "Epoch #23: loss=1.6726161241531372\r\n",
      "Epoch #24: loss=1.6592562198638916\r\n",
      "Epoch #25: loss=1.4548225402832031\r\n",
      "Epoch #26: loss=1.5748063325881958\r\n",
      "Epoch #27: loss=1.4709410667419434\r\n",
      "Epoch #28: loss=1.4615265130996704\r\n",
      "Epoch #29: loss=1.3514424562454224\r\n",
      "Epoch #30: loss=1.3001883029937744\r\n",
      "Epoch #31: loss=1.4942055940628052\r\n",
      "Epoch #32: loss=1.4157869815826416\r\n",
      "Epoch #33: loss=1.4832042455673218\r\n",
      "Epoch #34: loss=1.2984516620635986\r\n",
      "Epoch #35: loss=1.3841195106506348\r\n",
      "Epoch #36: loss=1.290649652481079\r\n",
      "Epoch #37: loss=1.3355813026428223\r\n",
      "Epoch #38: loss=1.4031680822372437\r\n",
      "Epoch #39: loss=1.2012437582015991\r\n",
      "Epoch #40: loss=1.3087258338928223\r\n",
      "Epoch #41: loss=1.2631107568740845\r\n",
      "Epoch #42: loss=1.2484173774719238\r\n",
      "Epoch #43: loss=1.2853254079818726\r\n",
      "Epoch #44: loss=1.2190226316452026\r\n",
      "Epoch #45: loss=1.136967658996582\r\n",
      "Epoch #46: loss=1.1997559070587158\r\n",
      "Epoch #47: loss=1.3265531063079834\r\n",
      "Epoch #48: loss=0.9539559483528137\r\n",
      "Epoch #49: loss=0.971953809261322\r\n",
      "Epoch #50: loss=0.9620553255081177\r\n",
      "Epoch #51: loss=1.2128263711929321\r\n",
      "Epoch #52: loss=1.245947003364563\r\n",
      "Epoch #53: loss=1.0579947233200073\r\n",
      "Epoch #54: loss=1.0367026329040527\r\n",
      "Epoch #55: loss=2.2531676292419434\r\n",
      "Epoch #56: loss=1.3745611906051636\r\n",
      "Epoch #57: loss=1.0249996185302734\r\n",
      "Epoch #58: loss=1.0422375202178955\r\n",
      "Epoch #59: loss=1.0491254329681396\r\n",
      "Epoch #60: loss=1.2467619180679321\r\n",
      "Epoch #61: loss=1.1736416816711426\r\n",
      "Epoch #62: loss=1.1671949625015259\r\n",
      "Epoch #63: loss=1.071424961090088\r\n",
      "Epoch #64: loss=0.9699128866195679\r\n",
      "Epoch #65: loss=1.1219714879989624\r\n",
      "Epoch #66: loss=1.1486953496932983\r\n",
      "Epoch #67: loss=1.3833554983139038\r\n",
      "Epoch #68: loss=1.1185543537139893\r\n",
      "Epoch #69: loss=1.0428775548934937\r\n",
      "Epoch #70: loss=1.0390446186065674\r\n",
      "Epoch #71: loss=1.29544198513031\r\n",
      "Epoch #72: loss=1.3797563314437866\r\n",
      "Epoch #73: loss=1.2076518535614014\r\n",
      "Epoch #74: loss=1.0233368873596191\r\n",
      "Epoch #75: loss=1.1852082014083862\r\n",
      "Epoch #76: loss=1.7538388967514038\r\n",
      "Epoch #77: loss=1.0111714601516724\r\n",
      "Epoch #78: loss=0.9602775573730469\r\n",
      "Epoch #79: loss=1.3047417402267456\r\n",
      "Epoch #80: loss=1.2549422979354858\r\n",
      "Epoch #81: loss=1.110469102859497\r\n",
      "Epoch #82: loss=1.0751758813858032\r\n",
      "Epoch #83: loss=0.9487165808677673\r\n",
      "Epoch #84: loss=0.9708799123764038\r\n",
      "Epoch #85: loss=1.0084476470947266\r\n",
      "Epoch #86: loss=0.8900011777877808\r\n",
      "Epoch #87: loss=0.8598583936691284\r\n",
      "Epoch #88: loss=0.8916181325912476\r\n",
      "Epoch #89: loss=0.9485072493553162\r\n",
      "Epoch #90: loss=0.8782431483268738\r\n",
      "Epoch #91: loss=0.9454774856567383\r\n",
      "Epoch #92: loss=0.9615128636360168\r\n",
      "Epoch #93: loss=1.3400214910507202\r\n",
      "Epoch #94: loss=0.9494996666908264\r\n",
      "Epoch #95: loss=0.7855477333068848\r\n",
      "Epoch #96: loss=0.8074545860290527\r\n",
      "Epoch #97: loss=0.8085643649101257\r\n",
      "Epoch #98: loss=0.8250293135643005\r\n",
      "Epoch #99: loss=0.8066226243972778\r\n",
      "Epoch #100: loss=0.8013077974319458\r\n",
      "Epoch #101: loss=0.8896943926811218\r\n",
      "Epoch #102: loss=0.7771165370941162\r\n",
      "Epoch #103: loss=0.6774515509605408\r\n",
      "Epoch #104: loss=0.7392272353172302\r\n",
      "Epoch #105: loss=1.717252254486084\r\n",
      "Epoch #106: loss=0.7203583717346191\r\n",
      "Epoch #107: loss=0.6896064877510071\r\n",
      "Epoch #108: loss=0.7229973077774048\r\n",
      "Epoch #109: loss=0.7125616073608398\r\n",
      "Epoch #110: loss=0.7161960601806641\r\n",
      "Epoch #111: loss=1.2575252056121826\r\n",
      "Epoch #112: loss=1.3013056516647339\r\n",
      "Epoch #113: loss=0.9074764251708984\r\n",
      "Epoch #114: loss=0.8486933708190918\r\n",
      "Epoch #115: loss=0.7015329599380493\r\n",
      "Epoch #116: loss=0.8197185397148132\r\n",
      "Epoch #117: loss=0.7335086464881897\r\n",
      "Epoch #118: loss=0.774747371673584\r\n",
      "Epoch #119: loss=0.8466657996177673\r\n",
      "Epoch #120: loss=0.6124119758605957\r\n",
      "Epoch #121: loss=0.6391935348510742\r\n",
      "Epoch #122: loss=0.6893457174301147\r\n",
      "Epoch #123: loss=0.7197557091712952\r\n",
      "Epoch #124: loss=1.1417157649993896\r\n",
      "Epoch #125: loss=0.7250019907951355\r\n",
      "Epoch #126: loss=0.5669034719467163\r\n",
      "Epoch #127: loss=0.8498293161392212\r\n",
      "Epoch #128: loss=0.6385444402694702\r\n",
      "Epoch #129: loss=0.5988057851791382\r\n",
      "Epoch #130: loss=0.9074546098709106\r\n",
      "Epoch #131: loss=1.3295962810516357\r\n",
      "Epoch #132: loss=0.6883013248443604\r\n",
      "Epoch #133: loss=0.6091118454933167\r\n",
      "Epoch #134: loss=0.5946405529975891\r\n",
      "Epoch #135: loss=0.6303887367248535\r\n",
      "Epoch #136: loss=0.8834462761878967\r\n",
      "Epoch #137: loss=0.5956875681877136\r\n",
      "Epoch #138: loss=0.6929048895835876\r\n",
      "Epoch #139: loss=0.6928207278251648\r\n",
      "Epoch #140: loss=0.6412013173103333\r\n",
      "Epoch #141: loss=0.8049601316452026\r\n",
      "Epoch #142: loss=0.6360867619514465\r\n",
      "Epoch #143: loss=1.0295466184616089\r\n",
      "Epoch #144: loss=0.6429718136787415\r\n",
      "Epoch #145: loss=0.5681795477867126\r\n",
      "Epoch #146: loss=0.6118177771568298\r\n",
      "Epoch #147: loss=0.7044609785079956\r\n",
      "Epoch #148: loss=0.5268136262893677\r\n",
      "Epoch #149: loss=0.5454371571540833\r\n",
      "Epoch #150: loss=0.8555881381034851\r\n",
      "Epoch #151: loss=0.8486358523368835\r\n",
      "Epoch #152: loss=0.643179178237915\r\n",
      "Epoch #153: loss=0.616947591304779\r\n",
      "Epoch #154: loss=0.6461881995201111\r\n",
      "Epoch #155: loss=0.5443617105484009\r\n",
      "Epoch #156: loss=0.871834397315979\r\n",
      "Epoch #157: loss=0.5999552011489868\r\n",
      "Epoch #158: loss=0.7737387418746948\r\n",
      "Epoch #159: loss=0.6443327069282532\r\n",
      "Epoch #160: loss=0.6880462765693665\r\n",
      "Epoch #161: loss=0.8740602731704712\r\n",
      "Epoch #162: loss=0.5104232430458069\r\n",
      "Epoch #163: loss=0.7043221592903137\r\n",
      "Epoch #164: loss=0.6705912947654724\r\n",
      "Epoch #165: loss=0.5314058661460876\r\n",
      "Epoch #166: loss=0.6038634777069092\r\n",
      "Epoch #167: loss=0.49865710735321045\r\n",
      "Epoch #168: loss=0.5749462842941284\r\n",
      "Epoch #169: loss=0.47639164328575134\r\n",
      "Epoch #170: loss=0.43688714504241943\r\n",
      "Epoch #171: loss=0.45204102993011475\r\n",
      "Epoch #172: loss=0.5710958242416382\r\n",
      "Epoch #173: loss=0.44657739996910095\r\n",
      "Epoch #174: loss=0.4650544822216034\r\n",
      "Epoch #175: loss=0.5024896264076233\r\n",
      "Epoch #176: loss=0.4492754638195038\r\n",
      "Epoch #177: loss=0.6103288531303406\r\n",
      "Epoch #178: loss=0.3760784864425659\r\n",
      "Epoch #179: loss=0.5350059270858765\r\n",
      "Epoch #180: loss=0.4646383225917816\r\n",
      "Epoch #181: loss=0.40062209963798523\r\n",
      "Epoch #182: loss=0.41583630442619324\r\n",
      "Epoch #183: loss=0.628451406955719\r\n",
      "Epoch #184: loss=0.3578042984008789\r\n",
      "Epoch #185: loss=0.5257275700569153\r\n",
      "Epoch #186: loss=0.44498422741889954\r\n",
      "Epoch #187: loss=0.481330543756485\r\n",
      "Epoch #188: loss=0.3712737262248993\r\n",
      "Epoch #189: loss=0.46913400292396545\r\n",
      "Epoch #190: loss=0.4844328463077545\r\n",
      "Epoch #191: loss=0.380290687084198\r\n",
      "Epoch #192: loss=0.35064858198165894\r\n",
      "Epoch #193: loss=2.767216920852661\r\n",
      "Epoch #194: loss=0.42809730768203735\r\n",
      "Epoch #195: loss=0.4004448354244232\r\n",
      "Epoch #196: loss=0.437654972076416\r\n",
      "Epoch #197: loss=0.5585256814956665\r\n",
      "Epoch #198: loss=0.570228099822998\r\n",
      "Epoch #199: loss=0.44643256068229675\r\n",
      "\r\n",
      "Training time: 0:00:22.366569\r\n",
      "\r\n",
      "Evaluation result: {'ours': {24: {'norm': {'MSE': 0.09220510767051501, 'MAE': 0.23130611169515455}, 'raw': {'MSE': 12.374452174243808, 'MAE': 2.679616289256327}}, 48: {'norm': {'MSE': 0.1223454740395641, 'MAE': 0.27182600093517056}, 'raw': {'MSE': 16.41946151885359, 'MAE': 3.149027816909807}}, 168: {'norm': {'MSE': 0.187768002876122, 'MAE': 0.3468794131991702}, 'raw': {'MSE': 25.199538617174166, 'MAE': 4.018500502231408}}, 336: {'norm': {'MSE': 0.1939721614202196, 'MAE': 0.35486861323056257}, 'raw': {'MSE': 26.032172135261938, 'MAE': 4.111053139018025}}, 720: {'norm': {'MSE': 0.20906656835288134, 'MAE': 0.37280892971800683}, 'raw': {'MSE': 28.057927772945835, 'MAE': 4.318886662922168}}}, 'ts2vec_infer_time': 2.4993786811828613, 'lr_train_time': {24: 1.5134680271148682, 48: 1.6126539707183838, 168: 2.5339062213897705, 336: 3.118626594543457, 720: 4.26159405708313}, 'lr_infer_time': {24: 0.02060723304748535, 48: 0.049662113189697266, 168: 0.13620615005493164, 336: 0.1623382568359375, 720: 0.31000304222106934}}\r\n",
      "Finished.\r\n"
     ]
    }
   ],
   "source": [
    "!python -u train.py ETTh2 forecast_univar --loader forecast_csv_univar --repr-dims 320 --max-threads 8 --seed 42 --eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fab9cf",
   "metadata": {
    "papermill": {
     "duration": 0.039934,
     "end_time": "2025-10-12T03:38:54.763600",
     "exception": false,
     "start_time": "2025-10-12T03:38:54.723666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Multivariate Forcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee07f9c",
   "metadata": {
    "papermill": {
     "duration": 0.039581,
     "end_time": "2025-10-12T03:38:54.844070",
     "exception": false,
     "start_time": "2025-10-12T03:38:54.804489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ETTm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c80a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:38:54.923359Z",
     "iopub.status.busy": "2025-10-12T03:38:54.923070Z",
     "iopub.status.idle": "2025-10-12T03:44:35.253517Z",
     "shell.execute_reply": "2025-10-12T03:44:35.252670Z"
    },
    "papermill": {
     "duration": 340.372013,
     "end_time": "2025-10-12T03:44:35.255029",
     "exception": false,
     "start_time": "2025-10-12T03:38:54.883016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTm1\r\n",
      "Arguments: Namespace(dataset='ETTm1', run_name='forecast_multivar', loader='forecast_csv', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0)\r\n",
      "Loading data... done\r\n",
      "Epoch #0: loss=7.049349784851074\r\n",
      "Epoch #1: loss=5.435647964477539\r\n",
      "Epoch #2: loss=4.009343147277832\r\n",
      "Epoch #3: loss=3.063127040863037\r\n",
      "Epoch #4: loss=3.1539838314056396\r\n",
      "Epoch #5: loss=2.7763137817382812\r\n",
      "Epoch #6: loss=2.567270278930664\r\n",
      "Epoch #7: loss=2.474722385406494\r\n",
      "Epoch #8: loss=2.4300646781921387\r\n",
      "Epoch #9: loss=2.3175296783447266\r\n",
      "Epoch #10: loss=2.1476645469665527\r\n",
      "Epoch #11: loss=2.2447457313537598\r\n",
      "Epoch #12: loss=2.2106094360351562\r\n",
      "Epoch #13: loss=2.134291172027588\r\n",
      "Epoch #14: loss=2.1385936737060547\r\n",
      "Epoch #15: loss=2.136467695236206\r\n",
      "Epoch #16: loss=1.9792180061340332\r\n",
      "Epoch #17: loss=1.959024429321289\r\n",
      "Epoch #18: loss=1.9927290678024292\r\n",
      "Epoch #19: loss=2.032108783721924\r\n",
      "Epoch #20: loss=2.0343079566955566\r\n",
      "Epoch #21: loss=1.873205542564392\r\n",
      "Epoch #22: loss=1.8435490131378174\r\n",
      "Epoch #23: loss=1.8998103141784668\r\n",
      "Epoch #24: loss=1.829864263534546\r\n",
      "Epoch #25: loss=1.7891416549682617\r\n",
      "Epoch #26: loss=1.8434008359909058\r\n",
      "Epoch #27: loss=1.8078405857086182\r\n",
      "Epoch #28: loss=1.7156685590744019\r\n",
      "Epoch #29: loss=1.7815316915512085\r\n",
      "Epoch #30: loss=1.6753829717636108\r\n",
      "Epoch #31: loss=1.6109697818756104\r\n",
      "Epoch #32: loss=1.599732756614685\r\n",
      "Epoch #33: loss=1.5299327373504639\r\n",
      "Epoch #34: loss=1.7398444414138794\r\n",
      "Epoch #35: loss=1.4552749395370483\r\n",
      "Epoch #36: loss=1.5579482316970825\r\n",
      "Epoch #37: loss=1.5661242008209229\r\n",
      "Epoch #38: loss=1.5808886289596558\r\n",
      "Epoch #39: loss=1.387712836265564\r\n",
      "Epoch #40: loss=1.428288459777832\r\n",
      "Epoch #41: loss=1.6337859630584717\r\n",
      "Epoch #42: loss=1.4249929189682007\r\n",
      "Epoch #43: loss=1.4430125951766968\r\n",
      "Epoch #44: loss=1.545559287071228\r\n",
      "Epoch #45: loss=1.3269097805023193\r\n",
      "Epoch #46: loss=1.371816873550415\r\n",
      "Epoch #47: loss=1.2950119972229004\r\n",
      "Epoch #48: loss=1.396899700164795\r\n",
      "Epoch #49: loss=1.2530556917190552\r\n",
      "Epoch #50: loss=1.2897568941116333\r\n",
      "Epoch #51: loss=1.2233233451843262\r\n",
      "Epoch #52: loss=1.2161972522735596\r\n",
      "Epoch #53: loss=1.390995740890503\r\n",
      "Epoch #54: loss=1.4284629821777344\r\n",
      "Epoch #55: loss=1.2676483392715454\r\n",
      "Epoch #56: loss=1.2196695804595947\r\n",
      "Epoch #57: loss=1.1253585815429688\r\n",
      "Epoch #58: loss=1.3441425561904907\r\n",
      "Epoch #59: loss=1.1336395740509033\r\n",
      "Epoch #60: loss=1.0601623058319092\r\n",
      "Epoch #61: loss=1.0087907314300537\r\n",
      "Epoch #62: loss=1.0093300342559814\r\n",
      "Epoch #63: loss=1.0556461811065674\r\n",
      "Epoch #64: loss=1.1170555353164673\r\n",
      "Epoch #65: loss=0.9964301586151123\r\n",
      "Epoch #66: loss=0.9762797355651855\r\n",
      "Epoch #67: loss=1.1298574209213257\r\n",
      "Epoch #68: loss=0.9538779258728027\r\n",
      "Epoch #69: loss=0.933788537979126\r\n",
      "Epoch #70: loss=1.3179274797439575\r\n",
      "Epoch #71: loss=1.0535802841186523\r\n",
      "Epoch #72: loss=1.250052809715271\r\n",
      "Epoch #73: loss=0.8811789751052856\r\n",
      "Epoch #74: loss=1.3866901397705078\r\n",
      "Epoch #75: loss=1.015740990638733\r\n",
      "Epoch #76: loss=0.8575501441955566\r\n",
      "Epoch #77: loss=1.0565086603164673\r\n",
      "Epoch #78: loss=0.9181113243103027\r\n",
      "Epoch #79: loss=0.9787697792053223\r\n",
      "Epoch #80: loss=0.9565568566322327\r\n",
      "Epoch #81: loss=1.0265167951583862\r\n",
      "Epoch #82: loss=0.9508780241012573\r\n",
      "Epoch #83: loss=1.1941355466842651\r\n",
      "Epoch #84: loss=0.8768220543861389\r\n",
      "Epoch #85: loss=0.8688775300979614\r\n",
      "Epoch #86: loss=1.335382342338562\r\n",
      "Epoch #87: loss=0.9583438038825989\r\n",
      "Epoch #88: loss=0.9026815295219421\r\n",
      "Epoch #89: loss=0.9567864537239075\r\n",
      "Epoch #90: loss=0.7868479490280151\r\n",
      "Epoch #91: loss=0.774540901184082\r\n",
      "Epoch #92: loss=0.9457985758781433\r\n",
      "Epoch #93: loss=0.9791566133499146\r\n",
      "Epoch #94: loss=1.691875696182251\r\n",
      "Epoch #95: loss=1.3019272089004517\r\n",
      "Epoch #96: loss=0.9702722430229187\r\n",
      "Epoch #97: loss=0.8201823234558105\r\n",
      "Epoch #98: loss=0.7993186712265015\r\n",
      "Epoch #99: loss=0.9933885931968689\r\n",
      "Epoch #100: loss=0.7884823679924011\r\n",
      "Epoch #101: loss=0.8939452767372131\r\n",
      "Epoch #102: loss=1.0755572319030762\r\n",
      "Epoch #103: loss=1.0450106859207153\r\n",
      "Epoch #104: loss=0.8048315048217773\r\n",
      "Epoch #105: loss=0.71739661693573\r\n",
      "Epoch #106: loss=0.9721738696098328\r\n",
      "Epoch #107: loss=0.7195461988449097\r\n",
      "Epoch #108: loss=1.2627900838851929\r\n",
      "Epoch #109: loss=0.7309626936912537\r\n",
      "Epoch #110: loss=0.8096647262573242\r\n",
      "Epoch #111: loss=1.1927369832992554\r\n",
      "Epoch #112: loss=0.8079244494438171\r\n",
      "Epoch #113: loss=0.7362887263298035\r\n",
      "Epoch #114: loss=0.9868599772453308\r\n",
      "Epoch #115: loss=0.70292729139328\r\n",
      "Epoch #116: loss=0.7456284761428833\r\n",
      "Epoch #117: loss=0.7033038139343262\r\n",
      "Epoch #118: loss=0.9804989695549011\r\n",
      "Epoch #119: loss=0.6878021955490112\r\n",
      "Epoch #120: loss=0.7316828966140747\r\n",
      "Epoch #121: loss=0.6534031629562378\r\n",
      "Epoch #122: loss=0.7704963088035583\r\n",
      "Epoch #123: loss=0.7248350381851196\r\n",
      "Epoch #124: loss=0.8039510250091553\r\n",
      "Epoch #125: loss=0.8180514574050903\r\n",
      "Epoch #126: loss=0.9178975224494934\r\n",
      "Epoch #127: loss=0.9961146712303162\r\n",
      "Epoch #128: loss=0.6483645439147949\r\n",
      "Epoch #129: loss=0.7483975291252136\r\n",
      "Epoch #130: loss=0.6525692343711853\r\n",
      "Epoch #131: loss=0.6825354099273682\r\n",
      "Epoch #132: loss=0.7333059310913086\r\n",
      "Epoch #133: loss=0.8581480383872986\r\n",
      "Epoch #134: loss=0.7192187905311584\r\n",
      "Epoch #135: loss=1.3544143438339233\r\n",
      "Epoch #136: loss=0.8302308917045593\r\n",
      "Epoch #137: loss=0.8254481554031372\r\n",
      "Epoch #138: loss=0.6870066523551941\r\n",
      "Epoch #139: loss=0.8390933275222778\r\n",
      "Epoch #140: loss=0.7756598591804504\r\n",
      "Epoch #141: loss=0.838822066783905\r\n",
      "Epoch #142: loss=0.6714795827865601\r\n",
      "Epoch #143: loss=0.6837717890739441\r\n",
      "Epoch #144: loss=0.8015163540840149\r\n",
      "Epoch #145: loss=0.8918890357017517\r\n",
      "Epoch #146: loss=0.6688506007194519\r\n",
      "Epoch #147: loss=0.7912424206733704\r\n",
      "Epoch #148: loss=0.7293334007263184\r\n",
      "Epoch #149: loss=1.230642318725586\r\n",
      "Epoch #150: loss=0.6282812356948853\r\n",
      "Epoch #151: loss=0.656359851360321\r\n",
      "Epoch #152: loss=0.8779303431510925\r\n",
      "Epoch #153: loss=0.6805562973022461\r\n",
      "Epoch #154: loss=0.5952872037887573\r\n",
      "Epoch #155: loss=0.982610821723938\r\n",
      "Epoch #156: loss=1.0018413066864014\r\n",
      "Epoch #157: loss=0.9721919894218445\r\n",
      "Epoch #158: loss=0.6201947927474976\r\n",
      "Epoch #159: loss=0.7574048042297363\r\n",
      "Epoch #160: loss=0.606891393661499\r\n",
      "Epoch #161: loss=0.7901976704597473\r\n",
      "Epoch #162: loss=0.6796825528144836\r\n",
      "Epoch #163: loss=0.5854129791259766\r\n",
      "Epoch #164: loss=0.7369567155838013\r\n",
      "Epoch #165: loss=1.0964045524597168\r\n",
      "Epoch #166: loss=0.6138051152229309\r\n",
      "Epoch #167: loss=0.6147150993347168\r\n",
      "Epoch #168: loss=1.0190871953964233\r\n",
      "Epoch #169: loss=0.6586073637008667\r\n",
      "Epoch #170: loss=0.8665642142295837\r\n",
      "Epoch #171: loss=0.746464192867279\r\n",
      "Epoch #172: loss=0.5920971632003784\r\n",
      "Epoch #173: loss=1.04478919506073\r\n",
      "Epoch #174: loss=0.816705048084259\r\n",
      "Epoch #175: loss=0.6423810720443726\r\n",
      "Epoch #176: loss=0.5768725275993347\r\n",
      "Epoch #177: loss=0.5519479513168335\r\n",
      "Epoch #178: loss=0.5599707365036011\r\n",
      "Epoch #179: loss=0.6850121021270752\r\n",
      "Epoch #180: loss=0.5457569360733032\r\n",
      "Epoch #181: loss=0.8266668319702148\r\n",
      "Epoch #182: loss=1.0962412357330322\r\n",
      "Epoch #183: loss=0.5918502807617188\r\n",
      "Epoch #184: loss=0.5054162740707397\r\n",
      "Epoch #185: loss=0.6479328870773315\r\n",
      "Epoch #186: loss=0.6565455198287964\r\n",
      "Epoch #187: loss=0.7118026614189148\r\n",
      "Epoch #188: loss=0.5673843026161194\r\n",
      "Epoch #189: loss=0.5860550403594971\r\n",
      "Epoch #190: loss=0.5085997581481934\r\n",
      "Epoch #191: loss=0.8848596811294556\r\n",
      "Epoch #192: loss=1.322248935699463\r\n",
      "Epoch #193: loss=0.6812198162078857\r\n",
      "Epoch #194: loss=0.5933208465576172\r\n",
      "Epoch #195: loss=0.5466951727867126\r\n",
      "Epoch #196: loss=0.6697804927825928\r\n",
      "Epoch #197: loss=0.5207294821739197\r\n",
      "Epoch #198: loss=0.5142394304275513\r\n",
      "Epoch #199: loss=0.5268141031265259\r\n",
      "Epoch #200: loss=0.6449277400970459\r\n",
      "Epoch #201: loss=0.9699657559394836\r\n",
      "Epoch #202: loss=0.5002675652503967\r\n",
      "Epoch #203: loss=0.46923646330833435\r\n",
      "Epoch #204: loss=0.582493782043457\r\n",
      "Epoch #205: loss=0.8884755373001099\r\n",
      "Epoch #206: loss=0.646818220615387\r\n",
      "Epoch #207: loss=0.511864423751831\r\n",
      "Epoch #208: loss=0.4895528256893158\r\n",
      "Epoch #209: loss=0.5498676300048828\r\n",
      "Epoch #210: loss=0.8006670475006104\r\n",
      "Epoch #211: loss=0.4362139105796814\r\n",
      "Epoch #212: loss=0.6632604598999023\r\n",
      "Epoch #213: loss=0.4838220775127411\r\n",
      "Epoch #214: loss=0.648482620716095\r\n",
      "Epoch #215: loss=0.5095564723014832\r\n",
      "Epoch #216: loss=1.126272439956665\r\n",
      "Epoch #217: loss=0.565236508846283\r\n",
      "Epoch #218: loss=0.6081201434135437\r\n",
      "Epoch #219: loss=0.5554863214492798\r\n",
      "Epoch #220: loss=0.5897765755653381\r\n",
      "Epoch #221: loss=0.50630784034729\r\n",
      "Epoch #222: loss=0.8744840025901794\r\n",
      "Epoch #223: loss=0.5226995348930359\r\n",
      "Epoch #224: loss=0.6077900528907776\r\n",
      "Epoch #225: loss=0.5034549832344055\r\n",
      "Epoch #226: loss=0.4828226864337921\r\n",
      "Epoch #227: loss=0.7549845576286316\r\n",
      "Epoch #228: loss=0.7187490463256836\r\n",
      "Epoch #229: loss=0.4533371329307556\r\n",
      "Epoch #230: loss=0.7043960690498352\r\n",
      "Epoch #231: loss=0.4426356554031372\r\n",
      "Epoch #232: loss=0.4195876121520996\r\n",
      "Epoch #233: loss=0.47206342220306396\r\n",
      "Epoch #234: loss=0.538589596748352\r\n",
      "Epoch #235: loss=0.5143144130706787\r\n",
      "Epoch #236: loss=0.6448472738265991\r\n",
      "Epoch #237: loss=0.44802603125572205\r\n",
      "Epoch #238: loss=0.44579970836639404\r\n",
      "Epoch #239: loss=0.5658009648323059\r\n",
      "Epoch #240: loss=0.48961612582206726\r\n",
      "Epoch #241: loss=0.4915090799331665\r\n",
      "Epoch #242: loss=0.39997756481170654\r\n",
      "Epoch #243: loss=0.7018498182296753\r\n",
      "Epoch #244: loss=0.3778536021709442\r\n",
      "Epoch #245: loss=0.38260743021965027\r\n",
      "Epoch #246: loss=0.49402832984924316\r\n",
      "Epoch #247: loss=0.38014349341392517\r\n",
      "Epoch #248: loss=0.5553793907165527\r\n",
      "Epoch #249: loss=0.9153925776481628\r\n",
      "Epoch #250: loss=0.43108057975769043\r\n",
      "Epoch #251: loss=0.35912105441093445\r\n",
      "Epoch #252: loss=0.43594804406166077\r\n",
      "Epoch #253: loss=0.5136082172393799\r\n",
      "Epoch #254: loss=0.3798043429851532\r\n",
      "Epoch #255: loss=0.8509009480476379\r\n",
      "Epoch #256: loss=0.35700517892837524\r\n",
      "Epoch #257: loss=0.3837074935436249\r\n",
      "Epoch #258: loss=0.5795484185218811\r\n",
      "Epoch #259: loss=0.46606650948524475\r\n",
      "Epoch #260: loss=0.4048866927623749\r\n",
      "Epoch #261: loss=0.37140953540802\r\n",
      "Epoch #262: loss=0.4598637521266937\r\n",
      "Epoch #263: loss=0.41005846858024597\r\n",
      "Epoch #264: loss=0.559763491153717\r\n",
      "Epoch #265: loss=0.5236734747886658\r\n",
      "Epoch #266: loss=0.6795654296875\r\n",
      "Epoch #267: loss=0.46137741208076477\r\n",
      "Epoch #268: loss=0.37104853987693787\r\n",
      "Epoch #269: loss=0.36607569456100464\r\n",
      "Epoch #270: loss=0.33411726355552673\r\n",
      "Epoch #271: loss=0.38458549976348877\r\n",
      "Epoch #272: loss=0.36636480689048767\r\n",
      "Epoch #273: loss=0.7375286817550659\r\n",
      "Epoch #274: loss=0.38930147886276245\r\n",
      "Epoch #275: loss=0.3830112814903259\r\n",
      "Epoch #276: loss=0.9503657817840576\r\n",
      "Epoch #277: loss=0.3931940495967865\r\n",
      "Epoch #278: loss=0.42698922753334045\r\n",
      "Epoch #279: loss=0.4410187304019928\r\n",
      "Epoch #280: loss=0.43073633313179016\r\n",
      "Epoch #281: loss=0.42017263174057007\r\n",
      "Epoch #282: loss=0.6203387975692749\r\n",
      "Epoch #283: loss=0.42592543363571167\r\n",
      "Epoch #284: loss=0.3736010491847992\r\n",
      "Epoch #285: loss=0.38890883326530457\r\n",
      "Epoch #286: loss=0.3430636525154114\r\n",
      "Epoch #287: loss=0.6436396241188049\r\n",
      "Epoch #288: loss=0.3398928642272949\r\n",
      "Epoch #289: loss=0.46175867319107056\r\n",
      "Epoch #290: loss=0.5680960416793823\r\n",
      "Epoch #291: loss=0.39821624755859375\r\n",
      "Epoch #292: loss=0.5501072406768799\r\n",
      "Epoch #293: loss=0.4788687229156494\r\n",
      "Epoch #294: loss=0.7293469905853271\r\n",
      "Epoch #295: loss=0.4156196415424347\r\n",
      "Epoch #296: loss=0.4828508794307709\r\n",
      "Epoch #297: loss=0.7106356024742126\r\n",
      "Epoch #298: loss=1.4786514043807983\r\n",
      "Epoch #299: loss=0.7476435303688049\r\n",
      "Epoch #300: loss=0.5438628792762756\r\n",
      "Epoch #301: loss=0.4815133512020111\r\n",
      "Epoch #302: loss=0.9114312529563904\r\n",
      "Epoch #303: loss=0.6192166209220886\r\n",
      "Epoch #304: loss=0.5939871072769165\r\n",
      "Epoch #305: loss=0.42594748735427856\r\n",
      "Epoch #306: loss=0.4748586416244507\r\n",
      "Epoch #307: loss=0.47182613611221313\r\n",
      "Epoch #308: loss=0.4340525269508362\r\n",
      "Epoch #309: loss=0.5638882517814636\r\n",
      "Epoch #310: loss=0.39027655124664307\r\n",
      "Epoch #311: loss=0.44862100481987\r\n",
      "Epoch #312: loss=0.703339695930481\r\n",
      "Epoch #313: loss=0.43378254771232605\r\n",
      "Epoch #314: loss=1.6358712911605835\r\n",
      "Epoch #315: loss=0.5548813343048096\r\n",
      "Epoch #316: loss=0.448051393032074\r\n",
      "Epoch #317: loss=1.2376197576522827\r\n",
      "Epoch #318: loss=0.40357670187950134\r\n",
      "Epoch #319: loss=0.4651810824871063\r\n",
      "Epoch #320: loss=0.4041784405708313\r\n",
      "Epoch #321: loss=0.5371060967445374\r\n",
      "Epoch #322: loss=0.5823847055435181\r\n",
      "Epoch #323: loss=0.37345725297927856\r\n",
      "Epoch #324: loss=0.34122323989868164\r\n",
      "Epoch #325: loss=0.43912601470947266\r\n",
      "Epoch #326: loss=0.5655025839805603\r\n",
      "Epoch #327: loss=0.341802716255188\r\n",
      "Epoch #328: loss=0.7428872585296631\r\n",
      "Epoch #329: loss=0.34333857893943787\r\n",
      "Epoch #330: loss=0.3644605576992035\r\n",
      "Epoch #331: loss=0.3857804834842682\r\n",
      "Epoch #332: loss=0.36809536814689636\r\n",
      "Epoch #333: loss=0.527990996837616\r\n",
      "Epoch #334: loss=1.742714285850525\r\n",
      "Epoch #335: loss=1.0126352310180664\r\n",
      "Epoch #336: loss=0.3928163945674896\r\n",
      "Epoch #337: loss=0.49557676911354065\r\n",
      "Epoch #338: loss=0.33788996934890747\r\n",
      "Epoch #339: loss=0.48265644907951355\r\n",
      "Epoch #340: loss=0.590268611907959\r\n",
      "Epoch #341: loss=0.45953813195228577\r\n",
      "Epoch #342: loss=0.3884130120277405\r\n",
      "Epoch #343: loss=0.37710511684417725\r\n",
      "Epoch #344: loss=0.34116634726524353\r\n",
      "Epoch #345: loss=0.3610183298587799\r\n",
      "Epoch #346: loss=0.3313291668891907\r\n",
      "Epoch #347: loss=0.30809712409973145\r\n",
      "Epoch #348: loss=0.41214460134506226\r\n",
      "Epoch #349: loss=0.43836045265197754\r\n",
      "Epoch #350: loss=0.2999408543109894\r\n",
      "Epoch #351: loss=0.362460196018219\r\n",
      "Epoch #352: loss=0.548448383808136\r\n",
      "Epoch #353: loss=0.5331156253814697\r\n",
      "Epoch #354: loss=0.34397563338279724\r\n",
      "Epoch #355: loss=0.4780255854129791\r\n",
      "Epoch #356: loss=0.3631775379180908\r\n",
      "Epoch #357: loss=0.4273442327976227\r\n",
      "Epoch #358: loss=0.3043108582496643\r\n",
      "Epoch #359: loss=0.2871241569519043\r\n",
      "Epoch #360: loss=0.6065409779548645\r\n",
      "Epoch #361: loss=0.361782968044281\r\n",
      "Epoch #362: loss=0.3127743601799011\r\n",
      "Epoch #363: loss=0.3056066334247589\r\n",
      "Epoch #364: loss=0.3117905259132385\r\n",
      "Epoch #365: loss=0.3833169639110565\r\n",
      "Epoch #366: loss=0.24814632534980774\r\n",
      "Epoch #367: loss=0.2489587962627411\r\n",
      "Epoch #368: loss=0.23650476336479187\r\n",
      "Epoch #369: loss=0.28036725521087646\r\n",
      "Epoch #370: loss=0.41141557693481445\r\n",
      "Epoch #371: loss=0.23824867606163025\r\n",
      "Epoch #372: loss=0.25774794816970825\r\n",
      "Epoch #373: loss=0.2868581712245941\r\n",
      "Epoch #374: loss=0.23897743225097656\r\n",
      "Epoch #375: loss=0.3886664807796478\r\n",
      "Epoch #376: loss=0.26578858494758606\r\n",
      "Epoch #377: loss=0.26980701088905334\r\n",
      "Epoch #378: loss=0.3238579332828522\r\n",
      "Epoch #379: loss=0.27644506096839905\r\n",
      "Epoch #380: loss=0.3352312743663788\r\n",
      "Epoch #381: loss=0.26237648725509644\r\n",
      "Epoch #382: loss=0.21613149344921112\r\n",
      "Epoch #383: loss=0.20642399787902832\r\n",
      "Epoch #384: loss=0.2413463294506073\r\n",
      "Epoch #385: loss=3.593092441558838\r\n",
      "Epoch #386: loss=0.32394763827323914\r\n",
      "Epoch #387: loss=0.4145320951938629\r\n",
      "Epoch #388: loss=0.30329087376594543\r\n",
      "Epoch #389: loss=0.34762680530548096\r\n",
      "Epoch #390: loss=0.8414468169212341\r\n",
      "Epoch #391: loss=0.5764549374580383\r\n",
      "Epoch #392: loss=0.40207862854003906\r\n",
      "Epoch #393: loss=0.4496212899684906\r\n",
      "Epoch #394: loss=0.3748493194580078\r\n",
      "Epoch #395: loss=0.4404878318309784\r\n",
      "Epoch #396: loss=0.3751499056816101\r\n",
      "Epoch #397: loss=0.41074490547180176\r\n",
      "Epoch #398: loss=0.3257613480091095\r\n",
      "Epoch #399: loss=0.3715599775314331\r\n",
      "Epoch #400: loss=0.33949747681617737\r\n",
      "Epoch #401: loss=0.32308703660964966\r\n",
      "Epoch #402: loss=0.3080236613750458\r\n",
      "Epoch #403: loss=0.345235675573349\r\n",
      "Epoch #404: loss=0.6842269897460938\r\n",
      "Epoch #405: loss=0.4302833080291748\r\n",
      "Epoch #406: loss=0.33777010440826416\r\n",
      "Epoch #407: loss=0.47069963812828064\r\n",
      "Epoch #408: loss=0.26450806856155396\r\n",
      "Epoch #409: loss=0.2802009582519531\r\n",
      "Epoch #410: loss=0.49004897475242615\r\n",
      "Epoch #411: loss=0.27824661135673523\r\n",
      "Epoch #412: loss=0.813286542892456\r\n",
      "Epoch #413: loss=0.29803481698036194\r\n",
      "Epoch #414: loss=1.0918411016464233\r\n",
      "Epoch #415: loss=0.38892003893852234\r\n",
      "Epoch #416: loss=0.40464887022972107\r\n",
      "Epoch #417: loss=0.34673944115638733\r\n",
      "Epoch #418: loss=0.3321698307991028\r\n",
      "Epoch #419: loss=0.35362106561660767\r\n",
      "Epoch #420: loss=0.49195289611816406\r\n",
      "Epoch #421: loss=0.2520170211791992\r\n",
      "Epoch #422: loss=0.38837090134620667\r\n",
      "Epoch #423: loss=0.7205942869186401\r\n",
      "Epoch #424: loss=0.34686148166656494\r\n",
      "Epoch #425: loss=0.6747876405715942\r\n",
      "Epoch #426: loss=0.2717162072658539\r\n",
      "Epoch #427: loss=0.25542426109313965\r\n",
      "Epoch #428: loss=0.7948595285415649\r\n",
      "Epoch #429: loss=0.6191350817680359\r\n",
      "Epoch #430: loss=0.6756961941719055\r\n",
      "Epoch #431: loss=0.3750731348991394\r\n",
      "Epoch #432: loss=0.4105466902256012\r\n",
      "Epoch #433: loss=0.37733638286590576\r\n",
      "Epoch #434: loss=0.2903141975402832\r\n",
      "Epoch #435: loss=0.3339826762676239\r\n",
      "Epoch #436: loss=0.2629832625389099\r\n",
      "Epoch #437: loss=0.5341970920562744\r\n",
      "Epoch #438: loss=0.30246439576148987\r\n",
      "Epoch #439: loss=0.47930407524108887\r\n",
      "Epoch #440: loss=0.6623033285140991\r\n",
      "Epoch #441: loss=0.3063126802444458\r\n",
      "Epoch #442: loss=0.6343757510185242\r\n",
      "Epoch #443: loss=0.28924885392189026\r\n",
      "Epoch #444: loss=0.3371550142765045\r\n",
      "Epoch #445: loss=0.27530771493911743\r\n",
      "Epoch #446: loss=0.2559652626514435\r\n",
      "Epoch #447: loss=0.27989059686660767\r\n",
      "Epoch #448: loss=0.30387797951698303\r\n",
      "Epoch #449: loss=0.3610052466392517\r\n",
      "Epoch #450: loss=0.27632462978363037\r\n",
      "Epoch #451: loss=0.5145732164382935\r\n",
      "Epoch #452: loss=0.23525398969650269\r\n",
      "Epoch #453: loss=0.23436783254146576\r\n",
      "Epoch #454: loss=0.47674861550331116\r\n",
      "Epoch #455: loss=0.300548791885376\r\n",
      "Epoch #456: loss=0.2441778928041458\r\n",
      "Epoch #457: loss=0.228851318359375\r\n",
      "Epoch #458: loss=0.4708447754383087\r\n",
      "Epoch #459: loss=0.1971505880355835\r\n",
      "Epoch #460: loss=0.20993876457214355\r\n",
      "Epoch #461: loss=0.22082732617855072\r\n",
      "Epoch #462: loss=0.3936757743358612\r\n",
      "Epoch #463: loss=0.24769380688667297\r\n",
      "Epoch #464: loss=0.18633684515953064\r\n",
      "Epoch #465: loss=0.38432633876800537\r\n",
      "Epoch #466: loss=0.22521637380123138\r\n",
      "Epoch #467: loss=0.22254829108715057\r\n",
      "Epoch #468: loss=0.21160800755023956\r\n",
      "Epoch #469: loss=0.22169187664985657\r\n",
      "Epoch #470: loss=0.37459975481033325\r\n",
      "Epoch #471: loss=0.23715361952781677\r\n",
      "Epoch #472: loss=0.2499210238456726\r\n",
      "Epoch #473: loss=0.5563429594039917\r\n",
      "Epoch #474: loss=0.23536723852157593\r\n",
      "Epoch #475: loss=0.17461179196834564\r\n",
      "Epoch #476: loss=0.16802671551704407\r\n",
      "Epoch #477: loss=0.40244561433792114\r\n",
      "Epoch #478: loss=0.29210972785949707\r\n",
      "Epoch #479: loss=0.16683676838874817\r\n",
      "Epoch #480: loss=0.21690042316913605\r\n",
      "Epoch #481: loss=0.5374720096588135\r\n",
      "Epoch #482: loss=0.16007721424102783\r\n",
      "Epoch #483: loss=0.17520777881145477\r\n",
      "Epoch #484: loss=0.3245304524898529\r\n",
      "Epoch #485: loss=0.1689329594373703\r\n",
      "Epoch #486: loss=0.2860798239707947\r\n",
      "Epoch #487: loss=0.20294754207134247\r\n",
      "Epoch #488: loss=0.227085679769516\r\n",
      "Epoch #489: loss=0.1715141087770462\r\n",
      "Epoch #490: loss=0.16788563132286072\r\n",
      "Epoch #491: loss=0.1512855887413025\r\n",
      "Epoch #492: loss=0.32321926951408386\r\n",
      "Epoch #493: loss=0.17966367304325104\r\n",
      "Epoch #494: loss=0.2626734673976898\r\n",
      "Epoch #495: loss=0.1619381606578827\r\n",
      "Epoch #496: loss=0.17912299931049347\r\n",
      "Epoch #497: loss=0.2753981649875641\r\n",
      "Epoch #498: loss=0.14069689810276031\r\n",
      "Epoch #499: loss=0.2315659373998642\r\n",
      "Epoch #500: loss=0.2504860460758209\r\n",
      "Epoch #501: loss=0.17876291275024414\r\n",
      "Epoch #502: loss=0.1325090229511261\r\n",
      "Epoch #503: loss=0.1451117843389511\r\n",
      "Epoch #504: loss=0.1828717440366745\r\n",
      "Epoch #505: loss=0.27187013626098633\r\n",
      "Epoch #506: loss=0.24642470479011536\r\n",
      "Epoch #507: loss=0.14896833896636963\r\n",
      "Epoch #508: loss=0.12474451959133148\r\n",
      "Epoch #509: loss=0.13820365071296692\r\n",
      "Epoch #510: loss=0.3601820766925812\r\n",
      "Epoch #511: loss=0.305271178483963\r\n",
      "Epoch #512: loss=0.16303911805152893\r\n",
      "Epoch #513: loss=0.1284036487340927\r\n",
      "Epoch #514: loss=0.14896844327449799\r\n",
      "Epoch #515: loss=0.11909744143486023\r\n",
      "Epoch #516: loss=0.13323771953582764\r\n",
      "Epoch #517: loss=0.11426761001348495\r\n",
      "Epoch #518: loss=0.09586280584335327\r\n",
      "Epoch #519: loss=0.1630389243364334\r\n",
      "Epoch #520: loss=0.1619539111852646\r\n",
      "Epoch #521: loss=0.11388985812664032\r\n",
      "Epoch #522: loss=0.2094033807516098\r\n",
      "Epoch #523: loss=0.5141050815582275\r\n",
      "Epoch #524: loss=0.11479071527719498\r\n",
      "Epoch #525: loss=0.1360938549041748\r\n",
      "Epoch #526: loss=0.2692670226097107\r\n",
      "Epoch #527: loss=0.10989844053983688\r\n",
      "Epoch #528: loss=0.13303175568580627\r\n",
      "Epoch #529: loss=0.19832229614257812\r\n",
      "Epoch #530: loss=0.11803138256072998\r\n",
      "Epoch #531: loss=0.09987470507621765\r\n",
      "Epoch #532: loss=0.12062427401542664\r\n",
      "Epoch #533: loss=0.11640819162130356\r\n",
      "Epoch #534: loss=0.41630491614341736\r\n",
      "Epoch #535: loss=0.1042809933423996\r\n",
      "Epoch #536: loss=0.22196409106254578\r\n",
      "Epoch #537: loss=0.18802331387996674\r\n",
      "Epoch #538: loss=0.1615869253873825\r\n",
      "Epoch #539: loss=0.13565082848072052\r\n",
      "Epoch #540: loss=0.42001834511756897\r\n",
      "Epoch #541: loss=0.13553312420845032\r\n",
      "Epoch #542: loss=0.1841045618057251\r\n",
      "Epoch #543: loss=0.1289258450269699\r\n",
      "Epoch #544: loss=0.28663545846939087\r\n",
      "Epoch #545: loss=0.2615245580673218\r\n",
      "Epoch #546: loss=0.1840725690126419\r\n",
      "Epoch #547: loss=1.8393701314926147\r\n",
      "Epoch #548: loss=0.19587548077106476\r\n",
      "Epoch #549: loss=0.14558513462543488\r\n",
      "Epoch #550: loss=0.24978773295879364\r\n",
      "Epoch #551: loss=0.24961979687213898\r\n",
      "Epoch #552: loss=0.154974102973938\r\n",
      "Epoch #553: loss=0.2223627269268036\r\n",
      "Epoch #554: loss=0.29338598251342773\r\n",
      "Epoch #555: loss=0.17861507833003998\r\n",
      "Epoch #556: loss=0.21700704097747803\r\n",
      "Epoch #557: loss=0.30741745233535767\r\n",
      "Epoch #558: loss=0.36004745960235596\r\n",
      "Epoch #559: loss=0.3172423243522644\r\n",
      "Epoch #560: loss=0.8787084221839905\r\n",
      "Epoch #561: loss=0.22100244462490082\r\n",
      "Epoch #562: loss=0.273707777261734\r\n",
      "Epoch #563: loss=0.4012047350406647\r\n",
      "Epoch #564: loss=0.17434820532798767\r\n",
      "Epoch #565: loss=0.41102176904678345\r\n",
      "Epoch #566: loss=0.16831855475902557\r\n",
      "Epoch #567: loss=0.18260155618190765\r\n",
      "Epoch #568: loss=0.18005675077438354\r\n",
      "Epoch #569: loss=0.14979970455169678\r\n",
      "Epoch #570: loss=0.47323933243751526\r\n",
      "Epoch #571: loss=0.20190179347991943\r\n",
      "Epoch #572: loss=0.11904963105916977\r\n",
      "Epoch #573: loss=0.12909190356731415\r\n",
      "Epoch #574: loss=0.24136988818645477\r\n",
      "Epoch #575: loss=0.11520272493362427\r\n",
      "Epoch #576: loss=0.1627802550792694\r\n",
      "Epoch #577: loss=0.12775182723999023\r\n",
      "Epoch #578: loss=0.4138657748699188\r\n",
      "Epoch #579: loss=0.1153574213385582\r\n",
      "Epoch #580: loss=0.12333225458860397\r\n",
      "Epoch #581: loss=0.12078806757926941\r\n",
      "Epoch #582: loss=0.174617737531662\r\n",
      "Epoch #583: loss=0.10942216217517853\r\n",
      "Epoch #584: loss=0.09481862187385559\r\n",
      "Epoch #585: loss=0.0979803055524826\r\n",
      "Epoch #586: loss=0.13707423210144043\r\n",
      "Epoch #587: loss=0.1883857697248459\r\n",
      "Epoch #588: loss=0.08909982442855835\r\n",
      "Epoch #589: loss=0.09411533921957016\r\n",
      "Epoch #590: loss=0.08730673044919968\r\n",
      "Epoch #591: loss=0.3342897593975067\r\n",
      "Epoch #592: loss=0.2716027796268463\r\n",
      "Epoch #593: loss=0.3976427912712097\r\n",
      "Epoch #594: loss=0.11028997600078583\r\n",
      "Epoch #595: loss=0.13638028502464294\r\n",
      "Epoch #596: loss=0.1488223373889923\r\n",
      "Epoch #597: loss=0.23498956859111786\r\n",
      "Epoch #598: loss=0.21557115018367767\r\n",
      "Epoch #599: loss=0.11052536964416504\r\n",
      "\r\n",
      "Training time: 0:02:59.721839\r\n",
      "\r\n",
      "Evaluation result: {'ours': {24: {'norm': {'MSE': 0.41718302175226263, 'MAE': 0.4293769232377788}, 'raw': {'MSE': 7.37968443354437, 'MAE': 1.4569722724264262}}, 48: {'norm': {'MSE': 0.5465949949588367, 'MAE': 0.4985572289234632}, 'raw': {'MSE': 9.79167528439506, 'MAE': 1.7036824651473892}}, 96: {'norm': {'MSE': 0.5826126038911296, 'MAE': 0.5251225067314956}, 'raw': {'MSE': 10.732532287734918, 'MAE': 1.8366195018437175}}, 288: {'norm': {'MSE': 0.659352286409218, 'MAE': 0.5786788435900352}, 'raw': {'MSE': 12.927181009461723, 'MAE': 2.0912139745567586}}, 672: {'norm': {'MSE': 0.7534463040435504, 'MAE': 0.6382281971107712}, 'raw': {'MSE': 14.648080082411047, 'MAE': 2.3016525916236077}}}, 'ts2vec_infer_time': 9.550708055496216, 'lr_train_time': {24: 6.484373569488525, 48: 8.547297239303589, 96: 12.324289083480835, 288: 29.0791494846344, 672: 60.7743444442749}, 'lr_infer_time': {24: 0.3712339401245117, 48: 0.6397624015808105, 96: 1.418964147567749, 288: 4.491976737976074, 672: 9.786079168319702}}\r\n",
      "Finished.\r\n"
     ]
    }
   ],
   "source": [
    "!python -u train.py ETTm1 forecast_multivar --loader forecast_csv --repr-dims 320 --max-threads 8 --seed 42 --eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c23b41",
   "metadata": {
    "papermill": {
     "duration": 0.063666,
     "end_time": "2025-10-12T03:44:35.382262",
     "exception": false,
     "start_time": "2025-10-12T03:44:35.318596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ETTh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa6d804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:44:35.509689Z",
     "iopub.status.busy": "2025-10-12T03:44:35.508150Z",
     "iopub.status.idle": "2025-10-12T03:46:31.393927Z",
     "shell.execute_reply": "2025-10-12T03:46:31.393143Z"
    },
    "papermill": {
     "duration": 115.949897,
     "end_time": "2025-10-12T03:46:31.395282",
     "exception": false,
     "start_time": "2025-10-12T03:44:35.445385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh1\r\n",
      "Arguments: Namespace(dataset='ETTh1', run_name='forecast_multivar', loader='forecast_csv', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0)\r\n",
      "Loading data... done\r\n",
      "Epoch #0: loss=5.711709022521973\r\n",
      "Epoch #1: loss=3.725677490234375\r\n",
      "Epoch #2: loss=3.4132614135742188\r\n",
      "Epoch #3: loss=2.588179349899292\r\n",
      "Epoch #4: loss=2.088526725769043\r\n",
      "Epoch #5: loss=2.5069804191589355\r\n",
      "Epoch #6: loss=2.5583572387695312\r\n",
      "Epoch #7: loss=1.888529658317566\r\n",
      "Epoch #8: loss=2.3567757606506348\r\n",
      "Epoch #9: loss=1.7047395706176758\r\n",
      "Epoch #10: loss=1.9402822256088257\r\n",
      "Epoch #11: loss=1.8994683027267456\r\n",
      "Epoch #12: loss=1.9278382062911987\r\n",
      "Epoch #13: loss=1.916809320449829\r\n",
      "Epoch #14: loss=1.7888288497924805\r\n",
      "Epoch #15: loss=1.770698070526123\r\n",
      "Epoch #16: loss=1.7802550792694092\r\n",
      "Epoch #17: loss=1.743808627128601\r\n",
      "Epoch #18: loss=1.6800483465194702\r\n",
      "Epoch #19: loss=1.8095872402191162\r\n",
      "Epoch #20: loss=1.7062640190124512\r\n",
      "Epoch #21: loss=1.751886248588562\r\n",
      "Epoch #22: loss=1.6161904335021973\r\n",
      "Epoch #23: loss=1.723557472229004\r\n",
      "Epoch #24: loss=1.7485469579696655\r\n",
      "Epoch #25: loss=1.507158875465393\r\n",
      "Epoch #26: loss=1.8127853870391846\r\n",
      "Epoch #27: loss=1.5981855392456055\r\n",
      "Epoch #28: loss=1.6318044662475586\r\n",
      "Epoch #29: loss=1.5392087697982788\r\n",
      "Epoch #30: loss=1.4787622690200806\r\n",
      "Epoch #31: loss=1.538927435874939\r\n",
      "Epoch #32: loss=1.4717400074005127\r\n",
      "Epoch #33: loss=1.5960348844528198\r\n",
      "Epoch #34: loss=1.3664630651474\r\n",
      "Epoch #35: loss=1.4025341272354126\r\n",
      "Epoch #36: loss=1.3301920890808105\r\n",
      "Epoch #37: loss=1.530442476272583\r\n",
      "Epoch #38: loss=1.5042684078216553\r\n",
      "Epoch #39: loss=1.2998310327529907\r\n",
      "Epoch #40: loss=1.3265353441238403\r\n",
      "Epoch #41: loss=1.3504267930984497\r\n",
      "Epoch #42: loss=1.2744536399841309\r\n",
      "Epoch #43: loss=1.3047021627426147\r\n",
      "Epoch #44: loss=1.3856651782989502\r\n",
      "Epoch #45: loss=1.2377114295959473\r\n",
      "Epoch #46: loss=1.3763352632522583\r\n",
      "Epoch #47: loss=1.3543471097946167\r\n",
      "Epoch #48: loss=1.103262186050415\r\n",
      "Epoch #49: loss=1.162811517715454\r\n",
      "Epoch #50: loss=1.1612645387649536\r\n",
      "Epoch #51: loss=1.2467104196548462\r\n",
      "Epoch #52: loss=1.3369903564453125\r\n",
      "Epoch #53: loss=1.2147916555404663\r\n",
      "Epoch #54: loss=1.1727042198181152\r\n",
      "Epoch #55: loss=2.5275321006774902\r\n",
      "Epoch #56: loss=1.6668903827667236\r\n",
      "Epoch #57: loss=1.0764355659484863\r\n",
      "Epoch #58: loss=1.1152777671813965\r\n",
      "Epoch #59: loss=1.158604621887207\r\n",
      "Epoch #60: loss=1.3538706302642822\r\n",
      "Epoch #61: loss=1.36335027217865\r\n",
      "Epoch #62: loss=1.1755011081695557\r\n",
      "Epoch #63: loss=1.105128288269043\r\n",
      "Epoch #64: loss=1.1208107471466064\r\n",
      "Epoch #65: loss=1.182731032371521\r\n",
      "Epoch #66: loss=1.1285237073898315\r\n",
      "Epoch #67: loss=1.0658828020095825\r\n",
      "Epoch #68: loss=1.1442232131958008\r\n",
      "Epoch #69: loss=1.0478260517120361\r\n",
      "Epoch #70: loss=1.035631775856018\r\n",
      "Epoch #71: loss=1.1473698616027832\r\n",
      "Epoch #72: loss=1.2339239120483398\r\n",
      "Epoch #73: loss=1.3536229133605957\r\n",
      "Epoch #74: loss=1.0350532531738281\r\n",
      "Epoch #75: loss=1.2624930143356323\r\n",
      "Epoch #76: loss=1.518608808517456\r\n",
      "Epoch #77: loss=1.1214430332183838\r\n",
      "Epoch #78: loss=1.097416877746582\r\n",
      "Epoch #79: loss=1.2189279794692993\r\n",
      "Epoch #80: loss=1.1476898193359375\r\n",
      "Epoch #81: loss=1.1600024700164795\r\n",
      "Epoch #82: loss=1.1721900701522827\r\n",
      "Epoch #83: loss=1.051961898803711\r\n",
      "Epoch #84: loss=1.0113699436187744\r\n",
      "Epoch #85: loss=1.0327110290527344\r\n",
      "Epoch #86: loss=1.0102934837341309\r\n",
      "Epoch #87: loss=0.9294424057006836\r\n",
      "Epoch #88: loss=0.9891841411590576\r\n",
      "Epoch #89: loss=0.91487056016922\r\n",
      "Epoch #90: loss=0.8612837791442871\r\n",
      "Epoch #91: loss=0.9967252612113953\r\n",
      "Epoch #92: loss=1.093888282775879\r\n",
      "Epoch #93: loss=1.255548119544983\r\n",
      "Epoch #94: loss=0.9862101078033447\r\n",
      "Epoch #95: loss=0.7818266749382019\r\n",
      "Epoch #96: loss=0.7960983514785767\r\n",
      "Epoch #97: loss=0.9060983657836914\r\n",
      "Epoch #98: loss=0.7822534441947937\r\n",
      "Epoch #99: loss=0.7435593605041504\r\n",
      "Epoch #100: loss=0.7705163359642029\r\n",
      "Epoch #101: loss=0.9043766856193542\r\n",
      "Epoch #102: loss=0.7311185598373413\r\n",
      "Epoch #103: loss=0.7131430506706238\r\n",
      "Epoch #104: loss=0.8331876993179321\r\n",
      "Epoch #105: loss=1.9450604915618896\r\n",
      "Epoch #106: loss=0.7498248219490051\r\n",
      "Epoch #107: loss=0.7458614110946655\r\n",
      "Epoch #108: loss=0.7197233438491821\r\n",
      "Epoch #109: loss=0.8021870851516724\r\n",
      "Epoch #110: loss=0.7366317510604858\r\n",
      "Epoch #111: loss=1.3884387016296387\r\n",
      "Epoch #112: loss=1.1048475503921509\r\n",
      "Epoch #113: loss=1.1974440813064575\r\n",
      "Epoch #114: loss=0.8917628526687622\r\n",
      "Epoch #115: loss=0.679714560508728\r\n",
      "Epoch #116: loss=0.8239837288856506\r\n",
      "Epoch #117: loss=0.7939155101776123\r\n",
      "Epoch #118: loss=0.8560433387756348\r\n",
      "Epoch #119: loss=0.7780398726463318\r\n",
      "Epoch #120: loss=0.6771042346954346\r\n",
      "Epoch #121: loss=0.6295032501220703\r\n",
      "Epoch #122: loss=0.722186267375946\r\n",
      "Epoch #123: loss=0.8402996063232422\r\n",
      "Epoch #124: loss=0.970616340637207\r\n",
      "Epoch #125: loss=0.7588574290275574\r\n",
      "Epoch #126: loss=0.5913207530975342\r\n",
      "Epoch #127: loss=0.8683140873908997\r\n",
      "Epoch #128: loss=0.69414883852005\r\n",
      "Epoch #129: loss=0.6440525054931641\r\n",
      "Epoch #130: loss=0.9276916980743408\r\n",
      "Epoch #131: loss=0.8848474025726318\r\n",
      "Epoch #132: loss=0.8197230696678162\r\n",
      "Epoch #133: loss=0.6519560813903809\r\n",
      "Epoch #134: loss=0.5715867280960083\r\n",
      "Epoch #135: loss=0.5825647711753845\r\n",
      "Epoch #136: loss=0.7369068264961243\r\n",
      "Epoch #137: loss=0.5684043169021606\r\n",
      "Epoch #138: loss=0.7016589045524597\r\n",
      "Epoch #139: loss=0.6895924210548401\r\n",
      "Epoch #140: loss=0.6003323793411255\r\n",
      "Epoch #141: loss=0.5833536386489868\r\n",
      "Epoch #142: loss=0.5305374264717102\r\n",
      "Epoch #143: loss=0.9175811409950256\r\n",
      "Epoch #144: loss=0.6867461800575256\r\n",
      "Epoch #145: loss=0.5158116817474365\r\n",
      "Epoch #146: loss=0.589310884475708\r\n",
      "Epoch #147: loss=0.5061761736869812\r\n",
      "Epoch #148: loss=0.49610239267349243\r\n",
      "Epoch #149: loss=0.5001034736633301\r\n",
      "Epoch #150: loss=0.7046605944633484\r\n",
      "Epoch #151: loss=0.7317298650741577\r\n",
      "Epoch #152: loss=0.48559868335723877\r\n",
      "Epoch #153: loss=0.5803432464599609\r\n",
      "Epoch #154: loss=0.6387757062911987\r\n",
      "Epoch #155: loss=0.4832567572593689\r\n",
      "Epoch #156: loss=0.7551456093788147\r\n",
      "Epoch #157: loss=0.5312332510948181\r\n",
      "Epoch #158: loss=0.662055492401123\r\n",
      "Epoch #159: loss=0.5333195924758911\r\n",
      "Epoch #160: loss=0.6175155639648438\r\n",
      "Epoch #161: loss=0.894049882888794\r\n",
      "Epoch #162: loss=0.5543579459190369\r\n",
      "Epoch #163: loss=0.7452907562255859\r\n",
      "Epoch #164: loss=0.7046964764595032\r\n",
      "Epoch #165: loss=0.5094678401947021\r\n",
      "Epoch #166: loss=0.6022805571556091\r\n",
      "Epoch #167: loss=0.4460432529449463\r\n",
      "Epoch #168: loss=0.5428965091705322\r\n",
      "Epoch #169: loss=0.46479901671409607\r\n",
      "Epoch #170: loss=0.45233315229415894\r\n",
      "Epoch #171: loss=0.462033212184906\r\n",
      "Epoch #172: loss=0.5797067284584045\r\n",
      "Epoch #173: loss=0.4195109009742737\r\n",
      "Epoch #174: loss=0.4844224750995636\r\n",
      "Epoch #175: loss=0.46391332149505615\r\n",
      "Epoch #176: loss=0.4288061857223511\r\n",
      "Epoch #177: loss=0.5995349884033203\r\n",
      "Epoch #178: loss=0.40425705909729004\r\n",
      "Epoch #179: loss=0.4755423963069916\r\n",
      "Epoch #180: loss=0.4684484302997589\r\n",
      "Epoch #181: loss=0.37094491720199585\r\n",
      "Epoch #182: loss=0.3910989463329315\r\n",
      "Epoch #183: loss=0.8146073222160339\r\n",
      "Epoch #184: loss=0.37714070081710815\r\n",
      "Epoch #185: loss=0.5371675491333008\r\n",
      "Epoch #186: loss=0.429210364818573\r\n",
      "Epoch #187: loss=0.5593264102935791\r\n",
      "Epoch #188: loss=0.37618058919906616\r\n",
      "Epoch #189: loss=0.5605601668357849\r\n",
      "Epoch #190: loss=0.4933604896068573\r\n",
      "Epoch #191: loss=0.40732070803642273\r\n",
      "Epoch #192: loss=0.5180932879447937\r\n",
      "Epoch #193: loss=1.928749918937683\r\n",
      "Epoch #194: loss=0.43772339820861816\r\n",
      "Epoch #195: loss=0.45597290992736816\r\n",
      "Epoch #196: loss=0.5065770745277405\r\n",
      "Epoch #197: loss=0.5929164290428162\r\n",
      "Epoch #198: loss=0.6619372963905334\r\n",
      "Epoch #199: loss=0.4090301990509033\r\n",
      "Epoch #200: loss=0.6630036234855652\r\n",
      "Epoch #201: loss=0.45687198638916016\r\n",
      "Epoch #202: loss=0.45766481757164\r\n",
      "Epoch #203: loss=0.6123859286308289\r\n",
      "Epoch #204: loss=0.4725078046321869\r\n",
      "Epoch #205: loss=0.6355684399604797\r\n",
      "Epoch #206: loss=1.7269306182861328\r\n",
      "Epoch #207: loss=0.48687732219696045\r\n",
      "Epoch #208: loss=0.4447173476219177\r\n",
      "Epoch #209: loss=0.5079367756843567\r\n",
      "Epoch #210: loss=0.4844597280025482\r\n",
      "Epoch #211: loss=0.6980276107788086\r\n",
      "Epoch #212: loss=0.444564551115036\r\n",
      "Epoch #213: loss=0.5194866061210632\r\n",
      "Epoch #214: loss=0.42658716440200806\r\n",
      "Epoch #215: loss=0.5530107021331787\r\n",
      "Epoch #216: loss=0.4479765295982361\r\n",
      "Epoch #217: loss=0.5171511769294739\r\n",
      "Epoch #218: loss=0.4677836298942566\r\n",
      "Epoch #219: loss=0.49501970410346985\r\n",
      "Epoch #220: loss=0.39649516344070435\r\n",
      "Epoch #221: loss=0.3988940119743347\r\n",
      "Epoch #222: loss=0.40431830286979675\r\n",
      "Epoch #223: loss=0.4213114380836487\r\n",
      "Epoch #224: loss=0.49867677688598633\r\n",
      "Epoch #225: loss=0.782455563545227\r\n",
      "Epoch #226: loss=0.7186112999916077\r\n",
      "Epoch #227: loss=0.4627480208873749\r\n",
      "Epoch #228: loss=0.5842600464820862\r\n",
      "Epoch #229: loss=0.49072933197021484\r\n",
      "Epoch #230: loss=0.4420681595802307\r\n",
      "Epoch #231: loss=0.47407272458076477\r\n",
      "Epoch #232: loss=0.36864206194877625\r\n",
      "Epoch #233: loss=0.4282377362251282\r\n",
      "Epoch #234: loss=0.5508913993835449\r\n",
      "Epoch #235: loss=0.42615413665771484\r\n",
      "Epoch #236: loss=0.38010260462760925\r\n",
      "Epoch #237: loss=0.4833777844905853\r\n",
      "Epoch #238: loss=0.4593251049518585\r\n",
      "Epoch #239: loss=0.4885779917240143\r\n",
      "Epoch #240: loss=0.46495601534843445\r\n",
      "Epoch #241: loss=0.3956650495529175\r\n",
      "Epoch #242: loss=0.528261125087738\r\n",
      "Epoch #243: loss=0.578450620174408\r\n",
      "Epoch #244: loss=0.3589779734611511\r\n",
      "Epoch #245: loss=0.3725334703922272\r\n",
      "Epoch #246: loss=0.3710169494152069\r\n",
      "Epoch #247: loss=0.3039560914039612\r\n",
      "Epoch #248: loss=0.31848838925361633\r\n",
      "Epoch #249: loss=0.38948315382003784\r\n",
      "Epoch #250: loss=1.2690479755401611\r\n",
      "Epoch #251: loss=0.28473004698753357\r\n",
      "Epoch #252: loss=0.708122730255127\r\n",
      "Epoch #253: loss=0.3153156340122223\r\n",
      "Epoch #254: loss=0.4239092767238617\r\n",
      "Epoch #255: loss=0.4339819550514221\r\n",
      "Epoch #256: loss=0.5642362833023071\r\n",
      "Epoch #257: loss=0.45401477813720703\r\n",
      "Epoch #258: loss=0.5568625330924988\r\n",
      "Epoch #259: loss=0.36819979548454285\r\n",
      "Epoch #260: loss=0.41080471873283386\r\n",
      "Epoch #261: loss=0.46374496817588806\r\n",
      "Epoch #262: loss=0.33275556564331055\r\n",
      "Epoch #263: loss=0.3825279176235199\r\n",
      "Epoch #264: loss=0.3270556330680847\r\n",
      "Epoch #265: loss=0.3931221663951874\r\n",
      "Epoch #266: loss=0.5022794008255005\r\n",
      "Epoch #267: loss=0.36088094115257263\r\n",
      "Epoch #268: loss=0.3265259861946106\r\n",
      "Epoch #269: loss=0.3270212411880493\r\n",
      "Epoch #270: loss=0.35482457280158997\r\n",
      "Epoch #271: loss=0.31610798835754395\r\n",
      "Epoch #272: loss=0.5175422430038452\r\n",
      "Epoch #273: loss=0.38246965408325195\r\n",
      "Epoch #274: loss=0.3303366005420685\r\n",
      "Epoch #275: loss=0.30876970291137695\r\n",
      "Epoch #276: loss=0.31637829542160034\r\n",
      "Epoch #277: loss=0.3234783709049225\r\n",
      "Epoch #278: loss=0.4419863820075989\r\n",
      "Epoch #279: loss=0.7665386199951172\r\n",
      "Epoch #280: loss=0.4343062937259674\r\n",
      "Epoch #281: loss=0.3749198913574219\r\n",
      "Epoch #282: loss=0.2748091220855713\r\n",
      "Epoch #283: loss=0.8138327598571777\r\n",
      "Epoch #284: loss=0.2735394239425659\r\n",
      "Epoch #285: loss=0.3355577886104584\r\n",
      "Epoch #286: loss=0.33543068170547485\r\n",
      "Epoch #287: loss=0.30101048946380615\r\n",
      "Epoch #288: loss=0.32187581062316895\r\n",
      "Epoch #289: loss=0.43852829933166504\r\n",
      "Epoch #290: loss=0.5129513144493103\r\n",
      "Epoch #291: loss=0.5330720543861389\r\n",
      "Epoch #292: loss=0.38222089409828186\r\n",
      "Epoch #293: loss=0.3436196744441986\r\n",
      "Epoch #294: loss=0.3888894021511078\r\n",
      "Epoch #295: loss=0.3810672461986542\r\n",
      "Epoch #296: loss=0.40414801239967346\r\n",
      "Epoch #297: loss=0.3545709550380707\r\n",
      "Epoch #298: loss=0.36770734190940857\r\n",
      "Epoch #299: loss=0.2363658845424652\r\n",
      "Epoch #300: loss=0.8540409803390503\r\n",
      "Epoch #301: loss=0.28754258155822754\r\n",
      "Epoch #302: loss=0.39916810393333435\r\n",
      "Epoch #303: loss=0.3812027871608734\r\n",
      "Epoch #304: loss=0.32261690497398376\r\n",
      "Epoch #305: loss=0.38870781660079956\r\n",
      "Epoch #306: loss=0.32080650329589844\r\n",
      "Epoch #307: loss=0.4151953458786011\r\n",
      "Epoch #308: loss=0.36310771107673645\r\n",
      "Epoch #309: loss=0.49849966168403625\r\n",
      "Epoch #310: loss=0.3601089119911194\r\n",
      "Epoch #311: loss=0.3458225429058075\r\n",
      "Epoch #312: loss=0.36727413535118103\r\n",
      "Epoch #313: loss=0.4804583787918091\r\n",
      "Epoch #314: loss=0.27794149518013\r\n",
      "Epoch #315: loss=0.32264986634254456\r\n",
      "Epoch #316: loss=0.2614503502845764\r\n",
      "Epoch #317: loss=0.45733919739723206\r\n",
      "Epoch #318: loss=0.32020625472068787\r\n",
      "Epoch #319: loss=0.31581223011016846\r\n",
      "Epoch #320: loss=0.23194901645183563\r\n",
      "Epoch #321: loss=0.2867220640182495\r\n",
      "Epoch #322: loss=0.24793049693107605\r\n",
      "Epoch #323: loss=0.34746503829956055\r\n",
      "Epoch #324: loss=0.24230417609214783\r\n",
      "Epoch #325: loss=0.37345778942108154\r\n",
      "Epoch #326: loss=0.4660922586917877\r\n",
      "Epoch #327: loss=0.517653226852417\r\n",
      "Epoch #328: loss=0.2942843735218048\r\n",
      "Epoch #329: loss=0.2949966490268707\r\n",
      "Epoch #330: loss=0.25792455673217773\r\n",
      "Epoch #331: loss=0.2585224211215973\r\n",
      "Epoch #332: loss=0.6312867403030396\r\n",
      "Epoch #333: loss=0.2343892902135849\r\n",
      "Epoch #334: loss=0.22650966048240662\r\n",
      "Epoch #335: loss=0.2868572771549225\r\n",
      "Epoch #336: loss=0.2336311638355255\r\n",
      "Epoch #337: loss=0.32225319743156433\r\n",
      "Epoch #338: loss=0.3105837404727936\r\n",
      "Epoch #339: loss=0.5537315607070923\r\n",
      "Epoch #340: loss=0.2863657772541046\r\n",
      "Epoch #341: loss=0.2757207155227661\r\n",
      "Epoch #342: loss=0.29546114802360535\r\n",
      "Epoch #343: loss=0.32241883873939514\r\n",
      "Epoch #344: loss=0.2146623134613037\r\n",
      "Epoch #345: loss=0.925217866897583\r\n",
      "Epoch #346: loss=0.21617144346237183\r\n",
      "Epoch #347: loss=0.3434924781322479\r\n",
      "Epoch #348: loss=0.2662521004676819\r\n",
      "Epoch #349: loss=0.32294049859046936\r\n",
      "Epoch #350: loss=0.46240168809890747\r\n",
      "Epoch #351: loss=0.22934985160827637\r\n",
      "Epoch #352: loss=0.25107863545417786\r\n",
      "Epoch #353: loss=0.3490262031555176\r\n",
      "Epoch #354: loss=0.21672140061855316\r\n",
      "Epoch #355: loss=0.22853349149227142\r\n",
      "Epoch #356: loss=0.22243010997772217\r\n",
      "Epoch #357: loss=0.21556036174297333\r\n",
      "Epoch #358: loss=0.2961878776550293\r\n",
      "Epoch #359: loss=0.20449917018413544\r\n",
      "Epoch #360: loss=0.34540560841560364\r\n",
      "Epoch #361: loss=0.24573010206222534\r\n",
      "Epoch #362: loss=0.2662717401981354\r\n",
      "Epoch #363: loss=0.31459149718284607\r\n",
      "Epoch #364: loss=0.21658672392368317\r\n",
      "Epoch #365: loss=0.27415913343429565\r\n",
      "Epoch #366: loss=0.2231941670179367\r\n",
      "Epoch #367: loss=0.20545469224452972\r\n",
      "Epoch #368: loss=0.2502543032169342\r\n",
      "Epoch #369: loss=0.22058096528053284\r\n",
      "Epoch #370: loss=0.21770048141479492\r\n",
      "Epoch #371: loss=0.2057286500930786\r\n",
      "Epoch #372: loss=0.5345236659049988\r\n",
      "Epoch #373: loss=0.25176316499710083\r\n",
      "Epoch #374: loss=0.29044583439826965\r\n",
      "Epoch #375: loss=0.24339815974235535\r\n",
      "Epoch #376: loss=0.1814986914396286\r\n",
      "Epoch #377: loss=0.21794527769088745\r\n",
      "Epoch #378: loss=0.1819777488708496\r\n",
      "Epoch #379: loss=0.2850571572780609\r\n",
      "Epoch #380: loss=0.22756585478782654\r\n",
      "Epoch #381: loss=1.4978502988815308\r\n",
      "Epoch #382: loss=0.26029014587402344\r\n",
      "Epoch #383: loss=0.23586300015449524\r\n",
      "Epoch #384: loss=0.2681126594543457\r\n",
      "Epoch #385: loss=0.22052258253097534\r\n",
      "Epoch #386: loss=0.23950521647930145\r\n",
      "Epoch #387: loss=0.2708795666694641\r\n",
      "Epoch #388: loss=0.27215149998664856\r\n",
      "Epoch #389: loss=0.2264283150434494\r\n",
      "Epoch #390: loss=0.2799995541572571\r\n",
      "Epoch #391: loss=0.20823079347610474\r\n",
      "Epoch #392: loss=0.199128195643425\r\n",
      "Epoch #393: loss=0.20787589251995087\r\n",
      "Epoch #394: loss=0.19153015315532684\r\n",
      "Epoch #395: loss=0.17968514561653137\r\n",
      "Epoch #396: loss=0.2584587633609772\r\n",
      "Epoch #397: loss=0.18801665306091309\r\n",
      "Epoch #398: loss=0.28558656573295593\r\n",
      "Epoch #399: loss=0.18145790696144104\r\n",
      "Epoch #400: loss=0.24633345007896423\r\n",
      "Epoch #401: loss=0.21319201588630676\r\n",
      "Epoch #402: loss=0.16244445741176605\r\n",
      "Epoch #403: loss=0.2507004737854004\r\n",
      "Epoch #404: loss=0.18311086297035217\r\n",
      "Epoch #405: loss=0.18425945937633514\r\n",
      "Epoch #406: loss=0.41836389899253845\r\n",
      "Epoch #407: loss=0.2322661131620407\r\n",
      "Epoch #408: loss=0.16729947924613953\r\n",
      "Epoch #409: loss=0.19480612874031067\r\n",
      "Epoch #410: loss=0.2454919070005417\r\n",
      "Epoch #411: loss=0.2064160257577896\r\n",
      "Epoch #412: loss=0.1614651083946228\r\n",
      "Epoch #413: loss=0.2877250015735626\r\n",
      "Epoch #414: loss=0.21898482739925385\r\n",
      "Epoch #415: loss=0.20810696482658386\r\n",
      "Epoch #416: loss=0.1460026651620865\r\n",
      "Epoch #417: loss=0.1884487122297287\r\n",
      "Epoch #418: loss=0.20905235409736633\r\n",
      "Epoch #419: loss=0.3079906404018402\r\n",
      "Epoch #420: loss=0.1924142688512802\r\n",
      "Epoch #421: loss=0.181218221783638\r\n",
      "Epoch #422: loss=1.429619312286377\r\n",
      "Epoch #423: loss=0.1980411261320114\r\n",
      "Epoch #424: loss=0.175667405128479\r\n",
      "Epoch #425: loss=0.24688701331615448\r\n",
      "Epoch #426: loss=0.18973779678344727\r\n",
      "Epoch #427: loss=0.1802903413772583\r\n",
      "Epoch #428: loss=0.6206488609313965\r\n",
      "Epoch #429: loss=0.282230943441391\r\n",
      "Epoch #430: loss=1.0694453716278076\r\n",
      "Epoch #431: loss=0.1756766438484192\r\n",
      "Epoch #432: loss=0.23387500643730164\r\n",
      "Epoch #433: loss=0.2587526738643646\r\n",
      "Epoch #434: loss=0.36418119072914124\r\n",
      "Epoch #435: loss=0.3394503891468048\r\n",
      "Epoch #436: loss=0.2538255751132965\r\n",
      "Epoch #437: loss=0.2697563171386719\r\n",
      "Epoch #438: loss=0.40548303723335266\r\n",
      "Epoch #439: loss=0.28110504150390625\r\n",
      "Epoch #440: loss=0.35112857818603516\r\n",
      "Epoch #441: loss=0.25158777832984924\r\n",
      "Epoch #442: loss=0.3317093849182129\r\n",
      "Epoch #443: loss=0.23037788271903992\r\n",
      "Epoch #444: loss=0.33927786350250244\r\n",
      "Epoch #445: loss=0.21152351796627045\r\n",
      "Epoch #446: loss=0.3802932798862457\r\n",
      "Epoch #447: loss=0.23907244205474854\r\n",
      "Epoch #448: loss=0.4055226147174835\r\n",
      "Epoch #449: loss=0.3036673069000244\r\n",
      "Epoch #450: loss=0.21891097724437714\r\n",
      "Epoch #451: loss=0.24763348698616028\r\n",
      "Epoch #452: loss=0.21039094030857086\r\n",
      "Epoch #453: loss=0.3131876289844513\r\n",
      "Epoch #454: loss=0.23696927726268768\r\n",
      "Epoch #455: loss=0.23213332891464233\r\n",
      "Epoch #456: loss=0.5654317736625671\r\n",
      "Epoch #457: loss=0.5112428665161133\r\n",
      "Epoch #458: loss=0.24806153774261475\r\n",
      "Epoch #459: loss=0.3622569739818573\r\n",
      "Epoch #460: loss=0.29361456632614136\r\n",
      "Epoch #461: loss=0.3087056577205658\r\n",
      "Epoch #462: loss=0.7971637845039368\r\n",
      "Epoch #463: loss=0.3243819773197174\r\n",
      "Epoch #464: loss=0.3623301684856415\r\n",
      "Epoch #465: loss=0.37753361463546753\r\n",
      "Epoch #466: loss=0.7068914175033569\r\n",
      "Epoch #467: loss=0.30450108647346497\r\n",
      "Epoch #468: loss=0.43965333700180054\r\n",
      "Epoch #469: loss=1.6059138774871826\r\n",
      "Epoch #470: loss=0.4482528269290924\r\n",
      "Epoch #471: loss=0.3384982645511627\r\n",
      "Epoch #472: loss=0.4042702317237854\r\n",
      "Epoch #473: loss=0.32677730917930603\r\n",
      "Epoch #474: loss=0.4263021945953369\r\n",
      "Epoch #475: loss=0.42689529061317444\r\n",
      "Epoch #476: loss=0.49163928627967834\r\n",
      "Epoch #477: loss=0.5568116307258606\r\n",
      "Epoch #478: loss=0.48420560359954834\r\n",
      "Epoch #479: loss=0.4615074098110199\r\n",
      "Epoch #480: loss=0.32951265573501587\r\n",
      "Epoch #481: loss=0.6357806324958801\r\n",
      "Epoch #482: loss=0.36216357350349426\r\n",
      "Epoch #483: loss=0.3104080557823181\r\n",
      "Epoch #484: loss=0.45999425649642944\r\n",
      "Epoch #485: loss=0.3019007742404938\r\n",
      "Epoch #486: loss=0.3636421859264374\r\n",
      "Epoch #487: loss=0.2936980426311493\r\n",
      "Epoch #488: loss=2.228135108947754\r\n",
      "Epoch #489: loss=0.45471975207328796\r\n",
      "Epoch #490: loss=0.27445125579833984\r\n",
      "Epoch #491: loss=0.3432566523551941\r\n",
      "Epoch #492: loss=0.3954092860221863\r\n",
      "Epoch #493: loss=0.35144945979118347\r\n",
      "Epoch #494: loss=0.32369551062583923\r\n",
      "Epoch #495: loss=0.3483124375343323\r\n",
      "Epoch #496: loss=0.40003713965415955\r\n",
      "Epoch #497: loss=0.361224502325058\r\n",
      "Epoch #498: loss=0.36925503611564636\r\n",
      "Epoch #499: loss=0.28036463260650635\r\n",
      "Epoch #500: loss=0.4292478561401367\r\n",
      "Epoch #501: loss=0.6182072758674622\r\n",
      "Epoch #502: loss=0.33843716979026794\r\n",
      "Epoch #503: loss=0.32120630145072937\r\n",
      "Epoch #504: loss=0.28039073944091797\r\n",
      "Epoch #505: loss=0.28360629081726074\r\n",
      "Epoch #506: loss=0.3146730661392212\r\n",
      "Epoch #507: loss=0.2295909821987152\r\n",
      "Epoch #508: loss=0.3626492917537689\r\n",
      "Epoch #509: loss=0.24335893988609314\r\n",
      "Epoch #510: loss=0.2886177897453308\r\n",
      "Epoch #511: loss=0.5067418813705444\r\n",
      "Epoch #512: loss=0.23044955730438232\r\n",
      "Epoch #513: loss=0.3922286331653595\r\n",
      "Epoch #514: loss=0.3428860306739807\r\n",
      "Epoch #515: loss=0.2735530436038971\r\n",
      "Epoch #516: loss=0.2451476752758026\r\n",
      "Epoch #517: loss=0.2687738537788391\r\n",
      "Epoch #518: loss=0.4645841419696808\r\n",
      "Epoch #519: loss=0.20001152157783508\r\n",
      "Epoch #520: loss=0.3336714804172516\r\n",
      "Epoch #521: loss=0.18905401229858398\r\n",
      "Epoch #522: loss=0.2562682330608368\r\n",
      "Epoch #523: loss=0.24663256108760834\r\n",
      "Epoch #524: loss=0.2056681364774704\r\n",
      "Epoch #525: loss=0.20812594890594482\r\n",
      "Epoch #526: loss=0.18360958993434906\r\n",
      "Epoch #527: loss=0.20304852724075317\r\n",
      "Epoch #528: loss=0.18348777294158936\r\n",
      "Epoch #529: loss=0.27469825744628906\r\n",
      "Epoch #530: loss=0.20205186307430267\r\n",
      "Epoch #531: loss=0.2537468671798706\r\n",
      "Epoch #532: loss=0.22834858298301697\r\n",
      "Epoch #533: loss=0.5254083871841431\r\n",
      "Epoch #534: loss=0.32124271988868713\r\n",
      "Epoch #535: loss=0.18738619983196259\r\n",
      "Epoch #536: loss=0.39618873596191406\r\n",
      "Epoch #537: loss=0.26647526025772095\r\n",
      "Epoch #538: loss=0.5878680348396301\r\n",
      "Epoch #539: loss=0.21509869396686554\r\n",
      "Epoch #540: loss=0.20344595611095428\r\n",
      "Epoch #541: loss=0.29990154504776\r\n",
      "Epoch #542: loss=0.20070241391658783\r\n",
      "Epoch #543: loss=0.38257551193237305\r\n",
      "Epoch #544: loss=0.20248731970787048\r\n",
      "Epoch #545: loss=0.18884891271591187\r\n",
      "Epoch #546: loss=0.20606517791748047\r\n",
      "Epoch #547: loss=0.1764414757490158\r\n",
      "Epoch #548: loss=0.18490709364414215\r\n",
      "Epoch #549: loss=0.3140851557254791\r\n",
      "Epoch #550: loss=0.27029314637184143\r\n",
      "Epoch #551: loss=0.17265234887599945\r\n",
      "Epoch #552: loss=0.24620632827281952\r\n",
      "Epoch #553: loss=0.35076066851615906\r\n",
      "Epoch #554: loss=0.46060073375701904\r\n",
      "Epoch #555: loss=0.20191235840320587\r\n",
      "Epoch #556: loss=0.4823254644870758\r\n",
      "Epoch #557: loss=0.24249762296676636\r\n",
      "Epoch #558: loss=0.3175506889820099\r\n",
      "Epoch #559: loss=0.1892382949590683\r\n",
      "Epoch #560: loss=0.255318284034729\r\n",
      "Epoch #561: loss=0.25807538628578186\r\n",
      "Epoch #562: loss=0.20562170445919037\r\n",
      "Epoch #563: loss=0.18476203083992004\r\n",
      "Epoch #564: loss=0.21543572843074799\r\n",
      "Epoch #565: loss=0.22469747066497803\r\n",
      "Epoch #566: loss=0.2591099441051483\r\n",
      "Epoch #567: loss=0.18823419511318207\r\n",
      "Epoch #568: loss=0.1819768249988556\r\n",
      "Epoch #569: loss=0.17713716626167297\r\n",
      "Epoch #570: loss=0.8817764520645142\r\n",
      "Epoch #571: loss=0.25169098377227783\r\n",
      "Epoch #572: loss=0.18261851370334625\r\n",
      "Epoch #573: loss=0.5389074683189392\r\n",
      "Epoch #574: loss=0.18728041648864746\r\n",
      "Epoch #575: loss=0.2079693078994751\r\n",
      "Epoch #576: loss=0.1763555258512497\r\n",
      "Epoch #577: loss=0.20268043875694275\r\n",
      "Epoch #578: loss=0.48005881905555725\r\n",
      "Epoch #579: loss=0.26281073689460754\r\n",
      "Epoch #580: loss=0.3533638119697571\r\n",
      "Epoch #581: loss=0.7159855961799622\r\n",
      "Epoch #582: loss=0.205971822142601\r\n",
      "Epoch #583: loss=0.2644526958465576\r\n",
      "Epoch #584: loss=0.20513740181922913\r\n",
      "Epoch #585: loss=0.2496250867843628\r\n",
      "Epoch #586: loss=0.26517653465270996\r\n",
      "Epoch #587: loss=0.18854878842830658\r\n",
      "Epoch #588: loss=0.1773127317428589\r\n",
      "Epoch #589: loss=0.19358737766742706\r\n",
      "Epoch #590: loss=0.2047923356294632\r\n",
      "Epoch #591: loss=0.25833457708358765\r\n",
      "Epoch #592: loss=0.16665801405906677\r\n",
      "Epoch #593: loss=0.18189959228038788\r\n",
      "Epoch #594: loss=0.18150481581687927\r\n",
      "Epoch #595: loss=0.30524763464927673\r\n",
      "Epoch #596: loss=0.18865592777729034\r\n",
      "Epoch #597: loss=0.7301735281944275\r\n",
      "Epoch #598: loss=0.20244264602661133\r\n",
      "Epoch #599: loss=0.23160743713378906\r\n",
      "\r\n",
      "Training time: 0:01:03.816687\r\n",
      "\r\n",
      "Evaluation result: {'ours': {24: {'norm': {'MSE': 0.5319905505137765, 'MAE': 0.5059309146506731}, 'raw': {'MSE': 10.749638238581968, 'MAE': 1.845519091390384}}, 48: {'norm': {'MSE': 0.5849573175401231, 'MAE': 0.5390904587552491}, 'raw': {'MSE': 12.672181621907328, 'MAE': 2.0347301458924676}}, 168: {'norm': {'MSE': 0.7166993413782624, 'MAE': 0.6180053828672429}, 'raw': {'MSE': 15.599448771913776, 'MAE': 2.350057993196028}}, 336: {'norm': {'MSE': 0.8511229744067479, 'MAE': 0.6899013486259857}, 'raw': {'MSE': 15.613183088698822, 'MAE': 2.440419266404687}}, 720: {'norm': {'MSE': 1.026238130826349, 'MAE': 0.7829500637348085}, 'raw': {'MSE': 16.478516907861106, 'MAE': 2.6471750010107686}}}, 'ts2vec_infer_time': 2.507737874984741, 'lr_train_time': {24: 2.5796139240264893, 48: 3.4819929599761963, 168: 5.775837659835815, 336: 9.649697065353394, 720: 16.86620259284973}, 'lr_infer_time': {24: 0.11516308784484863, 48: 0.1945347785949707, 168: 0.5462429523468018, 336: 1.2312932014465332, 720: 2.1145284175872803}}\r\n",
      "Finished.\r\n"
     ]
    }
   ],
   "source": [
    "!python -u train.py ETTh1 forecast_multivar --loader forecast_csv --repr-dims 320 --max-threads 8 --seed 42 --eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd12c628",
   "metadata": {
    "papermill": {
     "duration": 0.08318,
     "end_time": "2025-10-12T03:46:31.562451",
     "exception": false,
     "start_time": "2025-10-12T03:46:31.479271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ETTh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "932ece04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T03:46:31.735819Z",
     "iopub.status.busy": "2025-10-12T03:46:31.735463Z",
     "iopub.status.idle": "2025-10-12T03:48:27.686443Z",
     "shell.execute_reply": "2025-10-12T03:48:27.685621Z"
    },
    "papermill": {
     "duration": 116.042034,
     "end_time": "2025-10-12T03:48:27.687946",
     "exception": false,
     "start_time": "2025-10-12T03:46:31.645912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ETTh2\r\n",
      "Arguments: Namespace(dataset='ETTh2', run_name='forecast_multivar', loader='forecast_csv', gpu=0, batch_size=8, lr=0.001, repr_dims=320, max_train_length=3000, iters=None, epochs=None, save_every=None, seed=42, max_threads=8, eval=True, irregular=0)\r\n",
      "Loading data... done\r\n",
      "Epoch #0: loss=8.270641326904297\r\n",
      "Epoch #1: loss=5.7168803215026855\r\n",
      "Epoch #2: loss=5.300297737121582\r\n",
      "Epoch #3: loss=3.223628282546997\r\n",
      "Epoch #4: loss=3.1893842220306396\r\n",
      "Epoch #5: loss=2.4734084606170654\r\n",
      "Epoch #6: loss=2.986906051635742\r\n",
      "Epoch #7: loss=2.1076571941375732\r\n",
      "Epoch #8: loss=2.651277542114258\r\n",
      "Epoch #9: loss=1.8700937032699585\r\n",
      "Epoch #10: loss=2.1041603088378906\r\n",
      "Epoch #11: loss=2.035515069961548\r\n",
      "Epoch #12: loss=2.170874834060669\r\n",
      "Epoch #13: loss=1.9283792972564697\r\n",
      "Epoch #14: loss=2.060149669647217\r\n",
      "Epoch #15: loss=1.9774307012557983\r\n",
      "Epoch #16: loss=1.952595591545105\r\n",
      "Epoch #17: loss=1.9194130897521973\r\n",
      "Epoch #18: loss=1.9490835666656494\r\n",
      "Epoch #19: loss=1.7569524049758911\r\n",
      "Epoch #20: loss=1.80442214012146\r\n",
      "Epoch #21: loss=1.7531484365463257\r\n",
      "Epoch #22: loss=1.6674869060516357\r\n",
      "Epoch #23: loss=1.803713083267212\r\n",
      "Epoch #24: loss=1.9121371507644653\r\n",
      "Epoch #25: loss=1.7523993253707886\r\n",
      "Epoch #26: loss=1.73622727394104\r\n",
      "Epoch #27: loss=1.6823902130126953\r\n",
      "Epoch #28: loss=1.6966193914413452\r\n",
      "Epoch #29: loss=1.5787798166275024\r\n",
      "Epoch #30: loss=1.5867990255355835\r\n",
      "Epoch #31: loss=1.641905426979065\r\n",
      "Epoch #32: loss=1.5715768337249756\r\n",
      "Epoch #33: loss=1.6127980947494507\r\n",
      "Epoch #34: loss=1.4166511297225952\r\n",
      "Epoch #35: loss=1.5155844688415527\r\n",
      "Epoch #36: loss=1.3755300045013428\r\n",
      "Epoch #37: loss=1.6227964162826538\r\n",
      "Epoch #38: loss=1.6154130697250366\r\n",
      "Epoch #39: loss=1.2670449018478394\r\n",
      "Epoch #40: loss=1.3945196866989136\r\n",
      "Epoch #41: loss=1.3668262958526611\r\n",
      "Epoch #42: loss=1.300197720527649\r\n",
      "Epoch #43: loss=1.3959394693374634\r\n",
      "Epoch #44: loss=1.4296503067016602\r\n",
      "Epoch #45: loss=1.3026231527328491\r\n",
      "Epoch #46: loss=1.5050913095474243\r\n",
      "Epoch #47: loss=1.5039925575256348\r\n",
      "Epoch #48: loss=1.1726075410842896\r\n",
      "Epoch #49: loss=1.2445577383041382\r\n",
      "Epoch #50: loss=1.4131242036819458\r\n",
      "Epoch #51: loss=1.3471616506576538\r\n",
      "Epoch #52: loss=1.347886085510254\r\n",
      "Epoch #53: loss=1.3276948928833008\r\n",
      "Epoch #54: loss=1.298459768295288\r\n",
      "Epoch #55: loss=2.0019874572753906\r\n",
      "Epoch #56: loss=1.5364289283752441\r\n",
      "Epoch #57: loss=1.1779664754867554\r\n",
      "Epoch #58: loss=1.2302199602127075\r\n",
      "Epoch #59: loss=1.2386972904205322\r\n",
      "Epoch #60: loss=1.453140139579773\r\n",
      "Epoch #61: loss=1.3671865463256836\r\n",
      "Epoch #62: loss=1.2178325653076172\r\n",
      "Epoch #63: loss=1.1027791500091553\r\n",
      "Epoch #64: loss=1.13699209690094\r\n",
      "Epoch #65: loss=1.2274889945983887\r\n",
      "Epoch #66: loss=1.181085228919983\r\n",
      "Epoch #67: loss=1.153529405593872\r\n",
      "Epoch #68: loss=1.1671373844146729\r\n",
      "Epoch #69: loss=1.1176351308822632\r\n",
      "Epoch #70: loss=1.0645043849945068\r\n",
      "Epoch #71: loss=1.2667213678359985\r\n",
      "Epoch #72: loss=1.4395270347595215\r\n",
      "Epoch #73: loss=1.1408610343933105\r\n",
      "Epoch #74: loss=1.1388908624649048\r\n",
      "Epoch #75: loss=1.2741081714630127\r\n",
      "Epoch #76: loss=1.4703469276428223\r\n",
      "Epoch #77: loss=1.0265393257141113\r\n",
      "Epoch #78: loss=1.0278739929199219\r\n",
      "Epoch #79: loss=1.1455999612808228\r\n",
      "Epoch #80: loss=1.1522151231765747\r\n",
      "Epoch #81: loss=1.1550053358078003\r\n",
      "Epoch #82: loss=1.110001564025879\r\n",
      "Epoch #83: loss=0.9472503066062927\r\n",
      "Epoch #84: loss=1.0241715908050537\r\n",
      "Epoch #85: loss=0.9500020146369934\r\n",
      "Epoch #86: loss=0.9445800185203552\r\n",
      "Epoch #87: loss=0.8696115016937256\r\n",
      "Epoch #88: loss=0.9925376176834106\r\n",
      "Epoch #89: loss=1.0337361097335815\r\n",
      "Epoch #90: loss=0.8515406847000122\r\n",
      "Epoch #91: loss=1.0058032274246216\r\n",
      "Epoch #92: loss=1.1472586393356323\r\n",
      "Epoch #93: loss=1.4208228588104248\r\n",
      "Epoch #94: loss=1.0754077434539795\r\n",
      "Epoch #95: loss=0.9456549882888794\r\n",
      "Epoch #96: loss=0.885149359703064\r\n",
      "Epoch #97: loss=0.9054749011993408\r\n",
      "Epoch #98: loss=0.782319962978363\r\n",
      "Epoch #99: loss=0.7967200875282288\r\n",
      "Epoch #100: loss=0.8418211936950684\r\n",
      "Epoch #101: loss=0.9332824349403381\r\n",
      "Epoch #102: loss=0.8707590103149414\r\n",
      "Epoch #103: loss=0.7617661952972412\r\n",
      "Epoch #104: loss=0.9407990574836731\r\n",
      "Epoch #105: loss=1.761849284172058\r\n",
      "Epoch #106: loss=0.8252838850021362\r\n",
      "Epoch #107: loss=0.7431111335754395\r\n",
      "Epoch #108: loss=0.7837281227111816\r\n",
      "Epoch #109: loss=0.8588285446166992\r\n",
      "Epoch #110: loss=0.7922134399414062\r\n",
      "Epoch #111: loss=1.468316674232483\r\n",
      "Epoch #112: loss=1.2359994649887085\r\n",
      "Epoch #113: loss=1.0019056797027588\r\n",
      "Epoch #114: loss=1.0079110860824585\r\n",
      "Epoch #115: loss=0.7087504267692566\r\n",
      "Epoch #116: loss=0.8971845507621765\r\n",
      "Epoch #117: loss=0.7720838189125061\r\n",
      "Epoch #118: loss=0.8749588131904602\r\n",
      "Epoch #119: loss=0.8147091865539551\r\n",
      "Epoch #120: loss=0.6644394397735596\r\n",
      "Epoch #121: loss=0.6623028516769409\r\n",
      "Epoch #122: loss=0.6878633499145508\r\n",
      "Epoch #123: loss=0.8483867049217224\r\n",
      "Epoch #124: loss=1.2480682134628296\r\n",
      "Epoch #125: loss=0.782414436340332\r\n",
      "Epoch #126: loss=0.645527184009552\r\n",
      "Epoch #127: loss=1.071606993675232\r\n",
      "Epoch #128: loss=0.7434464693069458\r\n",
      "Epoch #129: loss=0.6896986365318298\r\n",
      "Epoch #130: loss=1.0754140615463257\r\n",
      "Epoch #131: loss=1.026458740234375\r\n",
      "Epoch #132: loss=0.9019094109535217\r\n",
      "Epoch #133: loss=0.8273069262504578\r\n",
      "Epoch #134: loss=0.7723441123962402\r\n",
      "Epoch #135: loss=0.9183254241943359\r\n",
      "Epoch #136: loss=0.8875114321708679\r\n",
      "Epoch #137: loss=0.8335723876953125\r\n",
      "Epoch #138: loss=0.8141158223152161\r\n",
      "Epoch #139: loss=0.7873753309249878\r\n",
      "Epoch #140: loss=0.7396053075790405\r\n",
      "Epoch #141: loss=0.7884173393249512\r\n",
      "Epoch #142: loss=0.6034811735153198\r\n",
      "Epoch #143: loss=1.1142452955245972\r\n",
      "Epoch #144: loss=0.8646420836448669\r\n",
      "Epoch #145: loss=0.6293693780899048\r\n",
      "Epoch #146: loss=0.6797330975532532\r\n",
      "Epoch #147: loss=0.607191801071167\r\n",
      "Epoch #148: loss=0.5796669721603394\r\n",
      "Epoch #149: loss=0.5535598993301392\r\n",
      "Epoch #150: loss=0.8451627492904663\r\n",
      "Epoch #151: loss=0.8553037643432617\r\n",
      "Epoch #152: loss=0.6128095984458923\r\n",
      "Epoch #153: loss=0.6012579202651978\r\n",
      "Epoch #154: loss=0.7595362067222595\r\n",
      "Epoch #155: loss=0.5814858675003052\r\n",
      "Epoch #156: loss=0.8867079019546509\r\n",
      "Epoch #157: loss=0.5916356444358826\r\n",
      "Epoch #158: loss=0.7907897233963013\r\n",
      "Epoch #159: loss=0.602403461933136\r\n",
      "Epoch #160: loss=0.7632719874382019\r\n",
      "Epoch #161: loss=0.9225438237190247\r\n",
      "Epoch #162: loss=0.6103094220161438\r\n",
      "Epoch #163: loss=0.7925017476081848\r\n",
      "Epoch #164: loss=0.7700495719909668\r\n",
      "Epoch #165: loss=0.5905703902244568\r\n",
      "Epoch #166: loss=0.7028166055679321\r\n",
      "Epoch #167: loss=0.5118013024330139\r\n",
      "Epoch #168: loss=0.5799682140350342\r\n",
      "Epoch #169: loss=0.5681455135345459\r\n",
      "Epoch #170: loss=0.5120154619216919\r\n",
      "Epoch #171: loss=0.5074885487556458\r\n",
      "Epoch #172: loss=0.6323186159133911\r\n",
      "Epoch #173: loss=0.5322255492210388\r\n",
      "Epoch #174: loss=0.6305522918701172\r\n",
      "Epoch #175: loss=0.560258686542511\r\n",
      "Epoch #176: loss=0.5248961448669434\r\n",
      "Epoch #177: loss=0.6120954751968384\r\n",
      "Epoch #178: loss=0.4629112184047699\r\n",
      "Epoch #179: loss=0.6164254546165466\r\n",
      "Epoch #180: loss=0.5621792078018188\r\n",
      "Epoch #181: loss=0.4274083375930786\r\n",
      "Epoch #182: loss=0.44499966502189636\r\n",
      "Epoch #183: loss=0.7932215929031372\r\n",
      "Epoch #184: loss=0.46767735481262207\r\n",
      "Epoch #185: loss=0.5556761622428894\r\n",
      "Epoch #186: loss=0.46399760246276855\r\n",
      "Epoch #187: loss=0.6379911303520203\r\n",
      "Epoch #188: loss=0.3943512439727783\r\n",
      "Epoch #189: loss=0.5801892280578613\r\n",
      "Epoch #190: loss=0.566107451915741\r\n",
      "Epoch #191: loss=0.4287312924861908\r\n",
      "Epoch #192: loss=0.3919997215270996\r\n",
      "Epoch #193: loss=2.625328540802002\r\n",
      "Epoch #194: loss=0.4484714865684509\r\n",
      "Epoch #195: loss=0.4085351824760437\r\n",
      "Epoch #196: loss=0.4511857032775879\r\n",
      "Epoch #197: loss=0.5813061594963074\r\n",
      "Epoch #198: loss=0.6858417987823486\r\n",
      "Epoch #199: loss=0.4232437312602997\r\n",
      "Epoch #200: loss=0.7682766318321228\r\n",
      "Epoch #201: loss=0.43679532408714294\r\n",
      "Epoch #202: loss=0.5051849484443665\r\n",
      "Epoch #203: loss=0.6943773627281189\r\n",
      "Epoch #204: loss=0.47532936930656433\r\n",
      "Epoch #205: loss=0.7126712203025818\r\n",
      "Epoch #206: loss=1.7407925128936768\r\n",
      "Epoch #207: loss=0.5012699365615845\r\n",
      "Epoch #208: loss=0.44075918197631836\r\n",
      "Epoch #209: loss=0.5291046500205994\r\n",
      "Epoch #210: loss=0.4912585914134979\r\n",
      "Epoch #211: loss=0.5234675407409668\r\n",
      "Epoch #212: loss=0.45515570044517517\r\n",
      "Epoch #213: loss=0.48420533537864685\r\n",
      "Epoch #214: loss=0.4182886779308319\r\n",
      "Epoch #215: loss=0.5581749081611633\r\n",
      "Epoch #216: loss=0.40752851963043213\r\n",
      "Epoch #217: loss=0.5599067807197571\r\n",
      "Epoch #218: loss=0.4900582730770111\r\n",
      "Epoch #219: loss=0.577478289604187\r\n",
      "Epoch #220: loss=0.38835152983665466\r\n",
      "Epoch #221: loss=0.3837355077266693\r\n",
      "Epoch #222: loss=0.3939145803451538\r\n",
      "Epoch #223: loss=0.42700088024139404\r\n",
      "Epoch #224: loss=0.5250965356826782\r\n",
      "Epoch #225: loss=0.7902522683143616\r\n",
      "Epoch #226: loss=0.8549209237098694\r\n",
      "Epoch #227: loss=0.4356415271759033\r\n",
      "Epoch #228: loss=0.5845119953155518\r\n",
      "Epoch #229: loss=0.4836447238922119\r\n",
      "Epoch #230: loss=0.4967586100101471\r\n",
      "Epoch #231: loss=0.41557222604751587\r\n",
      "Epoch #232: loss=0.3693772554397583\r\n",
      "Epoch #233: loss=0.4658256471157074\r\n",
      "Epoch #234: loss=0.47080275416374207\r\n",
      "Epoch #235: loss=0.44709905982017517\r\n",
      "Epoch #236: loss=0.3707490861415863\r\n",
      "Epoch #237: loss=0.5311863422393799\r\n",
      "Epoch #238: loss=0.4074000120162964\r\n",
      "Epoch #239: loss=0.5111263990402222\r\n",
      "Epoch #240: loss=0.4637810289859772\r\n",
      "Epoch #241: loss=0.41257449984550476\r\n",
      "Epoch #242: loss=0.4592803418636322\r\n",
      "Epoch #243: loss=0.572835385799408\r\n",
      "Epoch #244: loss=0.349717378616333\r\n",
      "Epoch #245: loss=0.35751140117645264\r\n",
      "Epoch #246: loss=0.3531542420387268\r\n",
      "Epoch #247: loss=0.3160972595214844\r\n",
      "Epoch #248: loss=0.30038702487945557\r\n",
      "Epoch #249: loss=0.35591956973075867\r\n",
      "Epoch #250: loss=1.0395214557647705\r\n",
      "Epoch #251: loss=0.29163065552711487\r\n",
      "Epoch #252: loss=0.8203279376029968\r\n",
      "Epoch #253: loss=0.32354941964149475\r\n",
      "Epoch #254: loss=0.3938209116458893\r\n",
      "Epoch #255: loss=0.46141836047172546\r\n",
      "Epoch #256: loss=0.5517945885658264\r\n",
      "Epoch #257: loss=0.5640738010406494\r\n",
      "Epoch #258: loss=0.7217965126037598\r\n",
      "Epoch #259: loss=0.4322517216205597\r\n",
      "Epoch #260: loss=0.435712993144989\r\n",
      "Epoch #261: loss=0.5538260340690613\r\n",
      "Epoch #262: loss=0.3410447835922241\r\n",
      "Epoch #263: loss=0.4047703742980957\r\n",
      "Epoch #264: loss=0.33205682039260864\r\n",
      "Epoch #265: loss=0.42275407910346985\r\n",
      "Epoch #266: loss=0.4623510241508484\r\n",
      "Epoch #267: loss=0.3855465352535248\r\n",
      "Epoch #268: loss=0.34046173095703125\r\n",
      "Epoch #269: loss=0.38225090503692627\r\n",
      "Epoch #270: loss=0.3630741536617279\r\n",
      "Epoch #271: loss=0.31083932518959045\r\n",
      "Epoch #272: loss=0.5475488305091858\r\n",
      "Epoch #273: loss=0.3567785322666168\r\n",
      "Epoch #274: loss=0.3750333786010742\r\n",
      "Epoch #275: loss=0.3589181900024414\r\n",
      "Epoch #276: loss=0.3013874888420105\r\n",
      "Epoch #277: loss=0.27869778871536255\r\n",
      "Epoch #278: loss=0.4460475444793701\r\n",
      "Epoch #279: loss=0.7317931056022644\r\n",
      "Epoch #280: loss=0.43345603346824646\r\n",
      "Epoch #281: loss=0.39028486609458923\r\n",
      "Epoch #282: loss=0.3198268413543701\r\n",
      "Epoch #283: loss=0.692082405090332\r\n",
      "Epoch #284: loss=0.29571428894996643\r\n",
      "Epoch #285: loss=0.34106990694999695\r\n",
      "Epoch #286: loss=0.3491732180118561\r\n",
      "Epoch #287: loss=0.2778310775756836\r\n",
      "Epoch #288: loss=0.2971588671207428\r\n",
      "Epoch #289: loss=0.31945300102233887\r\n",
      "Epoch #290: loss=0.46724992990493774\r\n",
      "Epoch #291: loss=0.550420880317688\r\n",
      "Epoch #292: loss=0.4769206941127777\r\n",
      "Epoch #293: loss=0.3949015438556671\r\n",
      "Epoch #294: loss=0.3516436517238617\r\n",
      "Epoch #295: loss=0.3538087010383606\r\n",
      "Epoch #296: loss=0.3667888343334198\r\n",
      "Epoch #297: loss=0.3225882053375244\r\n",
      "Epoch #298: loss=0.5032163858413696\r\n",
      "Epoch #299: loss=0.3651961088180542\r\n",
      "Epoch #300: loss=0.8563433289527893\r\n",
      "Epoch #301: loss=0.35447049140930176\r\n",
      "Epoch #302: loss=0.4406314492225647\r\n",
      "Epoch #303: loss=0.44466301798820496\r\n",
      "Epoch #304: loss=0.45252156257629395\r\n",
      "Epoch #305: loss=0.5324664115905762\r\n",
      "Epoch #306: loss=0.2930920422077179\r\n",
      "Epoch #307: loss=0.3577645719051361\r\n",
      "Epoch #308: loss=0.4354572594165802\r\n",
      "Epoch #309: loss=0.5598533749580383\r\n",
      "Epoch #310: loss=0.6767380833625793\r\n",
      "Epoch #311: loss=0.48397165536880493\r\n",
      "Epoch #312: loss=0.4489860236644745\r\n",
      "Epoch #313: loss=0.6291855573654175\r\n",
      "Epoch #314: loss=0.35415562987327576\r\n",
      "Epoch #315: loss=0.5267154574394226\r\n",
      "Epoch #316: loss=0.3607943058013916\r\n",
      "Epoch #317: loss=0.6302021145820618\r\n",
      "Epoch #318: loss=0.42564383149147034\r\n",
      "Epoch #319: loss=0.4831963777542114\r\n",
      "Epoch #320: loss=0.310678094625473\r\n",
      "Epoch #321: loss=0.34947264194488525\r\n",
      "Epoch #322: loss=0.3330624997615814\r\n",
      "Epoch #323: loss=0.6062677502632141\r\n",
      "Epoch #324: loss=0.5262023210525513\r\n",
      "Epoch #325: loss=0.6361637115478516\r\n",
      "Epoch #326: loss=0.5578727126121521\r\n",
      "Epoch #327: loss=0.6940597295761108\r\n",
      "Epoch #328: loss=0.36018869280815125\r\n",
      "Epoch #329: loss=0.4500617980957031\r\n",
      "Epoch #330: loss=0.4523945450782776\r\n",
      "Epoch #331: loss=0.5015416145324707\r\n",
      "Epoch #332: loss=0.6841884851455688\r\n",
      "Epoch #333: loss=0.36239075660705566\r\n",
      "Epoch #334: loss=0.36397117376327515\r\n",
      "Epoch #335: loss=0.4057984948158264\r\n",
      "Epoch #336: loss=0.36058852076530457\r\n",
      "Epoch #337: loss=0.4233855903148651\r\n",
      "Epoch #338: loss=0.4171946942806244\r\n",
      "Epoch #339: loss=0.9942471385002136\r\n",
      "Epoch #340: loss=0.3653513491153717\r\n",
      "Epoch #341: loss=0.2994784712791443\r\n",
      "Epoch #342: loss=0.3956049084663391\r\n",
      "Epoch #343: loss=0.44485944509506226\r\n",
      "Epoch #344: loss=0.27166318893432617\r\n",
      "Epoch #345: loss=0.9173794984817505\r\n",
      "Epoch #346: loss=0.26747891306877136\r\n",
      "Epoch #347: loss=0.3839131295681\r\n",
      "Epoch #348: loss=0.32593458890914917\r\n",
      "Epoch #349: loss=0.41001802682876587\r\n",
      "Epoch #350: loss=0.5435900092124939\r\n",
      "Epoch #351: loss=0.2944571077823639\r\n",
      "Epoch #352: loss=0.3034849762916565\r\n",
      "Epoch #353: loss=0.42147088050842285\r\n",
      "Epoch #354: loss=0.26068389415740967\r\n",
      "Epoch #355: loss=0.25383809208869934\r\n",
      "Epoch #356: loss=0.24629747867584229\r\n",
      "Epoch #357: loss=0.24942880868911743\r\n",
      "Epoch #358: loss=0.34230074286460876\r\n",
      "Epoch #359: loss=0.24081677198410034\r\n",
      "Epoch #360: loss=0.4427977204322815\r\n",
      "Epoch #361: loss=0.29038897156715393\r\n",
      "Epoch #362: loss=0.33995139598846436\r\n",
      "Epoch #363: loss=0.3432635962963104\r\n",
      "Epoch #364: loss=0.24859173595905304\r\n",
      "Epoch #365: loss=0.3016118109226227\r\n",
      "Epoch #366: loss=0.2810092568397522\r\n",
      "Epoch #367: loss=0.22472044825553894\r\n",
      "Epoch #368: loss=0.2541487216949463\r\n",
      "Epoch #369: loss=0.24135559797286987\r\n",
      "Epoch #370: loss=0.2640449106693268\r\n",
      "Epoch #371: loss=0.2164677381515503\r\n",
      "Epoch #372: loss=0.5714435577392578\r\n",
      "Epoch #373: loss=0.30638206005096436\r\n",
      "Epoch #374: loss=0.332376092672348\r\n",
      "Epoch #375: loss=0.280203253030777\r\n",
      "Epoch #376: loss=0.2048732042312622\r\n",
      "Epoch #377: loss=0.36636149883270264\r\n",
      "Epoch #378: loss=0.19442127645015717\r\n",
      "Epoch #379: loss=0.34442639350891113\r\n",
      "Epoch #380: loss=0.22451040148735046\r\n",
      "Epoch #381: loss=1.1713545322418213\r\n",
      "Epoch #382: loss=0.28921741247177124\r\n",
      "Epoch #383: loss=0.2484586238861084\r\n",
      "Epoch #384: loss=0.3566350042819977\r\n",
      "Epoch #385: loss=0.2885282039642334\r\n",
      "Epoch #386: loss=0.26649728417396545\r\n",
      "Epoch #387: loss=0.2948743402957916\r\n",
      "Epoch #388: loss=0.3166724443435669\r\n",
      "Epoch #389: loss=0.23844701051712036\r\n",
      "Epoch #390: loss=0.30509495735168457\r\n",
      "Epoch #391: loss=0.22558146715164185\r\n",
      "Epoch #392: loss=0.29742753505706787\r\n",
      "Epoch #393: loss=0.22365210950374603\r\n",
      "Epoch #394: loss=0.21538981795310974\r\n",
      "Epoch #395: loss=0.20546263456344604\r\n",
      "Epoch #396: loss=0.2541331350803375\r\n",
      "Epoch #397: loss=0.20832544565200806\r\n",
      "Epoch #398: loss=0.3141865134239197\r\n",
      "Epoch #399: loss=0.2189498245716095\r\n",
      "Epoch #400: loss=0.32637009024620056\r\n",
      "Epoch #401: loss=0.2456536591053009\r\n",
      "Epoch #402: loss=0.2008679360151291\r\n",
      "Epoch #403: loss=0.26503652334213257\r\n",
      "Epoch #404: loss=0.20565252006053925\r\n",
      "Epoch #405: loss=0.19000780582427979\r\n",
      "Epoch #406: loss=0.5120053291320801\r\n",
      "Epoch #407: loss=0.2509784698486328\r\n",
      "Epoch #408: loss=0.2127762883901596\r\n",
      "Epoch #409: loss=0.22577324509620667\r\n",
      "Epoch #410: loss=0.27524787187576294\r\n",
      "Epoch #411: loss=0.2316259741783142\r\n",
      "Epoch #412: loss=0.186555415391922\r\n",
      "Epoch #413: loss=0.3118396997451782\r\n",
      "Epoch #414: loss=0.22126558423042297\r\n",
      "Epoch #415: loss=0.21644923090934753\r\n",
      "Epoch #416: loss=0.18446028232574463\r\n",
      "Epoch #417: loss=0.20642870664596558\r\n",
      "Epoch #418: loss=0.227896049618721\r\n",
      "Epoch #419: loss=0.4116954803466797\r\n",
      "Epoch #420: loss=0.20792901515960693\r\n",
      "Epoch #421: loss=0.20155943930149078\r\n",
      "Epoch #422: loss=1.2795538902282715\r\n",
      "Epoch #423: loss=0.24155037105083466\r\n",
      "Epoch #424: loss=0.1824532002210617\r\n",
      "Epoch #425: loss=0.33537134528160095\r\n",
      "Epoch #426: loss=0.2120494693517685\r\n",
      "Epoch #427: loss=0.19251051545143127\r\n",
      "Epoch #428: loss=0.594878613948822\r\n",
      "Epoch #429: loss=0.35646697878837585\r\n",
      "Epoch #430: loss=1.0320020914077759\r\n",
      "Epoch #431: loss=0.19419458508491516\r\n",
      "Epoch #432: loss=0.2652255892753601\r\n",
      "Epoch #433: loss=0.28107520937919617\r\n",
      "Epoch #434: loss=0.3782598674297333\r\n",
      "Epoch #435: loss=0.3555048406124115\r\n",
      "Epoch #436: loss=0.2524142861366272\r\n",
      "Epoch #437: loss=0.2697218358516693\r\n",
      "Epoch #438: loss=0.349783331155777\r\n",
      "Epoch #439: loss=0.27522945404052734\r\n",
      "Epoch #440: loss=0.2812231481075287\r\n",
      "Epoch #441: loss=0.24537138640880585\r\n",
      "Epoch #442: loss=0.3249462842941284\r\n",
      "Epoch #443: loss=0.23240454494953156\r\n",
      "Epoch #444: loss=0.300510972738266\r\n",
      "Epoch #445: loss=0.22003647685050964\r\n",
      "Epoch #446: loss=0.35582488775253296\r\n",
      "Epoch #447: loss=0.27721959352493286\r\n",
      "Epoch #448: loss=0.26460695266723633\r\n",
      "Epoch #449: loss=0.19088347256183624\r\n",
      "Epoch #450: loss=0.1972811222076416\r\n",
      "Epoch #451: loss=0.21749159693717957\r\n",
      "Epoch #452: loss=0.21406269073486328\r\n",
      "Epoch #453: loss=0.3169437348842621\r\n",
      "Epoch #454: loss=0.2803587317466736\r\n",
      "Epoch #455: loss=0.22468842566013336\r\n",
      "Epoch #456: loss=0.5502181649208069\r\n",
      "Epoch #457: loss=0.3068997859954834\r\n",
      "Epoch #458: loss=0.2149011343717575\r\n",
      "Epoch #459: loss=0.3027702867984772\r\n",
      "Epoch #460: loss=0.23019693791866302\r\n",
      "Epoch #461: loss=0.3273544907569885\r\n",
      "Epoch #462: loss=0.22848019003868103\r\n",
      "Epoch #463: loss=0.22122883796691895\r\n",
      "Epoch #464: loss=0.26242795586586\r\n",
      "Epoch #465: loss=0.23368988931179047\r\n",
      "Epoch #466: loss=0.3825540542602539\r\n",
      "Epoch #467: loss=0.2371802031993866\r\n",
      "Epoch #468: loss=0.18685711920261383\r\n",
      "Epoch #469: loss=0.7991418838500977\r\n",
      "Epoch #470: loss=0.23701982200145721\r\n",
      "Epoch #471: loss=0.3143731653690338\r\n",
      "Epoch #472: loss=0.19028383493423462\r\n",
      "Epoch #473: loss=0.2748142182826996\r\n",
      "Epoch #474: loss=0.32242098450660706\r\n",
      "Epoch #475: loss=0.47162485122680664\r\n",
      "Epoch #476: loss=0.3283727467060089\r\n",
      "Epoch #477: loss=0.3722812533378601\r\n",
      "Epoch #478: loss=0.3228789269924164\r\n",
      "Epoch #479: loss=0.3116195797920227\r\n",
      "Epoch #480: loss=0.2220940887928009\r\n",
      "Epoch #481: loss=0.44259893894195557\r\n",
      "Epoch #482: loss=0.2693738639354706\r\n",
      "Epoch #483: loss=0.2546218931674957\r\n",
      "Epoch #484: loss=0.29667291045188904\r\n",
      "Epoch #485: loss=0.2249760627746582\r\n",
      "Epoch #486: loss=0.2486845850944519\r\n",
      "Epoch #487: loss=0.23088578879833221\r\n",
      "Epoch #488: loss=1.8498811721801758\r\n",
      "Epoch #489: loss=0.32537344098091125\r\n",
      "Epoch #490: loss=0.21176597476005554\r\n",
      "Epoch #491: loss=0.2965124547481537\r\n",
      "Epoch #492: loss=0.3223631680011749\r\n",
      "Epoch #493: loss=0.305544912815094\r\n",
      "Epoch #494: loss=0.23742443323135376\r\n",
      "Epoch #495: loss=0.22125910222530365\r\n",
      "Epoch #496: loss=0.31546878814697266\r\n",
      "Epoch #497: loss=0.26063403487205505\r\n",
      "Epoch #498: loss=0.2694356441497803\r\n",
      "Epoch #499: loss=0.19422774016857147\r\n",
      "Epoch #500: loss=0.33721673488616943\r\n",
      "Epoch #501: loss=0.5663721561431885\r\n",
      "Epoch #502: loss=0.249395489692688\r\n",
      "Epoch #503: loss=0.2985844016075134\r\n",
      "Epoch #504: loss=0.2091827392578125\r\n",
      "Epoch #505: loss=0.23963801562786102\r\n",
      "Epoch #506: loss=0.2553365230560303\r\n",
      "Epoch #507: loss=0.19798782467842102\r\n",
      "Epoch #508: loss=0.2896958589553833\r\n",
      "Epoch #509: loss=0.21004757285118103\r\n",
      "Epoch #510: loss=0.2270713746547699\r\n",
      "Epoch #511: loss=0.4731525480747223\r\n",
      "Epoch #512: loss=0.1822035014629364\r\n",
      "Epoch #513: loss=0.3591063618659973\r\n",
      "Epoch #514: loss=0.3323450982570648\r\n",
      "Epoch #515: loss=0.22789786756038666\r\n",
      "Epoch #516: loss=0.21327979862689972\r\n",
      "Epoch #517: loss=0.2499513477087021\r\n",
      "Epoch #518: loss=0.475080281496048\r\n",
      "Epoch #519: loss=0.17555449903011322\r\n",
      "Epoch #520: loss=0.25444063544273376\r\n",
      "Epoch #521: loss=0.18541137874126434\r\n",
      "Epoch #522: loss=0.19392701983451843\r\n",
      "Epoch #523: loss=0.22992423176765442\r\n",
      "Epoch #524: loss=0.1837991327047348\r\n",
      "Epoch #525: loss=0.34474167227745056\r\n",
      "Epoch #526: loss=0.1646268367767334\r\n",
      "Epoch #527: loss=0.18743877112865448\r\n",
      "Epoch #528: loss=0.1580965518951416\r\n",
      "Epoch #529: loss=0.2384156435728073\r\n",
      "Epoch #530: loss=0.22614972293376923\r\n",
      "Epoch #531: loss=0.25907984375953674\r\n",
      "Epoch #532: loss=0.21099604666233063\r\n",
      "Epoch #533: loss=0.6058682203292847\r\n",
      "Epoch #534: loss=0.3426755964756012\r\n",
      "Epoch #535: loss=0.17720292508602142\r\n",
      "Epoch #536: loss=0.4681767523288727\r\n",
      "Epoch #537: loss=0.2367955893278122\r\n",
      "Epoch #538: loss=0.5095054507255554\r\n",
      "Epoch #539: loss=0.19860482215881348\r\n",
      "Epoch #540: loss=0.17836245894432068\r\n",
      "Epoch #541: loss=0.27750635147094727\r\n",
      "Epoch #542: loss=0.18246518075466156\r\n",
      "Epoch #543: loss=0.45097604393959045\r\n",
      "Epoch #544: loss=0.175114244222641\r\n",
      "Epoch #545: loss=0.20518074929714203\r\n",
      "Epoch #546: loss=0.18145611882209778\r\n",
      "Epoch #547: loss=0.15897119045257568\r\n",
      "Epoch #548: loss=0.1711738258600235\r\n",
      "Epoch #549: loss=0.5767790675163269\r\n",
      "Epoch #550: loss=0.2747487723827362\r\n",
      "Epoch #551: loss=0.16526515781879425\r\n",
      "Epoch #552: loss=0.28798410296440125\r\n",
      "Epoch #553: loss=0.31808075308799744\r\n",
      "Epoch #554: loss=0.5109182596206665\r\n",
      "Epoch #555: loss=0.2268960326910019\r\n",
      "Epoch #556: loss=0.4863536059856415\r\n",
      "Epoch #557: loss=0.2576017677783966\r\n",
      "Epoch #558: loss=0.39525464177131653\r\n",
      "Epoch #559: loss=0.20382121205329895\r\n",
      "Epoch #560: loss=0.2351115196943283\r\n",
      "Epoch #561: loss=0.2283536195755005\r\n",
      "Epoch #562: loss=0.22565440833568573\r\n",
      "Epoch #563: loss=0.20558246970176697\r\n",
      "Epoch #564: loss=0.1949952393770218\r\n",
      "Epoch #565: loss=0.19358696043491364\r\n",
      "Epoch #566: loss=0.26298239827156067\r\n",
      "Epoch #567: loss=0.19296231865882874\r\n",
      "Epoch #568: loss=0.29733356833457947\r\n",
      "Epoch #569: loss=0.18039503693580627\r\n",
      "Epoch #570: loss=0.7346562743186951\r\n",
      "Epoch #571: loss=0.17959170043468475\r\n",
      "Epoch #572: loss=0.21677204966545105\r\n",
      "Epoch #573: loss=0.4544287621974945\r\n",
      "Epoch #574: loss=0.2043238878250122\r\n",
      "Epoch #575: loss=0.22262731194496155\r\n",
      "Epoch #576: loss=0.1868942677974701\r\n",
      "Epoch #577: loss=0.16865822672843933\r\n",
      "Epoch #578: loss=0.5363540053367615\r\n",
      "Epoch #579: loss=0.2886044383049011\r\n",
      "Epoch #580: loss=0.1540309190750122\r\n",
      "Epoch #581: loss=0.7262758612632751\r\n",
      "Epoch #582: loss=0.17137357592582703\r\n",
      "Epoch #583: loss=0.23138833045959473\r\n",
      "Epoch #584: loss=0.17651450634002686\r\n",
      "Epoch #585: loss=0.20106184482574463\r\n",
      "Epoch #586: loss=0.1773291528224945\r\n",
      "Epoch #587: loss=0.17899279296398163\r\n",
      "Epoch #588: loss=0.17640328407287598\r\n",
      "Epoch #589: loss=0.24143369495868683\r\n",
      "Epoch #590: loss=0.2043730616569519\r\n",
      "Epoch #591: loss=0.3213651180267334\r\n",
      "Epoch #592: loss=0.1669752299785614\r\n",
      "Epoch #593: loss=0.1502130925655365\r\n",
      "Epoch #594: loss=0.17333874106407166\r\n",
      "Epoch #595: loss=0.2985221743583679\r\n",
      "Epoch #596: loss=0.18259894847869873\r\n",
      "Epoch #597: loss=0.9067296981811523\r\n",
      "Epoch #598: loss=0.15954454243183136\r\n",
      "Epoch #599: loss=0.19932270050048828\r\n",
      "\r\n",
      "Training time: 0:01:03.822422\r\n",
      "\r\n",
      "Evaluation result: {'ours': {24: {'norm': {'MSE': 0.4001627190591166, 'MAE': 0.47039142620657437}, 'raw': {'MSE': 19.565995993826245, 'MAE': 3.3347914874672595}}, 48: {'norm': {'MSE': 0.5709245749607967, 'MAE': 0.5779883611979654}, 'raw': {'MSE': 32.146759957295686, 'MAE': 4.260965033996166}}, 168: {'norm': {'MSE': 1.8439207669477262, 'MAE': 1.0676347131650337}, 'raw': {'MSE': 65.46294819170295, 'MAE': 6.845514546861894}}, 336: {'norm': {'MSE': 2.2455501973686878, 'MAE': 1.206177154422061}, 'raw': {'MSE': 84.95392169084919, 'MAE': 7.87305577377563}}, 720: {'norm': {'MSE': 2.694436846941552, 'MAE': 1.3901362113124869}, 'raw': {'MSE': 132.57266809984924, 'MAE': 9.821448737598407}}}, 'ts2vec_infer_time': 2.504117965698242, 'lr_train_time': {24: 2.5572052001953125, 48: 3.34610915184021, 168: 5.711200714111328, 336: 9.704539060592651, 720: 17.129507541656494}, 'lr_infer_time': {24: 0.12439465522766113, 48: 0.1967296600341797, 168: 0.633073091506958, 336: 1.1958928108215332, 720: 2.1343917846679688}}\r\n",
      "Finished.\r\n"
     ]
    }
   ],
   "source": [
    "!python -u train.py ETTh2 forecast_multivar --loader forecast_csv --repr-dims 320 --max-threads 8 --seed 42 --eval"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2569834,
     "sourceId": 4371501,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 911.372046,
   "end_time": "2025-10-12T03:48:28.114859",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-12T03:33:16.742813",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
