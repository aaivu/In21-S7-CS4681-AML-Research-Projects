{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l_CNtJW_yjlS"
      },
      "outputs": [],
      "source": [
        "# # ================================\n",
        "# # INSTALL REQUIRED PACKAGES ()\n",
        "# # ================================\n",
        "\n",
        "# # Use the working approach from QuantizationTechniques.ipynb\n",
        "# !pip install keras\n",
        "# !pip install tensorflow\n",
        "# !pip install tensorflow-model-optimization\n",
        "# !pip install kagglehub --quiet\n",
        "\n",
        "# print(\"üì¶ Required packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH55FFSDyDwn",
        "outputId": "9039cdfb-26aa-4bb5-8ac7-f7559509c86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Setting up Colab environment...\n",
            "TensorFlow version: 2.19.0\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "üöÄ Environment setup complete!\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# COLAB ENVIRONMENT SETUP\n",
        "# ================================\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "import kagglehub\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "print(\"üîß Setting up Colab environment...\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"üöÄ Environment setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzpR9T1k5mPi",
        "outputId": "6a1301e1-615f-44c6-e5b9-92b62d276357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîê Setting up Kaggle authentication for ImageNet Mini dataset...\n",
            "üìÅ Downloading ImageNet Mini dataset from Kaggle...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ifigotin/imagenetmini-1000?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.92G/3.92G [02:59<00:00, 23.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset downloaded successfully!\n",
            "Dataset path: /root/.cache/kagglehub/datasets/ifigotin/imagenetmini-1000/versions/1\n",
            "Image size: 224x224\n",
            "Batch size: 32\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# IMAGENET MINI DATASET SETUP (TRAIN/TEST SPLIT)\n",
        "# ================================\n",
        "\n",
        "import kagglehub\n",
        "import glob\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "MAX_TRAIN_SAMPLES = None  # Use all training samples\n",
        "MAX_TEST_SAMPLES = None   # Use all test samples\n",
        "\n",
        "print(\"üîê Setting up Kaggle authentication for ImageNet Mini dataset...\")\n",
        "if 'kaggle.json' not in os.listdir():\n",
        "    sys.exit(\"Add kaggle.json to access the dataset from Kaggle or place a local dataset folder next to the notebook\")\n",
        "\n",
        "print(\"üìÅ Downloading ImageNet Mini dataset from Kaggle...\")\n",
        "try:\n",
        "    # Download ImageNet Mini dataset with train/test split\n",
        "    path = kagglehub.dataset_download(\"ifigotin/imagenetmini-1000\")\n",
        "    IMAGENET_PATH = path\n",
        "    print(\"‚úÖ Dataset downloaded successfully!\")\n",
        "    print(f\"Dataset path: {IMAGENET_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error downloading dataset: {e}\")\n",
        "    IMAGENET_PATH = None\n",
        "\n",
        "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls  /root/.cache/kagglehub/datasets/ifigotin/imagenetmini-1000/versions/1/\"/imagenet-mini\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dceOF60sEAH1",
        "outputId": "256e9913-7b3d-4672-88ce-8c3ce1bd1cb2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train  val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGENET_PATH = IMAGENET_PATH+\"/imagenet-mini\""
      ],
      "metadata": {
        "id": "sBGnJvz4EN5R"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5kG1gDfK5pFB"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# DATASET LOADING FUNCTIONS\n",
        "# ================================\n",
        "\n",
        "def load_imagenet_train_dataset(imagenet_path, img_size=224, batch_size=32, max_samples=None):\n",
        "    \"\"\"Load ImageNet Mini training dataset with proper preprocessing.\"\"\"\n",
        "    print(f\"üìÅ Loading ImageNet Mini training samples from: {imagenet_path}\")\n",
        "\n",
        "    train_dir = os.path.join(imagenet_path, \"train\")\n",
        "    if not os.path.exists(train_dir):\n",
        "        raise FileNotFoundError(f\"‚ùå Training folder not found at {train_dir}\")\n",
        "\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        train_dir,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\",\n",
        "        image_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,  # Shuffle training data\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    # Get total count before limiting\n",
        "    total_samples = tf.data.experimental.cardinality(dataset).numpy() * batch_size\n",
        "\n",
        "    # Optionally cap dataset\n",
        "    if max_samples:\n",
        "        dataset = dataset.unbatch().take(max_samples).batch(batch_size)\n",
        "        total_samples = min(total_samples, max_samples)\n",
        "\n",
        "    # Preprocess with EfficientNet normalization\n",
        "    def preprocess(image, label):\n",
        "        # EfficientNetV2 expects values in [0, 255] actually!\n",
        "        # preprocess_input will normalize them internally\n",
        "        image = tf.cast(image, tf.float32)  # Ensure float32\n",
        "        image = tf.keras.applications.efficientnet_v2.preprocess_input(image)\n",
        "        return image, label\n",
        "\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    print(f\"‚úÖ Training dataset ready with {total_samples} samples!\")\n",
        "    return dataset\n",
        "\n",
        "def load_imagenet_test_dataset(imagenet_path, img_size=224, batch_size=32, max_samples=None):\n",
        "    \"\"\"Load ImageNet Mini test dataset with proper preprocessing.\"\"\"\n",
        "    print(f\"üìÅ Loading ImageNet Mini test samples from: {imagenet_path}\")\n",
        "\n",
        "    test_dir = os.path.join(imagenet_path, \"val\")\n",
        "    if not os.path.exists(test_dir):\n",
        "        raise FileNotFoundError(f\"‚ùå Test folder not found at {test_dir}\")\n",
        "\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        test_dir,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\",\n",
        "        image_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False  # Don't shuffle test data\n",
        "    )\n",
        "\n",
        "    # Get total count before limiting\n",
        "    total_samples = tf.data.experimental.cardinality(dataset).numpy() * batch_size\n",
        "\n",
        "    # Optionally cap dataset\n",
        "    if max_samples:\n",
        "        dataset = dataset.unbatch().take(max_samples).batch(batch_size)\n",
        "        total_samples = min(total_samples, max_samples)\n",
        "\n",
        "    # Preprocess with EfficientNet normalization\n",
        "    def preprocess(image, label):\n",
        "        # EfficientNetV2 expects values in [0, 255] actually!\n",
        "        # preprocess_input will normalize them internally\n",
        "        image = tf.cast(image, tf.float32)  # Ensure float32\n",
        "        image = tf.keras.applications.efficientnet_v2.preprocess_input(image)\n",
        "        return image, label\n",
        "\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    print(f\"‚úÖ Test dataset ready with {total_samples} samples!\")\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcPlVUDQ5q1c",
        "outputId": "843075db-3018-4502-8a14-8f9179c59bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading ImageNet Mini datasets...\n",
            "\n",
            "üìö Loading training dataset...\n",
            "üìÅ Loading ImageNet Mini training samples from: /root/.cache/kagglehub/datasets/ifigotin/imagenetmini-1000/versions/1/imagenet-mini\n",
            "Found 34745 files belonging to 1000 classes.\n",
            "‚úÖ Training dataset ready with 34752 samples!\n",
            "\n",
            "üß™ Loading test dataset...\n",
            "üìÅ Loading ImageNet Mini test samples from: /root/.cache/kagglehub/datasets/ifigotin/imagenetmini-1000/versions/1/imagenet-mini\n",
            "Found 3923 files belonging to 1000 classes.\n",
            "‚úÖ Test dataset ready with 3936 samples!\n",
            "\n",
            "üß™ Testing training dataset with one batch...\n",
            "‚úÖ Training batch shape: (32, 224, 224, 3)\n",
            "üßæ Training labels shape: (32,)\n",
            "üé® Pixel range: [0.000, 255.000]\n",
            "\n",
            "üß™ Testing test dataset with one batch...\n",
            "‚úÖ Test batch shape: (32, 224, 224, 3)\n",
            "üßæ Test labels shape: (32,)\n",
            "‚úÖ ImageNet Mini datasets are ready for training and evaluation!\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# LOAD AND VERIFY DATASETS\n",
        "# ================================\n",
        "\n",
        "if IMAGENET_PATH:\n",
        "    print(\"üîÑ Loading ImageNet Mini datasets...\")\n",
        "\n",
        "    # Load training dataset\n",
        "    print(\"\\nüìö Loading training dataset...\")\n",
        "    train_dataset = load_imagenet_train_dataset(IMAGENET_PATH, IMG_SIZE, BATCH_SIZE, MAX_TRAIN_SAMPLES)\n",
        "\n",
        "    # Load test dataset\n",
        "    print(\"\\nüß™ Loading test dataset...\")\n",
        "    test_dataset = load_imagenet_test_dataset(IMAGENET_PATH, IMG_SIZE, BATCH_SIZE, MAX_TEST_SAMPLES)\n",
        "\n",
        "    if train_dataset and test_dataset:\n",
        "        try:\n",
        "            print(\"\\nüß™ Testing training dataset with one batch...\")\n",
        "            sample_batch, sample_labels = next(iter(train_dataset))\n",
        "            print(f\"‚úÖ Training batch shape: {sample_batch.shape}\")\n",
        "            print(f\"üßæ Training labels shape: {sample_labels.shape}\")\n",
        "            print(f\"üé® Pixel range: [{sample_batch.numpy().min():.3f}, {sample_batch.numpy().max():.3f}]\")\n",
        "\n",
        "            print(\"\\nüß™ Testing test dataset with one batch...\")\n",
        "            test_batch, test_labels = next(iter(test_dataset))\n",
        "            print(f\"‚úÖ Test batch shape: {test_batch.shape}\")\n",
        "            print(f\"üßæ Test labels shape: {test_labels.shape}\")\n",
        "\n",
        "            print(\"‚úÖ ImageNet Mini datasets are ready for training and evaluation!\")\n",
        "            DATASET_AVAILABLE = True\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error testing datasets: {e}\")\n",
        "            DATASET_AVAILABLE = False\n",
        "    else:\n",
        "        print(\"‚ùå Could not load datasets properly.\")\n",
        "        DATASET_AVAILABLE = False\n",
        "else:\n",
        "    print(\"‚ùå ImageNet Mini dataset not available\")\n",
        "    DATASET_AVAILABLE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hhNQ_Ze571i",
        "outputId": "244f5225-4dd4-4169-fc76-7ac9c1e651ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Setting up custom QuantizeConfig for unsupported layers...\n",
            "‚úÖ Custom QuantizeConfig classes defined!\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# CUSTOM QUANTIZE CONFIGS FOR UNSUPPORTED LAYERS\n",
        "# ================================\n",
        "\n",
        "print(\"‚öôÔ∏è Setting up custom QuantizeConfig for unsupported layers...\")\n",
        "\n",
        "from tensorflow_model_optimization.python.core.quantization.keras import quantize_config\n",
        "\n",
        "# Custom config for Multiply layer (used in SE blocks)\n",
        "class NoOpQuantizeConfig(quantize_config.QuantizeConfig):\n",
        "    \"\"\"Pass-through quantization config for layers that don't need quantization\"\"\"\n",
        "\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "        return []\n",
        "\n",
        "    def get_activations_and_quantizers(self, layer):\n",
        "        return []\n",
        "\n",
        "    def set_quantize_weights(self, layer, quantize_weights):\n",
        "        pass\n",
        "\n",
        "    def set_quantize_activations(self, layer, quantize_activations):\n",
        "        pass\n",
        "\n",
        "    def get_output_quantizers(self, layer):\n",
        "        return []\n",
        "\n",
        "    def get_config(self):\n",
        "        return {}\n",
        "\n",
        "# Custom config for Add layer (also used in residual connections)\n",
        "class DefaultQuantizeConfig(quantize_config.QuantizeConfig):\n",
        "    \"\"\"Default quantization for simple layers\"\"\"\n",
        "\n",
        "    def get_weights_and_quantizers(self, layer):\n",
        "        return []\n",
        "\n",
        "    def get_activations_and_quantizers(self, layer):\n",
        "        return []\n",
        "\n",
        "    def set_quantize_weights(self, layer, quantize_weights):\n",
        "        pass\n",
        "\n",
        "    def set_quantize_activations(self, layer, quantize_activations):\n",
        "        pass\n",
        "\n",
        "    def get_output_quantizers(self, layer):\n",
        "        return []\n",
        "\n",
        "    def get_config(self):\n",
        "        return {}\n",
        "\n",
        "print(\"‚úÖ Custom QuantizeConfig classes defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2_P6E_XyTCh",
        "outputId": "70824430-7e0a-47b5-d27b-d646e3491a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Creating EfficientNetV2B0 model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0.h5\n",
            "29403144/29403144 [==============================] - 3s 0us/step\n",
            "‚úÖ Model created successfully!\n",
            "Model parameters: 7,200,312\n"
          ]
        }
      ],
      "source": [
        "# # ================================\n",
        "# # MODEL CREATION\n",
        "# # ================================\n",
        "\n",
        "print(\"ü§ñ Creating EfficientNetV2B0 model...\")\n",
        "\n",
        "# Load base model without preprocessing layers to avoid QAT compatibility issues\n",
        "base_model = tf.keras.applications.EfficientNetV2B0(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3),\n",
        "    classes=1000,\n",
        "    include_preprocessing=False  # Critical: avoid Rescaling layer\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model created successfully!\")\n",
        "print(f\"Model parameters: {base_model.count_params():,}\")\n",
        "\n",
        "# Use the model directly\n",
        "model = base_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYIaTZlj7hZi",
        "outputId": "b02fdc0e-0143-4e7e-a7fe-3377795c1b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Annotating model with custom quantization configs...\n",
            "üîÑ Cloning model with quantization annotations...\n",
            "‚úÖ Model annotated successfully!\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# CUSTOM QUANTIZATION ANNOTATION\n",
        "# ================================\n",
        "\n",
        "print(\"üîß Annotating model with custom quantization configs...\")\n",
        "\n",
        "from tensorflow_model_optimization.quantization.keras import quantize_annotate_layer, quantize_annotate_model\n",
        "\n",
        "def apply_quantization_to_layer(layer):\n",
        "    \"\"\"Apply appropriate quantization config based on layer type\"\"\"\n",
        "\n",
        "    # Layers that don't need quantization\n",
        "    if isinstance(layer, (tf.keras.layers.Multiply,\n",
        "                         tf.keras.layers.Add,\n",
        "                         tf.keras.layers.Activation,\n",
        "                         tf.keras.layers.GlobalAveragePooling2D,\n",
        "                         tf.keras.layers.Dropout)):\n",
        "        return quantize_annotate_layer(layer, NoOpQuantizeConfig())\n",
        "\n",
        "    # Default quantization for other layers\n",
        "    return layer\n",
        "\n",
        "# Clone model with custom annotations\n",
        "print(\"üîÑ Cloning model with quantization annotations...\")\n",
        "annotated_model = tf.keras.models.clone_model(\n",
        "    model,\n",
        "    clone_function=apply_quantization_to_layer,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model annotated successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3h5H9o2ydPh",
        "outputId": "119091e3-6d37-43f1-9707-1c366052078e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî¢ Applying quantization to annotated model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tf_keras/src/initializers/__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.Constant'>, which may lead to improper serialization.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ QAT model created successfully!\n",
            "QAT model parameters: 7,200,415\n"
          ]
        }
      ],
      "source": [
        "from tensorflow_model_optimization.quantization.keras import quantize_scope\n",
        "\n",
        "print(\"üî¢ Applying quantization to annotated model...\")\n",
        "\n",
        "try:\n",
        "    # ‚úÖ Apply quantization inside the quantize_scope\n",
        "    with quantize_scope({'NoOpQuantizeConfig': NoOpQuantizeConfig}):\n",
        "      # Apply quantization\n",
        "      qat_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "\n",
        "    print(\"‚úÖ QAT model created successfully!\")\n",
        "    print(f\"QAT model parameters: {qat_model.count_params():,}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error applying quantization: {e}\")\n",
        "    print(\"\\nüí° Some layers may still be unsupported. Trying alternative approach...\")\n",
        "\n",
        "    # Alternative: Use selective quantization\n",
        "    print(\"üîÑ Using selective layer quantization...\")\n",
        "\n",
        "    def selective_quantize(layer):\n",
        "        \"\"\"Only quantize Conv2D and Dense layers\"\"\"\n",
        "        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n",
        "            return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
        "        return layer\n",
        "\n",
        "    annotated_model = tf.keras.models.clone_model(\n",
        "        model,\n",
        "        clone_function=selective_quantize,\n",
        "    )\n",
        "\n",
        "    qat_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n",
        "    print(\"‚úÖ Selective QAT model created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SQpzOUPRye6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce40af33-90ef-48bd-e584-0f6504ccb03a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Compiling QAT model...\n",
            "‚úÖ QAT model compiled!\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# MODEL COMPILATION\n",
        "# ================================\n",
        "\n",
        "print(\"‚öôÔ∏è Compiling QAT model...\")\n",
        "\n",
        "qat_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"‚úÖ QAT model compiled!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "e4_fxoRlDGhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72154ec1-bcc7-45d9-ec0a-0ee886dec640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting QAT training with ImageNet Mini...\n",
            "üìä Training parameters:\n",
            "   - Epochs: 5\n",
            "   - Learning rate: 1e-05\n",
            "   - Batch size: 32\n",
            "‚öôÔ∏è Compiling QAT model...\n",
            "‚úÖ QAT model compiled!\n",
            "üéØ Starting QAT training...\n",
            "Epoch 1/5\n",
            "1086/1086 [==============================] - 297s 216ms/step - loss: 0.9554 - accuracy: 0.7882 - val_loss: 1.0251 - val_accuracy: 0.7586\n",
            "Epoch 2/5\n",
            "1086/1086 [==============================] - 232s 213ms/step - loss: 0.7807 - accuracy: 0.8122 - val_loss: 0.9922 - val_accuracy: 0.7601\n",
            "Epoch 3/5\n",
            "1086/1086 [==============================] - 235s 216ms/step - loss: 0.7040 - accuracy: 0.8267 - val_loss: 0.9629 - val_accuracy: 0.7601\n",
            "Epoch 4/5\n",
            "1086/1086 [==============================] - 236s 216ms/step - loss: 0.6552 - accuracy: 0.8385 - val_loss: 0.9582 - val_accuracy: 0.7640\n",
            "Epoch 5/5\n",
            "1086/1086 [==============================] - 236s 217ms/step - loss: 0.6074 - accuracy: 0.8474 - val_loss: 0.9470 - val_accuracy: 0.7614\n",
            "‚úÖ QAT training completed!\n",
            "üíæ Saving trained QAT model...\n",
            "‚úÖ Trained QAT model saved to 'qat_trained_model'\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# QAT TRAINING WITH IMAGENET MINI\n",
        "# ================================\n",
        "\n",
        "if DATASET_AVAILABLE:\n",
        "    print(\"üöÄ Starting QAT training with ImageNet Mini...\")\n",
        "\n",
        "    # Training parameters\n",
        "    EPOCHS = 5  # Start with fewer epochs for testing\n",
        "    LEARNING_RATE = 1e-5\n",
        "\n",
        "    print(f\"üìä Training parameters:\")\n",
        "    print(f\"   - Epochs: {EPOCHS}\")\n",
        "    print(f\"   - Learning rate: {LEARNING_RATE}\")\n",
        "    print(f\"   - Batch size: {BATCH_SIZE}\")\n",
        "\n",
        "    # Compile the QAT model\n",
        "    print(\"‚öôÔ∏è Compiling QAT model...\")\n",
        "    qat_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ QAT model compiled!\")\n",
        "\n",
        "    # Start training\n",
        "    print(\"üéØ Starting QAT training...\")\n",
        "    history = qat_model.fit(\n",
        "        train_dataset,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=test_dataset,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"‚úÖ QAT training completed!\")\n",
        "\n",
        "    # Save the trained QAT model\n",
        "    print(\"üíæ Saving trained QAT model...\")\n",
        "    qat_model.save('qat_trained_model', include_optimizer=False)\n",
        "    print(\"‚úÖ Trained QAT model saved to 'qat_trained_model'\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Cannot start QAT training - datasets not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kjdbixIFDGhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae57add-cfab-445f-d43b-0fdf08d112d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Evaluating QAT model on test dataset...\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 0.9470 - accuracy: 0.7614\n",
            "‚úÖ QAT Model Performance:\n",
            "   - Test Loss: 0.9470\n",
            "   - Test Accuracy: 0.7614 (76.14%)\n",
            "\n",
            "üîÑ Evaluating baseline model for comparison...\n",
            "‚öôÔ∏è Compiling baseline model...\n",
            "‚úÖ Baseline model compiled!\n",
            "123/123 [==============================] - 16s 98ms/step - loss: 290.0702 - accuracy: 0.0013\n",
            "üìà Baseline Model Performance:\n",
            "   - Test Loss: 290.0702\n",
            "   - Test Accuracy: 0.0013 (0.13%)\n",
            "\n",
            "üìâ Accuracy Drop: -0.7601 (-76.01%)\n",
            "‚úÖ Good quantization! Accuracy drop is minimal.\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# EVALUATION ON TEST DATASET\n",
        "# ================================\n",
        "\n",
        "if DATASET_AVAILABLE:\n",
        "    print(\"üìä Evaluating QAT model on test dataset...\")\n",
        "\n",
        "    # Evaluate the trained QAT model\n",
        "    test_loss, test_accuracy = qat_model.evaluate(test_dataset, verbose=1)\n",
        "\n",
        "    print(f\"‚úÖ QAT Model Performance:\")\n",
        "    print(f\"   - Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"   - Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "    # Compare with baseline model if available\n",
        "    if 'model' in locals():\n",
        "        print(\"\\nüîÑ Evaluating baseline model for comparison...\")\n",
        "\n",
        "        # Compile the baseline model before evaluating\n",
        "        print(\"‚öôÔ∏è Compiling baseline model...\")\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        print(\"‚úÖ Baseline model compiled!\")\n",
        "\n",
        "        baseline_loss, baseline_accuracy = model.evaluate(test_dataset, verbose=1)\n",
        "\n",
        "        print(f\"üìà Baseline Model Performance:\")\n",
        "        print(f\"   - Test Loss: {baseline_loss:.4f}\")\n",
        "        print(f\"   - Test Accuracy: {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")\n",
        "\n",
        "        # Calculate accuracy drop\n",
        "        accuracy_drop = baseline_accuracy - test_accuracy\n",
        "        print(f\"\\nüìâ Accuracy Drop: {accuracy_drop:.4f} ({accuracy_drop*100:.2f}%)\")\n",
        "\n",
        "        if accuracy_drop < 0.05:  # Less than 5% drop\n",
        "            print(\"‚úÖ Good quantization! Accuracy drop is minimal.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Significant accuracy drop. Consider adjusting quantization parameters.\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Cannot evaluate - datasets not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vahPWgM0yYxA",
        "outputId": "50c1d796-3bb2-4722-bd34-4339f5ff5e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Saving QAT model...\n",
            "‚úÖ QAT model saved to 'qat_saved_model'\n",
            "üéâ Pipeline complete!\n",
            "\n",
            "üìã Next Steps:\n",
            "1. Convert to TFLite: Use TFLiteConverter to create optimized .tflite file\n",
            "2. Evaluate performance: Compare accuracy and inference speed\n",
            "3. Deploy: Use the quantized model in your application\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# ================================\n",
        "# MODEL EXPORT\n",
        "# ================================\n",
        "\n",
        "print(\"üíæ Saving QAT model...\")\n",
        "\n",
        "# Save the QAT-trained model in SavedModel format\n",
        "qat_model.save('qat_saved_model', include_optimizer=False)\n",
        "\n",
        "print(\"‚úÖ QAT model saved to 'qat_saved_model'\")\n",
        "print(\"üéâ Pipeline complete!\")\n",
        "\n",
        "# ================================\n",
        "# NEXT STEPS\n",
        "# ================================\n",
        "\n",
        "print(\"\\nüìã Next Steps:\")\n",
        "print(\"1. Convert to TFLite: Use TFLiteConverter to create optimized .tflite file\")\n",
        "print(\"2. Evaluate performance: Compare accuracy and inference speed\")\n",
        "print(\"3. Deploy: Use the quantized model in your application\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxYTtngb8EkR"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}