{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ffd03db4f2c044cf8c749db1d6af6301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_408ed0b314834e1f8b1a5df10a39d018",
              "IPY_MODEL_4cabdb87ea484bbf8c561f2f6c260ad0",
              "IPY_MODEL_050a0ded3df44ec5b09ee00cfc8b340e"
            ],
            "layout": "IPY_MODEL_7119638f0e134fb089e458af3bba1da4"
          }
        },
        "408ed0b314834e1f8b1a5df10a39d018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91151fb4459448aebaeff3e1649bf6cc",
            "placeholder": "​",
            "style": "IPY_MODEL_3cbf2295faa34acc90d5d77cc4f20e43",
            "value": "Map: 100%"
          }
        },
        "4cabdb87ea484bbf8c561f2f6c260ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8adfc97b853143d38e6468b9e78804e5",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_834bbb81422e40d4b675a846f367d3e5",
            "value": 100
          }
        },
        "050a0ded3df44ec5b09ee00cfc8b340e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9550e41cf18947a4841b2e666f4e356b",
            "placeholder": "​",
            "style": "IPY_MODEL_5acc861289d34ce5a27c46e9eae909bb",
            "value": " 100/100 [00:00&lt;00:00, 3578.30 examples/s]"
          }
        },
        "7119638f0e134fb089e458af3bba1da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91151fb4459448aebaeff3e1649bf6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cbf2295faa34acc90d5d77cc4f20e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8adfc97b853143d38e6468b9e78804e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834bbb81422e40d4b675a846f367d3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9550e41cf18947a4841b2e666f4e356b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5acc861289d34ce5a27c46e9eae909bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PdyISOuzDDRq"
      },
      "outputs": [],
      "source": [
        "# ! pip install -q transformers datasets evaluate sentencepiece huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install rouge_score"
      ],
      "metadata": {
        "id": "R5nnJfqmVGKO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Imports ----------\n",
        "from transformers import MT5ForConditionalGeneration, MT5Tokenizer\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "import torch"
      ],
      "metadata": {
        "id": "-HeyybSdKqIg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Config ----------\n",
        "HF_FINE_TUNED_REPO = \"Eshan210352R/mt5-small-denoising-en-fr-final-2\"\n",
        "BASE_MODEL = \"google/mt5-small\""
      ],
      "metadata": {
        "id": "j4JBXWhFKrDw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "FILJcEk_Kxbl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Load Models ----------\n",
        "fine_tuned_model = MT5ForConditionalGeneration.from_pretrained(HF_FINE_TUNED_REPO).to(device)\n",
        "fine_tuned_tokenizer = MT5Tokenizer.from_pretrained(HF_FINE_TUNED_REPO)"
      ],
      "metadata": {
        "id": "IRWJkWphKzsS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = MT5ForConditionalGeneration.from_pretrained(BASE_MODEL).to(device)\n",
        "base_tokenizer = MT5Tokenizer.from_pretrained(BASE_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erBatikcK12u",
        "outputId": "22aefd46-d862-43c0-cded-5f0c1df741d0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
            "The class this function is called from is 'MT5Tokenizer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Load Evaluation Dataset ----------\n",
        "language_pair = \"en-fr\"\n",
        "subset_size = 100\n",
        "opus100_dataset = load_dataset(\"opus100\", language_pair)\n",
        "validation_subset = opus100_dataset[\"validation\"].select(range(subset_size))"
      ],
      "metadata": {
        "id": "nKyb9xXDK4bS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply noise (same as training)\n",
        "import random\n",
        "def apply_noise(text):\n",
        "    words = text.split()\n",
        "    noisy_words = []\n",
        "    for word in words:\n",
        "        if random.random() < 0.1:  # 10% chance to delete a word\n",
        "            continue\n",
        "        if random.random() < 0.1 and len(word) > 1:\n",
        "            char_list = list(word)\n",
        "            del char_list[random.randint(0, len(char_list) - 1)]\n",
        "            word = \"\".join(char_list)\n",
        "        noisy_words.append(word)\n",
        "    if len(noisy_words) > 1 and random.random() < 0.05:\n",
        "        swap_index = random.randint(0, len(noisy_words) - 2)\n",
        "        noisy_words[swap_index], noisy_words[swap_index + 1] = noisy_words[swap_index + 1], noisy_words[swap_index]\n",
        "    return \" \".join(noisy_words)"
      ],
      "metadata": {
        "id": "S9jvlGJpK682"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_subset = validation_subset.map(lambda ex: {\n",
        "    \"en_noisy\": apply_noise(ex[\"translation\"][\"en\"]),\n",
        "    \"fr_noisy\": apply_noise(ex[\"translation\"][\"fr\"]),\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ffd03db4f2c044cf8c749db1d6af6301",
            "408ed0b314834e1f8b1a5df10a39d018",
            "4cabdb87ea484bbf8c561f2f6c260ad0",
            "050a0ded3df44ec5b09ee00cfc8b340e",
            "7119638f0e134fb089e458af3bba1da4",
            "91151fb4459448aebaeff3e1649bf6cc",
            "3cbf2295faa34acc90d5d77cc4f20e43",
            "8adfc97b853143d38e6468b9e78804e5",
            "834bbb81422e40d4b675a846f367d3e5",
            "9550e41cf18947a4841b2e666f4e356b",
            "5acc861289d34ce5a27c46e9eae909bb"
          ]
        },
        "id": "N9H5i4XTLAKx",
        "outputId": "fd7565a0-6ccb-40bb-e0b3-a116a10dcbd1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffd03db4f2c044cf8c749db1d6af6301"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Evaluation Function ----------\n",
        "def evaluate_model(model, tokenizer, src_texts, tgt_texts, max_length=512):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for src, tgt in zip(src_texts, tgt_texts):\n",
        "        inputs = tokenizer(src, return_tensors=\"pt\", truncation=True, max_length=max_length).to(device)\n",
        "        with torch.no_grad():\n",
        "            output_ids = model.generate(**inputs, max_length=max_length)\n",
        "        pred = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "        predictions.append(pred)\n",
        "        references.append(tgt)\n",
        "\n",
        "    # Compute BLEU\n",
        "    references_tokenized = [[ref.split()] for ref in references]\n",
        "    predictions_tokenized = [pred.split() for pred in predictions]\n",
        "    bleu_score = corpus_bleu(references_tokenized, predictions_tokenized)\n",
        "\n",
        "    # Compute ROUGE\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = {'rouge1':0, 'rouge2':0, 'rougeL':0}\n",
        "    for ref, pred in zip(references, predictions):\n",
        "        score = scorer.score(ref, pred)\n",
        "        for k in rouge_scores:\n",
        "            rouge_scores[k] += score[k].fmeasure\n",
        "    for k in rouge_scores:\n",
        "        rouge_scores[k] /= len(predictions)\n",
        "\n",
        "    return bleu_score, rouge_scores, predictions, references"
      ],
      "metadata": {
        "id": "BZLyxywdLBpi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Prepare Source and Target Texts ----------\n",
        "\n",
        "# Use list comprehension instead of .apply()\n",
        "src_texts_en_fr = validation_subset[\"en_noisy\"]\n",
        "tgt_texts_en_fr = [x[\"fr\"] for x in validation_subset[\"translation\"]]\n",
        "\n",
        "src_texts_fr_en = validation_subset[\"fr_noisy\"]\n",
        "tgt_texts_fr_en = [x[\"en\"] for x in validation_subset[\"translation\"]]\n"
      ],
      "metadata": {
        "id": "a7hxKROCLE9t"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Evaluate Fine-Tuned Model ----------\n",
        "print(\"Evaluating Fine-Tuned MT5...\")\n",
        "bleu_en_fr_ft, rouge_en_fr_ft, _, _ = evaluate_model(fine_tuned_model, fine_tuned_tokenizer, src_texts_en_fr, tgt_texts_en_fr)\n",
        "bleu_fr_en_ft, rouge_fr_en_ft, _, _ = evaluate_model(fine_tuned_model, fine_tuned_tokenizer, src_texts_fr_en, tgt_texts_fr_en)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKwYBgC2LH2Y",
        "outputId": "89cf70db-f6a6-41f3-bd62-7188b02812f8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Fine-Tuned MT5...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Evaluate Base Model ----------\n",
        "print(\"Evaluating Base MT5...\")\n",
        "bleu_en_fr_base, rouge_en_fr_base, _, _ = evaluate_model(base_model, base_tokenizer, src_texts_en_fr, tgt_texts_en_fr)\n",
        "bleu_fr_en_base, rouge_fr_en_base, _, _ = evaluate_model(base_model, base_tokenizer, src_texts_fr_en, tgt_texts_fr_en)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTFqzvOcLb1k",
        "outputId": "13332a1f-3540-47ef-b5e1-56e2f5511a43"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Base MT5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Print Comparison ----------\n",
        "print(\"\\n==== EN -> FR ====\")\n",
        "print(f\"Fine-Tuned BLEU: {bleu_en_fr_ft:.4f}, ROUGE1: {rouge_en_fr_ft['rouge1']:.4f}\")\n",
        "print(f\"Base BLEU: {bleu_en_fr_base:.4f}, ROUGE1: {rouge_en_fr_base['rouge1']:.4f}\")\n",
        "\n",
        "print(\"\\n==== FR -> EN ====\")\n",
        "print(f\"Fine-Tuned BLEU: {bleu_fr_en_ft:.4f}, ROUGE1: {rouge_fr_en_ft['rouge1']:.4f}\")\n",
        "print(f\"Base BLEU: {bleu_fr_en_base:.4f}, ROUGE1: {rouge_fr_en_base['rouge1']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DaksL_MLnDq",
        "outputId": "55cbc538-8233-4346-fbb8-2fc074eb9e66"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== EN -> FR ====\n",
            "Fine-Tuned BLEU: 0.0087, ROUGE1: 0.1920\n",
            "Base BLEU: 0.0000, ROUGE1: 0.0013\n",
            "\n",
            "==== FR -> EN ====\n",
            "Fine-Tuned BLEU: 0.0122, ROUGE1: 0.2997\n",
            "Base BLEU: 0.0000, ROUGE1: 0.0019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Perplexity Evaluation Function ----------\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import math"
      ],
      "metadata": {
        "id": "tTvIow5dVV1v"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_perplexity(model, tokenizer, src_texts, tgt_texts, max_length=512):\n",
        "    model.eval()\n",
        "    loss_fct = CrossEntropyLoss(ignore_index=tokenizer.pad_token_id, reduction='sum')\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    for src, tgt in zip(src_texts, tgt_texts):\n",
        "        # Encode source and target\n",
        "        inputs = tokenizer(src, return_tensors=\"pt\", truncation=True, max_length=max_length).to(device)\n",
        "        labels = tokenizer(tgt, return_tensors=\"pt\", truncation=True, max_length=max_length).to(device)[\"input_ids\"]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], labels=labels)\n",
        "            # outputs.loss is averaged over batch, we compute sum manually\n",
        "            loss = loss_fct(outputs.logits.view(-1, outputs.logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_tokens += (labels != tokenizer.pad_token_id).sum().item()\n",
        "\n",
        "    perplexity = math.exp(total_loss / total_tokens)\n",
        "    return perplexity\n"
      ],
      "metadata": {
        "id": "VFKDlECTcJ3u"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Evaluate Perplexity ----------\n",
        "print(\"\\nEvaluating Perplexity...\")"
      ],
      "metadata": {
        "id": "kDkyeX6_cL7C",
        "outputId": "6818c04c-ce6f-4d60-8599-7dede50ab7a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Perplexity...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EN -> FR\n",
        "ppl_en_fr_ft = evaluate_perplexity(fine_tuned_model, fine_tuned_tokenizer, src_texts_en_fr, tgt_texts_en_fr)\n",
        "ppl_en_fr_base = evaluate_perplexity(base_model, base_tokenizer, src_texts_en_fr, tgt_texts_en_fr)"
      ],
      "metadata": {
        "id": "6YHw3RS9cNoV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FR -> EN\n",
        "ppl_fr_en_ft = evaluate_perplexity(fine_tuned_model, fine_tuned_tokenizer, src_texts_fr_en, tgt_texts_fr_en)\n",
        "ppl_fr_en_base = evaluate_perplexity(base_model, base_tokenizer, src_texts_fr_en, tgt_texts_fr_en)"
      ],
      "metadata": {
        "id": "Ebv7Yzhic0Yi"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Print Comparison ----------\n",
        "print(\"\\n==== Perplexity Comparison ====\")\n",
        "print(f\"EN -> FR | Fine-Tuned: {ppl_en_fr_ft:.4f}, Base: {ppl_en_fr_base:.4f}\")\n",
        "print(f\"FR -> EN | Fine-Tuned: {ppl_fr_en_ft:.4f}, Base: {ppl_fr_en_base:.4f}\")"
      ],
      "metadata": {
        "id": "CD-NAO2gc3rF",
        "outputId": "295df959-9e93-4470-864d-daec15ae3d7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Perplexity Comparison ====\n",
            "EN -> FR | Fine-Tuned: 13.5817, Base: 72017926346.2707\n",
            "FR -> EN | Fine-Tuned: 20.2271, Base: 49482446559.1583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ZW4rxNIc6EZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}