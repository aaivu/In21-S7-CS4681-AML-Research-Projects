{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab00dd1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:22.695924Z",
     "iopub.status.busy": "2025-08-27T19:13:22.695624Z",
     "iopub.status.idle": "2025-08-27T19:13:27.966310Z",
     "shell.execute_reply": "2025-08-27T19:13:27.965543Z"
    },
    "papermill": {
     "duration": 5.276736,
     "end_time": "2025-08-27T19:13:27.967678",
     "exception": false,
     "start_time": "2025-08-27T19:13:22.690942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data/LOG_CHESTXRAY.pdf\n",
      "/kaggle/input/data/README_CHESTXRAY.pdf\n",
      "/kaggle/input/data/BBox_List_2017.csv\n",
      "/kaggle/input/data/test_list.txt\n",
      "/kaggle/input/data/ARXIV_V5_CHESTXRAY.pdf\n",
      "/kaggle/input/data/Data_Entry_2017.csv\n",
      "/kaggle/input/data/train_val_list.txt\n",
      "/kaggle/input/data/FAQ_CHESTXRAY.pdf\n",
      "/kaggle/input/data/images_003/images/00006199_010.png\n",
      "/kaggle/input/data/images_003/images/00004833_016.png\n",
      "/kaggle/input/data/images_003/images/00006260_000.png\n",
      "/kaggle/input/data/images_003/images/00004911_010.png\n",
      "/kaggle/input/data/images_003/images/00004186_007.png\n",
      "/kaggle/input/data/images_003/images/00004459_000.png\n",
      "/kaggle/input/data/images_003/images/00005004_001.png\n",
      "/kaggle/input/data/images_003/images/00005757_000.png\n",
      "/kaggle/input/data/images_003/images/00004221_001.png\n",
      "/kaggle/input/data/images_003/images/00004875_000.png\n",
      "/kaggle/input/data/images_003/images/00005448_001.png\n",
      "/kaggle/input/data/images_003/images/00005572_000.png\n",
      "/kaggle/input/data/images_003/images/00005271_002.png\n",
      "/kaggle/input/data/images_003/images/00004608_011.png\n",
      "/kaggle/input/data/images_003/images/00004067_000.png\n",
      "/kaggle/input/data/images_003/images/00006330_008.png\n",
      "/kaggle/input/data/images_003/images/00006301_001.png\n",
      "/kaggle/input/data/images_003/images/00005575_000.png\n",
      "/kaggle/input/data/images_003/images/00004824_014.png\n",
      "/kaggle/input/data/images_003/images/00004526_013.png\n",
      "/kaggle/input/data/images_003/images/00005720_000.png\n",
      "/kaggle/input/data/images_003/images/00004851_002.png\n",
      "/kaggle/input/data/images_003/images/00005532_023.png\n",
      "/kaggle/input/data/images_003/images/00006382_000.png\n",
      "/kaggle/input/data/images_003/images/00005769_000.png\n",
      "/kaggle/input/data/images_003/images/00005268_000.png\n",
      "/kaggle/input/data/images_003/images/00004436_008.png\n",
      "/kaggle/input/data/images_003/images/00004006_016.png\n",
      "/kaggle/input/data/images_003/images/00004876_001.png\n",
      "/kaggle/input/data/images_003/images/00004787_006.png\n",
      "/kaggle/input/data/images_003/images/00004156_008.png\n",
      "/kaggle/input/data/images_003/images/00006195_005.png\n",
      "/kaggle/input/data/images_003/images/00004441_000.png\n",
      "/kaggle/input/data/images_003/images/00004381_015.png\n",
      "/kaggle/input/data/images_003/images/00005220_010.png\n",
      "/kaggle/input/data/images_003/images/00004957_001.png\n",
      "/kaggle/input/data/images_003/images/00006517_009.png\n",
      "/kaggle/input/data/images_003/images/00004171_001.png\n",
      "/kaggle/input/data/images_003/images/00004338_010.png\n",
      "/kaggle/input/data/images_003/images/00004344_001.png\n",
      "/kaggle/input/data/images_003/images/00006035_004.png\n",
      "/kaggle/input/data/images_003/images/00004342_008.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "max_files = 50  # number of files to print\n",
    "count = 0\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        count += 1\n",
    "        if count >= max_files:\n",
    "            break\n",
    "    if count >= max_files:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4b51fa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:27.975446Z",
     "iopub.status.busy": "2025-08-27T19:13:27.975034Z",
     "iopub.status.idle": "2025-08-27T19:13:27.978558Z",
     "shell.execute_reply": "2025-08-27T19:13:27.977891Z"
    },
    "papermill": {
     "duration": 0.008352,
     "end_time": "2025-08-27T19:13:27.979751",
     "exception": false,
     "start_time": "2025-08-27T19:13:27.971399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb084ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:27.986784Z",
     "iopub.status.busy": "2025-08-27T19:13:27.986296Z",
     "iopub.status.idle": "2025-08-27T19:13:39.254656Z",
     "shell.execute_reply": "2025-08-27T19:13:39.253997Z"
    },
    "papermill": {
     "duration": 11.273314,
     "end_time": "2025-08-27T19:13:39.256219",
     "exception": false,
     "start_time": "2025-08-27T19:13:27.982905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4739ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:39.262898Z",
     "iopub.status.busy": "2025-08-27T19:13:39.262513Z",
     "iopub.status.idle": "2025-08-27T19:13:39.266243Z",
     "shell.execute_reply": "2025-08-27T19:13:39.265530Z"
    },
    "papermill": {
     "duration": 0.008097,
     "end_time": "2025-08-27T19:13:39.267305",
     "exception": false,
     "start_time": "2025-08-27T19:13:39.259208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc312f30",
   "metadata": {},
   "source": [
    "### Paths & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b175af16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:39.273792Z",
     "iopub.status.busy": "2025-08-27T19:13:39.273547Z",
     "iopub.status.idle": "2025-08-27T19:13:39.353638Z",
     "shell.execute_reply": "2025-08-27T19:13:39.352773Z"
    },
    "papermill": {
     "duration": 0.084807,
     "end_time": "2025-08-27T19:13:39.355097",
     "exception": false,
     "start_time": "2025-08-27T19:13:39.270290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = \"/kaggle/input/data/Data_Entry_2017.csv\"\n",
    "train_val_list = \"/kaggle/input/data/train_val_list.txt\"\n",
    "test_list = \"/kaggle/input/data/test_list.txt\"\n",
    "data_dir = \"/kaggle/input/data\"\n",
    "\n",
    "all_labels = [\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\",\n",
    "              \"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\", \"Consolidation\",\n",
    "              \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"]\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASSES = len(all_labels)\n",
    "NUM_EPOCHS = 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63d08b",
   "metadata": {},
   "source": [
    "### Load metadata & encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89750af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:39.361633Z",
     "iopub.status.busy": "2025-08-27T19:13:39.361417Z",
     "iopub.status.idle": "2025-08-27T19:13:44.415900Z",
     "shell.execute_reply": "2025-08-27T19:13:44.414988Z"
    },
    "papermill": {
     "duration": 5.059165,
     "end_time": "2025-08-27T19:13:44.417276",
     "exception": false,
     "start_time": "2025-08-27T19:13:39.358111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "def encode_labels(label_string):\n",
    "    labels = [0] * NUM_CLASSES\n",
    "    for i, cls in enumerate(all_labels):\n",
    "        if cls in label_string:\n",
    "            labels[i] = 1\n",
    "    return labels\n",
    "\n",
    "label_map = {row[\"Image Index\"]: encode_labels(row[\"Finding Labels\"]) for _, row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08184114",
   "metadata": {},
   "source": [
    "### Read train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf9c70f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:44.424615Z",
     "iopub.status.busy": "2025-08-27T19:13:44.424334Z",
     "iopub.status.idle": "2025-08-27T19:13:44.550835Z",
     "shell.execute_reply": "2025-08-27T19:13:44.549930Z"
    },
    "papermill": {
     "duration": 0.131489,
     "end_time": "2025-08-27T19:13:44.552144",
     "exception": false,
     "start_time": "2025-08-27T19:13:44.420655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 69625\n",
      "Number of validation images: 16899\n",
      "Number of test images: 25596\n"
     ]
    }
   ],
   "source": [
    "with open(train_val_list, \"r\") as f:\n",
    "    train_val_imgs = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open(test_list, \"r\") as f:\n",
    "    test_imgs = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Filter train/val dataframe\n",
    "train_val_df = df[df[\"Image Index\"].isin(train_val_imgs)]\n",
    "\n",
    "# Patient-level split (no overlap)\n",
    "patients = train_val_df[\"Patient ID\"].unique()\n",
    "train_patients, val_patients = train_test_split(patients, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = train_val_df[train_val_df[\"Patient ID\"].isin(train_patients)]\n",
    "val_df = train_val_df[train_val_df[\"Patient ID\"].isin(val_patients)]\n",
    "\n",
    "train_imgs = train_df[\"Image Index\"].tolist()\n",
    "val_imgs = val_df[\"Image Index\"].tolist()\n",
    "\n",
    "test_df = df[df[\"Image Index\"].isin(test_imgs)]\n",
    "test_imgs = test_df[\"Image Index\"].tolist()\n",
    "\n",
    "print(f\"Number of training images: {len(train_imgs)}\")\n",
    "print(f\"Number of validation images: {len(val_imgs)}\")\n",
    "print(f\"Number of test images: {len(test_imgs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012f4df",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "295cad56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:44.559299Z",
     "iopub.status.busy": "2025-08-27T19:13:44.559063Z",
     "iopub.status.idle": "2025-08-27T19:13:44.567604Z",
     "shell.execute_reply": "2025-08-27T19:13:44.566929Z"
    },
    "papermill": {
     "duration": 0.013249,
     "end_time": "2025-08-27T19:13:44.568730",
     "exception": false,
     "start_time": "2025-08-27T19:13:44.555481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, img_list, labels, root_dir, transform=None):\n",
    "        self.img_list = img_list\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx]\n",
    "        # Search in subfolders\n",
    "        img_path = None\n",
    "        for part in os.listdir(self.root_dir):\n",
    "            possible_path = os.path.join(self.root_dir, part, \"images\", img_name)\n",
    "            if os.path.exists(possible_path):\n",
    "                img_path = possible_path\n",
    "                break\n",
    "        if img_path is None:\n",
    "            raise FileNotFoundError(f\"{img_name} not found in {self.root_dir}\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = torch.FloatTensor(self.labels[img_name])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65801435",
   "metadata": {},
   "source": [
    "### Transforms with additional augmentation methods & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7becae57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:44.575274Z",
     "iopub.status.busy": "2025-08-27T19:13:44.575028Z",
     "iopub.status.idle": "2025-08-27T19:13:44.582041Z",
     "shell.execute_reply": "2025-08-27T19:13:44.581074Z"
    },
    "papermill": {
     "duration": 0.01166,
     "end_time": "2025-08-27T19:13:44.583242",
     "exception": false,
     "start_time": "2025-08-27T19:13:44.571582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.1)),  # random zoom & crop\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # random translations\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "])\n",
    "\n",
    "train_dataset = ChestXrayDataset(train_imgs, label_map, data_dir, train_transform)\n",
    "val_dataset   = ChestXrayDataset(val_imgs, label_map, data_dir, val_test_transform)\n",
    "test_dataset  = ChestXrayDataset(test_imgs, label_map, data_dir, val_test_transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538db74",
   "metadata": {},
   "source": [
    "### Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25827223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:44.589737Z",
     "iopub.status.busy": "2025-08-27T19:13:44.589345Z",
     "iopub.status.idle": "2025-08-27T19:13:44.594448Z",
     "shell.execute_reply": "2025-08-27T19:13:44.593768Z"
    },
    "papermill": {
     "duration": 0.009448,
     "end_time": "2025-08-27T19:13:44.595612",
     "exception": false,
     "start_time": "2025-08-27T19:13:44.586164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)  # probability of being classified correctly\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        return focal_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05450cc4",
   "metadata": {},
   "source": [
    "### Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c6cdf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:44.602556Z",
     "iopub.status.busy": "2025-08-27T19:13:44.602367Z",
     "iopub.status.idle": "2025-08-27T19:13:45.335568Z",
     "shell.execute_reply": "2025-08-27T19:13:45.334744Z"
    },
    "papermill": {
     "duration": 0.737747,
     "end_time": "2025-08-27T19:13:45.336972",
     "exception": false,
     "start_time": "2025-08-27T19:13:44.599225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 139MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = FocalLoss(alpha=1, gamma=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.9,0.999))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffeba3e",
   "metadata": {},
   "source": [
    "### Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fee860c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:45.344157Z",
     "iopub.status.busy": "2025-08-27T19:13:45.343938Z",
     "iopub.status.idle": "2025-08-27T19:13:45.350939Z",
     "shell.execute_reply": "2025-08-27T19:13:45.350391Z"
    },
    "papermill": {
     "duration": 0.011707,
     "end_time": "2025-08-27T19:13:45.351948",
     "exception": false,
     "start_time": "2025-08-27T19:13:45.340241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_outputs.append(outputs.cpu())\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_outputs = torch.cat(all_outputs).numpy()\n",
    "    # AUROC per class\n",
    "    aucs = []\n",
    "    for i in range(all_labels.shape[1]):\n",
    "        if all_labels[:, i].sum() > 0:\n",
    "            aucs.append(roc_auc_score(all_labels[:, i], all_outputs[:, i]))\n",
    "    mean_auc = sum(aucs) / len(aucs) if aucs else 0.0\n",
    "    return total_loss / len(loader.dataset), mean_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffefb232",
   "metadata": {},
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17740407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T19:13:45.358775Z",
     "iopub.status.busy": "2025-08-27T19:13:45.358544Z",
     "iopub.status.idle": "2025-08-27T23:54:47.100903Z",
     "shell.execute_reply": "2025-08-27T23:54:47.100088Z"
    },
    "papermill": {
     "duration": 16861.748434,
     "end_time": "2025-08-27T23:54:47.103453",
     "exception": false,
     "start_time": "2025-08-27T19:13:45.355019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0415 | Val Loss: 0.0384 | Val AUROC: 0.7966\n",
      "Best model saved.\n",
      "\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0388 | Val Loss: 0.0374 | Val AUROC: 0.8145\n",
      "Best model saved.\n",
      "\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0380 | Val Loss: 0.0369 | Val AUROC: 0.8215\n",
      "Best model saved.\n",
      "\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0373 | Val Loss: 0.0366 | Val AUROC: 0.8276\n",
      "Best model saved.\n",
      "\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0368 | Val Loss: 0.0363 | Val AUROC: 0.8285\n",
      "Best model saved.\n",
      "\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0363 | Val Loss: 0.0363 | Val AUROC: 0.8318\n",
      "Best model saved.\n",
      "\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0358 | Val Loss: 0.0375 | Val AUROC: 0.8247\n",
      "\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0354 | Val Loss: 0.0368 | Val AUROC: 0.8308\n",
      "\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0337 | Val Loss: 0.0358 | Val AUROC: 0.8398\n",
      "Best model saved.\n",
      "\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0330 | Val Loss: 0.0359 | Val AUROC: 0.8378\n",
      "\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0327 | Val Loss: 0.0363 | Val AUROC: 0.8363\n",
      "\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0324 | Val Loss: 0.0363 | Val AUROC: 0.8369\n",
      "\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0323 | Val Loss: 0.0364 | Val AUROC: 0.8370\n",
      "\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0323 | Val Loss: 0.0361 | Val AUROC: 0.8368\n",
      "\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0322 | Val Loss: 0.0361 | Val AUROC: 0.8361\n"
     ]
    }
   ],
   "source": [
    "best_auc = 0.0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "    val_loss, val_auc = validate(model, val_loader, criterion, DEVICE)\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUROC: {val_auc:.4f}\")\n",
    "    # Save best model\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), \"best_chexnet.pth\")\n",
    "        print(\"Best model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43aeae",
   "metadata": {},
   "source": [
    "### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67db8048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:54:53.499846Z",
     "iopub.status.busy": "2025-08-27T23:54:53.498935Z",
     "iopub.status.idle": "2025-08-27T23:59:41.922912Z",
     "shell.execute_reply": "2025-08-27T23:59:41.921992Z"
    },
    "papermill": {
     "duration": 291.609189,
     "end_time": "2025-08-27T23:59:41.924107",
     "exception": false,
     "start_time": "2025-08-27T23:54:50.314918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Loss: 0.0553 | Test AUROC: 0.8143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_chexnet.pth\"))\n",
    "test_loss, test_auc = validate(model, test_loader, criterion, DEVICE)\n",
    "print(f\"\\nFinal Test Loss: {test_loss:.4f} | Test AUROC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f73061b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:59:48.485242Z",
     "iopub.status.busy": "2025-08-27T23:59:48.484960Z",
     "iopub.status.idle": "2025-08-27T23:59:48.492978Z",
     "shell.execute_reply": "2025-08-27T23:59:48.492399Z"
    },
    "papermill": {
     "duration": 3.323063,
     "end_time": "2025-08-27T23:59:48.494114",
     "exception": false,
     "start_time": "2025-08-27T23:59:45.171051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, dataloader, device, all_labels, threshold=0.5):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.cpu().numpy()\n",
    "            outputs = torch.sigmoid(model(images)).cpu().numpy()\n",
    "            \n",
    "            y_true.append(targets)\n",
    "            y_pred.append(outputs)\n",
    "\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_pred = np.vstack(y_pred)\n",
    "\n",
    "    per_class_auc = {}\n",
    "    per_class_f1 = {}\n",
    "\n",
    "    for i, cls in enumerate(all_labels):\n",
    "        if y_true[:, i].sum() > 0:  # class has at least one positive\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "            except ValueError:\n",
    "                auc = float('nan')\n",
    "            per_class_auc[cls] = auc\n",
    "\n",
    "            # binarize predictions\n",
    "            y_bin = (y_pred[:, i] >= threshold).astype(int)\n",
    "            f1 = f1_score(y_true[:, i], y_bin, zero_division=0)\n",
    "            per_class_f1[cls] = f1\n",
    "        else:\n",
    "            per_class_auc[cls] = float('nan')\n",
    "            per_class_f1[cls] = float('nan')\n",
    "\n",
    "    mean_auc = np.nanmean(list(per_class_auc.values()))\n",
    "    mean_f1 = np.nanmean(list(per_class_f1.values()))\n",
    "\n",
    "    return per_class_auc, mean_auc, per_class_f1, mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39917076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T23:59:55.150385Z",
     "iopub.status.busy": "2025-08-27T23:59:55.150105Z",
     "iopub.status.idle": "2025-08-28T00:03:39.382130Z",
     "shell.execute_reply": "2025-08-28T00:03:39.381220Z"
    },
    "papermill": {
     "duration": 230.690943,
     "end_time": "2025-08-28T00:03:42.583205",
     "exception": false,
     "start_time": "2025-08-27T23:59:51.892262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class AUCs:\n",
      "Atelectasis: 0.7762\n",
      "Cardiomegaly: 0.8921\n",
      "Effusion: 0.8316\n",
      "Infiltration: 0.6876\n",
      "Mass: 0.8227\n",
      "Nodule: 0.7609\n",
      "Pneumonia: 0.7228\n",
      "Pneumothorax: 0.8569\n",
      "Consolidation: 0.7530\n",
      "Edema: 0.8474\n",
      "Emphysema: 0.9179\n",
      "Fibrosis: 0.8282\n",
      "Pleural_Thickening: 0.7738\n",
      "Hernia: 0.9290\n",
      "\n",
      "Per-class F1 scores:\n",
      "Atelectasis: 0.2467\n",
      "Cardiomegaly: 0.3027\n",
      "Effusion: 0.4667\n",
      "Infiltration: 0.3063\n",
      "Mass: 0.2820\n",
      "Nodule: 0.0954\n",
      "Pneumonia: 0.0000\n",
      "Pneumothorax: 0.2703\n",
      "Consolidation: 0.0119\n",
      "Edema: 0.0682\n",
      "Emphysema: 0.4191\n",
      "Fibrosis: 0.0304\n",
      "Pleural_Thickening: 0.0331\n",
      "Hernia: 0.4812\n",
      "\n",
      "Mean AUC (14 classes): 0.8143\n",
      "Mean F1 (14 classes): 0.2153\n"
     ]
    }
   ],
   "source": [
    "per_class_auc, mean_auc, per_class_f1, mean_f1 = evaluate_metrics(model, test_loader, DEVICE, all_labels)\n",
    "\n",
    "print(\"Per-class AUCs:\")\n",
    "for disease, auc in per_class_auc.items():\n",
    "    print(f\"{disease}: {auc:.4f}\")\n",
    "\n",
    "print(\"\\nPer-class F1 scores:\")\n",
    "for disease, f1 in per_class_f1.items():\n",
    "    print(f\"{disease}: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nMean AUC (14 classes): {mean_auc:.4f}\")\n",
    "print(f\"Mean F1 (14 classes): {mean_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5839,
     "sourceId": 18613,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17430.105743,
   "end_time": "2025-08-28T00:03:48.892852",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-27T19:13:18.787109",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
