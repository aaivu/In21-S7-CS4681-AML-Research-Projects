{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffbeaef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:21:47.904972Z",
     "iopub.status.busy": "2025-08-28T05:21:47.904706Z",
     "iopub.status.idle": "2025-08-28T05:22:00.045259Z",
     "shell.execute_reply": "2025-08-28T05:22:00.044506Z"
    },
    "papermill": {
     "duration": 12.146481,
     "end_time": "2025-08-28T05:22:00.046956",
     "exception": false,
     "start_time": "2025-08-28T05:21:47.900475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data/LOG_CHESTXRAY.pdf\n",
      "/kaggle/input/data/README_CHESTXRAY.pdf\n",
      "/kaggle/input/data/BBox_List_2017.csv\n",
      "/kaggle/input/data/test_list.txt\n",
      "/kaggle/input/data/ARXIV_V5_CHESTXRAY.pdf\n",
      "/kaggle/input/data/Data_Entry_2017.csv\n",
      "/kaggle/input/data/train_val_list.txt\n",
      "/kaggle/input/data/FAQ_CHESTXRAY.pdf\n",
      "/kaggle/input/data/images_003/images/00006199_010.png\n",
      "/kaggle/input/data/images_003/images/00004833_016.png\n",
      "/kaggle/input/data/images_003/images/00006260_000.png\n",
      "/kaggle/input/data/images_003/images/00004911_010.png\n",
      "/kaggle/input/data/images_003/images/00004186_007.png\n",
      "/kaggle/input/data/images_003/images/00004459_000.png\n",
      "/kaggle/input/data/images_003/images/00005004_001.png\n",
      "/kaggle/input/data/images_003/images/00005757_000.png\n",
      "/kaggle/input/data/images_003/images/00004221_001.png\n",
      "/kaggle/input/data/images_003/images/00004875_000.png\n",
      "/kaggle/input/data/images_003/images/00005448_001.png\n",
      "/kaggle/input/data/images_003/images/00005572_000.png\n",
      "/kaggle/input/data/images_003/images/00005271_002.png\n",
      "/kaggle/input/data/images_003/images/00004608_011.png\n",
      "/kaggle/input/data/images_003/images/00004067_000.png\n",
      "/kaggle/input/data/images_003/images/00006330_008.png\n",
      "/kaggle/input/data/images_003/images/00006301_001.png\n",
      "/kaggle/input/data/images_003/images/00005575_000.png\n",
      "/kaggle/input/data/images_003/images/00004824_014.png\n",
      "/kaggle/input/data/images_003/images/00004526_013.png\n",
      "/kaggle/input/data/images_003/images/00005720_000.png\n",
      "/kaggle/input/data/images_003/images/00004851_002.png\n",
      "/kaggle/input/data/images_003/images/00005532_023.png\n",
      "/kaggle/input/data/images_003/images/00006382_000.png\n",
      "/kaggle/input/data/images_003/images/00005769_000.png\n",
      "/kaggle/input/data/images_003/images/00005268_000.png\n",
      "/kaggle/input/data/images_003/images/00004436_008.png\n",
      "/kaggle/input/data/images_003/images/00004006_016.png\n",
      "/kaggle/input/data/images_003/images/00004876_001.png\n",
      "/kaggle/input/data/images_003/images/00004787_006.png\n",
      "/kaggle/input/data/images_003/images/00004156_008.png\n",
      "/kaggle/input/data/images_003/images/00006195_005.png\n",
      "/kaggle/input/data/images_003/images/00004441_000.png\n",
      "/kaggle/input/data/images_003/images/00004381_015.png\n",
      "/kaggle/input/data/images_003/images/00005220_010.png\n",
      "/kaggle/input/data/images_003/images/00004957_001.png\n",
      "/kaggle/input/data/images_003/images/00006517_009.png\n",
      "/kaggle/input/data/images_003/images/00004171_001.png\n",
      "/kaggle/input/data/images_003/images/00004338_010.png\n",
      "/kaggle/input/data/images_003/images/00004344_001.png\n",
      "/kaggle/input/data/images_003/images/00006035_004.png\n",
      "/kaggle/input/data/images_003/images/00004342_008.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "max_files = 50  # number of files to print\n",
    "count = 0\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        count += 1\n",
    "        if count >= max_files:\n",
    "            break\n",
    "    if count >= max_files:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7858b7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:00.054228Z",
     "iopub.status.busy": "2025-08-28T05:22:00.053958Z",
     "iopub.status.idle": "2025-08-28T05:22:00.057479Z",
     "shell.execute_reply": "2025-08-28T05:22:00.056933Z"
    },
    "papermill": {
     "duration": 0.008271,
     "end_time": "2025-08-28T05:22:00.058593",
     "exception": false,
     "start_time": "2025-08-28T05:22:00.050322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd13500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:00.065014Z",
     "iopub.status.busy": "2025-08-28T05:22:00.064808Z",
     "iopub.status.idle": "2025-08-28T05:22:11.228235Z",
     "shell.execute_reply": "2025-08-28T05:22:11.227407Z"
    },
    "papermill": {
     "duration": 11.168417,
     "end_time": "2025-08-28T05:22:11.229827",
     "exception": false,
     "start_time": "2025-08-28T05:22:00.061410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b43ac66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:11.236478Z",
     "iopub.status.busy": "2025-08-28T05:22:11.236088Z",
     "iopub.status.idle": "2025-08-28T05:22:11.239823Z",
     "shell.execute_reply": "2025-08-28T05:22:11.239106Z"
    },
    "papermill": {
     "duration": 0.00817,
     "end_time": "2025-08-28T05:22:11.240941",
     "exception": false,
     "start_time": "2025-08-28T05:22:11.232771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a534860",
   "metadata": {},
   "source": [
    "### Paths & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29acd190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:11.247262Z",
     "iopub.status.busy": "2025-08-28T05:22:11.247007Z",
     "iopub.status.idle": "2025-08-28T05:22:11.328353Z",
     "shell.execute_reply": "2025-08-28T05:22:11.327695Z"
    },
    "papermill": {
     "duration": 0.085708,
     "end_time": "2025-08-28T05:22:11.329397",
     "exception": false,
     "start_time": "2025-08-28T05:22:11.243689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_path = \"/kaggle/input/data/Data_Entry_2017.csv\"\n",
    "train_val_list = \"/kaggle/input/data/train_val_list.txt\"\n",
    "test_list = \"/kaggle/input/data/test_list.txt\"\n",
    "data_dir = \"/kaggle/input/data\"\n",
    "\n",
    "all_labels = [\"Atelectasis\", \"Cardiomegaly\", \"Effusion\", \"Infiltration\",\n",
    "              \"Mass\", \"Nodule\", \"Pneumonia\", \"Pneumothorax\", \"Consolidation\",\n",
    "              \"Edema\", \"Emphysema\", \"Fibrosis\", \"Pleural_Thickening\", \"Hernia\"]\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_CLASSES = len(all_labels)\n",
    "NUM_EPOCHS = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf42e3",
   "metadata": {},
   "source": [
    "### Load metadata & encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1994588c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:11.335958Z",
     "iopub.status.busy": "2025-08-28T05:22:11.335570Z",
     "iopub.status.idle": "2025-08-28T05:22:16.049953Z",
     "shell.execute_reply": "2025-08-28T05:22:16.049373Z"
    },
    "papermill": {
     "duration": 4.719025,
     "end_time": "2025-08-28T05:22:16.051313",
     "exception": false,
     "start_time": "2025-08-28T05:22:11.332288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "def encode_labels(label_string):\n",
    "    labels = [0] * NUM_CLASSES\n",
    "    for i, cls in enumerate(all_labels):\n",
    "        if cls in label_string:\n",
    "            labels[i] = 1\n",
    "    return labels\n",
    "\n",
    "label_map = {row[\"Image Index\"]: encode_labels(row[\"Finding Labels\"]) for _, row in df.iterrows()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96320a39",
   "metadata": {},
   "source": [
    "### Read train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85426612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:16.057993Z",
     "iopub.status.busy": "2025-08-28T05:22:16.057764Z",
     "iopub.status.idle": "2025-08-28T05:22:16.173087Z",
     "shell.execute_reply": "2025-08-28T05:22:16.172244Z"
    },
    "papermill": {
     "duration": 0.12016,
     "end_time": "2025-08-28T05:22:16.174581",
     "exception": false,
     "start_time": "2025-08-28T05:22:16.054421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 69625\n",
      "Number of validation images: 16899\n",
      "Number of test images: 25596\n"
     ]
    }
   ],
   "source": [
    "with open(train_val_list, \"r\") as f:\n",
    "    train_val_imgs = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open(test_list, \"r\") as f:\n",
    "    test_imgs = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Filter train/val dataframe\n",
    "train_val_df = df[df[\"Image Index\"].isin(train_val_imgs)]\n",
    "\n",
    "# Patient-level split (no overlap)\n",
    "patients = train_val_df[\"Patient ID\"].unique()\n",
    "train_patients, val_patients = train_test_split(patients, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = train_val_df[train_val_df[\"Patient ID\"].isin(train_patients)]\n",
    "val_df = train_val_df[train_val_df[\"Patient ID\"].isin(val_patients)]\n",
    "\n",
    "train_imgs = train_df[\"Image Index\"].tolist()\n",
    "val_imgs = val_df[\"Image Index\"].tolist()\n",
    "\n",
    "test_df = df[df[\"Image Index\"].isin(test_imgs)]\n",
    "test_imgs = test_df[\"Image Index\"].tolist()\n",
    "\n",
    "print(f\"Number of training images: {len(train_imgs)}\")\n",
    "print(f\"Number of validation images: {len(val_imgs)}\")\n",
    "print(f\"Number of test images: {len(test_imgs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e9531",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51e7c9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:16.181657Z",
     "iopub.status.busy": "2025-08-28T05:22:16.181417Z",
     "iopub.status.idle": "2025-08-28T05:22:16.190383Z",
     "shell.execute_reply": "2025-08-28T05:22:16.189667Z"
    },
    "papermill": {
     "duration": 0.01342,
     "end_time": "2025-08-28T05:22:16.191475",
     "exception": false,
     "start_time": "2025-08-28T05:22:16.178055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, img_list, labels, root_dir, transform=None):\n",
    "        self.img_list = img_list\n",
    "        self.labels = labels\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_list[idx]\n",
    "        # Search in subfolders\n",
    "        img_path = None\n",
    "        for part in os.listdir(self.root_dir):\n",
    "            possible_path = os.path.join(self.root_dir, part, \"images\", img_name)\n",
    "            if os.path.exists(possible_path):\n",
    "                img_path = possible_path\n",
    "                break\n",
    "        if img_path is None:\n",
    "            raise FileNotFoundError(f\"{img_name} not found in {self.root_dir}\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = torch.FloatTensor(self.labels[img_name])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7652143c",
   "metadata": {},
   "source": [
    "### Transforms & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7010bdab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:16.197692Z",
     "iopub.status.busy": "2025-08-28T05:22:16.197472Z",
     "iopub.status.idle": "2025-08-28T05:22:16.202971Z",
     "shell.execute_reply": "2025-08-28T05:22:16.202468Z"
    },
    "papermill": {
     "duration": 0.009817,
     "end_time": "2025-08-28T05:22:16.204014",
     "exception": false,
     "start_time": "2025-08-28T05:22:16.194197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ChestXrayDataset(train_imgs, label_map, data_dir, transform=train_transform)\n",
    "val_dataset   = ChestXrayDataset(val_imgs, label_map, data_dir, transform=val_test_transform)\n",
    "test_dataset  = ChestXrayDataset(test_imgs, label_map, data_dir, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d5195",
   "metadata": {},
   "source": [
    "### Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "256e0331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:16.210118Z",
     "iopub.status.busy": "2025-08-28T05:22:16.209917Z",
     "iopub.status.idle": "2025-08-28T05:22:16.926508Z",
     "shell.execute_reply": "2025-08-28T05:22:16.925643Z"
    },
    "papermill": {
     "duration": 0.721192,
     "end_time": "2025-08-28T05:22:16.927932",
     "exception": false,
     "start_time": "2025-08-28T05:22:16.206740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 158MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.9,0.999))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e48ee1",
   "metadata": {},
   "source": [
    "### Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c817002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:16.936175Z",
     "iopub.status.busy": "2025-08-28T05:22:16.935516Z",
     "iopub.status.idle": "2025-08-28T05:22:16.943008Z",
     "shell.execute_reply": "2025-08-28T05:22:16.942285Z"
    },
    "papermill": {
     "duration": 0.012946,
     "end_time": "2025-08-28T05:22:16.944119",
     "exception": false,
     "start_time": "2025-08-28T05:22:16.931173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\", leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_outputs.append(outputs.cpu())\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_outputs = torch.cat(all_outputs).numpy()\n",
    "    # AUROC per class\n",
    "    aucs = []\n",
    "    for i in range(all_labels.shape[1]):\n",
    "        if all_labels[:, i].sum() > 0:\n",
    "            aucs.append(roc_auc_score(all_labels[:, i], all_outputs[:, i]))\n",
    "    mean_auc = sum(aucs) / len(aucs) if aucs else 0.0\n",
    "    return total_loss / len(loader.dataset), mean_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d4bc6",
   "metadata": {},
   "source": [
    "### Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6e7170a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T05:22:16.950832Z",
     "iopub.status.busy": "2025-08-28T05:22:16.950626Z",
     "iopub.status.idle": "2025-08-28T09:27:05.688145Z",
     "shell.execute_reply": "2025-08-28T09:27:05.687241Z"
    },
    "papermill": {
     "duration": 14688.742431,
     "end_time": "2025-08-28T09:27:05.689485",
     "exception": false,
     "start_time": "2025-08-28T05:22:16.947054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1462 | Val Loss: 0.1350 | Val AUROC: 0.8009\n",
      "Best model saved.\n",
      "\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1343 | Val Loss: 0.1318 | Val AUROC: 0.8246\n",
      "Best model saved.\n",
      "\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1303 | Val Loss: 0.1311 | Val AUROC: 0.8285\n",
      "Best model saved.\n",
      "\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1267 | Val Loss: 0.1306 | Val AUROC: 0.8361\n",
      "Best model saved.\n",
      "\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1230 | Val Loss: 0.1310 | Val AUROC: 0.8326\n",
      "\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1186 | Val Loss: 0.1326 | Val AUROC: 0.8247\n",
      "\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1056 | Val Loss: 0.1326 | Val AUROC: 0.8301\n",
      "\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0997 | Val Loss: 0.1349 | Val AUROC: 0.8257\n",
      "\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0954 | Val Loss: 0.1353 | Val AUROC: 0.8235\n",
      "\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0945 | Val Loss: 0.1359 | Val AUROC: 0.8248\n",
      "\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0942 | Val Loss: 0.1357 | Val AUROC: 0.8244\n",
      "\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0941 | Val Loss: 0.1357 | Val AUROC: 0.8237\n",
      "\n",
      "Epoch 13/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0942 | Val Loss: 0.1359 | Val AUROC: 0.8243\n",
      "\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0941 | Val Loss: 0.1357 | Val AUROC: 0.8239\n",
      "\n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0941 | Val Loss: 0.1359 | Val AUROC: 0.8236\n"
     ]
    }
   ],
   "source": [
    "best_auc = 0.0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "    val_loss, val_auc = validate(model, val_loader, criterion, DEVICE)\n",
    "    scheduler.step(val_loss)\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUROC: {val_auc:.4f}\")\n",
    "    # Save best model\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        torch.save(model.state_dict(), \"best_chexnet.pth\")\n",
    "        print(\"Best model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552e1abe",
   "metadata": {},
   "source": [
    "### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5119cbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T09:27:12.104255Z",
     "iopub.status.busy": "2025-08-28T09:27:12.103931Z",
     "iopub.status.idle": "2025-08-28T09:31:49.119537Z",
     "shell.execute_reply": "2025-08-28T09:31:49.118597Z"
    },
    "papermill": {
     "duration": 280.299416,
     "end_time": "2025-08-28T09:31:49.120995",
     "exception": false,
     "start_time": "2025-08-28T09:27:08.821579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Loss: 0.2029 | Test AUROC: 0.8066\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_chexnet.pth\"))\n",
    "test_loss, test_auc = validate(model, test_loader, criterion, DEVICE)\n",
    "print(f\"\\nFinal Test Loss: {test_loss:.4f} | Test AUROC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e6b355d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T09:31:55.653499Z",
     "iopub.status.busy": "2025-08-28T09:31:55.652843Z",
     "iopub.status.idle": "2025-08-28T09:31:55.662006Z",
     "shell.execute_reply": "2025-08-28T09:31:55.661241Z"
    },
    "papermill": {
     "duration": 3.303535,
     "end_time": "2025-08-28T09:31:55.663176",
     "exception": false,
     "start_time": "2025-08-28T09:31:52.359641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, dataloader, device, all_labels, threshold=0.5):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.cpu().numpy()\n",
    "            outputs = torch.sigmoid(model(images)).cpu().numpy()\n",
    "            \n",
    "            y_true.append(targets)\n",
    "            y_pred.append(outputs)\n",
    "\n",
    "    y_true = np.vstack(y_true)\n",
    "    y_pred = np.vstack(y_pred)\n",
    "\n",
    "    per_class_auc = {}\n",
    "    per_class_f1 = {}\n",
    "\n",
    "    for i, cls in enumerate(all_labels):\n",
    "        if y_true[:, i].sum() > 0:  # class has at least one positive\n",
    "            try:\n",
    "                auc = roc_auc_score(y_true[:, i], y_pred[:, i])\n",
    "            except ValueError:\n",
    "                auc = float('nan')\n",
    "            per_class_auc[cls] = auc\n",
    "\n",
    "            # binarize predictions\n",
    "            y_bin = (y_pred[:, i] >= threshold).astype(int)\n",
    "            f1 = f1_score(y_true[:, i], y_bin, zero_division=0)\n",
    "            per_class_f1[cls] = f1\n",
    "        else:\n",
    "            per_class_auc[cls] = float('nan')\n",
    "            per_class_f1[cls] = float('nan')\n",
    "\n",
    "    mean_auc = np.nanmean(list(per_class_auc.values()))\n",
    "    mean_f1 = np.nanmean(list(per_class_f1.values()))\n",
    "\n",
    "    return per_class_auc, mean_auc, per_class_f1, mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e7955a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T09:32:01.981288Z",
     "iopub.status.busy": "2025-08-28T09:32:01.980985Z",
     "iopub.status.idle": "2025-08-28T09:35:46.633233Z",
     "shell.execute_reply": "2025-08-28T09:35:46.632341Z"
    },
    "papermill": {
     "duration": 231.100107,
     "end_time": "2025-08-28T09:35:49.906588",
     "exception": false,
     "start_time": "2025-08-28T09:31:58.806481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-class AUCs:\n",
      "Atelectasis: 0.7676\n",
      "Cardiomegaly: 0.8836\n",
      "Effusion: 0.8237\n",
      "Infiltration: 0.6993\n",
      "Mass: 0.8179\n",
      "Nodule: 0.7593\n",
      "Pneumonia: 0.6951\n",
      "Pneumothorax: 0.8528\n",
      "Consolidation: 0.7472\n",
      "Edema: 0.8439\n",
      "Emphysema: 0.9056\n",
      "Fibrosis: 0.8279\n",
      "Pleural_Thickening: 0.7680\n",
      "Hernia: 0.9011\n",
      "\n",
      "Per-class F1 scores:\n",
      "Atelectasis: 0.2284\n",
      "Cardiomegaly: 0.2812\n",
      "Effusion: 0.3496\n",
      "Infiltration: 0.2549\n",
      "Mass: 0.3084\n",
      "Nodule: 0.1245\n",
      "Pneumonia: 0.0000\n",
      "Pneumothorax: 0.3034\n",
      "Consolidation: 0.0000\n",
      "Edema: 0.0065\n",
      "Emphysema: 0.3549\n",
      "Fibrosis: 0.0046\n",
      "Pleural_Thickening: 0.0138\n",
      "Hernia: 0.0000\n",
      "\n",
      "Mean AUC (14 classes): 0.8066\n",
      "Mean F1 (14 classes): 0.1593\n"
     ]
    }
   ],
   "source": [
    "per_class_auc, mean_auc, per_class_f1, mean_f1 = evaluate_metrics(model, test_loader, DEVICE, all_labels)\n",
    "\n",
    "print(\"Per-class AUCs:\")\n",
    "for disease, auc in per_class_auc.items():\n",
    "    print(f\"{disease}: {auc:.4f}\")\n",
    "\n",
    "print(\"\\nPer-class F1 scores:\")\n",
    "for disease, f1 in per_class_f1.items():\n",
    "    print(f\"{disease}: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nMean AUC (14 classes): {mean_auc:.4f}\")\n",
    "print(f\"Mean F1 (14 classes): {mean_f1:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5839,
     "sourceId": 18613,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15251.959548,
   "end_time": "2025-08-28T09:35:55.830068",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-28T05:21:43.870520",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
