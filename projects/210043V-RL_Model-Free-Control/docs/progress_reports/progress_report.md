ðŸ§¾ Progress Report â€“ OurTD3 Research Project

Title: Agreement-Weighted Replay and Value-Improvement Regularization for Continuous Control
Author: Sajith Anuradha â€“ Department of Computer Science & Engineering, University of Moratuwa
Period: Weeks 4 â€“ 12

ðŸ—“ Week 4 â€“ Initial Implementation & Baseline Setup

Main Tasks
â€¢ Implemented the standard TD3 baseline with twin critics, target-policy smoothing, and delayed actor updates.
â€¢ Verified MuJoCo v5 environment installation (Hopper, Walker2d, HalfCheetah) through Gymnasium.
â€¢ Created core training loop, evaluation routine, and replay-buffer logic.
â€¢ Established logging pipeline using TensorBoard/W&B.
Outcome
â€¢ Achieved reproducible TD3 runs (~3.3k avg return on Hopper).
â€¢ Confirmed environment determinism and evaluation metrics.

ðŸ—“ Week 5 â€“ Agreement-Weighted Replay (AWR)

Main Tasks
â€¢ Designed and implemented agreement-weighted replay mechanism.
â€¢ Defined cosine-agreement weight
\alpha = \frac{\delta_1\delta_2}{|\delta_1||\delta_2|+\varepsilon} and integrated exponential weighting with normalization.
â€¢ Added hyper-parameters: Îº (agreement strength), weight clipping (0.5 â€“ 2.0).
â€¢ Ran comparative experiments (TD3 vs OurTD3-AWR).
Outcome
â€¢ Observed faster early learning on Hopper (+15 % sample-efficiency).
â€¢ Stable gradient behavior confirmed.

ðŸ—“ Week 6 â€“ Value-Improvement (VI) Regularizer

Main Tasks
â€¢ Added critic value-improvement term using greedy backup target y\_{\max}.
â€¢ Tuned Î» âˆˆ {0.005, 0.01, 0.05}.
â€¢ Conducted controlled ablations to analyze bias/variance trade-off.
Outcome
â€¢ Î» â‰ˆ 0.01 gave consistent asymptotic gain (~+300 return on HalfCheetah).
â€¢ Large Î» caused mild optimismâ€”documented limits.

ðŸ—“ Week 7 â€“ Stability Enhancements & Ablations

Main Tasks
â€¢ Added gradient-norm clipping (â€–âˆ‡â€–â‰¤10).
â€¢ Performed multi-seed (10Ã—) runs to measure variance.
â€¢ Combined AWR + VI â†’ final OurTD3 architecture.
â€¢ Measured runtime overhead and training variance.
Outcome
â€¢ Variance reduced â‰ˆ 25 %; runtime overhead < 3 %.
â€¢ All critics stable across seeds.

ðŸ—“ Week 8 â€“ Comprehensive Evaluation & Visualization

Main Tasks
â€¢ Generated complete learning-curve plots (return vs timesteps).
â€¢ Added performance tables and summary metrics.
â€¢ Prepared dataset/environment description for the paper.
â€¢ Validated results on Hopper-v5, Walker2d-v5, HalfCheetah-v5.
Outcome
â€¢ OurTD3 outperformed TD3 and TD3-BC on all benchmarks.
â€¢ Completed experiment summary and experiments.md.

ðŸ—“ Week 9 â€“ Short Paper Preparation & Optimization

Main Tasks
â€¢ Drafted short-paper version (4 pages) for internal submission.
â€¢ Optimized code for faster rollouts and reproducibility.
â€¢ Cleaned results directory, generated average/variance plots.
Outcome
â€¢ Short paper submitted successfully.
â€¢ Code and figures reproducible on single GPU.

ðŸ—“ Week 10 â€“ Algorithm Refinement & Hyper-tuning

Main Tasks
â€¢ Fine-tuned Îº annealing schedule (0â†’5) and Î» decay for smoother training.
â€¢ Performed sensitivity analysis for weight-normalization strategy.
â€¢ Polished figure captions and algorithm pseudocode for paper.
Outcome
â€¢ Improved stability on Walker2d (no late collapse).
â€¢ Ready for full paper integration.

ðŸ—“ Week 11 â€“ Full Paper Writing & Final Results

Main Tasks
â€¢ Expanded full research paper to 7 pages.
â€¢ Added extended sections: Dataset and Environments, Ablation Study, Discussion, Conclusion.
â€¢ Inserted final quantitative tables and updated bibliography.
Outcome
â€¢ Camera-ready draft produced with finalized plots and metrics.
â€¢ All experiments cross-verified and consistent.

ðŸ—“ Week 12 â€“ Finalization & Submission

Main Tasks
â€¢ Performed proofreading and supervisor revisions.
â€¢ Verified references, figure labels, and LaTeX build.
â€¢ Uploaded all artifacts: code, plots, experiments.md, and final PDF.
Outcome
â€¢ Research paper finalized and submitted.
â€¢ Repository structured and archived for reproducibility.
