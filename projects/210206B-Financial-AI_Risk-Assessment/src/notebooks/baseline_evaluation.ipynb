{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NODE Baseline Evaluation\n",
    "\n",
    "This notebook runs comprehensive baseline experiments to establish performance benchmarks for Neural Oblivious Decision Ensembles (NODE) before implementing enhancements.\n",
    "\n",
    "## Experiments to Run:\n",
    "- **Classification**: EPSILON, HIGGS, A9A datasets\n",
    "- **Regression**: YEAR dataset\n",
    "- **Model Configs**: Shallow (1 layer), Medium (2 layers), Deep (8 layers)\n",
    "\n",
    "## Expected Results:\n",
    "- Baseline performance metrics for comparison\n",
    "- Training time and convergence analysis\n",
    "- Model size and memory usage patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "PyTorch version: 2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Add lib to path\n",
    "sys.path.insert(0, '..')\n",
    "import lib\n",
    "from qhoptim.pyt import QHAdam\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Results storage\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EPSILON Dataset - Classification Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EPSILON dataset...\n",
      "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/epsilon_normalized.bz2 > ./data\\EPSILON\\epsilon_normalized.bz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–Œ                                                    | 39931904/3871424303 [01:16<48:16, 1322859.36it/s]"
     ]
    }
   ],
   "source": [
    "# EPSILON Dataset - Shallow NODE\n",
    "print(\"Loading EPSILON dataset...\")\n",
    "data = lib.Dataset(\"EPSILON\", random_state=1337, quantile_transform=True, quantile_noise=1e-3)\n",
    "\n",
    "num_features = data.X_train.shape[1]\n",
    "num_classes = len(set(data.y_train))\n",
    "\n",
    "print(f\"Features: {num_features}, Classes: {num_classes}\")\n",
    "print(f\"Train: {len(data.X_train)}, Valid: {len(data.X_valid)}, Test: {len(data.X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shallow NODE model\n",
    "experiment_name = f'epsilon_shallow_{int(time.time())}'\n",
    "\n",
    "model = nn.Sequential(\n",
    "    lib.DenseBlock(num_features, layer_dim=2048, num_layers=1, tree_dim=num_classes + 1, \n",
    "                   flatten_output=False, depth=6, choice_function=lib.entmax15, bin_function=lib.entmoid15),\n",
    "    lib.Lambda(lambda x: x[..., :num_classes].mean(dim=-2))\n",
    ").to(device)\n",
    "\n",
    "# Data-aware initialization\n",
    "with torch.no_grad():\n",
    "    model(torch.as_tensor(data.X_train[:2000], device=device))\n",
    "\n",
    "# Multi-GPU support\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "print(f\"Model created: {experiment_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train shallow model\n",
    "trainer = lib.Trainer(\n",
    "    model=model, loss_function=F.cross_entropy,\n",
    "    experiment_name=experiment_name,\n",
    "    warm_start=False,\n",
    "    Optimizer=QHAdam,\n",
    "    optimizer_params=dict(nus=(0.7, 1.0), betas=(0.95, 0.998)),\n",
    "    verbose=True,\n",
    "    n_last_checkpoints=5\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "loss_history, err_history = [], []\n",
    "best_val_err = 1.0\n",
    "best_step = 0\n",
    "early_stopping_rounds = 10000\n",
    "report_frequency = 100\n",
    "\n",
    "print(\"Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for batch in lib.iterate_minibatches(data.X_train, data.y_train, batch_size=1024, \n",
    "                                    shuffle=True, epochs=float('inf')):\n",
    "    metrics = trainer.train_on_batch(*batch, device=device)\n",
    "    loss_history.append(metrics['loss'])\n",
    "\n",
    "    if trainer.step % report_frequency == 0:\n",
    "        trainer.save_checkpoint()\n",
    "        trainer.average_checkpoints(out_tag='avg')\n",
    "        trainer.load_checkpoint(tag='avg')\n",
    "        err = trainer.evaluate_classification_error(\n",
    "            data.X_valid, data.y_valid, device=device, batch_size=1024)\n",
    "        \n",
    "        if err < best_val_err:\n",
    "            best_val_err = err\n",
    "            best_step = trainer.step\n",
    "            trainer.save_checkpoint(tag='best')\n",
    "        \n",
    "        err_history.append(err)\n",
    "        trainer.load_checkpoint()\n",
    "        trainer.remove_old_temp_checkpoints()\n",
    "            \n",
    "        print(f\"Step {trainer.step}: Loss={metrics['loss']:.5f}, Val Error={err:.5f}\")\n",
    "        \n",
    "    if trainer.step > best_step + early_stopping_rounds:\n",
    "        print(f'Early stopping: No improvement for {early_stopping_rounds} steps')\n",
    "        print(f\"Best step: {best_step}, Best Val Error: {best_val_err:.5f}\")\n",
    "        break\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "trainer.load_checkpoint(tag='best')\n",
    "test_error = trainer.evaluate_classification_error(data.X_test, data.y_test, device=device, batch_size=1024)\n",
    "test_auc = trainer.evaluate_auc(data.X_test, data.y_test, device=device, batch_size=512)\n",
    "test_logloss = trainer.evaluate_logloss(data.X_test, data.y_test, device=device, batch_size=512)\n",
    "\n",
    "print(f\"\\nEPSILON Shallow Results:\")\n",
    "print(f\"Test Error Rate: {test_error:.5f}\")\n",
    "print(f\"Test AUC: {test_auc:.5f}\")\n",
    "print(f\"Test LogLoss: {test_logloss:.5f}\")\n",
    "print(f\"Training Time: {training_time:.2f}s\")\n",
    "\n",
    "# Store results\n",
    "results['EPSILON_shallow'] = {\n",
    "    'dataset': 'EPSILON',\n",
    "    'model': 'shallow',\n",
    "    'test_error': test_error,\n",
    "    'test_auc': test_auc,\n",
    "    'test_logloss': test_logloss,\n",
    "    'training_time': training_time,\n",
    "    'best_step': best_step,\n",
    "    'best_val_error': best_val_err\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. YEAR Dataset - Regression Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR Dataset - Shallow NODE\n",
    "print(\"Loading YEAR dataset...\")\n",
    "data_year = lib.Dataset(\"YEAR\", random_state=1337, quantile_transform=True, quantile_noise=1e-3)\n",
    "\n",
    "in_features = data_year.X_train.shape[1]\n",
    "\n",
    "# Normalize target\n",
    "mu, std = data_year.y_train.mean(), data_year.y_train.std()\n",
    "normalize = lambda x: ((x - mu) / std).astype(np.float32)\n",
    "data_year.y_train, data_year.y_valid, data_year.y_test = map(normalize, [data_year.y_train, data_year.y_valid, data_year.y_test])\n",
    "\n",
    "print(f\"Features: {in_features}\")\n",
    "print(f\"Target mean: {mu:.5f}, std: {std:.5f}\")\n",
    "print(f\"Train: {len(data_year.X_train)}, Valid: {len(data_year.y_valid)}, Test: {len(data_year.y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shallow NODE model for regression\n",
    "experiment_name_year = f'year_shallow_{int(time.time())}'\n",
    "\n",
    "model_year = nn.Sequential(\n",
    "    lib.DenseBlock(in_features, 2048, num_layers=1, tree_dim=3, depth=6, flatten_output=False,\n",
    "                   choice_function=lib.entmax15, bin_function=lib.entmoid15),\n",
    "    lib.Lambda(lambda x: x[..., 0].mean(dim=-1))\n",
    ").to(device)\n",
    "\n",
    "# Data-aware initialization\n",
    "with torch.no_grad():\n",
    "    model_year(torch.as_tensor(data_year.X_train[:1000], device=device))\n",
    "\n",
    "# Multi-GPU support\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model_year = nn.DataParallel(model_year)\n",
    "\n",
    "print(f\"Model created: {experiment_name_year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train regression model\n",
    "trainer_year = lib.Trainer(\n",
    "    model=model_year, loss_function=F.mse_loss,\n",
    "    experiment_name=experiment_name_year,\n",
    "    warm_start=False,\n",
    "    Optimizer=QHAdam,\n",
    "    optimizer_params=dict(nus=(0.7, 1.0), betas=(0.95, 0.998)),\n",
    "    verbose=True,\n",
    "    n_last_checkpoints=5\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "loss_history_year, mse_history_year = [], []\n",
    "best_mse = float('inf')\n",
    "best_step_mse = 0\n",
    "early_stopping_rounds = 5000\n",
    "report_frequency = 100\n",
    "\n",
    "print(\"Starting training...\")\n",
    "start_time_year = time.time()\n",
    "\n",
    "for batch in lib.iterate_minibatches(data_year.X_train, data_year.y_train, batch_size=1024, \n",
    "                                    shuffle=True, epochs=float('inf')):\n",
    "    metrics = trainer_year.train_on_batch(*batch, device=device)\n",
    "    loss_history_year.append(metrics['loss'])\n",
    "\n",
    "    if trainer_year.step % report_frequency == 0:\n",
    "        trainer_year.save_checkpoint()\n",
    "        trainer_year.average_checkpoints(out_tag='avg')\n",
    "        trainer_year.load_checkpoint(tag='avg')\n",
    "        mse = trainer_year.evaluate_mse(\n",
    "            data_year.X_valid, data_year.y_valid, device=device, batch_size=16384)\n",
    "        \n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_step_mse = trainer_year.step\n",
    "            trainer_year.save_checkpoint(tag='best_mse')\n",
    "        \n",
    "        mse_history_year.append(mse)\n",
    "        trainer_year.load_checkpoint()\n",
    "        trainer_year.remove_old_temp_checkpoints()\n",
    "            \n",
    "        print(f\"Step {trainer_year.step}: Loss={metrics['loss']:.5f}, Val MSE={mse:.5f}\")\n",
    "        \n",
    "    if trainer_year.step > best_step_mse + early_stopping_rounds:\n",
    "        print(f'Early stopping: No improvement for {early_stopping_rounds} steps')\n",
    "        print(f\"Best step: {best_step_mse}, Best Val MSE: {best_mse:.5f}\")\n",
    "        break\n",
    "\n",
    "training_time_year = time.time() - start_time_year\n",
    "print(f\"Training completed in {training_time_year:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "trainer_year.load_checkpoint(tag='best_mse')\n",
    "test_mse = trainer_year.evaluate_mse(data_year.X_test, data_year.y_test, device=device)\n",
    "\n",
    "# Convert back to original scale\n",
    "test_rmse_original = np.sqrt(test_mse * std ** 2)\n",
    "\n",
    "print(f\"\\nYEAR Shallow Results:\")\n",
    "print(f\"Test MSE (normalized): {test_mse:.5f}\")\n",
    "print(f\"Test RMSE (original scale): {test_rmse_original:.5f}\")\n",
    "print(f\"Training Time: {training_time_year:.2f}s\")\n",
    "\n",
    "# Store results\n",
    "results['YEAR_shallow'] = {\n",
    "    'dataset': 'YEAR',\n",
    "    'model': 'shallow',\n",
    "    'test_mse': test_mse,\n",
    "    'test_rmse_original': test_rmse_original,\n",
    "    'training_time': training_time_year,\n",
    "    'best_step': best_step_mse,\n",
    "    'best_val_mse': best_mse\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results Summary and Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BASELINE RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for key, result in results.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Dataset: {result['dataset']}\")\n",
    "    print(f\"  Model: {result['model']}\")\n",
    "    print(f\"  Training Time: {result['training_time']:.2f}s\")\n",
    "    print(f\"  Best Step: {result['best_step']}\")\n",
    "    \n",
    "    if 'test_error' in result:\n",
    "        print(f\"  Test Error: {result['test_error']:.5f}\")\n",
    "        print(f\"  Test AUC: {result['test_auc']:.5f}\")\n",
    "        print(f\"  Test LogLoss: {result['test_logloss']:.5f}\")\n",
    "    else:\n",
    "        print(f\"  Test MSE: {result['test_mse']:.5f}\")\n",
    "        print(f\"  Test RMSE (original): {result['test_rmse_original']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to JSON\n",
    "with open('baseline_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\nResults saved to baseline_results.json\")\n",
    "\n",
    "# Create comparison DataFrame\n",
    "rows = []\n",
    "for key, result in results.items():\n",
    "    row = {\n",
    "        'Dataset': result['dataset'],\n",
    "        'Model': result['model'],\n",
    "        'Training_Time_s': result['training_time'],\n",
    "        'Best_Step': result['best_step']\n",
    "    }\n",
    "    \n",
    "    if 'test_error' in result:\n",
    "        row.update({\n",
    "            'Test_Error': result['test_error'],\n",
    "            'Test_AUC': result['test_auc'],\n",
    "            'Test_LogLoss': result['test_logloss']\n",
    "        })\n",
    "    else:\n",
    "        row['Test_MSE'] = result['test_mse']\n",
    "        row['Test_RMSE_Original'] = result['test_rmse_original']\n",
    "    \n",
    "    rows.append(row)\n",
    "\n",
    "df_results = pd.DataFrame(rows)\n",
    "df_results.to_csv('baseline_comparison.csv', index=False)\n",
    "\n",
    "print(\"\\nComparison table:\")\n",
    "print(df_results.to_string(index=False))\n",
    "print(\"\\nComparison table saved to baseline_comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Next Steps\n",
    "\n",
    "With baseline results established, you can now:\n",
    "\n",
    "1. **Implement Enhancements**:\n",
    "   - Focal Loss for imbalanced datasets\n",
    "   - Learning rate scheduling (warmup + cosine decay)\n",
    "   - Advanced optimizers (RAdam + Lookahead)\n",
    "   - Regularization (Dropout + BatchNorm)\n",
    "\n",
    "2. **Run Additional Baselines**:\n",
    "   - Deep NODE (8 layers) on same datasets\n",
    "   - Medium NODE (2 layers) for comparison\n",
    "   - Other datasets (HIGGS, A9A)\n",
    "\n",
    "3. **Compare with GBDT**:\n",
    "   - Run XGBoost and CatBoost on same datasets\n",
    "   - Establish fair comparison baselines\n",
    "\n",
    "4. **Analyze Results**:\n",
    "   - Training efficiency patterns\n",
    "   - Convergence behavior\n",
    "   - Memory usage analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
