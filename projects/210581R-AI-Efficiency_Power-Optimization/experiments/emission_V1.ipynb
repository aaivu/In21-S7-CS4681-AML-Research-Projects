{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- 1. Setup Environment ---\n!pip uninstall -y jax jaxlib tensorflow flax -q\n!pip install -U transformers datasets evaluate accelerate codecarbon -q\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T05:59:10.854543Z","iopub.execute_input":"2025-10-02T05:59:10.854770Z","iopub.status.idle":"2025-10-02T06:01:53.625405Z","shell.execute_reply.started":"2025-10-02T05:59:10.854738Z","shell.execute_reply":"2025-10-02T06:01:53.624690Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.6/503.6 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.9/374.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-genai 1.21.1 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\nfirebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\nlangchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# --- 2. Imports ---\nfrom datasets import load_dataset\nimport evaluate\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer\n)\nimport numpy as np\nimport torch\nfrom codecarbon import EmissionsTracker\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:01:53.627459Z","iopub.execute_input":"2025-10-02T06:01:53.627697Z","iopub.status.idle":"2025-10-02T06:02:09.025366Z","shell.execute_reply.started":"2025-10-02T06:01:53.627674Z","shell.execute_reply":"2025-10-02T06:02:09.024160Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# --- 3. Load Dataset (IMDB for Sentiment Classification) ---\ndataset = load_dataset(\"imdb\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:02:09.026225Z","iopub.execute_input":"2025-10-02T06:02:09.026702Z","iopub.status.idle":"2025-10-02T06:02:14.515616Z","shell.execute_reply.started":"2025-10-02T06:02:09.026678Z","shell.execute_reply":"2025-10-02T06:02:14.515103Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53081fdf4e14eb0af95433466326886"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f27eeb3fa24c2286d6c56dd3b4e569"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d5c18908e2e4f2b8a77502cafbb8aab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6a32171b0c04b5cba5e57716cae5e5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fc196f7a07b4566a3f2d4eecb1441e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cbe5091b02a48c7ae6631772b22aaa4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f3800cc23174c24abb7d2434fa6585f"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# --- 4. Load Tokenizer ---\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:03:48.599108Z","iopub.execute_input":"2025-10-02T06:03:48.599392Z","iopub.status.idle":"2025-10-02T06:04:36.296306Z","shell.execute_reply.started":"2025-10-02T06:03:48.599373Z","shell.execute_reply":"2025-10-02T06:04:36.295596Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"374fc38727b34be3aab71d5c9596997e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"659944158c3d4e3e9fdec4b5d687658f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/50000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"034b2837f52941d59ceb0ef7cd6af907"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# --- 5. Train/Test Split ---\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(5000))\nsmall_test_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(2000))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:04:36.297730Z","iopub.execute_input":"2025-10-02T06:04:36.298033Z","iopub.status.idle":"2025-10-02T06:04:36.327386Z","shell.execute_reply.started":"2025-10-02T06:04:36.298015Z","shell.execute_reply":"2025-10-02T06:04:36.326679Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# --- 6. Define Model ---\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:04:36.328055Z","iopub.execute_input":"2025-10-02T06:04:36.328300Z","iopub.status.idle":"2025-10-02T06:04:38.431497Z","shell.execute_reply.started":"2025-10-02T06:04:36.328281Z","shell.execute_reply":"2025-10-02T06:04:38.430786Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea25e5d8ac7d438e8953c01a379091f7"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# --- 7. Define Metric (Accuracy) ---\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return accuracy.compute(predictions=predictions, references=labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:04:44.077502Z","iopub.execute_input":"2025-10-02T06:04:44.077822Z","iopub.status.idle":"2025-10-02T06:04:44.425102Z","shell.execute_reply.started":"2025-10-02T06:04:44.077800Z","shell.execute_reply":"2025-10-02T06:04:44.424211Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# --- 8. TrainingArguments ---\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=50,\n    report_to=\"none\"  # disables wandb etc.\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:04:51.210057Z","iopub.execute_input":"2025-10-02T06:04:51.210654Z","iopub.status.idle":"2025-10-02T06:04:51.248129Z","shell.execute_reply.started":"2025-10-02T06:04:51.210628Z","shell.execute_reply":"2025-10-02T06:04:51.247499Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# --- 9. Trainer ---\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:04:57.971371Z","iopub.execute_input":"2025-10-02T06:04:57.972110Z","iopub.status.idle":"2025-10-02T06:04:58.266439Z","shell.execute_reply.started":"2025-10-02T06:04:57.972085Z","shell.execute_reply":"2025-10-02T06:04:58.265882Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/2457266571.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# --- 10. Track Energy with CodeCarbon ---\ntracker = EmissionsTracker(output_dir=\"./\", output_file=\"emissions.csv\")\ntracker.start()\n\ntrainer.train()\nresults = trainer.evaluate()\n\ntracker.stop()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:05:06.509138Z","iopub.execute_input":"2025-10-02T06:05:06.509653Z","iopub.status.idle":"2025-10-02T06:07:44.688260Z","shell.execute_reply.started":"2025-10-02T06:05:06.509630Z","shell.execute_reply":"2025-10-02T06:07:44.687653Z"}},"outputs":[{"name":"stderr","text":"[codecarbon WARNING @ 06:05:06] Multiple instances of codecarbon are allowed to run at the same time.\n[codecarbon INFO @ 06:05:06] [setup] RAM Tracking...\n[codecarbon INFO @ 06:05:06] [setup] CPU Tracking...\n[codecarbon WARNING @ 06:05:07] We saw that you have a Intel(R) Xeon(R) CPU @ 2.00GHz but we don't know it. Please contact us.\n[codecarbon WARNING @ 06:05:07] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n Linux OS detected: Please ensure RAPL files exist at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n\n[codecarbon INFO @ 06:05:07] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.00GHz\n[codecarbon WARNING @ 06:05:07] No CPU tracking mode found. Falling back on CPU constant mode.\n[codecarbon INFO @ 06:05:07] [setup] GPU Tracking...\n[codecarbon INFO @ 06:05:07] Tracking Nvidia GPU via pynvml\n[codecarbon INFO @ 06:05:07] The below tracking methods have been set up:\n                RAM Tracking Method: RAM power estimation model\n                CPU Tracking Method: global constant\n                GPU Tracking Method: pynvml\n            \n[codecarbon INFO @ 06:05:07] >>> Tracker's metadata:\n[codecarbon INFO @ 06:05:07]   Platform system: Linux-6.6.56+-x86_64-with-glibc2.35\n[codecarbon INFO @ 06:05:07]   Python version: 3.11.13\n[codecarbon INFO @ 06:05:07]   CodeCarbon version: 3.0.5\n[codecarbon INFO @ 06:05:07]   Available RAM : 31.350 GB\n[codecarbon INFO @ 06:05:07]   CPU count: 4 thread(s) in 1 physical CPU(s)\n[codecarbon INFO @ 06:05:07]   CPU model: Intel(R) Xeon(R) CPU @ 2.00GHz\n[codecarbon INFO @ 06:05:07]   GPU count: 2\n[codecarbon INFO @ 06:05:07]   GPU model: 2 x Tesla T4\n[codecarbon INFO @ 06:05:10] Emissions data (if any) will be saved to file /kaggle/working/emissions.csv\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='314' max='314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [314/314 02:21, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.317700</td>\n      <td>0.295303</td>\n      <td>0.875000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.218200</td>\n      <td>0.273474</td>\n      <td>0.883500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"[codecarbon INFO @ 06:05:25] Energy consumed for RAM : 0.000083 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:05:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:05:25] Energy consumed for All CPU : 0.000177 kWh\n[codecarbon INFO @ 06:05:25] Energy consumed for all GPUs : 0.000473 kWh. Total GPU Power : 113.35770669751145 W\n[codecarbon INFO @ 06:05:25] 0.000733 kWh of electricity used since the beginning.\n[codecarbon INFO @ 06:05:40] Energy consumed for RAM : 0.000167 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:05:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:05:40] Energy consumed for All CPU : 0.000354 kWh\n[codecarbon INFO @ 06:05:40] Energy consumed for all GPUs : 0.001013 kWh. Total GPU Power : 129.7639519324354 W\n[codecarbon INFO @ 06:05:40] 0.001534 kWh of electricity used since the beginning.\n[codecarbon INFO @ 06:05:55] Energy consumed for RAM : 0.000250 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:05:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:05:55] Energy consumed for All CPU : 0.000531 kWh\n[codecarbon INFO @ 06:05:55] Energy consumed for all GPUs : 0.001554 kWh. Total GPU Power : 129.93217715182098 W\n[codecarbon INFO @ 06:05:55] 0.002335 kWh of electricity used since the beginning.\n[codecarbon INFO @ 06:06:10] Energy consumed for RAM : 0.000333 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:06:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:06:10] Energy consumed for All CPU : 0.000708 kWh\n[codecarbon INFO @ 06:06:10] Energy consumed for all GPUs : 0.002095 kWh. Total GPU Power : 129.77000647620773 W\n[codecarbon INFO @ 06:06:10] 0.003136 kWh of electricity used since the beginning.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n[codecarbon INFO @ 06:06:25] Energy consumed for RAM : 0.000416 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:06:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:06:25] Energy consumed for All CPU : 0.000885 kWh\n[codecarbon INFO @ 06:06:25] Energy consumed for all GPUs : 0.002636 kWh. Total GPU Power : 130.12707116619865 W\n[codecarbon INFO @ 06:06:25] 0.003938 kWh of electricity used since the beginning.\n[codecarbon INFO @ 06:06:40] Energy consumed for RAM : 0.000500 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:06:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:06:40] Energy consumed for All CPU : 0.001062 kWh\n[codecarbon INFO @ 06:06:40] Energy consumed for all GPUs : 0.003179 kWh. Total GPU Power : 130.1611999816003 W\n[codecarbon INFO @ 06:06:40] 0.004740 kWh of electricity used since the beginning.\n[codecarbon INFO @ 06:06:55] Energy consumed for RAM : 0.000583 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:06:55] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:06:55] Energy consumed for All CPU : 0.001239 kWh\n[codecarbon INFO @ 06:06:55] Energy consumed for all GPUs : 0.003719 kWh. Total GPU Power : 129.83377024918286 W\n[codecarbon INFO @ 06:06:55] 0.005541 kWh of electricity used since the beginning.\n[codecarbon INFO @ 06:07:10] Energy consumed for RAM : 0.000666 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:07:10] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:07:10] Energy consumed for All CPU : 0.001416 kWh\n[codecarbon INFO @ 06:07:10] Energy consumed for all GPUs : 0.004257 kWh. Total GPU Power : 129.04251832126988 W\n[codecarbon INFO @ 06:07:10] 0.006339 kWh of electricity used since the beginning.\n[codecarbon INFO @ 06:07:10] 0.023906 g.CO2eq/s mean an estimation of 753.9093906635103 kg.CO2eq/year\n[codecarbon INFO @ 06:07:25] Energy consumed for RAM : 0.000750 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:07:25] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:07:25] Energy consumed for All CPU : 0.001593 kWh\n[codecarbon INFO @ 06:07:25] Energy consumed for all GPUs : 0.004796 kWh. Total GPU Power : 129.50072553718127 W\n[codecarbon INFO @ 06:07:25] 0.007139 kWh of electricity used since the beginning.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:08]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"[codecarbon INFO @ 06:07:40] Energy consumed for RAM : 0.000833 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:07:40] Delta energy consumed for CPU with constant : 0.000177 kWh, power : 42.5 W\n[codecarbon INFO @ 06:07:40] Energy consumed for All CPU : 0.001770 kWh\n[codecarbon INFO @ 06:07:40] Energy consumed for all GPUs : 0.005338 kWh. Total GPU Power : 130.26881948935628 W\n[codecarbon INFO @ 06:07:40] 0.007941 kWh of electricity used since the beginning.\n[codecarbon INFO @ 06:07:44] Energy consumed for RAM : 0.000854 kWh. RAM Power : 20.0 W\n[codecarbon INFO @ 06:07:44] Delta energy consumed for CPU with constant : 0.000044 kWh, power : 42.5 W\n[codecarbon INFO @ 06:07:44] Energy consumed for All CPU : 0.001814 kWh\n[codecarbon INFO @ 06:07:44] Energy consumed for all GPUs : 0.005474 kWh. Total GPU Power : 129.9605907413675 W\n[codecarbon INFO @ 06:07:44] 0.008142 kWh of electricity used since the beginning.\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.0036852646073084047"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# --- 11. Show Results ---\nprint(\"Final Accuracy:\", results[\"eval_accuracy\"])\nprint(\"CodeCarbon log saved to emissions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T06:07:44.689383Z","iopub.execute_input":"2025-10-02T06:07:44.689603Z","iopub.status.idle":"2025-10-02T06:07:44.693796Z","shell.execute_reply.started":"2025-10-02T06:07:44.689587Z","shell.execute_reply":"2025-10-02T06:07:44.692982Z"}},"outputs":[{"name":"stdout","text":"Final Accuracy: 0.8835\nCodeCarbon log saved to emissions.csv\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}